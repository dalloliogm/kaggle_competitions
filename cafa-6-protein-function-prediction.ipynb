{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7180fe6f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.003557,
     "end_time": "2025-10-23T13:48:50.849929",
     "exception": false,
     "start_time": "2025-10-23T13:48:50.846372",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üß¨ Protein Function Prediction using Machine Learning\n",
    "\n",
    "## üìã Project Overview\n",
    "\n",
    "This project demonstrates how to build a **machine learning solution for protein function prediction** - a key problem in bioinformatics. The project uses publicly available techniques and datasets to predict biological functions of proteins based on their amino acid sequences.\n",
    "\n",
    "**Project Type:** Educational Machine Learning Project  \n",
    "**Domain:** Bioinformatics & Computational Biology  \n",
    "**Problem Type:** Multi-label Classification  \n",
    "**Approach:** Ensemble Learning Methods\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Project Goal\n",
    "\n",
    "### Objective\n",
    "Build an intelligent system that can predict Gene Ontology (GO) function annotations for protein sequences using machine learning, demonstrating:\n",
    "- Advanced feature engineering techniques\n",
    "- Ensemble learning strategies\n",
    "- Multi-label classification handling\n",
    "- Model validation and optimization\n",
    "\n",
    "### Why This Problem Matters\n",
    "Protein function prediction is essential for:\n",
    "- üß™ Drug discovery and development\n",
    "- üî¨ Understanding biological processes\n",
    "- üß¨ Genomic research and annotation\n",
    "- üíä Disease mechanism research\n",
    "- üåç Biotechnology applications\n",
    "\n",
    "---\n",
    "\n",
    "## üèóÔ∏è Project Architecture\n",
    "\n",
    "### Solution Approach\n",
    "\n",
    "```\n",
    "PROTEIN SEQUENCES\n",
    "    ‚Üì\n",
    "[FEATURE EXTRACTION] ‚Üí Convert sequences to numerical features\n",
    "    ‚îú‚îÄ‚îÄ Amino acid composition\n",
    "    ‚îú‚îÄ‚îÄ Physical properties (charge, hydrophobicity)\n",
    "    ‚îú‚îÄ‚îÄ Sequence patterns and motifs\n",
    "    ‚îî‚îÄ‚îÄ Structural indicators\n",
    "    ‚Üì\n",
    "[DATA PREPARATION] ‚Üí Format for machine learning\n",
    "    ‚îú‚îÄ‚îÄ Handle missing values\n",
    "    ‚îú‚îÄ‚îÄ Normalize features\n",
    "    ‚îú‚îÄ‚îÄ Create train-validation splits\n",
    "    ‚îî‚îÄ‚îÄ Encode multi-label targets\n",
    "    ‚Üì\n",
    "[ENSEMBLE MODELING] ‚Üí Train multiple models\n",
    "    ‚îú‚îÄ‚îÄ Random Forest Classifier\n",
    "    ‚îú‚îÄ‚îÄ Gradient Boosting\n",
    "    ‚îî‚îÄ‚îÄ XGBoost\n",
    "    ‚Üì\n",
    "[PREDICTION] ‚Üí Generate ensemble predictions\n",
    "    ‚îú‚îÄ‚îÄ Combine model outputs\n",
    "    ‚îú‚îÄ‚îÄ Apply thresholding\n",
    "    ‚îî‚îÄ‚îÄ Select GO terms\n",
    "    ‚Üì\n",
    "PREDICTIONS ‚Üí Function annotations for proteins\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ú® Key Technical Components\n",
    "\n",
    "### 1. Feature Engineering\n",
    "\n",
    "#### Sequence-Based Features\n",
    "- **Amino Acid Composition** (20 features)\n",
    "  - Frequency of each amino acid\n",
    "  - Normalized by sequence length\n",
    "  \n",
    "- **Physical Properties** (6 features)\n",
    "  - Hydrophobic/polar ratios\n",
    "  - Charge distribution\n",
    "  - Aromaticity measures\n",
    "  \n",
    "- **Structural Indicators** (8 features)\n",
    "  - Helix-forming propensity\n",
    "  - Disorder indicators\n",
    "  - Turn and coil propensity\n",
    "  \n",
    "- **Sequence Patterns** (10+ features)\n",
    "  - Dipeptide frequencies\n",
    "  - Motif presence\n",
    "  - Pattern distributions\n",
    "\n",
    "#### Derived Features\n",
    "- Logarithmic sequence length\n",
    "- N-terminal and C-terminal properties\n",
    "- Normalized distributions\n",
    "- Interaction features\n",
    "\n",
    "### 2. Machine Learning Models\n",
    "\n",
    "**Model 1: Random Forest**\n",
    "- Advantages: Fast, handles non-linearity, interpretable\n",
    "- Parameters: 100-150 trees, depth 15-18\n",
    "- Use case: Baseline and feature importance\n",
    "\n",
    "**Model 2: Gradient Boosting**\n",
    "- Advantages: Sequential optimization, strong performance\n",
    "- Parameters: 80-100 trees, depth 5-6\n",
    "- Use case: Refined predictions\n",
    "\n",
    "**Model 3: XGBoost**\n",
    "- Advantages: State-of-the-art, regularization, fast\n",
    "- Parameters: 80-100 trees, depth 6-7, learning rate 0.1\n",
    "- Use case: Final optimization\n",
    "\n",
    "**Ensemble Strategy**\n",
    "- Train individual models on same data\n",
    "- Average probability predictions\n",
    "- Apply threshold for binary classification\n",
    "- Combine predictions for robustness\n",
    "\n",
    "### 3. Multi-Label Classification\n",
    "\n",
    "**Challenge:** Each protein has multiple functions  \n",
    "**Solution:**\n",
    "- One-vs-rest binary classifiers for each GO term\n",
    "- Output probability for each possible function\n",
    "- Threshold-based selection of predicted functions\n",
    "- Handle class imbalance with appropriate weighting\n",
    "\n",
    "---\n",
    "\n",
    "## üì¶ Technology Stack\n",
    "\n",
    "### Programming Environment\n",
    "- **Language:** Python 3.7+\n",
    "- **Notebook:** Jupyter / Kaggle Notebooks\n",
    "\n",
    "### Core Libraries\n",
    "```\n",
    "Data Processing:\n",
    "  - pandas: Data manipulation and analysis\n",
    "  - numpy: Numerical computing\n",
    "\n",
    "Machine Learning:\n",
    "  - scikit-learn: ML algorithms and preprocessing\n",
    "  - xgboost: Gradient boosting framework\n",
    "\n",
    "Visualization:\n",
    "  - matplotlib: Plotting and charts\n",
    "  - seaborn: Statistical data visualization\n",
    "\n",
    "File Handling:\n",
    "  - Standard file I/O for FASTA/TSV formats\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Project Workflow\n",
    "\n",
    "### Phase 1: Data Understanding\n",
    "1. Load protein sequences (FASTA format)\n",
    "2. Load taxonomy and function annotations (TSV format)\n",
    "3. Exploratory data analysis\n",
    "4. Visualize data distributions\n",
    "5. Identify patterns and challenges\n",
    "\n",
    "### Phase 2: Feature Engineering\n",
    "1. Extract amino acid compositions\n",
    "2. Calculate physical/chemical properties\n",
    "3. Compute sequence patterns\n",
    "4. Normalize and scale features\n",
    "5. Create interaction features\n",
    "\n",
    "### Phase 3: Model Development\n",
    "1. Prepare train-validation split\n",
    "2. Train individual models\n",
    "3. Evaluate on validation set\n",
    "4. Calculate performance metrics (F1-score)\n",
    "5. Analyze prediction quality\n",
    "\n",
    "### Phase 4: Ensemble & Optimization\n",
    "1. Combine model predictions\n",
    "2. Tune prediction thresholds\n",
    "3. Handle edge cases\n",
    "4. Validate on test set\n",
    "5. Generate final predictions\n",
    "\n",
    "### Phase 5: Evaluation & Analysis\n",
    "1. Compute performance metrics\n",
    "2. Generate precision-recall curves\n",
    "3. Analyze error patterns\n",
    "4. Document results\n",
    "5. Prepare submission\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Data Specifications\n",
    "\n",
    "### Input Data Format\n",
    "\n",
    "**Protein Sequences (FASTA)**\n",
    "```\n",
    ">ProteinID1\n",
    "MKTIIALSYIFCLVFADYKDDDKGTFTVENTAFITAHVQMFEKQDTLNGGAKTFTVTE\n",
    "\n",
    ">ProteinID2\n",
    "MKILIGKEVGSVHQGISIKPESAQHSTDCDKKVTL...\n",
    "```\n",
    "\n",
    "**Function Annotations (TSV)**\n",
    "```\n",
    "ProteinID1\tGO:0008150\tProcess\n",
    "ProteinID1\tGO:0005575\tComponent\n",
    "ProteinID2\tGO:0003674\tFunction\n",
    "```\n",
    "\n",
    "**Taxonomy Information (TSV)**\n",
    "```\n",
    "ProteinID1\t9606\n",
    "ProteinID2\t10090\n",
    "```\n",
    "\n",
    "### Output Format\n",
    "\n",
    "**Predictions (TSV)**\n",
    "```\n",
    "ProteinID1\tGO:0008150 GO:0005575 GO:0003674\n",
    "ProteinID2\tGO:0003674 GO:0005575\n",
    "ProteinID3\tGO:0008150\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üîç Model Performance Expectations\n",
    "\n",
    "### Validation Metrics\n",
    "- **F1-Score:** 0.45-0.60 (depends on model combination)\n",
    "- **Precision:** 0.50-0.65\n",
    "- **Recall:** 0.40-0.55\n",
    "- **Accuracy (Multi-label):** Varies by GO term\n",
    "\n",
    "### Training Efficiency\n",
    "- **Feature Extraction:** 5-10 minutes\n",
    "- **Model Training:** 40-60 minutes\n",
    "- **Prediction:** 10-15 minutes\n",
    "- **Total Runtime:** 55-85 minutes\n",
    "\n",
    "### Expected Results\n",
    "- Reasonable predictions for most proteins\n",
    "- Better performance on common GO terms\n",
    "- Variable performance on rare functions\n",
    "- Ensemble improves over single models\n",
    "\n",
    "---\n",
    "\n",
    "## üí° Key Learnings & Techniques\n",
    "\n",
    "### Machine Learning Concepts\n",
    "‚úÖ Feature engineering from biological sequences  \n",
    "‚úÖ Handling multi-label classification problems  \n",
    "‚úÖ Ensemble methods and stacking  \n",
    "‚úÖ Hyperparameter tuning  \n",
    "‚úÖ Model validation and evaluation  \n",
    "‚úÖ Imbalanced classification handling  \n",
    "‚úÖ Threshold optimization for classification  \n",
    "\n",
    "### Bioinformatics Concepts\n",
    "‚úÖ Amino acid properties and structure  \n",
    "‚úÖ Sequence analysis and patterns  \n",
    "‚úÖ Gene Ontology and function annotations  \n",
    "‚úÖ Organism taxonomy and evolution  \n",
    "‚úÖ Protein structure-function relationships  \n",
    "\n",
    "### Best Practices\n",
    "‚úÖ Reproducible code with random seeds  \n",
    "‚úÖ Clear documentation and comments  \n",
    "‚úÖ Proper train-validation-test splits  \n",
    "‚úÖ Performance metrics tracking  \n",
    "‚úÖ Error handling and edge cases  \n",
    "‚úÖ Scalable architecture  \n",
    "\n",
    "---\n",
    "\n",
    "## üéì How to Use This Project\n",
    "\n",
    "### For Learning\n",
    "1. Study the feature engineering approach\n",
    "2. Understand ensemble methodology\n",
    "3. Learn multi-label classification techniques\n",
    "4. Adapt for similar problems\n",
    "\n",
    "### For Implementation\n",
    "1. Prepare your protein sequence data\n",
    "2. Adapt feature extraction for your needs\n",
    "3. Modify model parameters as needed\n",
    "4. Extend with domain-specific features\n",
    "\n",
    "### For Improvement\n",
    "1. Add deep learning embeddings\n",
    "2. Include more sequence features\n",
    "3. Use advanced ensemble techniques\n",
    "4. Implement cross-validation\n",
    "5. Add transfer learning\n",
    "\n",
    "---\n",
    "\n",
    "## üìà Potential Extensions\n",
    "\n",
    "### Advanced Techniques\n",
    "- **Deep Learning:** Use pre-trained protein models (ESM2, ProtBERT)\n",
    "- **Transfer Learning:** Leverage biological foundation models\n",
    "- **Attention Mechanisms:** Learn feature importance automatically\n",
    "- **Graph Neural Networks:** Model protein structure and interactions\n",
    "- **Stacking:** Use meta-learner on model outputs\n",
    "\n",
    "### Domain Enhancements\n",
    "- **Taxonomic Information:** Incorporate organism-specific patterns\n",
    "- **Sequence Alignment:** Use homology information\n",
    "- **Structure Features:** Include 3D protein structure data\n",
    "- **Interaction Data:** Use protein-protein interaction networks\n",
    "- **Literature Mining:** Incorporate biological knowledge\n",
    "\n",
    "### Operational Improvements\n",
    "- **Hyperparameter Tuning:** GridSearch/RandomSearch optimization\n",
    "- **K-Fold Validation:** More robust evaluation\n",
    "- **Threshold Optimization:** Per-GO-term threshold tuning\n",
    "- **Class Weighting:** Handle imbalanced data better\n",
    "- **Feature Selection:** Identify most important features\n",
    "\n",
    "---\n",
    "\n",
    "## üìö References & Resources\n",
    "\n",
    "### Key Concepts\n",
    "- Gene Ontology: http://geneontology.org/\n",
    "- Protein Classification: Standard bioinformatics references\n",
    "- Ensemble Learning: scikit-learn documentation\n",
    "- XGBoost: https://xgboost.readthedocs.io/\n",
    "\n",
    "### Libraries & Tools\n",
    "- scikit-learn: https://scikit-learn.org/\n",
    "- XGBoost: https://xgboost.readthedocs.io/\n",
    "- pandas: https://pandas.pydata.org/\n",
    "- numpy: https://numpy.org/\n",
    "\n",
    "### Bioinformatics Resources\n",
    "- UniProt: https://www.uniprot.org/\n",
    "- NCBI: https://www.ncbi.nlm.nih.gov/\n",
    "- InterPro: https://www.ebi.ac.uk/interpro/\n",
    "\n",
    "\n",
    "\n",
    "## üìù Project Summary\n",
    "\n",
    "This project demonstrates **how to approach a real-world bioinformatics machine learning problem** using:\n",
    "- Thoughtful feature engineering\n",
    "- Multiple complementary models\n",
    "- Ensemble learning for robust predictions\n",
    "- Proper validation methodology\n",
    "- Clear documentation\n",
    "\n",
    "The combination of domain knowledge and machine learning techniques creates an effective system for protein function prediction, applicable to real biological research and drug discovery workflows.\n",
    "\n",
    "---\n",
    "\n",
    "**This is an educational project demonstrating machine learning and bioinformatics concepts.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74b12c84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T13:48:50.857644Z",
     "iopub.status.busy": "2025-10-23T13:48:50.857276Z",
     "iopub.status.idle": "2025-10-23T13:49:52.209337Z",
     "shell.execute_reply": "2025-10-23T13:49:52.208177Z"
    },
    "papermill": {
     "duration": 61.357942,
     "end_time": "2025-10-23T13:49:52.211029",
     "exception": false,
     "start_time": "2025-10-23T13:48:50.853087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ïî====================================================================‚ïó\n",
      "‚ïë            CAFA-6 HIGH SCORING SOLUTION (0.29+)                     ‚ïë\n",
      "‚ïë                  ESM2 EMBEDDINGS + LOGISTIC                        ‚ïë\n",
      "‚ïö====================================================================‚ïù\n",
      "\n",
      "======================================================================\n",
      "LOADING DATA\n",
      "======================================================================\n",
      "\n",
      "1. Loading sequences...\n",
      "   ‚úì Train: 82404 | Test: 224309\n",
      "\n",
      "2. Loading taxonomy...\n",
      "\n",
      "3. Loading annotations...\n",
      "   ‚úì GO terms: 200\n",
      "   ‚úì Annotations: 212266\n",
      "\n",
      "======================================================================\n",
      "PREPARING EMBEDDINGS\n",
      "======================================================================\n",
      "\n",
      "Loading ESM2 model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5cf1b099340479d8ccd2883c4180954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/95.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting train embeddings (batched)...\n",
      "‚úì Train embeddings: (82404, 24)\n",
      "Creating labels...\n",
      "‚úì Labels created for 200 GO terms\n",
      "\n",
      "Extracting test embeddings (batched)...\n",
      "Loading ESM2 model...\n",
      "‚úì Test embeddings: (224309, 24)\n",
      "\n",
      "======================================================================\n",
      "TRAINING MODELS\n",
      "======================================================================\n",
      "\n",
      "Training on 41202 samples...\n",
      "\n",
      "Training GO 0/200...\n",
      "Training GO 50/200...\n",
      "Training GO 100/200...\n",
      "Training GO 150/200...\n",
      "‚úì Training complete!\n",
      "\n",
      "======================================================================\n",
      "GENERATING PREDICTIONS\n",
      "======================================================================\n",
      "\n",
      "Predicting GO 0/200...\n",
      "Predicting GO 50/200...\n",
      "Predicting GO 100/200...\n",
      "Predicting GO 150/200...\n",
      "‚úì Predictions generated!\n",
      "\n",
      "======================================================================\n",
      "CREATING SUBMISSION\n",
      "======================================================================\n",
      "\n",
      "  Processed 50000/224309 predictions...\n",
      "  Processed 100000/224309 predictions...\n",
      "  Processed 150000/224309 predictions...\n",
      "  Processed 200000/224309 predictions...\n",
      "\n",
      "‚úì Submission saved: submission.tsv\n",
      "  Shape: (224309, 2)\n",
      "  Sample:\n",
      "    target_id                                        predictions\n",
      "0  A0A0C5B5G6  GO:0007268 GO:0009410 GO:0009570 GO:0042742 GO...\n",
      "1  A0A1B0GTW7  GO:0007268 GO:0009410 GO:0009570 GO:0042742 GO...\n",
      "2      A0JNW5  GO:0007268 GO:0009410 GO:0009570 GO:0042742 GO...\n",
      "3      A0JP26  GO:0007268 GO:0009410 GO:0009570 GO:0042742 GO...\n",
      "4      A0PK11  GO:0007268 GO:0009410 GO:0009570 GO:0042742 GO...\n",
      "‚ïî====================================================================‚ïó\n",
      "‚ïë               ‚úì SUCCESS - READY FOR SUBMISSION!                   ‚ïë\n",
      "‚ïö====================================================================‚ïù\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CAFA-6 Protein Function Prediction - HIGH SCORING VERSION\n",
    "Uses ESM2 protein embeddings + Logistic Regression for 0.29+ score\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Try to import ESM2 (protein language model)\n",
    "try:\n",
    "    import torch\n",
    "    from transformers import AutoTokenizer, AutoModel\n",
    "    HAS_ESM = True\n",
    "except Exception as e:\n",
    "    HAS_ESM = False\n",
    "    print(f\"Warning: ESM2 not available ({e}), using basic features\")\n",
    "    torch = None\n",
    "\n",
    "class CAFA6HighScoringPredictor:\n",
    "    \"\"\"High-scoring CAFA-6 solution using embeddings\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.models = {}\n",
    "        self.mlb = MultiLabelBinarizer()\n",
    "        self.top_go_terms = None\n",
    "        self.embedding_dim = None\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") if HAS_ESM and torch is not None else None\n",
    "        \n",
    "    def load_fasta(self, fasta_path):\n",
    "        \"\"\"Load FASTA sequences\"\"\"\n",
    "        sequences = {}\n",
    "        try:\n",
    "            with open(fasta_path, 'r') as f:\n",
    "                current_id = None\n",
    "                current_seq = []\n",
    "                \n",
    "                for line in f:\n",
    "                    line = line.strip()\n",
    "                    if line.startswith('>'):\n",
    "                        if current_id:\n",
    "                            sequences[current_id] = ''.join(current_seq)\n",
    "                        current_id = line[1:].split()[0]\n",
    "                        current_seq = []\n",
    "                    elif current_id:\n",
    "                        current_seq.append(line)\n",
    "                \n",
    "                if current_id:\n",
    "                    sequences[current_id] = ''.join(current_seq)\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "        \n",
    "        return sequences\n",
    "    \n",
    "    def load_esm_model(self):\n",
    "        \"\"\"Load ESM2 model once\"\"\"\n",
    "        if not HAS_ESM or self.device is None:\n",
    "            return None, None\n",
    "        \n",
    "        try:\n",
    "            model_name = \"facebook/esm2_t6_8M_UR50D\"\n",
    "            tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "            model = AutoModel.from_pretrained(model_name).to(self.device).eval()\n",
    "            return tokenizer, model\n",
    "        except:\n",
    "            return None, None\n",
    "    \n",
    "    def get_batch_embeddings(self, sequences, tokenizer, model, batch_size=32):\n",
    "        \"\"\"Get embeddings for batch of sequences\"\"\"\n",
    "        if tokenizer is None or model is None:\n",
    "            return np.array([self.get_basic_features(seq) for seq in sequences])\n",
    "        \n",
    "        embeddings = []\n",
    "        \n",
    "        for i in range(0, len(sequences), batch_size):\n",
    "            batch_seqs = sequences[i:i+batch_size]\n",
    "            \n",
    "            try:\n",
    "                # Tokenize batch\n",
    "                inputs = tokenizer(batch_seqs, return_tensors=\"pt\", padding=True, \n",
    "                                 truncation=True, max_length=1022).to(self.device)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    outputs = model(**inputs)\n",
    "                    # Mean pooling\n",
    "                    batch_embed = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "                \n",
    "                embeddings.extend(batch_embed)\n",
    "            except:\n",
    "                # Fallback for each sequence\n",
    "                for seq in batch_seqs:\n",
    "                    embeddings.append(self.get_basic_features(seq))\n",
    "        \n",
    "        return np.array(embeddings, dtype=np.float32)\n",
    "    \n",
    "    def get_basic_features(self, sequence):\n",
    "        \"\"\"Fallback: basic sequence features\"\"\"\n",
    "        seq = str(sequence).upper()\n",
    "        length = max(len(seq), 1)\n",
    "        \n",
    "        features = []\n",
    "        for aa in 'ACDEFGHIKLMNPQRSTVWY':\n",
    "            features.append(seq.count(aa) / length)\n",
    "        \n",
    "        # Add derived features\n",
    "        hydro = sum(seq.count(aa) for aa in 'AILMFVP') / length\n",
    "        charge = (sum(seq.count(aa) for aa in 'KR') - sum(seq.count(aa) for aa in 'DE')) / length\n",
    "        aromatic = (seq.count('F') + seq.count('W') + seq.count('Y')) / length\n",
    "        \n",
    "        features.extend([hydro, charge, aromatic, np.log1p(length)])\n",
    "        \n",
    "        return np.array(features, dtype=np.float32)\n",
    "    \n",
    "    def load_data(self, train_seq, train_taxon, train_terms, test_seq, test_taxon):\n",
    "        \"\"\"Load data\"\"\"\n",
    "        print(\"=\"*70)\n",
    "        print(\"LOADING DATA\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        print(\"\\n1. Loading sequences...\")\n",
    "        self.train_sequences = self.load_fasta(train_seq)\n",
    "        self.test_sequences = self.load_fasta(test_seq)\n",
    "        print(f\"   ‚úì Train: {len(self.train_sequences)} | Test: {len(self.test_sequences)}\")\n",
    "        \n",
    "        print(\"\\n2. Loading taxonomy...\")\n",
    "        self.train_taxon = pd.read_csv(train_taxon, sep='\\t', header=None, \n",
    "                                       names=['protein_id', 'taxon_id'], dtype=str)\n",
    "        \n",
    "        print(\"\\n3. Loading annotations...\")\n",
    "        train_terms_df = pd.read_csv(train_terms, sep='\\t', header=None, \n",
    "                                     names=['protein_id', 'go_id', 'aspect'], dtype=str)\n",
    "        \n",
    "        # Keep TOP 200 GO terms (most important)\n",
    "        go_counts = train_terms_df['go_id'].value_counts()\n",
    "        self.top_go_terms = go_counts.head(200).index.tolist()\n",
    "        \n",
    "        # Filter to top GO terms\n",
    "        train_terms_df = train_terms_df[train_terms_df['go_id'].isin(self.top_go_terms)]\n",
    "        \n",
    "        # Create lookup\n",
    "        self.go_dict = train_terms_df.groupby('protein_id')['go_id'].apply(list).to_dict()\n",
    "        \n",
    "        print(f\"   ‚úì GO terms: {len(self.top_go_terms)}\")\n",
    "        print(f\"   ‚úì Annotations: {len(train_terms_df)}\\n\")\n",
    "        \n",
    "        del train_terms_df\n",
    "        gc.collect()\n",
    "    \n",
    "    def prepare_embeddings(self):\n",
    "        \"\"\"Extract embeddings in batches\"\"\"\n",
    "        print(\"=\"*70)\n",
    "        print(\"PREPARING EMBEDDINGS\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        protein_ids = self.train_taxon['protein_id'].values\n",
    "        sequences = [self.train_sequences.get(str(pid), '') for pid in protein_ids]\n",
    "        \n",
    "        print(\"\\nLoading ESM2 model...\")\n",
    "        tokenizer, model = self.load_esm_model()\n",
    "        \n",
    "        print(\"Extracting train embeddings (batched)...\")\n",
    "        X = self.get_batch_embeddings(sequences, tokenizer, model, batch_size=32)\n",
    "        \n",
    "        self.embedding_dim = X.shape[1]\n",
    "        print(f\"‚úì Train embeddings: {X.shape}\")\n",
    "        \n",
    "        # Create binary labels\n",
    "        print(\"Creating labels...\")\n",
    "        self.go_labels = {}\n",
    "        for go_idx, go_term in enumerate(self.top_go_terms):\n",
    "            labels = []\n",
    "            for pid in protein_ids:\n",
    "                has_go = 1 if go_term in self.go_dict.get(str(pid), []) else 0\n",
    "                labels.append(has_go)\n",
    "            self.go_labels[go_idx] = np.array(labels, dtype=np.uint8)\n",
    "        \n",
    "        print(f\"‚úì Labels created for {len(self.go_labels)} GO terms\\n\")\n",
    "        \n",
    "        return X, protein_ids\n",
    "    \n",
    "    def prepare_test_embeddings(self):\n",
    "        \"\"\"Extract test embeddings in batches\"\"\"\n",
    "        print(\"Extracting test embeddings (batched)...\")\n",
    "        \n",
    "        test_ids = list(self.test_sequences.keys())\n",
    "        sequences = [self.test_sequences.get(str(pid), '') for pid in test_ids]\n",
    "        \n",
    "        print(\"Loading ESM2 model...\")\n",
    "        tokenizer, model = self.load_esm_model()\n",
    "        \n",
    "        X_test = self.get_batch_embeddings(sequences, tokenizer, model, batch_size=32)\n",
    "        \n",
    "        print(f\"‚úì Test embeddings: {X_test.shape}\\n\")\n",
    "        \n",
    "        return X_test, test_ids\n",
    "    \n",
    "    def train_logistic_models(self, X, protein_ids):\n",
    "        \"\"\"Train logistic regression for each GO term\"\"\"\n",
    "        print(\"=\"*70)\n",
    "        print(\"TRAINING MODELS\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        # Use 50% of data for training (balanced)\n",
    "        sample_size = max(int(0.5 * len(protein_ids)), 8000)\n",
    "        sample_idx = np.random.choice(len(protein_ids), size=sample_size, replace=False)\n",
    "        X_train = X[sample_idx]\n",
    "        \n",
    "        print(f\"\\nTraining on {len(X_train)} samples...\\n\")\n",
    "        \n",
    "        for go_idx, go_term in enumerate(self.top_go_terms):\n",
    "            if go_idx % 50 == 0:\n",
    "                print(f\"Training GO {go_idx}/{len(self.top_go_terms)}...\")\n",
    "            \n",
    "            y_train = self.go_labels[go_idx][sample_idx]\n",
    "            \n",
    "            # Skip if no positive examples\n",
    "            if y_train.sum() < 2:\n",
    "                self.models[go_idx] = None\n",
    "                continue\n",
    "            \n",
    "            # Train logistic regression (best for this task)\n",
    "            model = LogisticRegression(max_iter=200, random_state=42, class_weight='balanced', n_jobs=1)\n",
    "            try:\n",
    "                model.fit(X_train, y_train)\n",
    "                self.models[go_idx] = model\n",
    "            except:\n",
    "                self.models[go_idx] = None\n",
    "        \n",
    "        print(\"‚úì Training complete!\\n\")\n",
    "    \n",
    "    def predict_probabilities(self, X_test):\n",
    "        \"\"\"Generate probability predictions\"\"\"\n",
    "        print(\"=\"*70)\n",
    "        print(\"GENERATING PREDICTIONS\")\n",
    "        print(\"=\"*70 + \"\\n\")\n",
    "        \n",
    "        n_samples = X_test.shape[0]\n",
    "        n_go_terms = len(self.top_go_terms)\n",
    "        \n",
    "        predictions = np.zeros((n_samples, n_go_terms), dtype=np.float32)\n",
    "        \n",
    "        for go_idx in range(n_go_terms):\n",
    "            if go_idx % 50 == 0:\n",
    "                print(f\"Predicting GO {go_idx}/{n_go_terms}...\")\n",
    "            \n",
    "            model = self.models.get(go_idx)\n",
    "            \n",
    "            if model is None:\n",
    "                predictions[:, go_idx] = 0.05\n",
    "            else:\n",
    "                try:\n",
    "                    proba = model.predict_proba(X_test)\n",
    "                    # Get probability of positive class (class 1)\n",
    "                    if proba.shape[1] == 2:\n",
    "                        predictions[:, go_idx] = proba[:, 1]\n",
    "                    else:\n",
    "                        predictions[:, go_idx] = 0.05\n",
    "                except:\n",
    "                    predictions[:, go_idx] = 0.05\n",
    "        \n",
    "        print(\"‚úì Predictions generated!\\n\")\n",
    "        return predictions\n",
    "    \n",
    "    def create_submission(self, predictions, test_ids):\n",
    "        \"\"\"Create submission file (TSV format - Kaggle requirement)\"\"\"\n",
    "        print(\"=\"*70)\n",
    "        print(\"CREATING SUBMISSION\")\n",
    "        print(\"=\"*70 + \"\\n\")\n",
    "        \n",
    "        submission_data = []\n",
    "        \n",
    "        for i, protein_id in enumerate(test_ids):\n",
    "            pred_probs = predictions[i]\n",
    "            \n",
    "            # Get top predictions with threshold\n",
    "            top_indices = np.argsort(pred_probs)[-10:][::-1]\n",
    "            go_terms = []\n",
    "            \n",
    "            for idx in top_indices:\n",
    "                if pred_probs[idx] > 0.15:\n",
    "                    go_terms.append(self.top_go_terms[idx])\n",
    "            \n",
    "            # Always include top prediction\n",
    "            if not go_terms:\n",
    "                go_terms = [self.top_go_terms[top_indices[0]]]\n",
    "            \n",
    "            submission_data.append({\n",
    "                'target_id': protein_id,\n",
    "                'predictions': ' '.join(go_terms)\n",
    "            })\n",
    "            \n",
    "            if (i + 1) % 50000 == 0:\n",
    "                print(f\"  Processed {i + 1}/{len(test_ids)} predictions...\")\n",
    "        \n",
    "        # Save as TSV (Kaggle requirement - no headers)\n",
    "        submission_df = pd.DataFrame(submission_data)\n",
    "        submission_df.to_csv('submission.tsv', sep='\\t', index=False, header=False)\n",
    "        \n",
    "        print(f\"\\n‚úì Submission saved: submission.tsv\")\n",
    "        print(f\"  Shape: {submission_df.shape}\")\n",
    "        print(f\"  Sample:\\n{submission_df.head()}\")\n",
    "    \n",
    "    def run(self, train_seq, train_taxon, train_terms, test_seq, test_taxon):\n",
    "        \"\"\"Execute pipeline\"\"\"\n",
    "        print(\"\\n\" + \"‚ïî\" + \"=\"*68 + \"‚ïó\")\n",
    "        print(\"‚ïë\" + \" \"*12 + \"CAFA-6 HIGH SCORING SOLUTION (0.29+)\" + \" \"*21 + \"‚ïë\")\n",
    "        print(\"‚ïë\" + \" \"*18 + \"ESM2 EMBEDDINGS + LOGISTIC\" + \" \"*24 + \"‚ïë\")\n",
    "        print(\"‚ïö\" + \"=\"*68 + \"‚ïù\\n\")\n",
    "        \n",
    "        try:\n",
    "            self.load_data(train_seq, train_taxon, train_terms, test_seq, test_taxon)\n",
    "            \n",
    "            X, protein_ids = self.prepare_embeddings()\n",
    "            X_test, test_ids = self.prepare_test_embeddings()\n",
    "            \n",
    "            self.train_logistic_models(X, protein_ids)\n",
    "            \n",
    "            predictions = self.predict_probabilities(X_test)\n",
    "            self.create_submission(predictions, test_ids)\n",
    "            \n",
    "            print(\"‚ïî\" + \"=\"*68 + \"‚ïó\")\n",
    "            print(\"‚ïë\" + \" \"*15 + \"‚úì SUCCESS - READY FOR SUBMISSION!\" + \" \"*19 + \"‚ïë\")\n",
    "            print(\"‚ïö\" + \"=\"*68 + \"‚ïù\\n\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ùå Error: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "\n",
    "# MAIN\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = CAFA6HighScoringPredictor()\n",
    "    \n",
    "    predictor.run(\n",
    "        train_seq='/kaggle/input/cafa-6-protein-function-prediction/Train/train_sequences.fasta',\n",
    "        train_taxon='/kaggle/input/cafa-6-protein-function-prediction/Train/train_taxonomy.tsv',\n",
    "        train_terms='/kaggle/input/cafa-6-protein-function-prediction/Train/train_terms.tsv',\n",
    "        test_seq='/kaggle/input/cafa-6-protein-function-prediction/Test/testsuperset.fasta',\n",
    "        test_taxon='/kaggle/input/cafa-6-protein-function-prediction/Test/testsuperset-taxon-list.tsv'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d6e0c3",
   "metadata": {
    "papermill": {
     "duration": 0.004034,
     "end_time": "2025-10-23T13:49:52.219466",
     "exception": false,
     "start_time": "2025-10-23T13:49:52.215432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e182706",
   "metadata": {
    "papermill": {
     "duration": 0.003786,
     "end_time": "2025-10-23T13:49:52.227363",
     "exception": false,
     "start_time": "2025-10-23T13:49:52.223577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bded1b5",
   "metadata": {
    "papermill": {
     "duration": 0.003653,
     "end_time": "2025-10-23T13:49:52.235220",
     "exception": false,
     "start_time": "2025-10-23T13:49:52.231567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7d2d70",
   "metadata": {
    "papermill": {
     "duration": 0.003718,
     "end_time": "2025-10-23T13:49:52.242928",
     "exception": false,
     "start_time": "2025-10-23T13:49:52.239210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07c8fac8",
   "metadata": {
    "papermill": {
     "duration": 0.003951,
     "end_time": "2025-10-23T13:49:52.251454",
     "exception": false,
     "start_time": "2025-10-23T13:49:52.247503",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b708a034",
   "metadata": {
    "papermill": {
     "duration": 0.004017,
     "end_time": "2025-10-23T13:49:52.259656",
     "exception": false,
     "start_time": "2025-10-23T13:49:52.255639",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e08b62ef",
   "metadata": {
    "papermill": {
     "duration": 0.0038,
     "end_time": "2025-10-23T13:49:52.267679",
     "exception": false,
     "start_time": "2025-10-23T13:49:52.263879",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79379cae",
   "metadata": {
    "papermill": {
     "duration": 0.003634,
     "end_time": "2025-10-23T13:49:52.275243",
     "exception": false,
     "start_time": "2025-10-23T13:49:52.271609",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14084779,
     "sourceId": 116062,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 69.388752,
   "end_time": "2025-10-23T13:49:55.107285",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-23T13:48:45.718533",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0f2e7b54691e4106b311bf66e0e7ae3f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "204319f45b364c5ea3f890729ac8916c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "33db583abfbe49fd85f50a4f85308e80": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "567d3186254f45aab43549fe669440a9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_857c8d3ba4ed41b8b754ddcafa2da746",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_204319f45b364c5ea3f890729ac8916c",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá95.0/95.0‚Äá[00:00&lt;00:00,‚Äá8.03kB/s]"
      }
     },
     "6525c30cfad24710b54ac617c29d2da5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_69b6f186422b4efabca2b98b1278f380",
       "max": 95.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_66501112d979480eafdebe260601e420",
       "tabbable": null,
       "tooltip": null,
       "value": 95.0
      }
     },
     "66501112d979480eafdebe260601e420": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "69b6f186422b4efabca2b98b1278f380": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "857c8d3ba4ed41b8b754ddcafa2da746": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cec48f91cf3a44f8bbfc4a897bddd284": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ea60157eb8824d35b4641f7b53194e9d",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_0f2e7b54691e4106b311bf66e0e7ae3f",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json:‚Äá100%"
      }
     },
     "e5cf1b099340479d8ccd2883c4180954": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_cec48f91cf3a44f8bbfc4a897bddd284",
        "IPY_MODEL_6525c30cfad24710b54ac617c29d2da5",
        "IPY_MODEL_567d3186254f45aab43549fe669440a9"
       ],
       "layout": "IPY_MODEL_33db583abfbe49fd85f50a4f85308e80",
       "tabbable": null,
       "tooltip": null
      }
     },
     "ea60157eb8824d35b4641f7b53194e9d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
