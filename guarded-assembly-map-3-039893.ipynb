{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d4b2190",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.003179,
     "end_time": "2025-10-15T07:33:09.232972",
     "exception": false,
     "start_time": "2025-10-15T07:33:09.229793",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ðŸ§·ðŸ” Guardrailed Ensemble MAP@3  \n",
    "\n",
    "> **Changelog (this fork):**  \n",
    "> â€¢ Perâ€‘model *familyâ€‘guardrailed decoding* (filter to `True_` / `False_` before writing base results)  \n",
    "> â€¢ Ensemble enforces same family filtering + safe backfill  \n",
    "> â€¢ Threaded, staggered multiâ€‘GPU inference (Qwen & DeepSeek)  \n",
    "> â€¢ Full probability artifacts (`prob_0..24`, `top_classes`) per model  \n",
    "> â€¢ Standardized prompts (â€œCorrect? Yes/Noâ€) and consistent tokenization. Funny thing is this discussion appears right at the top but it is not always being enforced: https://www.kaggle.com/competitions/map-charting-student-math-misunderstandings/discussion/589400\n",
    "\n",
    "> *Based on original by @kishanvavdara â€” see [original notebook](https://www.kaggle.com/code/kishanvavdara/ensemble-gemma-qwen-deepseek)*  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02456553",
   "metadata": {
    "papermill": {
     "duration": 0.002074,
     "end_time": "2025-10-15T07:33:09.237742",
     "exception": false,
     "start_time": "2025-10-15T07:33:09.235668",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1) Competition: task & metric  \n",
    "\n",
    "Youâ€™re working on the **MAP: Charting Student Math Misunderstandings** competition.  \n",
    "\n",
    "**Task:** Given a question, the studentâ€™s MC answer, and their explanation, you must output a **topâ€‘3** `Category:Misconception` prediction (spaceâ€‘separated). Labels include a **family prefix** (`True_` or `False_`) + a coarse label (e.g. `Misconception`, `Neither`, `Correct`).  \n",
    "\n",
    "**Evaluation:** **MAP@3** â€” so ordering matters.  \n",
    "\n",
    "**Data layout:** `train.csv` has true `Category` + `Misconception`, `test.csv` doesnâ€™t. You must map each `row_id` to 3 predictions.  \n",
    "\n",
    "> This forkâ€™s design emphasizes **consistency and interpretability**, not hyperâ€‘tweaked dominance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf05a86",
   "metadata": {
    "papermill": {
     "duration": 0.00206,
     "end_time": "2025-10-15T07:33:09.242006",
     "exception": false,
     "start_time": "2025-10-15T07:33:09.239946",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2) Pipeline overview  \n",
    "\n",
    "### 2.1 Family heuristic & pre-processing  \n",
    "- From `train`, extract a â€œcanonical correct MC answer per QuestionIdâ€ among `True_`â€‘labeled rows; merge to `test` to define `is_correct âˆˆ {0,1}`.  \n",
    "- Map that to a **family prefix**: `True_` if `is_correct=1` else `False_`.  \n",
    "\n",
    "### 2.2 Prompting & tokenization  \n",
    "- Use short, deterministic prompt templates (e.g. â€œCorrect? Yes/Noâ€).  \n",
    "- Tokenize with `max_length=256`, truncation, and padding via a `DataCollatorWithPadding`.\n",
    "\n",
    "### 2.3 Inference per model  \n",
    "- **Gemmaâ€‘2â€‘9B + LoRA**: load base + adapter; may see `score.weight` warnings if head uninitialized.  \n",
    "- **Qwen3â€‘8B & DeepSeekMathâ€‘7B**: run in parallel threads on separate GPUs with small batches and staggered start delays.  \n",
    "- **Guardrailed decoding**: filter top classes to the rowâ€™s family prefix, dedupe, then backfill to exactly 3 using safe placeholders (`Neither:NA`, `Correct:NA` etc.).\n",
    "\n",
    "### 2.4 Ensemble & blending  \n",
    "- Each model outputs a probability artifact (with `prob_0..24`, `top_classes`).  \n",
    "- Merge them on `row_id`.  \n",
    "- For each candidate class, compute:\n",
    "  1. weighted sum of probabilities  \n",
    "  2. agreement (how many models predicted it)  \n",
    "  3. max weighted prob  \n",
    "- Score: `0.6Â·sum + 0.3Â·agreement + 0.1Â·max`  \n",
    "- Final: filter to correct family prefix, sort, take topâ€‘3, safe backfill as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be835f5",
   "metadata": {
    "papermill": {
     "duration": 0.002092,
     "end_time": "2025-10-15T07:33:09.246303",
     "exception": false,
     "start_time": "2025-10-15T07:33:09.244211",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "## 3) Remarks & pitfalls  \n",
    "\n",
    "- The **Gemma head initialization warning** does not break inference, but indicates the classification head may not be well aligned â€” youâ€™re better off persisting a tuned head.  \n",
    "- The **family heuristic** (derived from majority vote in train) is approximate; in rarer cases it might mislabel some rows, forcing fallback placeholders.  \n",
    "- To reduce nondeterminism, **seed** `numpy`, `torch`, and Pythonâ€™s `random`.  \n",
    "- The artifact CSVs (probabilities + top_classes) are intentional: they enable **post hoc stacking, calibration, and introspection**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a1346ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T07:33:09.252178Z",
     "iopub.status.busy": "2025-10-15T07:33:09.251903Z",
     "iopub.status.idle": "2025-10-15T07:33:09.262048Z",
     "shell.execute_reply": "2025-10-15T07:33:09.261394Z"
    },
    "papermill": {
     "duration": 0.014546,
     "end_time": "2025-10-15T07:33:09.263178",
     "exception": false,
     "start_time": "2025-10-15T07:33:09.248632",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing gemma2_inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile gemma2_inference.py\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import os\n",
    "from IPython.display import display, Math, Latex\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "import pandas as pd, numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import DataCollatorWithPadding\n",
    "from peft import PeftModel\n",
    "from scipy.special import softmax\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "\n",
    "lora_path = \"/kaggle/input/gemma2-9b-it-cv945\"\n",
    "MAX_LEN = 256\n",
    "# helpers\n",
    "def format_input(row):\n",
    "    x = \"Yes\"\n",
    "    if not row['is_correct']:\n",
    "        x = \"No\"\n",
    "    return (\n",
    "        f\"Question: {row['QuestionText']}\\n\"\n",
    "        f\"Answer: {row['MC_Answer']}\\n\"\n",
    "        f\"Correct? {x}\\n\"\n",
    "        f\"Student Explanation: {row['StudentExplanation']}\"\n",
    "    )\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=256)\n",
    "\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "train = pd.read_csv('/kaggle/input/map-charting-student-math-misunderstandings/train.csv')\n",
    "\n",
    "train.Misconception = train.Misconception.fillna('NA')\n",
    "train['target'] = train.Category+\":\"+train.Misconception\n",
    "train['label'] = le.fit_transform(train['target'])\n",
    "target_classes = le.classes_\n",
    "n_classes = len(target_classes)\n",
    "print(f\"Train shape: {train.shape} with {n_classes} target classes\")\n",
    "idx = train.apply(lambda row: row.Category.split('_')[0],axis=1)=='True'\n",
    "correct = train.loc[idx].copy()\n",
    "correct['c'] = correct.groupby(['QuestionId','MC_Answer']).MC_Answer.transform('count')\n",
    "correct = correct.sort_values('c',ascending=False)\n",
    "correct = correct.drop_duplicates(['QuestionId'])\n",
    "correct = correct[['QuestionId','MC_Answer']]\n",
    "correct['is_correct'] = 1\n",
    "\n",
    "# Prepare test data\n",
    "test = pd.read_csv('/kaggle/input/map-charting-student-math-misunderstandings/test.csv')\n",
    "test = test.merge(correct, on=['QuestionId','MC_Answer'], how='left')\n",
    "test.is_correct = test.is_correct.fillna(0)\n",
    "test['text'] = test.apply(format_input, axis=1)\n",
    "\n",
    "\n",
    "# load model & tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(lora_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"/kaggle/input/gemma2-9b-it-bf16\",\n",
    "    num_labels=n_classes,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "model = PeftModel.from_pretrained(model, lora_path)\n",
    "model.eval()\n",
    "\n",
    "# Tokenize dataset\n",
    "ds_test = Dataset.from_pandas(test[['text']])\n",
    "ds_test = ds_test.map(tokenize, batched=True, remove_columns=['text'])\n",
    "\n",
    "# Create data collator for efficient batching with padding\n",
    "data_collator = DataCollatorWithPadding(\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=MAX_LEN,  \n",
    "    return_tensors=\"pt\")\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    ds_test,\n",
    "    batch_size=8,  \n",
    "    shuffle=False,\n",
    "    collate_fn=data_collator,\n",
    "    pin_memory=True,  \n",
    "    num_workers=2     \n",
    ")\n",
    "\n",
    "# Fast inference loop\n",
    "all_logits = []\n",
    "device = next(model.parameters()).device\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(dataloader, desc=\"Inference\"):\n",
    "        # Move batch to device\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(**batch)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # Convert bfloat16 to float32 then move to CPU and store\n",
    "        all_logits.append(logits.float().cpu().numpy())\n",
    "\n",
    "# Concatenate all logits\n",
    "predictions = np.concatenate(all_logits, axis=0)\n",
    "\n",
    "# Convert to probs\n",
    "probs = softmax(predictions, axis=1)\n",
    "\n",
    "# Get top predictions (all 65 classes ranked)\n",
    "top_indices = np.argsort(-probs, axis=1)\n",
    "\n",
    "# Decode to class names\n",
    "flat_indices = top_indices.flatten()\n",
    "decoded_labels = le.inverse_transform(flat_indices)\n",
    "top_labels = decoded_labels.reshape(top_indices.shape)\n",
    "\n",
    "# Build per-row family prefix from test.is_correct (1 -> True_, 0 -> False_)\n",
    "fam_prefix = np.where(test.is_correct.values == 1, \"True_\", \"False_\")\n",
    "valid_labels = set(target_classes)\n",
    "\n",
    "filtered_top3 = []\n",
    "for i in range(len(test)):\n",
    "    pref = fam_prefix[i]\n",
    "    row = [lab for lab in top_labels[i, :] if lab.startswith(pref)]\n",
    "\n",
    "    # de-dup while preserving order\n",
    "    seen = set(); row = [x for x in row if not (x in seen or seen.add(x))]\n",
    "\n",
    "    # backfill safely from allowed labels (prefer Neither, then Correct when True_)\n",
    "    fillers = [f\"{pref}Neither:NA\", f\"{pref}Correct:NA\"] if pref == \"True_\" else [f\"{pref}Neither:NA\"]\n",
    "    for f in fillers:\n",
    "        if len(row) >= 3: break\n",
    "        if f in valid_labels and f not in row:\n",
    "            row.append(f)\n",
    "    while len(row) < 3:\n",
    "        # last resort: keep repeating a valid family-safe filler that's allowed\n",
    "        f = fillers[0] if fillers and fillers[0] in valid_labels else next(l for l in valid_labels if l.startswith(pref))\n",
    "        row.append(f)\n",
    "\n",
    "    filtered_top3.append(\" \".join(row[:3]))\n",
    "\n",
    "joined_preds = filtered_top3  # <â€” replace previous joined_preds\n",
    "\n",
    "# Create submission (top 3)\n",
    "#joined_preds = [\" \".join(row[:3]) for row in top_labels]\n",
    "\n",
    "sub = pd.DataFrame({\n",
    "    \"row_id\": test.row_id.values,\n",
    "    \"Category:Misconception\": joined_preds\n",
    "})\n",
    "sub.to_csv(\"submission_gemma.csv\", index=False)\n",
    "\n",
    "prob_data = []\n",
    "for i in range(len(test)):\n",
    "    prob_dict = {f\"prob_{j}\": probs[i, top_indices[i, j]] for j in range(25)}  # Top 25\n",
    "    prob_dict['row_id'] = test.row_id.values[i]\n",
    "    prob_dict['top_classes'] = \" \".join(top_labels[i, :25])  # Top 25 class names\n",
    "    prob_data.append(prob_dict)\n",
    "\n",
    "prob_df = pd.DataFrame(prob_data)\n",
    "prob_df.to_csv(\"submission_gemma_prob.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be8b0e71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T07:33:09.269165Z",
     "iopub.status.busy": "2025-10-15T07:33:09.268948Z",
     "iopub.status.idle": "2025-10-15T07:33:09.276554Z",
     "shell.execute_reply": "2025-10-15T07:33:09.275651Z"
    },
    "papermill": {
     "duration": 0.012113,
     "end_time": "2025-10-15T07:33:09.277802",
     "exception": false,
     "start_time": "2025-10-15T07:33:09.265689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing qwen3_deepseek_inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile qwen3_deepseek_inference.py\n",
    "\n",
    "# we do parallel inference, for deepseek and qwen3\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datasets import Dataset\n",
    "import threading\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, DataCollatorWithPadding\n",
    "from scipy.special import softmax\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "\n",
    "train = pd.read_csv('/kaggle/input/map-charting-student-math-misunderstandings/train.csv')\n",
    "test  = pd.read_csv('/kaggle/input/map-charting-student-math-misunderstandings/test.csv')\n",
    "\n",
    "model_paths = [\n",
    "    \"/kaggle/input/deekseepmath-7b-map-competition/MAP_EXP_09_FULL\",\n",
    "   \"/kaggle/input/qwen3-8b-map-competition/MAP_EXP_16_FULL\"]\n",
    "\n",
    "def format_input(row):\n",
    "    x = \"This answer is correct.\"\n",
    "    if not row['is_correct']:\n",
    "        x = \"This is answer is incorrect.\"\n",
    "    return (\n",
    "        f\"Question: {row['QuestionText']}\\n\"\n",
    "        f\"Answer: {row['MC_Answer']}\\n\"\n",
    "        f\"{x}\\n\"\n",
    "        f\"Student Explanation: {row['StudentExplanation']}\")\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "train.Misconception  = train.Misconception.fillna('NA')\n",
    "train['target']   = train.Category + ':' +train.Misconception\n",
    "train['label']    = le.fit_transform(train['target'])\n",
    "\n",
    "n_classes = len(le.classes_)\n",
    "print(f\"Train shape: {train.shape} with {n_classes} target classes\")\n",
    "idx = train.apply(lambda row: row.Category.split('_')[0],axis=1)=='True'\n",
    "correct = train.loc[idx].copy()\n",
    "correct['c'] = correct.groupby(['QuestionId','MC_Answer']).MC_Answer.transform('count')\n",
    "correct = correct.sort_values('c',ascending=False)\n",
    "correct = correct.drop_duplicates(['QuestionId'])\n",
    "correct = correct[['QuestionId','MC_Answer']]\n",
    "correct['is_correct'] = 1\n",
    "\n",
    "test = test.merge(correct, on=['QuestionId','MC_Answer'], how='left')\n",
    "test.is_correct = test.is_correct.fillna(0)\n",
    "test['text'] = test.apply(format_input,axis=1)\n",
    "ds_test = Dataset.from_pandas(test)\n",
    "\n",
    "\n",
    "def run_inference_on_gpu(model_path, gpu_id, test_data, output_name):\n",
    "    \"\"\"Run inference for one model on one GPU\"\"\"\n",
    "    \n",
    "    device = f\"cuda:{gpu_id}\"\n",
    "    print(f\"Loading {output_name} on {device}...\")\n",
    "    \n",
    "    # Load model\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_path, \n",
    "        device_map=device, \n",
    "        torch_dtype=torch.float16\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model.config.pad_token_id = tokenizer.pad_token_id\n",
    "    model.eval()\n",
    "    \n",
    "    # Tokenize function\n",
    "    def tokenize(batch):\n",
    "        return tokenizer(batch[\"text\"], \n",
    "                        truncation=True,\n",
    "                        max_length=256)\n",
    "    \n",
    "    ds_test = Dataset.from_pandas(test_data[['text']])\n",
    "    ds_test = ds_test.map(tokenize, batched=True, remove_columns=['text'])\n",
    "    \n",
    "    # Data collator\n",
    "    data_collator = DataCollatorWithPadding(\n",
    "        tokenizer=tokenizer,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    # DataLoader\n",
    "    dataloader = DataLoader(\n",
    "        ds_test,\n",
    "        batch_size=4,\n",
    "        shuffle=False,\n",
    "        collate_fn=data_collator,\n",
    "        pin_memory=True,\n",
    "        num_workers=0\n",
    "    )\n",
    "    \n",
    "    # Inference\n",
    "    all_logits = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=f\"{output_name}\"):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            all_logits.append(outputs.logits.float().cpu().numpy())\n",
    "    \n",
    "    predictions = np.concatenate(all_logits, axis=0)\n",
    "    \n",
    "    # Process results\n",
    "    probs = softmax(predictions, axis=1)\n",
    "    top_indices = np.argsort(-probs, axis=1)\n",
    "    \n",
    "    # Decode labels\n",
    "    flat_indices = top_indices.flatten()\n",
    "    decoded_labels = le.inverse_transform(flat_indices)\n",
    "    top_labels = decoded_labels.reshape(top_indices.shape)\n",
    "    \n",
    "    filtered_top3 = []\n",
    "\n",
    "    # Build per-row family prefix from test.is_correct (1 -> True_, 0 -> False_)\n",
    "    fam_prefix = np.where(test_data.is_correct.values == 1, \"True_\", \"False_\")\n",
    "    valid_labels = set(le.classes_)  # or: set(le.classes_)\n",
    "    for i in range(len(test_data)):\n",
    "        pref = fam_prefix[i]\n",
    "        row = [lab for lab in top_labels[i, :] if lab.startswith(pref)]\n",
    "    \n",
    "        # de-dup while preserving order\n",
    "        seen = set(); row = [x for x in row if not (x in seen or seen.add(x))]\n",
    "    \n",
    "        # backfill safely from allowed labels (prefer Neither, then Correct when True_)\n",
    "        fillers = [f\"{pref}Neither:NA\", f\"{pref}Correct:NA\"] if pref == \"True_\" else [f\"{pref}Neither:NA\"]\n",
    "        for f in fillers:\n",
    "            if len(row) >= 3: break\n",
    "            if f in valid_labels and f not in row:\n",
    "                row.append(f)\n",
    "        while len(row) < 3:\n",
    "            # last resort: keep repeating a valid family-safe filler that's allowed\n",
    "            f = fillers[0] if fillers and fillers[0] in valid_labels else next(l for l in valid_labels if l.startswith(pref))\n",
    "            row.append(f)\n",
    "    \n",
    "        filtered_top3.append(\" \".join(row[:3]))\n",
    "    \n",
    "    joined_preds = filtered_top3  # <â€” replace previous joined_preds\n",
    "\n",
    "    sub = pd.DataFrame({\n",
    "        \"row_id\": test_data.row_id.values,\n",
    "        \"Category:Misconception\": joined_preds\n",
    "    })\n",
    "    sub.to_csv(f\"submission_{output_name}.csv\", index=False)\n",
    "    \n",
    "    # Save probabilities for ensemble\n",
    "    prob_data = []\n",
    "    for i in range(len(predictions)):\n",
    "        prob_dict = {f\"prob_{j}\": probs[i, top_indices[i, j]] for j in range(25)}\n",
    "        prob_dict['row_id'] = test_data.row_id.values[i]\n",
    "        prob_dict['top_classes'] = \" \".join(top_labels[i, :25])\n",
    "        prob_data.append(prob_dict)\n",
    "    \n",
    "    prob_df = pd.DataFrame(prob_data)\n",
    "    prob_df.to_csv(f\"submission_{output_name}_probabilities.csv\", index=False)\n",
    "    \n",
    "    print(f\" {output_name} completed - saved submission and probabilities\")\n",
    "    \n",
    "    # Clean up GPU memory\n",
    "    del model, tokenizer\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(\" Starting multi-GPU inference...\")\n",
    "start_time = time.time()\n",
    "\n",
    "threads = []\n",
    "gpu_assignments = [\n",
    "    (model_paths[0], 0, \"deepseek\"),\n",
    "    (model_paths[1], 1, \"qwen3\"),\n",
    "]\n",
    "\n",
    "# Start threads\n",
    "for model_path, gpu_id, name in gpu_assignments:\n",
    "    if gpu_id < torch.cuda.device_count():  \n",
    "        thread = threading.Thread(\n",
    "            target=run_inference_on_gpu,\n",
    "            args=(model_path, gpu_id, test, name)\n",
    "        )\n",
    "        threads.append(thread)\n",
    "        thread.start()\n",
    "        time.sleep(10)  # Stagger starts to avoid memory issues\n",
    "\n",
    "# Wait for completion\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\" completed in {end_time - start_time:.2f} seconds!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e69ad30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T05:24:19.923503Z",
     "iopub.status.busy": "2025-09-05T05:24:19.922686Z",
     "iopub.status.idle": "2025-09-05T05:24:19.927662Z",
     "shell.execute_reply": "2025-09-05T05:24:19.926846Z",
     "shell.execute_reply.started": "2025-09-05T05:24:19.923473Z"
    },
    "papermill": {
     "duration": 0.002272,
     "end_time": "2025-10-15T07:33:09.282704",
     "exception": false,
     "start_time": "2025-10-15T07:33:09.280432",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "431a01de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T07:33:09.288430Z",
     "iopub.status.busy": "2025-10-15T07:33:09.288179Z",
     "iopub.status.idle": "2025-10-15T07:38:36.995690Z",
     "shell.execute_reply": "2025-10-15T07:38:36.994647Z"
    },
    "papermill": {
     "duration": 327.712146,
     "end_time": "2025-10-15T07:38:36.997408",
     "exception": false,
     "start_time": "2025-10-15T07:33:09.285262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-15 07:33:34.001152: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1760513614.383102      39 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "E0000 00:00:1760513614.494998      39 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "Train shape: (36696, 9) with 65 target classes\r\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [01:43<00:00, 25.98s/it]\r\n",
      "Some weights of Gemma2ForSequenceClassification were not initialized from the model checkpoint at /kaggle/input/gemma2-9b-it-bf16 and are newly initialized: ['score.weight']\r\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\r\n",
      "/usr/local/lib/python3.11/dist-packages/peft/config.py:165: UserWarning: Unexpected keyword arguments ['qalora_group_size', 'use_qalora'] for class LoraConfig, these are ignored. This probably means that you're loading a configuration file that was saved using a higher version of the library and additional parameters have been introduced since. It is highly recommended to upgrade the PEFT version before continuing (e.g. by running `pip install -U peft`).\r\n",
      "  warnings.warn(\r\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 70.90 examples/s]\r\n",
      "Inference:   0%|                                          | 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2714: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\r\n",
      "  warnings.warn(\r\n",
      "Inference: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:02<00:00,  2.98s/it]\r\n",
      "2025-10-15 07:36:08.356165: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1760513768.386427      66 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "E0000 00:00:1760513768.394623      66 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "Train shape: (36696, 9) with 65 target classes\r\n",
      " Starting multi-GPU inference...\r\n",
      "Loading deepseek on cuda:0...\r\n",
      "Loading checkpoint shards:   0%|                          | 0/3 [00:00<?, ?it/s]Loading qwen3 on cuda:1...\r\n",
      "\r\n",
      "Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            | 1/3 [00:45<01:30, 45.36s/it]\r\n",
      "Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      | 2/3 [01:23<00:40, 40.96s/it]\r\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [01:46<00:00, 35.51s/it]\r\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 133.29 examples/s]\r\n",
      "deepseek: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.33s/it]\r\n",
      " deepseek completed - saved submission and probabilities\r\n",
      "\r\n",
      "Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3/4 [02:07<00:41, 41.95s/it]\u001b[A\r\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [02:09<00:00, 32.47s/it]\r\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 505.16 examples/s]\r\n",
      "qwen3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.91it/s]\r\n",
      " qwen3 completed - saved submission and probabilities\r\n",
      " completed in 141.13 seconds!\r\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "!python /kaggle/working/gemma2_inference.py\n",
    "time.sleep(10)\n",
    "!python /kaggle/working/qwen3_deepseek_inference.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a1d805",
   "metadata": {
    "papermill": {
     "duration": 0.003865,
     "end_time": "2025-10-15T07:38:37.006117",
     "exception": false,
     "start_time": "2025-10-15T07:38:37.002252",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Ensemble "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bf0deab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T07:38:37.015978Z",
     "iopub.status.busy": "2025-10-15T07:38:37.015736Z",
     "iopub.status.idle": "2025-10-15T07:38:37.613613Z",
     "shell.execute_reply": "2025-10-15T07:38:37.612757Z"
    },
    "papermill": {
     "duration": 0.604747,
     "end_time": "2025-10-15T07:38:37.614803",
     "exception": false,
     "start_time": "2025-10-15T07:38:37.010056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   row_id                             Category:Misconception\n",
      "0   36696  True_Correct:NA True_Neither:NA True_Misconcep...\n",
      "1   36697  False_Misconception:WNB False_Neither:NA False...\n",
      "2   36698  True_Neither:NA True_Correct:NA True_Misconcep...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# -------------------------\n",
    "# Build family map\n",
    "# -------------------------\n",
    "train = pd.read_csv('/kaggle/input/map-charting-student-math-misunderstandings/train.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/map-charting-student-math-misunderstandings/test.csv')\n",
    "\n",
    "train['is_true'] = train['Category'].str.startswith('True')\n",
    "correct = (train[train.is_true]\n",
    "           .assign(c=lambda df: df.groupby(['QuestionId','MC_Answer']).MC_Answer.transform('count'))\n",
    "           .sort_values('c', ascending=False)\n",
    "           .drop_duplicates(['QuestionId'])[['QuestionId','MC_Answer']])\n",
    "correct['is_correct'] = 1\n",
    "\n",
    "fam_map = (test_df.merge(correct, on=['QuestionId','MC_Answer'], how='left')\n",
    "                  .assign(is_correct=lambda df: df.is_correct.fillna(0).astype(int))\n",
    "                  .set_index('row_id')['is_correct']\n",
    "                  .map({1: 'True_', 0: 'False_'}).to_dict())\n",
    "\n",
    "# -------------------------\n",
    "# Ensemble\n",
    "# -------------------------\n",
    "def extract_class_probabilities(row, model_suffix='', top_k=25):\n",
    "    \"\"\"Extract class names and probabilities from a row\"\"\"\n",
    "    classes_col = f'top_classes{model_suffix}'\n",
    "    if classes_col in row:\n",
    "        classes = row[classes_col].split(' ')[:top_k]\n",
    "    else:\n",
    "        return {}\n",
    "    class_probs = {}\n",
    "    for i in range(min(top_k, len(classes))):\n",
    "        prob_col = f'prob_{i}{model_suffix}'\n",
    "        if prob_col in row:\n",
    "            class_probs[classes[i]] = row[prob_col]\n",
    "    return class_probs\n",
    "\n",
    "\n",
    "def ensemble_with_disagreement_handling(prob_files, model_weights=None, top_k=3):\n",
    "    n_models = len(prob_files)\n",
    "    prob_dfs = []\n",
    "    final_predictions = []\n",
    "    \n",
    "    for file_path in prob_files:\n",
    "        df = pd.read_csv(file_path)\n",
    "        prob_dfs.append(df)\n",
    "    \n",
    "    # Merge on row_id\n",
    "    merged_df = prob_dfs[0]\n",
    "    for i, df in enumerate(prob_dfs[1:], 1):\n",
    "        merged_df = pd.merge(merged_df, df, on='row_id', suffixes=('', f'_model{i+1}'))\n",
    "      \n",
    "    for idx, row in merged_df.iterrows():\n",
    "        pref = fam_map[row['row_id']]  # family for this row\n",
    "        \n",
    "        # Extract probabilities from each model\n",
    "        all_class_probs = []\n",
    "        for i in range(n_models):\n",
    "            suffix = f'_model{i+1}' if i > 0 else ''\n",
    "            class_probs = extract_class_probabilities(row, suffix, top_k=25)\n",
    "            all_class_probs.append(class_probs)\n",
    "        \n",
    "        # Get all unique classes\n",
    "        all_classes = set()\n",
    "        for class_probs in all_class_probs:\n",
    "            all_classes.update(class_probs.keys())\n",
    "        \n",
    "        # Calculate scores\n",
    "        class_votes = defaultdict(int)\n",
    "        class_total_prob = defaultdict(float)\n",
    "        class_max_prob = defaultdict(float)\n",
    "        \n",
    "        for i, class_probs in enumerate(all_class_probs):\n",
    "            weight = model_weights[i]\n",
    "            for class_name, prob in class_probs.items():\n",
    "                class_votes[class_name] += 1\n",
    "                class_total_prob[class_name] += prob * weight\n",
    "                class_max_prob[class_name] = max(class_max_prob[class_name], prob * weight)\n",
    "        \n",
    "        final_scores = {}\n",
    "        for class_name in all_classes:\n",
    "            base_score = class_total_prob[class_name]\n",
    "            agreement_bonus = class_votes[class_name] / n_models\n",
    "            confidence_bonus = class_max_prob[class_name]\n",
    "            final_scores[class_name] = (\n",
    "                base_score * 0.6 +\n",
    "                agreement_bonus * 0.3 +\n",
    "                confidence_bonus * 0.1\n",
    "            )\n",
    "        \n",
    "        # -------------------------\n",
    "        # Family filter\n",
    "        # -------------------------\n",
    "        final_scores = {k: v for k, v in final_scores.items() if k.startswith(pref)}\n",
    "        \n",
    "        # Sort and get top-k\n",
    "        sorted_classes = sorted(final_scores.items(), key=lambda x: -x[1])\n",
    "        top_classes = [class_name for class_name, _ in sorted_classes[:top_k]]\n",
    "        \n",
    "        # Backfill if < 3\n",
    "        fillers = [f\"{pref}Neither:NA\"] + ([f\"{pref}Correct:NA\"] if pref == \"True_\" else [])\n",
    "        for f in fillers:\n",
    "            if len(top_classes) >= 3: break\n",
    "            if f not in top_classes:\n",
    "                top_classes.append(f)\n",
    "        while len(top_classes) < 3:\n",
    "            top_classes.append(fillers[0])\n",
    "        \n",
    "        final_predictions.append(' '.join(top_classes))\n",
    "    \n",
    "    return final_predictions\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Run ensemble\n",
    "# -------------------------\n",
    "w1, w2, w3 = 1.2, 1.0, 0.8\n",
    "prob_files = [\n",
    "    '/kaggle/working/submission_deepseek_probabilities.csv',\n",
    "    '/kaggle/working/submission_gemma_prob.csv',\n",
    "    '/kaggle/working/submission_qwen3_probabilities.csv'\n",
    "]\n",
    "\n",
    "predictions = ensemble_with_disagreement_handling(\n",
    "    prob_files, \n",
    "    model_weights=[w1, w2, w3],  \n",
    "    top_k=3\n",
    ")\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'row_id': test_df.row_id.values,\n",
    "    'Category:Misconception': predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(submission.head())"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 12957508,
     "sourceId": 104383,
     "sourceType": "competition"
    },
    {
     "datasetId": 7930680,
     "sourceId": 12559632,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7930694,
     "sourceId": 12559652,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8039184,
     "sourceId": 12719174,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8045877,
     "sourceId": 12729471,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 334.993131,
   "end_time": "2025-10-15T07:38:38.036602",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-15T07:33:03.043471",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
