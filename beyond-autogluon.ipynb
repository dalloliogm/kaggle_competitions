{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":98450,"databundleVersionId":11749951,"sourceType":"competition"}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/dalloliogm/beyond-autogluon?scriptVersionId=239128545\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# Install necessary libraries\n!pip install -q autogluon[multimodal]\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-11T17:20:52.495519Z","iopub.execute_input":"2025-05-11T17:20:52.496166Z","iopub.status.idle":"2025-05-11T17:22:41.930524Z","shell.execute_reply.started":"2025-05-11T17:20:52.496142Z","shell.execute_reply":"2025-05-11T17:22:41.929743Z"}},"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: autogluon 1.3.0 does not provide the extra 'multimodal'\u001b[0m\u001b[33m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.7/222.7 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.5/454.5 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m382.4/382.4 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.2/181.2 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.8/275.8 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.0/819.0 kB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.9/125.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m103.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m354.4/354.4 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m101.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m94.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.3/135.3 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncategory-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.6.1 which is incompatible.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\nibis-framework 9.2.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import autogluon.core as ag\n#from autogluon import ImagePredictor\nimport pandas as pd\nimport os\nimport numpy as np\nfrom autogluon.multimodal import MultiModalPredictor\nfrom PIL import Image\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Convert images to PNG\n\nAutogluon doesn't read .npy images, so we save them as png","metadata":{}},{"cell_type":"code","source":"# Path where the images are saved\nimage_folder = '/kaggle/working/hyperspectral_images/'\n\n# Read the train.csv file that contains the labels\ntrain_df = pd.read_csv('/kaggle/input/beyond-visible-spectrum-ai-for-agriculture-2025/train.csv')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\n# Define the output directory where you will save the images\noutput_dir = '/kaggle/working/hyperspectral_images/'\n\n# Create the directory if it doesn't exist\nos.makedirs(output_dir, exist_ok=True)\n\n# Convert the .npy files to image files and save them\ndef save_image_from_npy(image_name, image_data):\n    # Ensure image has correct dimensions (e.g., 128x128x125)\n    if image_data.shape == (128, 128, 125):\n        # Normalize the data to the range 0-255\n        # Here, we'll just take the first band for simplicity\n        image = image_data[:, :, 0]  # Extract the first band (change if you want to visualize different bands)\n        image = np.clip(image, 0, 255)  # Clip values to valid image range\n        image = image.astype(np.uint8)  # Convert to unsigned 8-bit integer type\n        image_path = os.path.join(output_dir, image_name.replace('.npy', '.png'))\n        # Convert numpy array to image using PIL\n        pil_image = Image.fromarray(image)\n        pil_image.save(image_path)\n        #print(f\"Saved {image_name}\")\n    else:\n        print(f\"Skipping {image_name} due to unexpected shape {image_data.shape}\")\n\n# Loop through the training data and save the images\nfor idx, row in train_df.iterrows():\n    try:\n        # Load the .npy image\n        image = load_npy_image(row['id'])\n        \n        # Check the shape of the image and reshape if necessary\n        save_image_from_npy(row['id'], image)\n    \n    except ValueError as e:\n        print(f\"Error loading {row['id']}: {e}\")\n        continue  # Skip the image and continue with the next one\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T17:31:27.407857Z","iopub.execute_input":"2025-05-11T17:31:27.408152Z","iopub.status.idle":"2025-05-11T17:31:33.676993Z","shell.execute_reply.started":"2025-05-11T17:31:27.408128Z","shell.execute_reply":"2025-05-11T17:31:33.676363Z"}},"outputs":[{"name":"stdout","text":"Skipping sample2411.npy due to unexpected shape (128, 57, 125)\nSkipping sample2143.npy due to unexpected shape (128, 57, 125)\nSkipping sample1875.npy due to unexpected shape (128, 57, 125)\nSkipping sample1071.npy due to unexpected shape (128, 57, 125)\nSkipping sample736.npy due to unexpected shape (128, 57, 125)\nSkipping sample602.npy due to unexpected shape (128, 57, 125)\nSkipping sample133.npy due to unexpected shape (128, 57, 125)\nSkipping sample2076.npy due to unexpected shape (128, 57, 125)\nSkipping sample200.npy due to unexpected shape (128, 57, 125)\nError loading sample2451.npy: cannot reshape array of size 1785856 into shape (128,128,125)\nSkipping sample669.npy due to unexpected shape (128, 57, 125)\nSkipping sample2009.npy due to unexpected shape (128, 57, 125)\nSkipping sample267.npy due to unexpected shape (128, 57, 125)\nSkipping sample1339.npy due to unexpected shape (128, 57, 125)\nSkipping sample468.npy due to unexpected shape (128, 57, 125)\nSkipping sample1741.npy due to unexpected shape (128, 57, 125)\nSkipping sample2587.npy due to unexpected shape (128, 57, 125)\nSkipping sample1205.npy due to unexpected shape (128, 57, 125)\nSkipping sample2277.npy due to unexpected shape (128, 57, 125)\nSkipping sample2654.npy due to unexpected shape (128, 57, 125)\nSkipping sample803.npy due to unexpected shape (128, 57, 125)\nSkipping sample1607.npy due to unexpected shape (128, 57, 125)\nSkipping sample937.npy due to unexpected shape (128, 57, 125)\nSkipping sample2344.npy due to unexpected shape (128, 57, 125)\nSkipping sample1808.npy due to unexpected shape (128, 57, 125)\nSkipping sample1004.npy due to unexpected shape (128, 57, 125)\nSkipping sample334.npy due to unexpected shape (128, 57, 125)\nSkipping sample1473.npy due to unexpected shape (128, 57, 125)\nSkipping sample1272.npy due to unexpected shape (128, 57, 125)\nSkipping sample535.npy due to unexpected shape (128, 57, 125)\nSkipping sample1942.npy due to unexpected shape (128, 57, 125)\nSkipping sample1674.npy due to unexpected shape (128, 57, 125)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"\n\n# Map the image filenames to the new .png file paths\ntrain_df['image_path'] = train_df['id'].apply(lambda x: os.path.join(image_folder, x.replace('.npy', '.png')))\n\n# Now the dataframe has 'image_path' and 'label' columns\n# Preview the updated dataframe\nprint(train_df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T17:32:40.330408Z","iopub.execute_input":"2025-05-11T17:32:40.331107Z","iopub.status.idle":"2025-05-11T17:32:40.349178Z","shell.execute_reply.started":"2025-05-11T17:32:40.331073Z","shell.execute_reply":"2025-05-11T17:32:40.34863Z"}},"outputs":[{"name":"stdout","text":"               id  label                                         image_path\n0   sample697.npy      7  /kaggle/working/hyperspectral_images/sample697...\n1    sample54.npy     81  /kaggle/working/hyperspectral_images/sample54.png\n2  sample2270.npy      4  /kaggle/working/hyperspectral_images/sample227...\n3  sample1401.npy     99  /kaggle/working/hyperspectral_images/sample140...\n4  sample1901.npy     43  /kaggle/working/hyperspectral_images/sample190...\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"## Running Autogluon prediction","metadata":{}},{"cell_type":"code","source":"from autogluon.multimodal import MultiModalPredictor\n\n# Initialize AutoGluon MultiModalPredictor with label column name\npredictor = MultiModalPredictor(label=\"label\")\n\n# Perform k-fold cross-validation (e.g., 5-fold)\ncv_results = predictor.fit(\n    train_data=train_df,\n    time_limit=3600,  # Set a time limit for training\n    num_bagging_folds=5,  # Number of folds for cross-validation\n    num_bagging_sets=1,   # Number of models to be trained per fold\n    presets='best_quality'\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T17:33:08.879424Z","iopub.execute_input":"2025-05-11T17:33:08.880066Z"}},"outputs":[{"name":"stderr","text":"No path specified. Models will be saved in: \"AutogluonModels/ag-20250511_173308\"\n=================== System Info ===================\nAutoGluon Version:  1.3.0\nPython Version:     3.11.11\nOperating System:   Linux\nPlatform Machine:   x86_64\nPlatform Version:   #1 SMP PREEMPT_DYNAMIC Sun Nov 10 10:07:59 UTC 2024\nCPU Count:          4\nPytorch Version:    2.5.1+cu124\nCUDA Version:       12.4\nMemory Avail:       29.12 GB / 31.35 GB (92.9%)\nDisk Space Avail:   19.49 GB / 19.52 GB (99.9%)\n===================================================\nAutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n\tFirst 10 (of 101) unique label values:  [7, 81, 4, 99, 43, 85, 47, 83, 39, 23]\n\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n/usr/local/lib/python3.11/dist-packages/autogluon/multimodal/data/infer_types.py:248: UserWarning: Among 500 sampled images in column 'image_path', 2% images can't be open. You may need to thoroughly check your data to see the percentage of missing images, and estimate the potential influence. By default, we use an image with zero pixels. You can also set hyperparameter 'data.image.missing_value_strategy' to be 'skip', which skips samples that contain a missing image.\n  warnings.warn(\n\nAutoMM starts to create your model. ✨✨✨\n\nTo track the learning progress, you can open a terminal and launch Tensorboard:\n    ```shell\n    # Assume you have installed tensorboard\n    tensorboard --logdir /kaggle/working/AutogluonModels/ag-20250511_173308\n    ```\n\nINFO: Seed set to 0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/395M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6950b74f549f44088b988bfe5785a7ad"}},"metadata":{}},{"name":"stderr","text":"GPU Count: 1\nGPU Count to be Used: 1\n\nINFO: Using 16bit Automatic Mixed Precision (AMP)\nINFO: GPU available: True (cuda), used: True\nINFO: TPU available: False, using: 0 TPU cores\nINFO: HPU available: False, using: 0 HPUs\nINFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\nINFO: \n  | Name              | Type                            | Params | Mode \n------------------------------------------------------------------------------\n0 | model             | TimmAutoModelForImagePrediction | 96.0 M | train\n1 | validation_metric | MulticlassAccuracy              | 0      | train\n2 | loss_func         | CrossEntropyLoss                | 0      | train\n------------------------------------------------------------------------------\n96.0 M    Trainable params\n0         Non-trainable params\n96.0 M    Total params\n383.964   Total estimated model params size (MB)\n863       Modules in train mode\n0         Modules in eval mode\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"929a0e84ab144cc694a288c1a43a4518"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"INFO: Epoch 0, global step 6: 'val_accuracy' reached 0.00917 (best 0.00917), saving model to '/kaggle/working/AutogluonModels/ag-20250511_173308/epoch=0-step=6.ckpt' as top 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"INFO: Epoch 0, global step 14: 'val_accuracy' reached 0.00459 (best 0.00917), saving model to '/kaggle/working/AutogluonModels/ag-20250511_173308/epoch=0-step=14.ckpt' as top 3\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"### Plotting CV scores","metadata":{}},{"cell_type":"code","source":"# Extract the cross-validation results\ncv_scores = cv_results['cv_results']['mean_test_score']  # Mean CV score per fold\n\n# Plot the CV scores\nplt.figure(figsize=(10, 6))\nplt.plot(range(1, len(cv_scores) + 1), cv_scores, marker='o', linestyle='-', color='b')\nplt.title(\"Cross-Validation Scores per Fold\")\nplt.xlabel(\"Fold\")\nplt.ylabel(\"CV Score (Mean Test Score)\")\nplt.grid(True)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Predicting and creating submission","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport os\n\n# Path where the images are saved\nimage_folder = '/kaggle/working/hyperspectral_images/'\n\n# Read the test.csv file that contains the test image IDs\ntest_df = pd.read_csv('/kaggle/input/beyond-visible-spectrum-ai-for-agriculture-2025/test.csv')\n\n# Map the image filenames to the .png file paths\ntest_df['image_path'] = test_df['id'].apply(lambda x: os.path.join(image_folder, x.replace('.npy', '.png')))\n\n# Make predictions using the trained AutoGluon model\npredictions = predictor.predict(test_df['image_path'])\n\n# Prepare the submission DataFrame\nsubmission_df = pd.DataFrame({\n    'id': test_df['id'],  # The IDs from the test.csv\n    'label': predictions   # The predicted labels from the model\n})\n\n# Save the submission file\nsubmission_df.to_csv('submission.csv', index=False)\n\n# Optionally, show the first few rows of the submission file\nprint(submission_df.head())\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}