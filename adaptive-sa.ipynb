{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fce5bcb",
   "metadata": {
    "papermill": {
     "duration": 0.003092,
     "end_time": "2026-01-06T13:43:23.853022",
     "exception": false,
     "start_time": "2026-01-06T13:43:23.849930",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# This Simulated Annealing Is Designed for Teaching Purposes\n",
    "\n",
    "The main goal of this simulated annealing framework is to help everyone learn how to tune parameters and how to improve their own annealing strategies.\n",
    "\n",
    "First of all, temperature selection is critical and must be tested based on your specific problem. Different temperature settings can lead to improvements under different conditions.\n",
    "    For the initial temperature, if you observe significant early improvements, it can be set relatively high, for example in the range of 8–16. When progress slows down in later stages, it is better to gradually reduce the initial temperature, such as to 3–1. The ending temperature is generally not recommended to be changed frequently, although you can still experiment to find a more suitable value if needed.\n",
    "\n",
    "Second, regarding how to improve your simulated annealing, you should first analyze what problems exist in your current implementation. In my experience, many annealing implementations are generated by AI, and AI often makes a critical mistake: it sets the movement or rotation step sizes too large. However, in the later stages of optimization, each object (e.g., each tree) is already positioned within a very small range. Large perturbations at this stage cause the algorithm to waste a lot of time exploring irrelevant or unproductive regions.\n",
    "\n",
    "Third, if you are unsure about how to choose appropriate movement or rotation parameters, you can ask AI to add adaptive step-size mechanisms. This approach can significantly reduce the time spent on manual parameter tuning. However, its limitation is that convergence is usually slower, so it should be used with this trade-off in mind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59e27d98",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-06T13:43:23.860275Z",
     "iopub.status.busy": "2026-01-06T13:43:23.859841Z",
     "iopub.status.idle": "2026-01-06T13:43:23.883016Z",
     "shell.execute_reply": "2026-01-06T13:43:23.882014Z"
    },
    "papermill": {
     "duration": 0.029686,
     "end_time": "2026-01-06T13:43:23.885029",
     "exception": false,
     "start_time": "2026-01-06T13:43:23.855343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing sa.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile sa.py\n",
    "import pandas as pd\n",
    "from decimal import Decimal, getcontext\n",
    "from shapely import affinity\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.strtree import STRtree\n",
    "import time\n",
    "import multiprocessing\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import argparse\n",
    "\n",
    "getcontext().prec = 50\n",
    "scale_factor = Decimal('1e18')\n",
    "\n",
    "class ChristmasTree:\n",
    "    def __init__(self, center_x='0', center_y='0', angle='0', item_id=None):\n",
    "        self.center_x = Decimal(center_x)\n",
    "        self.center_y = Decimal(center_y)\n",
    "        self.angle = Decimal(angle)\n",
    "        self.item_id = item_id\n",
    "        self.polygon = self._create_polygon()\n",
    "\n",
    "    def _create_polygon(self):\n",
    "        trunk_w = Decimal('0.15'); trunk_h = Decimal('0.2')\n",
    "        base_w = Decimal('0.7'); base_y = Decimal('0.0')\n",
    "        mid_w = Decimal('0.4'); tier_2_y = Decimal('0.25')\n",
    "        top_w = Decimal('0.25'); tier_1_y = Decimal('0.5')\n",
    "        tip_y = Decimal('0.8'); trunk_bottom_y = -trunk_h\n",
    "\n",
    "        initial_polygon = Polygon([\n",
    "            (Decimal('0.0') * scale_factor, tip_y * scale_factor),\n",
    "            (top_w / Decimal('2') * scale_factor, tier_1_y * scale_factor),\n",
    "            (top_w / Decimal('4') * scale_factor, tier_1_y * scale_factor),\n",
    "            (mid_w / Decimal('2') * scale_factor, tier_2_y * scale_factor),\n",
    "            (mid_w / Decimal('4') * scale_factor, tier_2_y * scale_factor),\n",
    "            (base_w / Decimal('2') * scale_factor, base_y * scale_factor),\n",
    "            (trunk_w / Decimal('2') * scale_factor, base_y * scale_factor),\n",
    "            (trunk_w / Decimal('2') * scale_factor, trunk_bottom_y * scale_factor),\n",
    "            (-(trunk_w / Decimal('2')) * scale_factor, trunk_bottom_y * scale_factor),\n",
    "            (-(trunk_w / Decimal('2')) * scale_factor, base_y * scale_factor),\n",
    "            (-(base_w / Decimal('2')) * scale_factor, base_y * scale_factor),\n",
    "            (-(mid_w / Decimal('4')) * scale_factor, tier_2_y * scale_factor),\n",
    "            (-(mid_w / Decimal('2')) * scale_factor, tier_2_y * scale_factor),\n",
    "            (-(top_w / Decimal('4')) * scale_factor, tier_1_y * scale_factor),\n",
    "            (-(top_w / Decimal('2')) * scale_factor, tier_1_y * scale_factor),\n",
    "        ])\n",
    "        rotated = affinity.rotate(initial_polygon, float(self.angle), origin=(0, 0))\n",
    "        return affinity.translate(\n",
    "            rotated,\n",
    "            xoff=float(self.center_x * scale_factor),\n",
    "            yoff=float(self.center_y * scale_factor)\n",
    "        )\n",
    "\n",
    "    def clone(self) -> \"ChristmasTree\":\n",
    "        new_tree = ChristmasTree.__new__(ChristmasTree)\n",
    "        new_tree.center_x = self.center_x\n",
    "        new_tree.center_y = self.center_y\n",
    "        new_tree.angle = self.angle\n",
    "        new_tree.item_id = self.item_id\n",
    "        new_tree.polygon = self.polygon\n",
    "        return new_tree\n",
    "\n",
    "\n",
    "def splitmix64(x: int) -> int:\n",
    "    \"\"\"Deterministic 64-bit mixer (same spirit as C++ SplitMix64).\"\"\"\n",
    "    x &= 0xFFFFFFFFFFFFFFFF\n",
    "    x = (x + 0x9E3779B97F4A7C15) & 0xFFFFFFFFFFFFFFFF\n",
    "    z = x\n",
    "    z = (z ^ (z >> 30)) * 0xBF58476D1CE4E5B9 & 0xFFFFFFFFFFFFFFFF\n",
    "    z = (z ^ (z >> 27)) * 0x94D049BB133111EB & 0xFFFFFFFFFFFFFFFF\n",
    "    z = z ^ (z >> 31)\n",
    "    return z & 0xFFFFFFFFFFFFFFFF\n",
    "\n",
    "\n",
    "def parse_int_range(s: str):\n",
    "    \"\"\"Parse '40-80' (inclusive) or single int like '12'. Returns (min,max) or None.\"\"\"\n",
    "    if s is None:\n",
    "        return None\n",
    "    s = str(s).strip()\n",
    "    if not s:\n",
    "        return None\n",
    "    if '-' in s:\n",
    "        a, b = s.split('-', 1)\n",
    "        a = int(a.strip())\n",
    "        b = int(b.strip())\n",
    "        if a > b:\n",
    "            a, b = b, a\n",
    "        return a, b\n",
    "    v = int(s)\n",
    "    return v, v\n",
    "\n",
    "\n",
    "def get_tree_list_side_length_fast(polygons) -> float:\n",
    "    if not polygons:\n",
    "        return 0.0\n",
    "    minx, miny, maxx, maxy = polygons[0].bounds\n",
    "    for p in polygons[1:]:\n",
    "        b = p.bounds\n",
    "        if b[0] < minx: minx = b[0]\n",
    "        if b[1] < miny: miny = b[1]\n",
    "        if b[2] > maxx: maxx = b[2]\n",
    "        if b[3] > maxy: maxy = b[3]\n",
    "    return max(maxx - minx, maxy - miny) / float(scale_factor)\n",
    "\n",
    "\n",
    "def validate_no_overlaps(polygons):\n",
    "    if not polygons:\n",
    "        return True\n",
    "\n",
    "    strtree = STRtree(polygons)\n",
    "\n",
    "    for i, poly in enumerate(polygons):\n",
    "        candidates = strtree.query(poly)\n",
    "\n",
    "        for cand in candidates:\n",
    "            if hasattr(cand, \"geom_type\"):\n",
    "                other = cand\n",
    "                if other is poly:\n",
    "                    continue\n",
    "            else:\n",
    "                j = int(cand)\n",
    "                if j == i:\n",
    "                    continue\n",
    "                other = polygons[j]\n",
    "\n",
    "            if (not poly.disjoint(other)) and (not poly.touches(other)):\n",
    "                return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def parse_csv(csv_path):\n",
    "    print(f'Loading csv: {csv_path}')\n",
    "    result = pd.read_csv(csv_path)\n",
    "    for col in ['x', 'y', 'deg']:\n",
    "        if result[col].dtype == object:\n",
    "            result[col] = result[col].astype(str).str.strip('s')\n",
    "\n",
    "    # id is usually like \"<group>_<item>\"; keep item_id so we can preserve IDs on save.\n",
    "    result[['group_id', 'item_id']] = result['id'].str.split('_', n=1, expand=True)\n",
    "\n",
    "    dict_of_tree_list = {}\n",
    "    for group_id, group_data in result.groupby('group_id'):\n",
    "        # iterrows -> itertuples\n",
    "        tree_list = [\n",
    "            ChristmasTree(center_x=str(row.x), center_y=str(row.y), angle=str(row.deg), item_id=str(row.item_id))\n",
    "            for row in group_data.itertuples(index=False)\n",
    "        ]\n",
    "        dict_of_tree_list[group_id] = tree_list\n",
    "    return dict_of_tree_list\n",
    "\n",
    "\n",
    "def save_dict_to_csv(dict_of_tree_list, output_path):\n",
    "    print(f\"Saving solution to {output_path}...\")\n",
    "    data = []\n",
    "    sorted_keys = sorted(dict_of_tree_list.keys(), key=lambda x: int(x))\n",
    "    for group_id in sorted_keys:\n",
    "        trees = dict_of_tree_list[group_id]\n",
    "        for i, tree in enumerate(trees):\n",
    "            item_id = tree.item_id if tree.item_id is not None else str(i)\n",
    "            data.append({\n",
    "                'id': f\"{group_id}_{item_id}\",\n",
    "                'x': f\"s{tree.center_x}\",\n",
    "                'y': f\"s{tree.center_y}\",\n",
    "                'deg': f\"s{tree.angle}\",\n",
    "            })\n",
    "    df = pd.DataFrame(data)[['id', 'x', 'y', 'deg']]\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(\"Save complete.\")\n",
    "\n",
    "\n",
    "\n",
    "def run_simulated_annealing(args):\n",
    "    (\n",
    "        group_id,\n",
    "        initial_trees,\n",
    "        max_iterations,\n",
    "        t_start,\n",
    "        t_end,\n",
    "        base_seed,\n",
    "        adapt_window,\n",
    "        target_accept,\n",
    "        adapt_strength,\n",
    "        t_min_multiplier,\n",
    "        t_max_multiplier,\n",
    "        stagnation_iters,\n",
    "        reheat_fraction,\n",
    "        max_reheats,\n",
    "    ) = args\n",
    "    n_trees = len(initial_trees)\n",
    "\n",
    "    gid_int = int(group_id)\n",
    "    task_seed = splitmix64((int(base_seed) ^ (gid_int * 0x9E3779B97F4A7C15)) & 0xFFFFFFFFFFFFFFFF)\n",
    "    rng = random.Random(task_seed)\n",
    "\n",
    "    is_small_n = n_trees <= 50\n",
    "\n",
    "    if is_small_n:\n",
    "        effective_max_iter = max_iterations * 3\n",
    "        effective_t_start = t_start * 2.0\n",
    "        gravity_weight = 1e-4\n",
    "    else:\n",
    "        effective_max_iter = max_iterations\n",
    "        effective_t_start = t_start\n",
    "        gravity_weight = 1e-6\n",
    "\n",
    "    state = []\n",
    "    for t in initial_trees:\n",
    "        cx_float = float(t.center_x) * float(scale_factor)\n",
    "        cy_float = float(t.center_y) * float(scale_factor)\n",
    "        state.append({\n",
    "            'poly': t.polygon,\n",
    "            'cx': cx_float,\n",
    "            'cy': cy_float,\n",
    "            'angle': float(t.angle),\n",
    "        })\n",
    "\n",
    "    current_polys = [s['poly'] for s in state]\n",
    "    current_bounds = [p.bounds for p in current_polys]\n",
    "\n",
    "    scale_f = float(scale_factor)\n",
    "    inv_scale_f = 1.0 / scale_f\n",
    "    inv_scale_f2 = 1.0 / (scale_f * scale_f)\n",
    "\n",
    "    def _envelope_from_bounds(bounds_list):\n",
    "        if not bounds_list:\n",
    "            return (0.0, 0.0, 0.0, 0.0)\n",
    "        minx, miny, maxx, maxy = bounds_list[0]\n",
    "        for b in bounds_list[1:]:\n",
    "            if b[0] < minx: minx = b[0]\n",
    "            if b[1] < miny: miny = b[1]\n",
    "            if b[2] > maxx: maxx = b[2]\n",
    "            if b[3] > maxy: maxy = b[3]\n",
    "        return (minx, miny, maxx, maxy)\n",
    "\n",
    "    def _envelope_from_bounds_replace(bounds_list, replace_i: int, replace_bounds):\n",
    "        if not bounds_list:\n",
    "            return (0.0, 0.0, 0.0, 0.0)\n",
    "        b0 = replace_bounds if replace_i == 0 else bounds_list[0]\n",
    "        minx, miny, maxx, maxy = b0\n",
    "        for i, b in enumerate(bounds_list[1:], start=1):\n",
    "            if i == replace_i:\n",
    "                b = replace_bounds\n",
    "            if b[0] < minx: minx = b[0]\n",
    "            if b[1] < miny: miny = b[1]\n",
    "            if b[2] > maxx: maxx = b[2]\n",
    "            if b[3] > maxy: maxy = b[3]\n",
    "        return (minx, miny, maxx, maxy)\n",
    "\n",
    "    def _side_len_from_env(env):\n",
    "        minx, miny, maxx, maxy = env\n",
    "        return max(maxx - minx, maxy - miny) * inv_scale_f\n",
    "\n",
    "\n",
    "    env = _envelope_from_bounds(current_bounds)\n",
    "    dist_sum = 0.0\n",
    "    for s in state:\n",
    "        dist_sum += s['cx'] * s['cx'] + s['cy'] * s['cy']\n",
    "\n",
    "    # Dynamic boundary penalty: keep a moving limit_size that tightens\n",
    "    # when we find a new best feasible side.\n",
    "    boundary_penalty_coeff = 1000.0\n",
    "    tighten_factor = 0.995\n",
    "\n",
    "    def boundary_penalty(env_local, replace_i=None, replace_bounds=None, limit_size_unscaled=0.0):\n",
    "        if not (limit_size_unscaled > 0.0):\n",
    "            return 0.0\n",
    "        # Penalize any tree bbox that exceeds the square [minx, minx+limit] x [miny, miny+limit].\n",
    "        env_minx, env_miny, _, _ = env_local\n",
    "        x_limit_scaled = env_minx + limit_size_unscaled * scale_f\n",
    "        y_limit_scaled = env_miny + limit_size_unscaled * scale_f\n",
    "        penalty = 0.0\n",
    "        for i in range(n_trees):\n",
    "            b = replace_bounds if (replace_bounds is not None and i == replace_i) else current_bounds[i]\n",
    "            # Only penalize overflow on +x/+y, matching the C++ change request.\n",
    "            dx = b[2] - x_limit_scaled\n",
    "            if dx > 0.0:\n",
    "                penalty += boundary_penalty_coeff * (dx * dx) * inv_scale_f2\n",
    "            dy = b[3] - y_limit_scaled\n",
    "            if dy > 0.0:\n",
    "                penalty += boundary_penalty_coeff * (dy * dy) * inv_scale_f2\n",
    "        return penalty\n",
    "\n",
    "    def energy_from(env_local, dist_sum_local, progress01, replace_i=None, replace_bounds=None, limit_size_unscaled=0.0):\n",
    "        side_len = _side_len_from_env(env_local)\n",
    "        normalized_dist = (dist_sum_local * inv_scale_f2) / max(1, n_trees)\n",
    "        grav_w = gravity_weight * max(0.0, 1.0 - progress01)\n",
    "        penalty = boundary_penalty(env_local, replace_i, replace_bounds, limit_size_unscaled)\n",
    "        # Match C++: side^2 + gravity + penalty\n",
    "        return (side_len * side_len) + grav_w * normalized_dist + penalty, side_len\n",
    "\n",
    "    limit_size = _side_len_from_env(env)\n",
    "    current_energy, current_side_len = energy_from(env, dist_sum, 0.0, None, None, limit_size)\n",
    "\n",
    "    best_state_params = [{'cx': s['cx'], 'cy': s['cy'], 'angle': s['angle']} for s in state]\n",
    "    best_real_score = current_side_len\n",
    "\n",
    "    # Temperature schedule (kept for acceptance probability) with adaptive multiplier + clamps.\n",
    "    schedule_T = effective_t_start\n",
    "    cooling_rate = math.pow(t_end / effective_t_start, 1.0 / effective_max_iter)\n",
    "    T_mult = 1.0\n",
    "    T_abs_min = max(0.0, t_end * max(1.0, float(t_min_multiplier)))\n",
    "    T_abs_max = max(T_abs_min, effective_t_start * max(1.0, float(t_max_multiplier)))\n",
    "\n",
    "    def clamp_T(x):\n",
    "        if x < T_abs_min:\n",
    "            return T_abs_min\n",
    "        if x > T_abs_max:\n",
    "            return T_abs_max\n",
    "        return x\n",
    "\n",
    "    T = clamp_T(schedule_T * T_mult)\n",
    "\n",
    "    # Adaptive temperature control (acceptance-rate targeting)\n",
    "    adapt_window = max(0, int(adapt_window))\n",
    "    try:\n",
    "        target_accept = float(target_accept)\n",
    "    except Exception:\n",
    "        target_accept = 0.25\n",
    "    if not (0.0 < target_accept < 1.0):\n",
    "        target_accept = 0.25\n",
    "    try:\n",
    "        adapt_strength = float(adapt_strength)\n",
    "    except Exception:\n",
    "        adapt_strength = 0.0\n",
    "    if not (adapt_strength >= 0.0):\n",
    "        adapt_strength = 0.0\n",
    "    window_trials = 0\n",
    "    window_accepts = 0\n",
    "\n",
    "    # Stagnation reheating\n",
    "    stagnation_iters = max(0, int(stagnation_iters))\n",
    "    try:\n",
    "        reheat_fraction = float(reheat_fraction)\n",
    "    except Exception:\n",
    "        reheat_fraction = 0.0\n",
    "    if not (reheat_fraction >= 0.0):\n",
    "        reheat_fraction = 0.0\n",
    "    max_reheats = int(max_reheats)\n",
    "    reheats_done = 0\n",
    "    last_progress_it = 0  # last time best_real_score improved OR we reheated\n",
    "\n",
    "    # Adaptive step-size control (decoupled from temperature)\n",
    "    class StepController:\n",
    "        def __init__(self):\n",
    "            self.move_scale = 1.0\n",
    "            self.rotate_scale = 1.0\n",
    "            self.attempts = 0\n",
    "            self.accepts = 0\n",
    "\n",
    "    step_ctrl = StepController()\n",
    "    STEP_BATCH = 500\n",
    "    STEP_TARGET = 0.25\n",
    "    STEP_MIN = 1e-5\n",
    "    STEP_MAX = 10.0\n",
    "\n",
    "    def clamp_step(x):\n",
    "        if x < STEP_MIN:\n",
    "            return STEP_MIN\n",
    "        if x > STEP_MAX:\n",
    "            return STEP_MAX\n",
    "        return x\n",
    "\n",
    "    def step_update(accepted: bool):\n",
    "        step_ctrl.attempts += 1\n",
    "        if accepted:\n",
    "            step_ctrl.accepts += 1\n",
    "        if step_ctrl.attempts >= STEP_BATCH:\n",
    "            acc = step_ctrl.accepts / max(1, step_ctrl.attempts)\n",
    "            if acc > STEP_TARGET:\n",
    "                step_ctrl.move_scale = clamp_step(step_ctrl.move_scale * 1.02)\n",
    "                step_ctrl.rotate_scale = clamp_step(step_ctrl.rotate_scale * 1.02)\n",
    "            elif acc < STEP_TARGET:\n",
    "                step_ctrl.move_scale = clamp_step(step_ctrl.move_scale * 0.98)\n",
    "                step_ctrl.rotate_scale = clamp_step(step_ctrl.rotate_scale * 0.98)\n",
    "            step_ctrl.attempts = 0\n",
    "            step_ctrl.accepts = 0\n",
    "\n",
    "    for i in range(effective_max_iter):\n",
    "        progress = i / effective_max_iter\n",
    "\n",
    "        # Stagnation-triggered reheating (based on best improvements)\n",
    "        if stagnation_iters > 0 and (i - last_progress_it) >= stagnation_iters:\n",
    "            if max_reheats == 0 or reheats_done < max_reheats:\n",
    "                target_T = effective_t_start * reheat_fraction\n",
    "                if target_T > 0.0:\n",
    "                    denom = max(1e-30, schedule_T)\n",
    "                    T_mult = max(T_mult, target_T / denom)\n",
    "                    T = clamp_T(schedule_T * T_mult)\n",
    "                    reheats_done += 1\n",
    "                    # Reset temp adaptation window so it reflects post-reheat dynamics.\n",
    "                    window_trials = 0\n",
    "                    window_accepts = 0\n",
    "                last_progress_it = i\n",
    "\n",
    "        # Adaptive step sizes (decoupled from T)\n",
    "        base_move = 0.005 if is_small_n else 0.001\n",
    "        base_rotate = 0.001 if is_small_n else 0.002\n",
    "        move_scale = base_move * step_ctrl.move_scale\n",
    "        rotate_scale = base_rotate * step_ctrl.rotate_scale\n",
    "\n",
    "        idx = rng.randint(0, n_trees - 1)\n",
    "        target = state[idx]\n",
    "\n",
    "        orig_poly = target['poly']\n",
    "        orig_bounds = current_bounds[idx]\n",
    "        orig_cx, orig_cy, orig_angle = target['cx'], target['cy'], target['angle']\n",
    "\n",
    "        dx = (rng.random() - 0.5) * scale_f * 0.1 * move_scale\n",
    "        dy = (rng.random() - 0.5) * scale_f * 0.1 * move_scale\n",
    "        d_angle = (rng.random() - 0.5) * rotate_scale\n",
    "\n",
    "        rotated_poly = affinity.rotate(orig_poly, d_angle, origin=(orig_cx, orig_cy))\n",
    "        new_poly = affinity.translate(rotated_poly, xoff=dx, yoff=dy)\n",
    "        new_bounds = new_poly.bounds\n",
    "        minx, miny, maxx, maxy = new_bounds\n",
    "\n",
    "        new_cx = orig_cx + dx\n",
    "        new_cy = orig_cy + dy\n",
    "        new_angle = orig_angle + d_angle\n",
    "\n",
    "        collision = False\n",
    "        for k in range(n_trees):\n",
    "            if k == idx:\n",
    "                continue\n",
    "            ox1, oy1, ox2, oy2 = current_bounds[k]\n",
    "            if maxx < ox1 or minx > ox2 or maxy < oy1 or miny > oy2:\n",
    "                continue\n",
    "            other = current_polys[k]\n",
    "\n",
    "            if (not new_poly.disjoint(other)) and (not new_poly.touches(other)):\n",
    "                collision = True\n",
    "                break\n",
    "\n",
    "        if collision:\n",
    "            # Count as an attempt for the step controller.\n",
    "            step_update(False)\n",
    "\n",
    "            schedule_T *= cooling_rate\n",
    "            T = clamp_T(schedule_T * T_mult)\n",
    "            continue\n",
    "\n",
    "        old_d = orig_cx * orig_cx + orig_cy * orig_cy\n",
    "        new_d = new_cx * new_cx + new_cy * new_cy\n",
    "        cand_dist_sum = dist_sum - old_d + new_d\n",
    "\n",
    "        env_minx, env_miny, env_maxx, env_maxy = env\n",
    "        need_recompute = (\n",
    "            (orig_bounds[0] == env_minx and new_bounds[0] > env_minx) or\n",
    "            (orig_bounds[1] == env_miny and new_bounds[1] > env_miny) or\n",
    "            (orig_bounds[2] == env_maxx and new_bounds[2] < env_maxx) or\n",
    "            (orig_bounds[3] == env_maxy and new_bounds[3] < env_maxy)\n",
    "        )\n",
    "        if need_recompute:\n",
    "            cand_env = _envelope_from_bounds_replace(current_bounds, idx, new_bounds)\n",
    "        else:\n",
    "            cand_env = (\n",
    "                min(env_minx, new_bounds[0]),\n",
    "                min(env_miny, new_bounds[1]),\n",
    "                max(env_maxx, new_bounds[2]),\n",
    "                max(env_maxy, new_bounds[3]),\n",
    "            )\n",
    "\n",
    "        new_energy, new_real_score = energy_from(\n",
    "            cand_env,\n",
    "            cand_dist_sum,\n",
    "            progress,\n",
    "            replace_i=idx,\n",
    "            replace_bounds=new_bounds,\n",
    "            limit_size_unscaled=limit_size,\n",
    "        )\n",
    "        delta = new_energy - current_energy\n",
    "\n",
    "        accept = False\n",
    "        if delta < 0:\n",
    "            accept = True\n",
    "        else:\n",
    "            if T > 1e-12:\n",
    "                scale = 1000.0 / max(1.0, 2.0 * current_side_len)\n",
    "                prob = math.exp(-delta * scale / T)\n",
    "                accept = rng.random() < prob\n",
    "\n",
    "        # Update adaptive temperature stats only for feasible (non-colliding) proposals.\n",
    "        if adapt_window > 0:\n",
    "            window_trials += 1\n",
    "            if accept:\n",
    "                window_accepts += 1\n",
    "            if window_trials >= adapt_window:\n",
    "                acc = window_accepts / max(1, window_trials)\n",
    "                adj = math.exp(adapt_strength * (target_accept - acc))\n",
    "                adj = max(0.5, min(2.0, adj))\n",
    "                T_mult *= adj\n",
    "                T = clamp_T(schedule_T * T_mult)\n",
    "                window_trials = 0\n",
    "                window_accepts = 0\n",
    "\n",
    "        if accept:\n",
    "            current_polys[idx] = new_poly\n",
    "            current_bounds[idx] = new_bounds\n",
    "            target['poly'] = new_poly\n",
    "            target['cx'] = new_cx\n",
    "            target['cy'] = new_cy\n",
    "            target['angle'] = new_angle\n",
    "\n",
    "            current_energy = new_energy\n",
    "            env = cand_env\n",
    "            dist_sum = cand_dist_sum\n",
    "            current_side_len = new_real_score\n",
    "\n",
    "            if new_real_score < best_real_score:\n",
    "                best_real_score = new_real_score\n",
    "                last_progress_it = i\n",
    "                # Dynamic compression: tighten boundary after finding a new best feasible solution.\n",
    "                limit_size = best_real_score * tighten_factor\n",
    "                for k in range(n_trees):\n",
    "                    best_state_params[k]['cx'] = state[k]['cx']\n",
    "                    best_state_params[k]['cy'] = state[k]['cy']\n",
    "                    best_state_params[k]['angle'] = state[k]['angle']\n",
    "\n",
    "        # Step controller feedback uses accept/reject outcome of this iteration.\n",
    "        step_update(accept)\n",
    "\n",
    "        schedule_T *= cooling_rate\n",
    "        T = clamp_T(schedule_T * T_mult)\n",
    "\n",
    "    final_trees = []\n",
    "    final_polys_check = []\n",
    "    for p in best_state_params:\n",
    "        cx_dec = Decimal(p['cx']) / scale_factor\n",
    "        cy_dec = Decimal(p['cy']) / scale_factor\n",
    "        angle_dec = Decimal(p['angle'])\n",
    "        new_t = ChristmasTree(str(cx_dec), str(cy_dec), str(angle_dec))\n",
    "        final_trees.append(new_t)\n",
    "        final_polys_check.append(new_t.polygon)\n",
    "\n",
    "    if not validate_no_overlaps(final_polys_check):\n",
    "        orig_score = get_tree_list_side_length_fast([t.polygon for t in initial_trees])\n",
    "        return group_id, initial_trees, orig_score\n",
    "\n",
    "    return group_id, final_trees, best_real_score\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"Santa-2025 SA optimizer (Python/Shapely).\")\n",
    "    parser.add_argument(\"--input\", default=\"/kaggle/input/a-bit-better-the-best-open-source-result-for-date/submission.csv\", help=\"Input CSV path\")\n",
    "    parser.add_argument(\"--output\", default=\"/kaggle/working/submission.csv\", help=\"Output CSV path\")\n",
    "    parser.add_argument(\"--iter\", type=int, default=10000, help=\"Base iterations per group\")\n",
    "    parser.add_argument(\"--tstart\", type=float, default=1.0, help=\"Start temperature\")\n",
    "    parser.add_argument(\"--tend\", type=float, default=0.00003, help=\"End temperature\")\n",
    "    parser.add_argument(\"--processes\", default=\"auto\", help=\"Process count or 'auto'\")\n",
    "    parser.add_argument(\"--seed\", type=int, default=4489708, help=\"Deterministic base seed\")\n",
    "    parser.add_argument(\"--range\", default=None, help=\"Only optimize groups in inclusive range a-b\")\n",
    "    parser.add_argument(\"--gid_min\", type=int, default=None, help=\"Only optimize groups >= gid_min\")\n",
    "    parser.add_argument(\"--gid_max\", type=int, default=None, help=\"Only optimize groups <= gid_max\")\n",
    "    parser.add_argument(\"--time_limit_sec\", type=int, default=11.5 * 3600, help=\"Wall time limit\")\n",
    "    parser.add_argument(\"--save_every\", type=int, default=20, help=\"Checkpoint frequency by finished groups\")\n",
    "\n",
    "    # adaptive temperature + reheating\n",
    "    parser.add_argument(\"--adapt_window\", type=int, default=200, help=\"Adaptive temperature window\")\n",
    "    parser.add_argument(\"--target_accept\", type=float, default=0.25, help=\"Target accept rate for adaptive temperature\")\n",
    "    parser.add_argument(\"--adapt_strength\", type=float, default=0.75, help=\"Strength of adaptive temperature updates\")\n",
    "    parser.add_argument(\"--t_min_multiplier\", type=float, default=1.0, help=\"Min T multiplier relative to t_end\")\n",
    "    parser.add_argument(\"--t_max_multiplier\", type=float, default=2.0, help=\"Max T multiplier relative to t_start\")\n",
    "    parser.add_argument(\"--stagnation\", type=int, default=20, help=\"Stagnation iters before reheating\")\n",
    "    parser.add_argument(\"--reheat_fraction\", type=float, default=0.8, help=\"Reheat target as fraction of t_start\")\n",
    "    parser.add_argument(\"--max_reheats\", type=int, default=20, help=\"0 => unlimited reheats\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    INPUT_CSV = args.input\n",
    "    OUTPUT_CSV = args.output\n",
    "\n",
    "    try:\n",
    "        dict_of_tree_list = parse_csv(INPUT_CSV)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Could not find {INPUT_CSV}.\")\n",
    "        return\n",
    "\n",
    "    all_groups_sorted = sorted(dict_of_tree_list.keys(), key=lambda x: int(x), reverse=True)\n",
    "\n",
    "    gid_min = args.gid_min\n",
    "    gid_max = args.gid_max\n",
    "    r = parse_int_range(args.range)\n",
    "    if r is not None:\n",
    "        gid_min, gid_max = r\n",
    "\n",
    "    if gid_min is None:\n",
    "        gid_min = -10**18\n",
    "    if gid_max is None:\n",
    "        gid_max = 10**18\n",
    "\n",
    "    groups_to_optimize = [gid for gid in all_groups_sorted if gid_min <= int(gid) <= gid_max]\n",
    "\n",
    "    MAX_ITER = int(args.iter)\n",
    "    T_START = float(args.tstart)\n",
    "    T_END = float(args.tend)\n",
    "\n",
    "    KAGGLE_TIME_LIMIT_SEC = int(args.time_limit_sec)\n",
    "    SAVE_EVERY_N_GROUPS = int(args.save_every)\n",
    "\n",
    "    tasks = []\n",
    "    for gid in groups_to_optimize:\n",
    "        tasks.append(\n",
    "            (\n",
    "                gid,\n",
    "                dict_of_tree_list[gid],\n",
    "                MAX_ITER,\n",
    "                T_START,\n",
    "                T_END,\n",
    "                args.seed,\n",
    "                args.adapt_window,\n",
    "                args.target_accept,\n",
    "                args.adapt_strength,\n",
    "                args.t_min_multiplier,\n",
    "                args.t_max_multiplier,\n",
    "                args.stagnation,\n",
    "                args.reheat_fraction,\n",
    "                args.max_reheats,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    if str(args.processes).lower() == \"auto\":\n",
    "        num_processes = multiprocessing.cpu_count()\n",
    "    else:\n",
    "        num_processes = max(1, int(args.processes))\n",
    "\n",
    "    # Don't spawn more workers than tasks.\n",
    "    num_processes = min(num_processes, max(1, len(tasks)))\n",
    "\n",
    "    print(f\"Starting SA on {len(tasks)}/{len(all_groups_sorted)} groups using {num_processes} processes...\")\n",
    "    if gid_min != -10**18 or gid_max != 10**18:\n",
    "        print(f\"Group filter: {gid_min}-{gid_max} (inclusive)\")\n",
    "    print(f\"Seed(base): {args.seed}\")\n",
    "    print(f\"Time Limit: {KAGGLE_TIME_LIMIT_SEC / 3600:.2f} hours\")\n",
    "    print(\"Press Ctrl+C to stop early and save progress.\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    improved_count = 0\n",
    "    total_tasks = len(tasks)\n",
    "    finished_tasks = 0\n",
    "\n",
    "    pool = multiprocessing.Pool(processes=num_processes)\n",
    "\n",
    "    try:\n",
    "        results_iter = pool.imap_unordered(run_simulated_annealing, tasks, chunksize=1)\n",
    "\n",
    "        for result in results_iter:\n",
    "            group_id, optimized_trees, score = result\n",
    "            finished_tasks += 1\n",
    "\n",
    "            orig_polys = [t.polygon for t in dict_of_tree_list[group_id]]\n",
    "            orig_score = get_tree_list_side_length_fast(orig_polys)\n",
    "\n",
    "            status_msg = \"\"\n",
    "            if score < orig_score:\n",
    "                diff = orig_score - score\n",
    "                if diff > 1e-12:\n",
    "                    status_msg = f\" -> Improved! (-{diff:.6f})\"\n",
    "                    dict_of_tree_list[group_id] = optimized_trees\n",
    "                    improved_count += 1\n",
    "\n",
    "            elapsed_time = time.time() - start_time\n",
    "            if elapsed_time > KAGGLE_TIME_LIMIT_SEC:\n",
    "                print(\n",
    "                    f\"\\n[WARNING] Time limit approach ({elapsed_time / 3600:.2f}h). \"\n",
    "                    \"Stopping early to save data safely.\"\n",
    "                )\n",
    "                pool.terminate()\n",
    "                break\n",
    "\n",
    "            if finished_tasks % SAVE_EVERY_N_GROUPS == 0:\n",
    "                print(\n",
    "                    f\"   >>> Auto-saving checkpoint at \"\n",
    "                    f\"{finished_tasks}/{total_tasks}...\"\n",
    "                )\n",
    "                save_dict_to_csv(dict_of_tree_list, OUTPUT_CSV)\n",
    "\n",
    "            print(\n",
    "                f\"[{finished_tasks}/{total_tasks}] \"\n",
    "                f\"G:{group_id} {orig_score:.5f}->{score:.5f} {status_msg}\"\n",
    "            )\n",
    "\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        print(f\"\\nOptimization finished normally in {time.time() - start_time:.2f}s\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\n!!! Caught Ctrl+C (KeyboardInterrupt) !!!\")\n",
    "        print(\"Terminating workers and saving current progress...\")\n",
    "        pool.terminate()\n",
    "        pool.join()\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn error occurred: {e}\")\n",
    "        pool.terminate()\n",
    "        pool.join()\n",
    "    finally:\n",
    "        print(f\"Final Save. Total Improved: {improved_count}\")\n",
    "        save_dict_to_csv(dict_of_tree_list, OUTPUT_CSV)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    multiprocessing.freeze_support()\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3774f928",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T13:43:23.890707Z",
     "iopub.status.busy": "2026-01-06T13:43:23.890345Z",
     "iopub.status.idle": "2026-01-06T23:17:08.276177Z",
     "shell.execute_reply": "2026-01-06T23:17:08.275008Z"
    },
    "papermill": {
     "duration": 34424.391243,
     "end_time": "2026-01-06T23:17:08.278453",
     "exception": false,
     "start_time": "2026-01-06T13:43:23.887210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading csv: /kaggle/input/a-bit-better-the-best-open-source-result-for-date/submission.csv\r\n",
      "Starting SA on 200/200 groups using 4 processes...\r\n",
      "Seed(base): 4489708\r\n",
      "Time Limit: 11.50 hours\r\n",
      "Press Ctrl+C to stop early and save progress.\r\n",
      "[1/200] G:197 8.19702->8.19702 \r\n",
      "[2/200] G:198 8.22139->8.22139 \r\n",
      "[3/200] G:199 8.22699->8.22699 \r\n",
      "[4/200] G:200 8.23155->8.23155 \r\n",
      "[5/200] G:194 8.12370->8.12370 \r\n",
      "[6/200] G:195 8.14175->8.14175 \r\n",
      "[7/200] G:193 8.10250->8.10250 \r\n",
      "[8/200] G:196 8.16540->8.16540 \r\n",
      "[9/200] G:192 8.02389->8.02389 \r\n",
      "[10/200] G:191 8.02033->8.02033 \r\n",
      "[11/200] G:190 8.01661->8.01661 \r\n",
      "[12/200] G:189 8.00776->8.00776 \r\n",
      "[13/200] G:188 7.99471->7.99471 \r\n",
      "[14/200] G:187 7.98135->7.98135 \r\n",
      "[15/200] G:185 7.94518->7.94518 \r\n",
      "[16/200] G:186 7.96985->7.96985 \r\n",
      "[17/200] G:183 7.89263->7.89263 \r\n",
      "[18/200] G:182 7.74984->7.74984 \r\n",
      "[19/200] G:181 7.72866->7.72866 \r\n",
      "   >>> Auto-saving checkpoint at 20/200...\r\n",
      "Saving solution to /kaggle/working/submission.csv...\r\n",
      "Save complete.\r\n",
      "[20/200] G:184 7.93232->7.93232 \r\n",
      "[21/200] G:180 7.72539->7.72539 \r\n",
      "[22/200] G:179 7.72043->7.72043 \r\n",
      "[23/200] G:177 7.71573->7.71573 \r\n",
      "[24/200] G:178 7.71582->7.71582 \r\n",
      "[25/200] G:176 7.71568->7.71568 \r\n",
      "[26/200] G:174 7.68605->7.68605 \r\n",
      "[27/200] G:175 7.69887->7.69887 \r\n",
      "[28/200] G:173 7.66378->7.66378 \r\n",
      "[29/200] G:172 7.65768->7.65768 \r\n",
      "[30/200] G:169 7.60818->7.60818 \r\n",
      "[31/200] G:171 7.64129->7.64129 \r\n",
      "[32/200] G:170 7.61953->7.61953  -> Improved! (-0.000000)\r\n",
      "[33/200] G:168 7.47373->7.47373 \r\n",
      "[34/200] G:166 7.45535->7.45535 \r\n",
      "[35/200] G:167 7.45567->7.45567 \r\n",
      "[36/200] G:165 7.44121->7.44121 \r\n",
      "[37/200] G:164 7.43798->7.43798 \r\n",
      "[38/200] G:163 7.41819->7.41819 \r\n",
      "[39/200] G:162 7.40344->7.40344 \r\n",
      "   >>> Auto-saving checkpoint at 40/200...\r\n",
      "Saving solution to /kaggle/working/submission.csv...\r\n",
      "Save complete.\r\n",
      "[40/200] G:161 7.38910->7.38910 \r\n",
      "[41/200] G:160 7.38591->7.38591 \r\n",
      "[42/200] G:159 7.38413->7.38413 \r\n",
      "[43/200] G:158 7.37045->7.37045 \r\n",
      "[44/200] G:157 7.33575->7.33575 \r\n",
      "[45/200] G:156 7.17495->7.17495 \r\n",
      "[46/200] G:154 7.17359->7.17359 \r\n",
      "[47/200] G:155 7.17451->7.17451 \r\n",
      "[48/200] G:153 7.17321->7.17321 \r\n",
      "[49/200] G:152 7.17316->7.17316 \r\n",
      "[50/200] G:150 7.11064->7.11064 \r\n",
      "[51/200] G:149 7.10480->7.10480 \r\n",
      "[52/200] G:151 7.16852->7.16852 \r\n",
      "[53/200] G:148 7.09217->7.09217 \r\n",
      "[54/200] G:147 7.08851->7.08851 \r\n",
      "[55/200] G:146 7.08133->7.08133 \r\n",
      "[56/200] G:145 7.06219->7.06219  -> Improved! (-0.000003)\r\n",
      "[57/200] G:144 7.02066->7.02066 \r\n",
      "[58/200] G:143 7.01885->7.01885 \r\n",
      "[59/200] G:142 6.98628->6.98628 \r\n",
      "   >>> Auto-saving checkpoint at 60/200...\r\n",
      "Saving solution to /kaggle/working/submission.csv...\r\n",
      "Save complete.\r\n",
      "[60/200] G:141 6.98063->6.98063 \r\n",
      "[61/200] G:140 6.90036->6.90036 \r\n",
      "[62/200] G:139 6.88549->6.88549 \r\n",
      "[63/200] G:138 6.87510->6.87509  -> Improved! (-0.000002)\r\n",
      "[64/200] G:137 6.87209->6.87209  -> Improved! (-0.000000)\r\n",
      "[65/200] G:136 6.85773->6.85773 \r\n",
      "[66/200] G:135 6.85075->6.85075  -> Improved! (-0.000000)\r\n",
      "[67/200] G:134 6.84583->6.84583 \r\n",
      "[68/200] G:133 6.74244->6.74244 \r\n",
      "[69/200] G:132 6.64105->6.64105 \r\n",
      "[70/200] G:131 6.63785->6.63785 \r\n",
      "[71/200] G:130 6.63703->6.63703 \r\n",
      "[72/200] G:129 6.63688->6.63688 \r\n",
      "[73/200] G:128 6.63589->6.63589 \r\n",
      "[74/200] G:127 6.59644->6.59644 \r\n",
      "[75/200] G:126 6.58505->6.58505 \r\n",
      "[76/200] G:125 6.57775->6.57775 \r\n",
      "[77/200] G:124 6.55842->6.55842 \r\n",
      "[78/200] G:123 6.55791->6.55791 \r\n",
      "[79/200] G:122 6.55384->6.55384 \r\n",
      "   >>> Auto-saving checkpoint at 80/200...\r\n",
      "Saving solution to /kaggle/working/submission.csv...\r\n",
      "Save complete.\r\n",
      "[80/200] G:121 6.52089->6.52089 \r\n",
      "[81/200] G:120 6.36582->6.36582 \r\n",
      "[82/200] G:119 6.35221->6.35221 \r\n",
      "[83/200] G:118 6.33272->6.33272 \r\n",
      "[84/200] G:117 6.32531->6.32531 \r\n",
      "[85/200] G:116 6.32117->6.32117  -> Improved! (-0.000001)\r\n",
      "[86/200] G:115 6.31779->6.31779  -> Improved! (-0.000000)\r\n",
      "[87/200] G:114 6.27713->6.27713 \r\n",
      "[88/200] G:113 6.27433->6.27433 \r\n",
      "[89/200] G:112 6.25177->6.25177 \r\n",
      "[90/200] G:111 6.18194->6.18194 \r\n",
      "[91/200] G:110 6.09403->6.09403 \r\n",
      "[92/200] G:109 6.09269->6.09269 \r\n",
      "[93/200] G:108 6.09153->6.09153 \r\n",
      "[94/200] G:107 6.08628->6.08628 \r\n",
      "[95/200] G:106 6.02009->6.02008  -> Improved! (-0.000002)\r\n",
      "[96/200] G:105 6.00021->6.00021 \r\n",
      "[97/200] G:104 5.95359->5.95359 \r\n",
      "[98/200] G:103 5.95358->5.95358 \r\n",
      "[99/200] G:102 5.95356->5.95356 \r\n",
      "   >>> Auto-saving checkpoint at 100/200...\r\n",
      "Saving solution to /kaggle/working/submission.csv...\r\n",
      "Save complete.\r\n",
      "[100/200] G:101 5.94930->5.94930 \r\n",
      "[101/200] G:100 5.87824->5.87824 \r\n",
      "[102/200] G:099 5.87197->5.87197 \r\n",
      "[103/200] G:098 5.86925->5.86925 \r\n",
      "[104/200] G:097 5.86239->5.86239 \r\n",
      "[105/200] G:096 5.76670->5.76670 \r\n",
      "[106/200] G:095 5.75885->5.75885 \r\n",
      "[107/200] G:094 5.75524->5.75524 \r\n",
      "[108/200] G:093 5.74174->5.74174 \r\n",
      "[109/200] G:092 5.70039->5.70039 \r\n",
      "[110/200] G:091 5.62678->5.62678 \r\n",
      "[111/200] G:090 5.56942->5.56942 \r\n",
      "[112/200] G:089 5.56622->5.56622 \r\n",
      "[113/200] G:088 5.55610->5.55610 \r\n",
      "[114/200] G:087 5.55358->5.55358 \r\n",
      "[115/200] G:086 5.53041->5.53041 \r\n",
      "[116/200] G:085 5.46176->5.46176 \r\n",
      "[117/200] G:084 5.43832->5.43832 \r\n",
      "[118/200] G:083 5.43564->5.43564  -> Improved! (-0.000000)\r\n",
      "[119/200] G:082 5.42932->5.42932 \r\n",
      "   >>> Auto-saving checkpoint at 120/200...\r\n",
      "Saving solution to /kaggle/working/submission.csv...\r\n",
      "Save complete.\r\n",
      "[120/200] G:081 5.41711->5.41711  -> Improved! (-0.000000)\r\n",
      "[121/200] G:080 5.25270->5.25270 \r\n",
      "[122/200] G:079 5.24758->5.24758 \r\n",
      "[123/200] G:078 5.23674->5.23674 \r\n",
      "[124/200] G:077 5.20004->5.20004 \r\n",
      "[125/200] G:076 5.17671->5.17671 \r\n",
      "[126/200] G:075 5.16272->5.16272 \r\n",
      "[127/200] G:074 5.15186->5.15186 \r\n",
      "[128/200] G:073 5.14201->5.14201 \r\n",
      "[129/200] G:072 5.00966->5.00966 \r\n",
      "[130/200] G:071 5.00096->5.00096 \r\n",
      "[131/200] G:070 4.94632->4.94632 \r\n",
      "[132/200] G:069 4.94597->4.94597 \r\n",
      "[133/200] G:068 4.90373->4.90373 \r\n",
      "[134/200] G:067 4.86914->4.86914 \r\n",
      "[135/200] G:066 4.86701->4.86701 \r\n",
      "[136/200] G:065 4.86286->4.86286 \r\n",
      "[137/200] G:064 4.73605->4.73605 \r\n",
      "[138/200] G:063 4.73220->4.73220 \r\n",
      "[139/200] G:062 4.69243->4.69243 \r\n",
      "   >>> Auto-saving checkpoint at 140/200...\r\n",
      "Saving solution to /kaggle/working/submission.csv...\r\n",
      "Save complete.\r\n",
      "[140/200] G:061 4.67637->4.67637 \r\n",
      "[141/200] G:060 4.62986->4.62986 \r\n",
      "[142/200] G:059 4.62536->4.62536 \r\n",
      "[143/200] G:058 4.60311->4.60311 \r\n",
      "[144/200] G:057 4.52437->4.52437 \r\n",
      "[145/200] G:056 4.44163->4.44163 \r\n",
      "[146/200] G:055 4.41894->4.41894 \r\n",
      "[147/200] G:054 4.41718->4.41718 \r\n",
      "[148/200] G:053 4.37932->4.37932 \r\n",
      "[149/200] G:052 4.33473->4.33473 \r\n",
      "[150/200] G:051 4.31802->4.31802  -> Improved! (-0.000001)\r\n",
      "[151/200] G:050 4.24709->4.24709 \r\n",
      "[152/200] G:049 4.23930->4.23930 \r\n",
      "[153/200] G:048 4.13104->4.13104 \r\n",
      "[154/200] G:047 4.09905->4.09905 \r\n",
      "[155/200] G:046 4.09450->4.09450 \r\n",
      "[156/200] G:045 4.04474->4.04474 \r\n",
      "[157/200] G:044 4.02318->4.02318 \r\n",
      "[158/200] G:043 3.98896->3.98896 \r\n",
      "[159/200] G:042 3.92522->3.92522 \r\n",
      "   >>> Auto-saving checkpoint at 160/200...\r\n",
      "Saving solution to /kaggle/working/submission.csv...\r\n",
      "Save complete.\r\n",
      "[160/200] G:041 3.88465->3.88465 \r\n",
      "[161/200] G:040 3.80605->3.80605 \r\n",
      "[162/200] G:039 3.75480->3.75480 \r\n",
      "[163/200] G:038 3.73474->3.73474 \r\n",
      "[164/200] G:037 3.69896->3.69896 \r\n",
      "[165/200] G:036 3.59410->3.59410 \r\n",
      "[166/200] G:035 3.58329->3.58329 \r\n",
      "[167/200] G:034 3.54911->3.54911 \r\n",
      "[168/200] G:033 3.49471->3.49471 \r\n",
      "[169/200] G:032 3.42077->3.42077 \r\n",
      "[170/200] G:031 3.38936->3.38936 \r\n",
      "[171/200] G:029 3.26529->3.26529 \r\n",
      "[172/200] G:030 3.29037->3.29037 \r\n",
      "[173/200] G:028 3.20171->3.20171 \r\n",
      "[174/200] G:027 3.12944->3.12944 \r\n",
      "[175/200] G:026 3.12385->3.12385 \r\n",
      "[176/200] G:025 3.05019->3.05019 \r\n",
      "[177/200] G:024 2.96178->2.96178 \r\n",
      "[178/200] G:023 2.91227->2.91227 \r\n",
      "[179/200] G:021 2.81167->2.81167 \r\n",
      "   >>> Auto-saving checkpoint at 180/200...\r\n",
      "Saving solution to /kaggle/working/submission.csv...\r\n",
      "Save complete.\r\n",
      "[180/200] G:022 2.87328->2.87328 \r\n",
      "[181/200] G:020 2.74384->2.74384 \r\n",
      "[182/200] G:019 2.64645->2.64645 \r\n",
      "[183/200] G:018 2.57641->2.57641 \r\n",
      "[184/200] G:017 2.50812->2.50812 \r\n",
      "[185/200] G:016 2.44664->2.44664 \r\n",
      "[186/200] G:015 2.38496->2.38496 \r\n",
      "[187/200] G:013 2.20005->2.20005 \r\n",
      "[188/200] G:014 2.30772->2.30772 \r\n",
      "[189/200] G:012 2.11488->2.11488 \r\n",
      "[190/200] G:011 2.03300->2.03300 \r\n",
      "[191/200] G:010 1.94070->1.94070 \r\n",
      "[192/200] G:009 1.86728->1.86728 \r\n",
      "[193/200] G:008 1.75592->1.75592 \r\n",
      "[194/200] G:007 1.67310->1.67310 \r\n",
      "[195/200] G:005 1.44369->1.44369 \r\n",
      "[196/200] G:006 1.54844->1.54844 \r\n",
      "[197/200] G:004 1.29081->1.29081 \r\n",
      "[198/200] G:003 1.14203->1.14203 \r\n",
      "[199/200] G:001 0.81317->0.81317 \r\n",
      "   >>> Auto-saving checkpoint at 200/200...\r\n",
      "Saving solution to /kaggle/working/submission.csv...\r\n",
      "Save complete.\r\n",
      "[200/200] G:002 0.94950->0.94950 \r\n",
      "\r\n",
      "Optimization finished normally in 34417.27s\r\n",
      "Final Save. Total Improved: 11\r\n",
      "Saving solution to /kaggle/working/submission.csv...\r\n",
      "Save complete.\r\n"
     ]
    }
   ],
   "source": [
    "!python sa.py \\\n",
    "  --input /kaggle/input/a-bit-better-the-best-open-source-result-for-date/submission.csv \\\n",
    "  --output /kaggle/working/submission.csv \\\n",
    "  --iter 1000000 \\\n",
    "  --tstart 3.0 \\\n",
    "  --tend 0.0003 \\\n",
    "  --processes auto \\\n",
    "  --seed 4489708 \\\n",
    "  --time_limit_sec 41400 \\\n",
    "  --save_every 20 \\\n",
    "  --adapt_window 200 \\\n",
    "  --target_accept 0.25 \\\n",
    "  --adapt_strength 0.75 \\\n",
    "  --t_min_multiplier 1.0 \\\n",
    "  --t_max_multiplier 2.0 \\\n",
    "  --stagnation 20 \\\n",
    "  --reheat_fraction 0.8 \\\n",
    "  --max_reheats 20\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 290260019,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 34429.316032,
   "end_time": "2026-01-06T23:17:08.610872",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-06T13:43:19.294840",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
