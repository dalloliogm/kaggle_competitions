{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fb228b7",
   "metadata": {
    "papermill": {
     "duration": 0.002835,
     "end_time": "2025-12-14T11:41:43.998790",
     "exception": false,
     "start_time": "2025-12-14T11:41:43.995955",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Autogluon infer\n",
    "\n",
    "This notebook uses a model trained with Autogluon in another notebook: https://www.kaggle.com/code/dalloliogm/hull-tactical-autogluon-train-and-infer-tabular\n",
    "\n",
    "This is a workaround to submit a model trained for multiple hours, as otherwise the kaggle interface fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b824b36",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-14T11:41:44.005167Z",
     "iopub.status.busy": "2025-12-14T11:41:44.004746Z",
     "iopub.status.idle": "2025-12-14T11:44:20.090239Z",
     "shell.execute_reply": "2025-12-14T11:44:20.089002Z"
    },
    "papermill": {
     "duration": 156.091582,
     "end_time": "2025-12-14T11:44:20.092854",
     "exception": false,
     "start_time": "2025-12-14T11:41:44.001272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\r\n",
      "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.5.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "WHEELS = Path(\"/kaggle/input/autogluon-1-4-0-offline\")  # <- your dataset\n",
    "\n",
    "!pip install --no-index --quiet --find-links=\"{WHEELS}\" \\\n",
    "  \"torch==2.5.1\" \"torchvision==0.20.1\" \"torchaudio==2.5.1\" \"bitsandbytes>=0.46.1\" \"mlforecast==0.14.0\" \"optuna==4.3.0\"\n",
    "\n",
    "!pip install --no-index --quiet --find-links=\"{WHEELS}\" \\\n",
    "    \"autogluon.tabular\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c0fe357",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T11:44:20.099843Z",
     "iopub.status.busy": "2025-12-14T11:44:20.099487Z",
     "iopub.status.idle": "2025-12-14T11:44:20.105113Z",
     "shell.execute_reply": "2025-12-14T11:44:20.103947Z"
    },
    "papermill": {
     "duration": 0.01125,
     "end_time": "2025-12-14T11:44:20.106606",
     "exception": false,
     "start_time": "2025-12-14T11:44:20.095356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set this to inference to use a previously trained model\n",
    "notebook_mode = \"inference\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d8b6a04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T11:44:20.113167Z",
     "iopub.status.busy": "2025-12-14T11:44:20.112803Z",
     "iopub.status.idle": "2025-12-14T11:44:26.244427Z",
     "shell.execute_reply": "2025-12-14T11:44:26.243389Z"
    },
    "papermill": {
     "duration": 6.137289,
     "end_time": "2025-12-14T11:44:26.246381",
     "exception": false,
     "start_time": "2025-12-14T11:44:20.109092",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from autogluon.tabular import TabularPredictor\n",
    "import autogluon\n",
    "\n",
    "# =========================\n",
    "# MODE SWITCH\n",
    "# =========================\n",
    "# Set manually in the notebook:\n",
    "# notebook_mode = \"training\" or \"inference\"\n",
    "assert notebook_mode in (\"training\", \"inference\")\n",
    "\n",
    "# Path where your pre-trained models live (dataset input)\n",
    "PRETRAINED_MODEL_DIR = Path(\n",
    "    \"/kaggle/input/hull-tactical-autogluon-train-and-infer-tabular/AutogluonModels/ag-20251212_181000/\"\n",
    ")\n",
    "\n",
    "# Optional: where to save if you train in this notebook\n",
    "WORKING_MODEL_DIR = Path(\"/kaggle/working/AutogluonModels\")\n",
    "\n",
    "# =========================\n",
    "# CONSTANTS + POSTPROCESS\n",
    "# =========================\n",
    "ALPHA_FOR_SCORER = 0.600132\n",
    "TAU_ABS_FOR_SCORER = 9.43717e-05\n",
    "MIN_INVESTMENT, MAX_INVESTMENT = 0.0, 2.0\n",
    "\n",
    "def post_process_signal(y_pred,\n",
    "                        *,\n",
    "                        tau: float = TAU_ABS_FOR_SCORER,\n",
    "                        alpha: float = ALPHA_FOR_SCORER,\n",
    "                        min_investment: float = MIN_INVESTMENT,\n",
    "                        max_investment: float = MAX_INVESTMENT):\n",
    "    sig = np.asarray(y_pred, dtype=float).ravel()\n",
    "    pos = np.where(sig > tau, alpha, 0.0)\n",
    "    return np.clip(pos, min_investment, max_investment)\n",
    "\n",
    "# =========================\n",
    "# DATA\n",
    "# =========================\n",
    "DATA_PATH = \"/kaggle/input/hull-tactical-market-prediction/\"\n",
    "TARGET = \"forward_returns\"\n",
    "\n",
    "DROP_IF_EXISTS = [\"row_id\", \"id\", \"risk_free_rate\", \"market_forward_excess_returns\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "962e3dd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T11:44:26.254317Z",
     "iopub.status.busy": "2025-12-14T11:44:26.253618Z",
     "iopub.status.idle": "2025-12-14T11:44:26.260080Z",
     "shell.execute_reply": "2025-12-14T11:44:26.259091Z"
    },
    "papermill": {
     "duration": 0.012971,
     "end_time": "2025-12-14T11:44:26.262195",
     "exception": false,
     "start_time": "2025-12-14T11:44:26.249224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# We'll only read train if training (keeps inference lightweight)\n",
    "train = None\n",
    "if notebook_mode == \"training\":\n",
    "    train = pd.read_csv(f\"{DATA_PATH}train.csv\")\n",
    "    if TARGET not in train.columns:\n",
    "        raise ValueError(f\"Expected target column '{TARGET}' in train.csv; found: {list(train.columns)}\")\n",
    "    use_cols = [c for c in train.columns if c not in DROP_IF_EXISTS]\n",
    "    train = train[use_cols]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0b3ca52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T11:44:26.269388Z",
     "iopub.status.busy": "2025-12-14T11:44:26.269036Z",
     "iopub.status.idle": "2025-12-14T11:44:27.056877Z",
     "shell.execute_reply": "2025-12-14T11:44:27.055763Z"
    },
    "papermill": {
     "duration": 0.793565,
     "end_time": "2025-12-14T11:44:27.058581",
     "exception": false,
     "start_time": "2025-12-14T11:44:26.265016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[inference] Loaded predictor from: /kaggle/input/hull-tactical-autogluon-train-and-infer-tabular/AutogluonModels/ag-20251212_181000\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# LOAD OR TRAIN PREDICTOR\n",
    "# =========================\n",
    "predictor = None\n",
    "\n",
    "if notebook_mode == \"inference\":\n",
    "    # Load pre-trained model\n",
    "    predictor = TabularPredictor.load(str(PRETRAINED_MODEL_DIR))\n",
    "    print(f\"[inference] Loaded predictor from: {PRETRAINED_MODEL_DIR}\")\n",
    "\n",
    "else:\n",
    "    # Train model\n",
    "    predictor = TabularPredictor(\n",
    "        label=TARGET,\n",
    "        eval_metric=\"rmse\",\n",
    "        problem_type=\"regression\",\n",
    "        path=str(WORKING_MODEL_DIR),  # ensures models are written under /kaggle/working\n",
    "    )\n",
    "\n",
    "    predictor.fit(\n",
    "        train_data=train,\n",
    "        presets=\"best_quality\",\n",
    "        time_limit=60 * 60 * 9,\n",
    "    )\n",
    "\n",
    "    print(f\"[training] Trained. Models saved to: {WORKING_MODEL_DIR}\")\n",
    "    # If you want: zip /kaggle/working/AutogluonModels into a dataset later.\n",
    "\n",
    "# Cache feature list once (works for both training+inference)\n",
    "MODEL_FEATURES = predictor.feature_metadata.get_features()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f00c401e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T11:44:27.069870Z",
     "iopub.status.busy": "2025-12-14T11:44:27.069541Z",
     "iopub.status.idle": "2025-12-14T11:44:27.077492Z",
     "shell.execute_reply": "2025-12-14T11:44:27.076367Z"
    },
    "papermill": {
     "duration": 0.016012,
     "end_time": "2025-12-14T11:44:27.079170",
     "exception": false,
     "start_time": "2025-12-14T11:44:27.063158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# KAGGLE PREDICT FN\n",
    "# =========================\n",
    "def predict(test: pl.DataFrame) -> float:\n",
    "    \"\"\"Return a single post-processed position for a single-row Polars DataFrame.\"\"\"\n",
    "    if not isinstance(test, pl.DataFrame):\n",
    "        raise TypeError(\"predict(test): expected a Polars DataFrame input\")\n",
    "    if test.height != 1:\n",
    "        raise ValueError(f\"predict(test): expected a single-row Polars DataFrame, got {test.height} rows\")\n",
    "\n",
    "    # Drop known non-feature columns if present\n",
    "    drop_cols = [c for c in DROP_IF_EXISTS if c in test.columns]\n",
    "    test_pl = test.drop(drop_cols) if drop_cols else test\n",
    "\n",
    "    # Ensure target isn't present at inference\n",
    "    if TARGET in test_pl.columns:\n",
    "        test_pl = test_pl.drop(TARGET)\n",
    "\n",
    "    # Polars -> Pandas for AutoGluon\n",
    "    test_pd = test_pl.to_pandas()\n",
    "\n",
    "    # Align columns to model features (drops extras, adds missing as 0)\n",
    "    test_pd = test_pd.reindex(columns=MODEL_FEATURES, fill_value=0)\n",
    "\n",
    "    raw = predictor.predict(test_pd)\n",
    "    pos = post_process_signal(raw)\n",
    "    return float(np.asarray(pos).ravel()[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f764ffb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T11:44:27.085908Z",
     "iopub.status.busy": "2025-12-14T11:44:27.085548Z",
     "iopub.status.idle": "2025-12-14T11:44:43.890337Z",
     "shell.execute_reply": "2025-12-14T11:44:43.889217Z"
    },
    "papermill": {
     "duration": 16.812287,
     "end_time": "2025-12-14T11:44:43.894009",
     "exception": false,
     "start_time": "2025-12-14T11:44:27.081722",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# KAGGLE SERVER BOOTSTRAP\n",
    "# =========================\n",
    "import kaggle_evaluation.default_inference_server as kis\n",
    "\n",
    "inference_server = kis.DefaultInferenceServer(predict)\n",
    "\n",
    "if os.getenv(\"KAGGLE_IS_COMPETITION_RERUN\"):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway((DATA_PATH,))\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14861981,
     "isSourceIdPinned": false,
     "sourceId": 111543,
     "sourceType": "competition"
    },
    {
     "datasetId": 8353464,
     "sourceId": 13183252,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 285791737,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 187.35478,
   "end_time": "2025-12-14T11:44:46.456639",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-14T11:41:39.101859",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
