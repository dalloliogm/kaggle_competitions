{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87223da3",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.002787,
     "end_time": "2025-10-12T08:26:53.246301",
     "exception": false,
     "start_time": "2025-10-12T08:26:53.243514",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Ensemble Gemma-2 9b, Qwen3 8b & Deepseek math 7b \n",
    "\n",
    "Inference runs in 2hours, so lot of room for more models. We infer Gemma 9b on 2 gpus because it is loaded in fp16. We run Qwen 3 8b and deepseek math 7b parallel on 2 gpus, to save time. After inference, for ensembling we use prob confidence, weighted average and agreement between models.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Credits:   \n",
    "@cdeotte - [Gemma 9b weights](https://www.kaggle.com/datasets/cdeotte/gemma2-9b-it-cv945)  \n",
    "@jaytonde - [Qwen 3 8b weights](https://www.kaggle.com/datasets/jaytonde/qwen3-8b-map-competition)  \n",
    "@jaytonde - [Deepseek math 7b weights](https://www.kaggle.com/datasets/jaytonde/deekseepmath-7b-map-competition) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d8e29c",
   "metadata": {
    "papermill": {
     "duration": 0.002002,
     "end_time": "2025-10-12T08:26:53.250736",
     "exception": false,
     "start_time": "2025-10-12T08:26:53.248734",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model-1: Gemma2  9b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb7dcef3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T08:26:53.255903Z",
     "iopub.status.busy": "2025-10-12T08:26:53.255704Z",
     "iopub.status.idle": "2025-10-12T08:26:53.265448Z",
     "shell.execute_reply": "2025-10-12T08:26:53.264796Z"
    },
    "papermill": {
     "duration": 0.01369,
     "end_time": "2025-10-12T08:26:53.266471",
     "exception": false,
     "start_time": "2025-10-12T08:26:53.252781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing gemma2_inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile gemma2_inference.py\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import os\n",
    "from IPython.display import display, Math, Latex\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "import pandas as pd, numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import DataCollatorWithPadding\n",
    "from peft import PeftModel\n",
    "from scipy.special import softmax\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "\n",
    "lora_path = \"/kaggle/input/gemma2-9b-it-cv945\"\n",
    "MAX_LEN = 256\n",
    "# helpers\n",
    "def format_input(row):\n",
    "    x = \"Yes\"\n",
    "    if not row['is_correct']:\n",
    "        x = \"No\"\n",
    "    return (\n",
    "        f\"Question: {row['QuestionText']}\\n\"\n",
    "        f\"Answer: {row['MC_Answer']}\\n\"\n",
    "        f\"Correct? {x}\\n\"\n",
    "        f\"Student Explanation: {row['StudentExplanation']}\"\n",
    "    )\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=256)\n",
    "\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "train = pd.read_csv('/kaggle/input/map-charting-student-math-misunderstandings/train.csv')\n",
    "\n",
    "train.Misconception = train.Misconception.fillna('NA')\n",
    "train['target'] = train.Category+\":\"+train.Misconception\n",
    "train['label'] = le.fit_transform(train['target'])\n",
    "target_classes = le.classes_\n",
    "n_classes = len(target_classes)\n",
    "print(f\"Train shape: {train.shape} with {n_classes} target classes\")\n",
    "idx = train.apply(lambda row: row.Category.split('_')[0],axis=1)=='True'\n",
    "correct = train.loc[idx].copy()\n",
    "correct['c'] = correct.groupby(['QuestionId','MC_Answer']).MC_Answer.transform('count')\n",
    "correct = correct.sort_values('c',ascending=False)\n",
    "correct = correct.drop_duplicates(['QuestionId'])\n",
    "correct = correct[['QuestionId','MC_Answer']]\n",
    "correct['is_correct'] = 1\n",
    "\n",
    "# Prepare test data\n",
    "test = pd.read_csv('/kaggle/input/map-charting-student-math-misunderstandings/test.csv')\n",
    "test = test.merge(correct, on=['QuestionId','MC_Answer'], how='left')\n",
    "test.is_correct = test.is_correct.fillna(0)\n",
    "test['text'] = test.apply(format_input, axis=1)\n",
    "\n",
    "\n",
    "# load model & tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(lora_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"/kaggle/input/gemma2-9b-it-bf16\",\n",
    "    num_labels=n_classes,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "model = PeftModel.from_pretrained(model, lora_path)\n",
    "model.eval()\n",
    "\n",
    "# Tokenize dataset\n",
    "ds_test = Dataset.from_pandas(test[['text']])\n",
    "ds_test = ds_test.map(tokenize, batched=True, remove_columns=['text'])\n",
    "\n",
    "# Create data collator for efficient batching with padding\n",
    "data_collator = DataCollatorWithPadding(\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=MAX_LEN,  \n",
    "    return_tensors=\"pt\")\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    ds_test,\n",
    "    batch_size=8,  \n",
    "    shuffle=False,\n",
    "    collate_fn=data_collator,\n",
    "    pin_memory=True,  \n",
    "    num_workers=2     \n",
    ")\n",
    "\n",
    "# Fast inference loop\n",
    "all_logits = []\n",
    "device = next(model.parameters()).device\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(dataloader, desc=\"Inference\"):\n",
    "        # Move batch to device\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(**batch)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # Convert bfloat16 to float32 then move to CPU and store\n",
    "        all_logits.append(logits.float().cpu().numpy())\n",
    "\n",
    "# Concatenate all logits\n",
    "predictions = np.concatenate(all_logits, axis=0)\n",
    "\n",
    "# Convert to probs\n",
    "probs = softmax(predictions, axis=1)\n",
    "\n",
    "# Get top predictions (all 65 classes ranked)\n",
    "top_indices = np.argsort(-probs, axis=1)\n",
    "\n",
    "# Decode to class names\n",
    "flat_indices = top_indices.flatten()\n",
    "decoded_labels = le.inverse_transform(flat_indices)\n",
    "top_labels = decoded_labels.reshape(top_indices.shape)\n",
    "\n",
    "# Create submission (top 3)\n",
    "joined_preds = [\" \".join(row[:3]) for row in top_labels]\n",
    "\n",
    "sub = pd.DataFrame({\n",
    "    \"row_id\": test.row_id.values,\n",
    "    \"Category:Misconception\": joined_preds\n",
    "})\n",
    "sub.to_csv(\"submission_gemma.csv\", index=False)\n",
    "\n",
    "prob_data = []\n",
    "for i in range(len(test)):\n",
    "    prob_dict = {f\"prob_{j}\": probs[i, top_indices[i, j]] for j in range(25)}  # Top 25\n",
    "    prob_dict['row_id'] = test.row_id.values[i]\n",
    "    prob_dict['top_classes'] = \" \".join(top_labels[i, :25])  # Top 25 class names\n",
    "    prob_data.append(prob_dict)\n",
    "\n",
    "prob_df = pd.DataFrame(prob_data)\n",
    "prob_df.to_csv(\"submission_gemma_prob.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530b3ea0",
   "metadata": {
    "papermill": {
     "duration": 0.001938,
     "end_time": "2025-10-12T08:26:53.270518",
     "exception": false,
     "start_time": "2025-10-12T08:26:53.268580",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model 2-3: Qwen 3 8b & Deepseek math 7b parallel\n",
    "Run deepseek on cuda:0 and qwen 3 on cuda:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e65b36a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T08:26:53.275538Z",
     "iopub.status.busy": "2025-10-12T08:26:53.275364Z",
     "iopub.status.idle": "2025-10-12T08:26:53.280847Z",
     "shell.execute_reply": "2025-10-12T08:26:53.280245Z"
    },
    "papermill": {
     "duration": 0.009263,
     "end_time": "2025-10-12T08:26:53.281855",
     "exception": false,
     "start_time": "2025-10-12T08:26:53.272592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing qwen3_deepseek_inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile qwen3_deepseek_inference.py\n",
    "\n",
    "# we do parallel inference, for deepseek and qwen3\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datasets import Dataset\n",
    "import threading\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, DataCollatorWithPadding\n",
    "from scipy.special import softmax\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "\n",
    "train = pd.read_csv('/kaggle/input/map-charting-student-math-misunderstandings/train.csv')\n",
    "test  = pd.read_csv('/kaggle/input/map-charting-student-math-misunderstandings/test.csv')\n",
    "\n",
    "model_paths = [\n",
    "    \"/kaggle/input/deekseepmath-7b-map-competition/MAP_EXP_09_FULL\",\n",
    "   \"/kaggle/input/qwen3-8b-map-competition/MAP_EXP_16_FULL\"]\n",
    "\n",
    "def format_input(row):\n",
    "    x = \"This answer is correct.\"\n",
    "    if not row['is_correct']:\n",
    "        x = \"This is answer is incorrect.\"\n",
    "    return (\n",
    "        f\"Question: {row['QuestionText']}\\n\"\n",
    "        f\"Answer: {row['MC_Answer']}\\n\"\n",
    "        f\"{x}\\n\"\n",
    "        f\"Student Explanation: {row['StudentExplanation']}\")\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "train.Misconception  = train.Misconception.fillna('NA')\n",
    "train['target']   = train.Category + ':' +train.Misconception\n",
    "train['label']    = le.fit_transform(train['target'])\n",
    "\n",
    "n_classes = len(le.classes_)\n",
    "print(f\"Train shape: {train.shape} with {n_classes} target classes\")\n",
    "idx = train.apply(lambda row: row.Category.split('_')[0],axis=1)=='True'\n",
    "correct = train.loc[idx].copy()\n",
    "correct['c'] = correct.groupby(['QuestionId','MC_Answer']).MC_Answer.transform('count')\n",
    "correct = correct.sort_values('c',ascending=False)\n",
    "correct = correct.drop_duplicates(['QuestionId'])\n",
    "correct = correct[['QuestionId','MC_Answer']]\n",
    "correct['is_correct'] = 1\n",
    "\n",
    "test = test.merge(correct, on=['QuestionId','MC_Answer'], how='left')\n",
    "test.is_correct = test.is_correct.fillna(0)\n",
    "test['text'] = test.apply(format_input,axis=1)\n",
    "ds_test = Dataset.from_pandas(test)\n",
    "\n",
    "\n",
    "def run_inference_on_gpu(model_path, gpu_id, test_data, output_name):\n",
    "    \"\"\"Run inference for one model on one GPU\"\"\"\n",
    "    \n",
    "    device = f\"cuda:{gpu_id}\"\n",
    "    print(f\"Loading {output_name} on {device}...\")\n",
    "    \n",
    "    # Load model\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_path, \n",
    "        device_map=device, \n",
    "        torch_dtype=torch.float16\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model.config.pad_token_id = tokenizer.pad_token_id\n",
    "    model.eval()\n",
    "    \n",
    "    # Tokenize function\n",
    "    def tokenize(batch):\n",
    "        return tokenizer(batch[\"text\"], \n",
    "                        truncation=True,\n",
    "                        max_length=256)\n",
    "    \n",
    "    ds_test = Dataset.from_pandas(test_data[['text']])\n",
    "    ds_test = ds_test.map(tokenize, batched=True, remove_columns=['text'])\n",
    "    \n",
    "    # Data collator\n",
    "    data_collator = DataCollatorWithPadding(\n",
    "        tokenizer=tokenizer,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    # DataLoader\n",
    "    dataloader = DataLoader(\n",
    "        ds_test,\n",
    "        batch_size=4,\n",
    "        shuffle=False,\n",
    "        collate_fn=data_collator,\n",
    "        pin_memory=True,\n",
    "        num_workers=0\n",
    "    )\n",
    "    \n",
    "    # Inference\n",
    "    all_logits = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=f\"{output_name}\"):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            all_logits.append(outputs.logits.float().cpu().numpy())\n",
    "    \n",
    "    predictions = np.concatenate(all_logits, axis=0)\n",
    "    \n",
    "    # Process results\n",
    "    probs = softmax(predictions, axis=1)\n",
    "    top_indices = np.argsort(-probs, axis=1)\n",
    "    \n",
    "    # Decode labels\n",
    "    flat_indices = top_indices.flatten()\n",
    "    decoded_labels = le.inverse_transform(flat_indices)\n",
    "    top_labels = decoded_labels.reshape(top_indices.shape)\n",
    "    \n",
    "    # Save top-3 submission\n",
    "    joined_preds = [\" \".join(row[:3]) for row in top_labels]\n",
    "    sub = pd.DataFrame({\n",
    "        \"row_id\": test_data.row_id.values,\n",
    "        \"Category:Misconception\": joined_preds\n",
    "    })\n",
    "    sub.to_csv(f\"submission_{output_name}.csv\", index=False)\n",
    "    \n",
    "    # Save probabilities for ensemble\n",
    "    prob_data = []\n",
    "    for i in range(len(predictions)):\n",
    "        prob_dict = {f\"prob_{j}\": probs[i, top_indices[i, j]] for j in range(25)}\n",
    "        prob_dict['row_id'] = test_data.row_id.values[i]\n",
    "        prob_dict['top_classes'] = \" \".join(top_labels[i, :25])\n",
    "        prob_data.append(prob_dict)\n",
    "    \n",
    "    prob_df = pd.DataFrame(prob_data)\n",
    "    prob_df.to_csv(f\"submission_{output_name}_probabilities.csv\", index=False)\n",
    "    \n",
    "    print(f\" {output_name} completed - saved submission and probabilities\")\n",
    "    \n",
    "    # Clean up GPU memory\n",
    "    del model, tokenizer\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(\" Starting multi-GPU inference...\")\n",
    "start_time = time.time()\n",
    "\n",
    "threads = []\n",
    "gpu_assignments = [\n",
    "    (model_paths[0], 0, \"deepseek\"),\n",
    "    (model_paths[1], 1, \"qwen3\"),\n",
    "]\n",
    "\n",
    "# Start threads\n",
    "for model_path, gpu_id, name in gpu_assignments:\n",
    "    if gpu_id < torch.cuda.device_count():  \n",
    "        thread = threading.Thread(\n",
    "            target=run_inference_on_gpu,\n",
    "            args=(model_path, gpu_id, test, name)\n",
    "        )\n",
    "        threads.append(thread)\n",
    "        thread.start()\n",
    "        time.sleep(10)  # Stagger starts to avoid memory issues\n",
    "\n",
    "# Wait for completion\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\" completed in {end_time - start_time:.2f} seconds!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a85026",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T05:24:19.923503Z",
     "iopub.status.busy": "2025-09-05T05:24:19.922686Z",
     "iopub.status.idle": "2025-09-05T05:24:19.927662Z",
     "shell.execute_reply": "2025-09-05T05:24:19.926846Z",
     "shell.execute_reply.started": "2025-09-05T05:24:19.923473Z"
    },
    "papermill": {
     "duration": 0.001957,
     "end_time": "2025-10-12T08:26:53.285913",
     "exception": false,
     "start_time": "2025-10-12T08:26:53.283956",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "034e4f7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T08:26:53.290583Z",
     "iopub.status.busy": "2025-10-12T08:26:53.290419Z",
     "iopub.status.idle": "2025-10-12T08:31:29.461790Z",
     "shell.execute_reply": "2025-10-12T08:31:29.460971Z"
    },
    "papermill": {
     "duration": 276.175446,
     "end_time": "2025-10-12T08:31:29.463381",
     "exception": false,
     "start_time": "2025-10-12T08:26:53.287935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-12 08:27:08.142936: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1760257628.324081      39 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "E0000 00:00:1760257628.377427      39 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "Train shape: (36696, 9) with 65 target classes\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [01:26<00:00, 21.57s/it]\r\n",
      "Some weights of Gemma2ForSequenceClassification were not initialized from the model checkpoint at /kaggle/input/gemma2-9b-it-bf16 and are newly initialized: ['score.weight']\r\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\r\n",
      "/usr/local/lib/python3.11/dist-packages/peft/config.py:165: UserWarning: Unexpected keyword arguments ['qalora_group_size', 'use_qalora'] for class LoraConfig, these are ignored. This probably means that you're loading a configuration file that was saved using a higher version of the library and additional parameters have been introduced since. It is highly recommended to upgrade the PEFT version before continuing (e.g. by running `pip install -U peft`).\r\n",
      "  warnings.warn(\r\n",
      "Map: 100%|████████████████████████████████| 3/3 [00:00<00:00, 137.32 examples/s]\r\n",
      "Inference:   0%|                                          | 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2714: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\r\n",
      "  warnings.warn(\r\n",
      "Inference: 100%|██████████████████████████████████| 1/1 [00:02<00:00,  2.39s/it]\r\n",
      "2025-10-12 08:29:15.197861: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1760257755.219665      66 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "E0000 00:00:1760257755.226406      66 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "Train shape: (36696, 9) with 65 target classes\r\n",
      " Starting multi-GPU inference...\r\n",
      "Loading deepseek on cuda:0...\r\n",
      "Loading checkpoint shards:   0%|                          | 0/3 [00:00<?, ?it/s]Loading qwen3 on cuda:1...\r\n",
      "\r\n",
      "Loading checkpoint shards:  33%|██████            | 1/3 [00:38<01:16, 38.45s/it]\r\n",
      "Loading checkpoint shards:  67%|████████████      | 2/3 [01:17<00:38, 38.67s/it]\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 3/3 [01:40<00:00, 33.63s/it]\r\n",
      "Map: 100%|████████████████████████████████| 3/3 [00:00<00:00, 241.36 examples/s]\r\n",
      "deepseek: 100%|███████████████████████████████████| 1/1 [00:00<00:00,  1.11it/s]\r\n",
      " deepseek completed - saved submission and probabilities\r\n",
      "\r\n",
      "Loading checkpoint shards:  75%|█████████████▌    | 3/4 [01:54<00:38, 38.21s/it]\u001b[A\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [01:57<00:00, 29.29s/it]\r\n",
      "Map: 100%|████████████████████████████████| 3/3 [00:00<00:00, 552.05 examples/s]\r\n",
      "qwen3: 100%|██████████████████████████████████████| 1/1 [00:00<00:00,  3.13it/s]\r\n",
      " qwen3 completed - saved submission and probabilities\r\n",
      " completed in 128.27 seconds!\r\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "!python /kaggle/working/gemma2_inference.py\n",
    "time.sleep(10)\n",
    "!python /kaggle/working/qwen3_deepseek_inference.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d199fb23",
   "metadata": {
    "papermill": {
     "duration": 0.003383,
     "end_time": "2025-10-12T08:31:29.470597",
     "exception": false,
     "start_time": "2025-10-12T08:31:29.467214",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Ensemble "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbd90d0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T08:31:29.479044Z",
     "iopub.status.busy": "2025-10-12T08:31:29.478797Z",
     "iopub.status.idle": "2025-10-12T08:31:29.990356Z",
     "shell.execute_reply": "2025-10-12T08:31:29.989581Z"
    },
    "papermill": {
     "duration": 0.517528,
     "end_time": "2025-10-12T08:31:29.991613",
     "exception": false,
     "start_time": "2025-10-12T08:31:29.474085",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>Category:Misconception</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36696</td>\n",
       "      <td>True_Correct:NA True_Neither:NA True_Misconcep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36697</td>\n",
       "      <td>False_Misconception:WNB False_Neither:NA False...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36698</td>\n",
       "      <td>True_Neither:NA True_Correct:NA True_Misconcep...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id                             Category:Misconception\n",
       "0   36696  True_Correct:NA True_Neither:NA True_Misconcep...\n",
       "1   36697  False_Misconception:WNB False_Neither:NA False...\n",
       "2   36698  True_Neither:NA True_Correct:NA True_Misconcep..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from scipy.special import softmax\n",
    "\n",
    "\n",
    "\n",
    "def extract_class_probabilities(row, model_suffix='', top_k=25):\n",
    "    \"\"\"Extract class names and probabilities from a row\"\"\"\n",
    "    # Get top classes\n",
    "    classes_col = f'top_classes{model_suffix}'\n",
    "    if classes_col in row:\n",
    "        classes = row[classes_col].split(' ')[:top_k]\n",
    "    else:\n",
    "        return {}\n",
    "    # Get probabilities\n",
    "    class_probs = {}\n",
    "    for i in range(min(top_k, len(classes))):\n",
    "        prob_col = f'prob_{i}{model_suffix}'\n",
    "        if prob_col in row:\n",
    "            class_probs[classes[i]] = row[prob_col]\n",
    "    return class_probs\n",
    "\n",
    "\n",
    "def ensemble_with_disagreement_handling(prob_files, model_weights=None, top_k=3):\n",
    "    n_models = len(prob_files)\n",
    "    prob_dfs = []\n",
    "    final_predictions = []\n",
    "    \n",
    "    for file_path in prob_files:\n",
    "        df = pd.read_csv(file_path)\n",
    "        prob_dfs.append(df)\n",
    "    \n",
    "    # Merge on row_id\n",
    "    merged_df = prob_dfs[0]\n",
    "    for i, df in enumerate(prob_dfs[1:], 1):\n",
    "        merged_df = pd.merge(merged_df, df, on='row_id', suffixes=('', f'_model{i+1}'))\n",
    "      \n",
    "    for idx, row in merged_df.iterrows():\n",
    "        \n",
    "        # Extract probabilities from each model\n",
    "        all_class_probs = []\n",
    "        for i in range(n_models):\n",
    "            suffix = f'_model{i+1}' if i > 0 else ''\n",
    "            class_probs = extract_class_probabilities(row, suffix, top_k=25)\n",
    "            all_class_probs.append(class_probs)\n",
    "        \n",
    "        # Get all unique classes\n",
    "        all_classes = set()\n",
    "        for class_probs in all_class_probs:\n",
    "            all_classes.update(class_probs.keys())\n",
    "        \n",
    "        # Calculate agreement and disagreement\n",
    "        class_votes = defaultdict(int)\n",
    "        class_total_prob = defaultdict(float)\n",
    "        class_max_prob = defaultdict(float)\n",
    "        \n",
    "        for i, class_probs in enumerate(all_class_probs):\n",
    "            weight = model_weights[i]\n",
    "            \n",
    "            for class_name, prob in class_probs.items():\n",
    "                class_votes[class_name] += 1\n",
    "                class_total_prob[class_name] += prob * weight\n",
    "                class_max_prob[class_name] = max(class_max_prob[class_name], prob * weight)\n",
    "        \n",
    "        final_scores = {}\n",
    "        for class_name in all_classes:\n",
    "            \n",
    "            # Base score: weighted average probability\n",
    "            base_score = class_total_prob[class_name]\n",
    "            \n",
    "            # Agreement : classes predicted by more models get boost\n",
    "            agreement_bonus = class_votes[class_name] / n_models\n",
    "            \n",
    "            # Confidence bonus: classes with high max probability get boost\n",
    "            confidence_bonus = class_max_prob[class_name]\n",
    "            \n",
    "            # Combined score\n",
    "            final_scores[class_name] = (\n",
    "                base_score * 0.6 +           # 60% base probs\n",
    "                agreement_bonus * 0.3 +      # 30% agreement\n",
    "                confidence_bonus * 0.1       # 10% confidence\n",
    "            )\n",
    "        \n",
    "        # Sort and get top-k\n",
    "        sorted_classes = sorted(final_scores.items(), key=lambda x: -x[1])\n",
    "        top_classes = [class_name for class_name, _ in sorted_classes[:top_k]]\n",
    "        \n",
    "        final_predictions.append(' '.join(top_classes))\n",
    "    \n",
    "    return final_predictions\n",
    "\n",
    "# single models scores\n",
    "# deepseek math 7b - 0.944\n",
    "# qwen3 8b - 0.943\n",
    "# gemma 2 9b - 0.942\n",
    "w1 = 1.2\n",
    "w2 = 1.0\n",
    "w3 = 0.8\n",
    "\n",
    "prob_files = [\n",
    "    '/kaggle/working/submission_deepseek_probabilities.csv',\n",
    "    '/kaggle/working/submission_gemma_prob.csv',\n",
    "        '/kaggle/working/submission_qwen3_probabilities.csv'\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "predictions = ensemble_with_disagreement_handling(\n",
    "        prob_files, \n",
    "        model_weights=[w1, w2, w3],  \n",
    "        top_k=3\n",
    "    )\n",
    "    \n",
    "test_df = pd.read_csv('/kaggle/input/map-charting-student-math-misunderstandings/test.csv')\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'row_id': test_df.row_id.values,\n",
    "    'Category:Misconception': predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab0c0d3",
   "metadata": {
    "papermill": {
     "duration": 0.003535,
     "end_time": "2025-10-12T08:31:29.999187",
     "exception": false,
     "start_time": "2025-10-12T08:31:29.995652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 12957508,
     "sourceId": 104383,
     "sourceType": "competition"
    },
    {
     "datasetId": 7930680,
     "sourceId": 12559632,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7930694,
     "sourceId": 12559652,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8039184,
     "sourceId": 12719174,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8045877,
     "sourceId": 12729471,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 281.099375,
   "end_time": "2025-10-12T08:31:30.319927",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-12T08:26:49.220552",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
