{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fc7574a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T07:52:40.562331Z",
     "iopub.status.busy": "2025-06-02T07:52:40.562074Z",
     "iopub.status.idle": "2025-06-02T07:55:52.676752Z",
     "shell.execute_reply": "2025-06-02T07:55:52.675823Z"
    },
    "papermill": {
     "duration": 192.120435,
     "end_time": "2025-06-02T07:55:52.678536",
     "exception": false,
     "start_time": "2025-06-02T07:52:40.558101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-02 07:52:44.437874: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748850764.614499      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748850764.674127      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ imports ready · tensorflow 2.18.0\n",
      "▶ TRAIN MODE – loading dataset …\n",
      "  IMU 7 | TOF/THM 325 | total 332 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1748850833.398921      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "I0000 00:00:1748850848.905249      59 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 96ms/step - accuracy: 0.1204 - loss: 3.1237 - val_accuracy: 0.1839 - val_loss: 2.7589\n",
      "Epoch 2/70\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.2627 - loss: 2.3973 - val_accuracy: 0.3041 - val_loss: 2.4413\n",
      "Epoch 3/70\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.3022 - loss: 2.2144 - val_accuracy: 0.3507 - val_loss: 2.2603\n",
      "Epoch 4/70\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.3207 - loss: 2.2434 - val_accuracy: 0.3814 - val_loss: 2.1146\n",
      "Epoch 5/70\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.3278 - loss: 2.2215 - val_accuracy: 0.3906 - val_loss: 2.0382\n",
      "Epoch 6/70\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.3620 - loss: 2.0358 - val_accuracy: 0.4427 - val_loss: 1.8840\n",
      "Epoch 7/70\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.3867 - loss: 2.1286 - val_accuracy: 0.4439 - val_loss: 1.8169\n",
      "Epoch 8/70\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.4355 - loss: 1.8696 - val_accuracy: 0.4862 - val_loss: 1.7629\n",
      "Epoch 9/70\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.4359 - loss: 1.9465 - val_accuracy: 0.4966 - val_loss: 1.7001\n",
      "Epoch 10/70\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.4600 - loss: 1.9532 - val_accuracy: 0.5267 - val_loss: 1.6403\n",
      "Epoch 11/70\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.4882 - loss: 1.8644 - val_accuracy: 0.5457 - val_loss: 1.6063\n",
      "Epoch 12/70\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.5165 - loss: 1.6990 - val_accuracy: 0.5549 - val_loss: 1.5783\n",
      "Epoch 13/70\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.5236 - loss: 1.8699 - val_accuracy: 0.5567 - val_loss: 1.5674\n",
      "Epoch 14/70\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.5088 - loss: 1.8335 - val_accuracy: 0.5610 - val_loss: 1.5576\n",
      "Epoch 15/70\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.5075 - loss: 1.7805 - val_accuracy: 0.5297 - val_loss: 1.6186\n",
      "Epoch 16/70\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.5030 - loss: 1.8430 - val_accuracy: 0.5322 - val_loss: 1.6059\n",
      "Epoch 17/70\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.5174 - loss: 1.7266 - val_accuracy: 0.5162 - val_loss: 1.6447\n",
      "Epoch 18/70\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.5509 - loss: 1.6562 - val_accuracy: 0.5536 - val_loss: 1.6061\n",
      "Epoch 19/70\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.5516 - loss: 1.7910 - val_accuracy: 0.5720 - val_loss: 1.4949\n",
      "Epoch 20/70\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.5862 - loss: 1.6152 - val_accuracy: 0.5904 - val_loss: 1.4866\n",
      "Epoch 21/70\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.6003 - loss: 1.6317 - val_accuracy: 0.5886 - val_loss: 1.4620\n",
      "Epoch 22/70\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.6296 - loss: 1.5608 - val_accuracy: 0.5794 - val_loss: 1.4817\n",
      "Epoch 23/70\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.6133 - loss: 1.5434 - val_accuracy: 0.5886 - val_loss: 1.4484\n",
      "Epoch 24/70\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.6126 - loss: 1.6061 - val_accuracy: 0.6217 - val_loss: 1.3889\n",
      "Epoch 25/70\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.6493 - loss: 1.4809 - val_accuracy: 0.6266 - val_loss: 1.3758\n",
      "Epoch 26/70\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.6596 - loss: 1.4759 - val_accuracy: 0.6309 - val_loss: 1.3656\n",
      "Epoch 27/70\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.6633 - loss: 1.5592 - val_accuracy: 0.6284 - val_loss: 1.3629\n",
      "Epoch 28/70\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.6604 - loss: 1.5913 - val_accuracy: 0.6211 - val_loss: 1.3707\n",
      "Epoch 29/70\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.6827 - loss: 1.3911 - val_accuracy: 0.6358 - val_loss: 1.3515\n",
      "Epoch 30/70\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.6867 - loss: 1.5046 - val_accuracy: 0.6407 - val_loss: 1.3389\n",
      "Epoch 31/70\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.6767 - loss: 1.4438 - val_accuracy: 0.6560 - val_loss: 1.3242\n",
      "Epoch 32/70\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.6990 - loss: 1.4670 - val_accuracy: 0.6438 - val_loss: 1.3280\n",
      "Epoch 33/70\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.6288 - loss: 1.7184 - val_accuracy: 0.6462 - val_loss: 1.3289\n",
      "Epoch 34/70\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.7107 - loss: 1.3524 - val_accuracy: 0.6438 - val_loss: 1.3246\n",
      "Epoch 35/70\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.6910 - loss: 1.4609 - val_accuracy: 0.6119 - val_loss: 1.4322\n",
      "Epoch 36/70\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.6396 - loss: 1.5281 - val_accuracy: 0.6180 - val_loss: 1.4314\n",
      "Epoch 37/70\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.6383 - loss: 1.6783 - val_accuracy: 0.6223 - val_loss: 1.3869\n",
      "Epoch 38/70\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.6401 - loss: 1.6475 - val_accuracy: 0.6174 - val_loss: 1.4032\n",
      "Epoch 39/70\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.6619 - loss: 1.5074 - val_accuracy: 0.6370 - val_loss: 1.3844\n",
      "Epoch 40/70\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.6703 - loss: 1.4482 - val_accuracy: 0.6150 - val_loss: 1.4232\n",
      "Epoch 41/70\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.6540 - loss: 1.5656 - val_accuracy: 0.6199 - val_loss: 1.4128\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "✔ Training done – artefacts saved in .\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step\n",
      "Hold‑out H‑F1 = 0.7965\n"
     ]
    }
   ],
   "source": [
    "# Two‑Branch Human‑Activity‑Recognition Pipeline (IMU + Thermopile/TOF  + SE‑CNN + BiLSTM + Attention)\n",
    "# upvote for me if you like it and before copy <<>>\n",
    "# I want to find some teammates (responsible). If you want, contact me.\n",
    "\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.utils import Sequence, to_categorical, pad_sequences\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv1D, BatchNormalization, Activation, add, MaxPooling1D, Dropout,\n",
    "    Bidirectional, LSTM, GlobalAveragePooling1D, Dense, Multiply, Reshape,\n",
    "    Lambda, Concatenate\n",
    ")\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "import polars as pl\n",
    "# (Competition metric will only be imported when TRAINing)\n",
    "\n",
    "# ---------------------------- CONFIG ---------------------------------\n",
    "TRAIN = True                     # ← set to True when you want to train\n",
    "RAW_DIR = Path(\"/kaggle/input/cmi-detect-behavior-with-sensor-data\")\n",
    "PRETRAINED_DIR = Path(\"/kaggle/input/pretrained-model\")  # used when TRAIN=False\n",
    "EXPORT_DIR = Path(\"./\")                                    # artefacts will be saved here\n",
    "BATCH_SIZE = 128\n",
    "PAD_PERCENTILE = 90\n",
    "LR_INIT = 1e-3\n",
    "WD = 1e-4\n",
    "MIXUP_ALPHA = 0.2\n",
    "EPOCHS = 70\n",
    "PATIENCE = 10\n",
    "\n",
    "print(\"▶ imports ready · tensorflow\", tf.__version__)\n",
    "\n",
    "# -------------------------- 1. UTILITIES ------------------------------\n",
    "\n",
    "def time_sum(x):\n",
    "    return K.sum(x, axis=1)\n",
    "\n",
    "def squeeze_last_axis(x):\n",
    "    return tf.squeeze(x, axis=-1)\n",
    "\n",
    "def expand_last_axis(x):\n",
    "    return tf.expand_dims(x, axis=-1)\n",
    "\n",
    "def se_block(x, reduction=8):\n",
    "    ch = x.shape[-1]\n",
    "    se = GlobalAveragePooling1D()(x)\n",
    "    se = Dense(ch // reduction, activation='relu')(se)\n",
    "    se = Dense(ch, activation='sigmoid')(se)\n",
    "    se = Reshape((1, ch))(se)\n",
    "    return Multiply()([x, se])\n",
    "\n",
    "def residual_se_cnn_block(x, filters, kernel_size, pool_size=2, drop=0.3, wd=1e-4):\n",
    "    shortcut = x\n",
    "    for _ in range(2):\n",
    "        x = Conv1D(filters, kernel_size, padding='same', use_bias=False,\n",
    "                   kernel_regularizer=l2(wd))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "    x = se_block(x)\n",
    "    if shortcut.shape[-1] != filters:\n",
    "        shortcut = Conv1D(filters, 1, padding='same', use_bias=False,\n",
    "                          kernel_regularizer=l2(wd))(shortcut)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "    x = add([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling1D(pool_size)(x)\n",
    "    x = Dropout(drop)(x)\n",
    "    return x\n",
    "\n",
    "def attention_layer(inputs):\n",
    "    score = Dense(1, activation='tanh')(inputs)\n",
    "    score = Lambda(squeeze_last_axis)(score)\n",
    "    weights = Activation('softmax')(score)\n",
    "    weights = Lambda(expand_last_axis)(weights)\n",
    "    context = Multiply()([inputs, weights])\n",
    "    context = Lambda(time_sum)(context)\n",
    "    return context\n",
    "\n",
    "# ----------------------- 2. DATA HELPERS ------------------------------\n",
    "\n",
    "def preprocess_sequence(df_seq: pd.DataFrame, feature_cols: list[str], scaler: StandardScaler):\n",
    "    mat = df_seq[feature_cols].ffill().bfill().fillna(0).values\n",
    "    return scaler.transform(mat).astype('float32')\n",
    "\n",
    "class MixupGenerator(Sequence):\n",
    "    def __init__(self, X, y, batch_size, alpha=0.2):\n",
    "        self.X, self.y = X, y\n",
    "        self.batch = batch_size\n",
    "        self.alpha = alpha\n",
    "        self.indices = np.arange(len(X))\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.X) / self.batch))\n",
    "    def __getitem__(self, i):\n",
    "        idx = self.indices[i*self.batch:(i+1)*self.batch]\n",
    "        Xb, yb = self.X[idx], self.y[idx]\n",
    "        lam = np.random.beta(self.alpha, self.alpha)\n",
    "        perm = np.random.permutation(len(Xb))\n",
    "        X_mix = lam * Xb + (1-lam) * Xb[perm]\n",
    "        y_mix = lam * yb + (1-lam) * yb[perm]\n",
    "        return X_mix, y_mix\n",
    "    def on_epoch_end(self):\n",
    "        np.random.shuffle(self.indices)\n",
    "\n",
    "# ----------------------- 3. MODEL DEFINITION --------------------------\n",
    "\n",
    "def build_two_branch_model(pad_len, imu_dim, tof_dim, n_classes, wd=1e-4):\n",
    "    inp = Input(shape=(pad_len, imu_dim+tof_dim))\n",
    "    imu = Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    # IMU deep branch\n",
    "    x1 = residual_se_cnn_block(imu, 64, 3, drop=0.3, wd=wd)\n",
    "    x1 = residual_se_cnn_block(x1, 128, 5, drop=0.3, wd=wd)\n",
    "\n",
    "    # TOF/Thermal lighter branch\n",
    "    x2 = Conv1D(64, 3, padding='same', use_bias=False, kernel_regularizer=l2(wd))(tof)\n",
    "    x2 = BatchNormalization()(x2); x2 = Activation('relu')(x2)\n",
    "    x2 = MaxPooling1D(2)(x2); x2 = Dropout(0.3)(x2)\n",
    "    x2 = Conv1D(128, 3, padding='same', use_bias=False, kernel_regularizer=l2(wd))(x2)\n",
    "    x2 = BatchNormalization()(x2); x2 = Activation('relu')(x2)\n",
    "    x2 = MaxPooling1D(2)(x2); x2 = Dropout(0.3)(x2)\n",
    "\n",
    "    merged = Concatenate()([x1, x2])\n",
    "\n",
    "    x = Bidirectional(LSTM(128, return_sequences=True, kernel_regularizer=l2(wd)))(merged)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = attention_layer(x)\n",
    "\n",
    "    for units, drop in [(256, 0.5), (128, 0.3)]:\n",
    "        x = Dense(units, use_bias=False, kernel_regularizer=l2(wd))(x)\n",
    "        x = BatchNormalization()(x); x = Activation('relu')(x)\n",
    "        x = Dropout(drop)(x)\n",
    "\n",
    "    out = Dense(n_classes, activation='softmax', kernel_regularizer=l2(wd))(x)\n",
    "    return Model(inp, out)\n",
    "\n",
    "# ----------------------- 4. TRAINING PHASE ----------------------------\n",
    "\n",
    "if TRAIN:\n",
    "    print(\"▶ TRAIN MODE – loading dataset …\")\n",
    "    df = pd.read_csv(RAW_DIR / \"train.csv\")\n",
    "\n",
    "    # label encoding\n",
    "    le = LabelEncoder(); df['gesture_int'] = le.fit_transform(df['gesture'])\n",
    "    np.save(EXPORT_DIR / \"gesture_classes.npy\", le.classes_)\n",
    "\n",
    "    # feature list\n",
    "    meta_cols = {'gesture', 'gesture_int', 'sequence_type', 'behavior', 'orientation',\n",
    "                 'row_id', 'subject', 'phase', 'sequence_id', 'sequence_counter'}\n",
    "    feature_cols = [c for c in df.columns if c not in meta_cols]\n",
    "\n",
    "    imu_cols  = [c for c in feature_cols if not (c.startswith('thm_') or c.startswith('tof_'))]\n",
    "    tof_cols  = [c for c in feature_cols if c.startswith('thm_') or c.startswith('tof_')]\n",
    "    print(f\"  IMU {len(imu_cols)} | TOF/THM {len(tof_cols)} | total {len(feature_cols)} features\")\n",
    "\n",
    "    # global scaler\n",
    "    scaler = StandardScaler().fit(df[feature_cols].ffill().bfill().fillna(0).values)\n",
    "    joblib.dump(scaler, EXPORT_DIR / \"scaler.pkl\")\n",
    "\n",
    "    # build sequences\n",
    "    seq_gp = df.groupby('sequence_id')\n",
    "    X_list, y_list, lens = [], [], []\n",
    "    for seq_id, seq in seq_gp:\n",
    "        mat = preprocess_sequence(seq, feature_cols, scaler)\n",
    "        X_list.append(mat)\n",
    "        y_list.append(seq['gesture_int'].iloc[0])\n",
    "        lens.append(len(mat))\n",
    "    pad_len = int(np.percentile(lens, PAD_PERCENTILE))\n",
    "    np.save(EXPORT_DIR / \"sequence_maxlen.npy\", pad_len)\n",
    "    np.save(EXPORT_DIR / \"feature_cols.npy\", np.array(feature_cols))\n",
    "\n",
    "    X = pad_sequences(X_list, maxlen=pad_len, padding='post', truncating='post', dtype='float32')\n",
    "    y = to_categorical(y_list, num_classes=len(le.classes_))\n",
    "\n",
    "    # split\n",
    "    X_tr, X_val, y_tr, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y_list)\n",
    "\n",
    "    # class weights\n",
    "    cw_vals = compute_class_weight('balanced', classes=np.arange(len(le.classes_)), y=y_list)\n",
    "    class_weight = dict(enumerate(cw_vals))\n",
    "\n",
    "    # model\n",
    "    model = build_two_branch_model(pad_len, len(imu_cols), len(tof_cols), len(le.classes_), wd=WD)\n",
    "    steps = len(X_tr)//BATCH_SIZE\n",
    "    lr_sched = tf.keras.optimizers.schedules.CosineDecayRestarts(LR_INIT, first_decay_steps=5*steps)\n",
    "    model.compile(optimizer=Adam(lr_sched),\n",
    "                  loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.05),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    train_gen = MixupGenerator(X_tr, y_tr, batch_size=BATCH_SIZE, alpha=MIXUP_ALPHA)\n",
    "    cb = EarlyStopping(patience=PATIENCE, restore_best_weights=True, verbose=1)\n",
    "    model.fit(train_gen, epochs=EPOCHS, validation_data=(X_val, y_val),\n",
    "              class_weight=class_weight, callbacks=[cb], verbose=1)\n",
    "\n",
    "    model.save(EXPORT_DIR / \"gesture_two_branch_mixup.h5\")\n",
    "    print(\"✔ Training done – artefacts saved in\", EXPORT_DIR)\n",
    "\n",
    "    # quick metric\n",
    "    from cmi_2025_metric_copy_for_import import CompetitionMetric\n",
    "    preds = model.predict(X_val).argmax(1)\n",
    "    true  = y_val.argmax(1)\n",
    "    h_f1 = CompetitionMetric().calculate_hierarchical_f1(\n",
    "        pd.DataFrame({'gesture': le.classes_[true]}),\n",
    "        pd.DataFrame({'gesture': le.classes_[preds]}))\n",
    "    print(\"Hold‑out H‑F1 =\", round(h_f1, 4))\n",
    "\n",
    "else:\n",
    "    print(\"▶ INFERENCE MODE – loading artefacts from\", PRETRAINED_DIR)\n",
    "    feature_cols   = np.load(PRETRAINED_DIR / \"feature_cols.npy\", allow_pickle=True).tolist()\n",
    "    pad_len        = int(np.load(PRETRAINED_DIR / \"sequence_maxlen.npy\"))\n",
    "    scaler         = joblib.load(PRETRAINED_DIR / \"scaler.pkl\")\n",
    "    gesture_classes = np.load(PRETRAINED_DIR / \"gesture_classes.npy\", allow_pickle=True)\n",
    "\n",
    "    imu_cols = [c for c in feature_cols if not (c.startswith('thm_') or c.startswith('tof_'))]\n",
    "    tof_cols = [c for c in feature_cols if c.startswith('thm_') or c.startswith('tof_')]\n",
    "\n",
    "    custom_objs = {\n",
    "        'time_sum': time_sum,\n",
    "        'squeeze_last_axis': squeeze_last_axis,\n",
    "        'expand_last_axis': expand_last_axis,\n",
    "        'se_block': se_block,\n",
    "        'residual_se_cnn_block': residual_se_cnn_block,\n",
    "        'attention_layer': attention_layer,\n",
    "    }\n",
    "    model = load_model(PRETRAINED_DIR / \"gesture_two_branch_mixup.h5\",\n",
    "                       compile=False, custom_objects=custom_objs)\n",
    "    print(\"  model, scaler, pads loaded – ready for evaluation\")\n",
    "\n",
    "# ----------------------- 5. KAGGLE predict() --------------------------\n",
    "\n",
    "# make sure gesture_classes exists in both modes\n",
    "if TRAIN:\n",
    "    gesture_classes = le.classes_\n",
    "\n",
    "\n",
    "def predict(sequence: pl.DataFrame, demographics: pl.DataFrame) -> str:\n",
    "    global gesture_classes\n",
    "    if gesture_classes is None:\n",
    "        gesture_classes = np.load(PRETRAINED_DIR / \"gesture_classes.npy\", allow_pickle=True)\n",
    "\n",
    "    df_seq = sequence.to_pandas()\n",
    "    mat = preprocess_sequence(df_seq, feature_cols, scaler)\n",
    "    pad = pad_sequences([mat], maxlen=pad_len, padding='post', truncating='post', dtype='float32')\n",
    "    idx = int(model.predict(pad, verbose=0).argmax(1)[0])\n",
    "    return str(gesture_classes[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97f93262",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T07:55:52.784920Z",
     "iopub.status.busy": "2025-06-02T07:55:52.784647Z",
     "iopub.status.idle": "2025-06-02T07:55:54.574257Z",
     "shell.execute_reply": "2025-06-02T07:55:54.573513Z"
    },
    "papermill": {
     "duration": 1.839961,
     "end_time": "2025-06-02T07:55:54.575776",
     "exception": false,
     "start_time": "2025-06-02T07:55:52.735815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import kaggle_evaluation.cmi_inference_server\n",
    "inference_server = kaggle_evaluation.cmi_inference_server.CMIInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway(\n",
    "        data_paths=(\n",
    "            '/kaggle/input/cmi-detect-behavior-with-sensor-data/test.csv',\n",
    "            '/kaggle/input/cmi-detect-behavior-with-sensor-data/test_demographics.csv',\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb4fce5",
   "metadata": {
    "papermill": {
     "duration": 0.046638,
     "end_time": "2025-06-02T07:55:54.721936",
     "exception": false,
     "start_time": "2025-06-02T07:55:54.675298",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### UPVOTE "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 12518947,
     "sourceId": 102335,
     "sourceType": "competition"
    },
    {
     "sourceId": 242954653,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 201.380144,
   "end_time": "2025-06-02T07:55:57.752203",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-02T07:52:36.372059",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
