{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e1ae554",
   "metadata": {
    "papermill": {
     "duration": 0.003912,
     "end_time": "2025-11-04T11:24:47.010737",
     "exception": false,
     "start_time": "2025-11-04T11:24:47.006825",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Note: Changes from original notebook: remove Sentence Transformer model, only use LLMs for final result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46564a6",
   "metadata": {
    "papermill": {
     "duration": 0.00316,
     "end_time": "2025-11-04T11:24:47.017491",
     "exception": false,
     "start_time": "2025-11-04T11:24:47.014331",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "586af063",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T11:24:47.026091Z",
     "iopub.status.busy": "2025-11-04T11:24:47.025436Z",
     "iopub.status.idle": "2025-11-04T11:25:32.961897Z",
     "shell.execute_reply": "2025-11-04T11:25:32.960908Z"
    },
    "papermill": {
     "duration": 45.946476,
     "end_time": "2025-11-04T11:25:32.967607",
     "exception": false,
     "start_time": "2025-11-04T11:24:47.021131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/lmsys-packages/triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from triton==2.2.0) (3.13.1)\r\n",
      "Installing collected packages: triton\r\n",
      "Successfully installed triton-2.2.0\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install /kaggle/input/lmsys-packages/triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c2f3584",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T11:25:32.976046Z",
     "iopub.status.busy": "2025-11-04T11:25:32.975668Z",
     "iopub.status.idle": "2025-11-04T11:26:21.469248Z",
     "shell.execute_reply": "2025-11-04T11:26:21.468076Z"
    },
    "papermill": {
     "duration": 48.504594,
     "end_time": "2025-11-04T11:26:21.475677",
     "exception": false,
     "start_time": "2025-11-04T11:25:32.971083",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/lmsys-packages/xformers-0.0.24042abc8.d20240802-cp310-cp310-linux_x86_64.whl\r\n",
      "Requirement already satisfied: torch>=1.12 in /opt/conda/lib/python3.10/site-packages (from xformers==0.0.24042abc8.d20240802) (2.1.2)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from xformers==0.0.24042abc8.d20240802) (1.26.4)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.12->xformers==0.0.24042abc8.d20240802) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.12->xformers==0.0.24042abc8.d20240802) (4.9.0)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.12->xformers==0.0.24042abc8.d20240802) (1.13.0)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.12->xformers==0.0.24042abc8.d20240802) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.12->xformers==0.0.24042abc8.d20240802) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.12->xformers==0.0.24042abc8.d20240802) (2024.5.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.12->xformers==0.0.24042abc8.d20240802) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.12->xformers==0.0.24042abc8.d20240802) (1.3.0)\r\n",
      "Installing collected packages: xformers\r\n",
      "Successfully installed xformers-0.0.24+042abc8.d20240802\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install /kaggle/input/lmsys-packages/xformers-0.0.24042abc8.d20240802-cp310-cp310-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8105021e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T11:26:21.486594Z",
     "iopub.status.busy": "2025-11-04T11:26:21.485740Z",
     "iopub.status.idle": "2025-11-04T11:26:22.597675Z",
     "shell.execute_reply": "2025-11-04T11:26:22.596365Z"
    },
    "papermill": {
     "duration": 1.119901,
     "end_time": "2025-11-04T11:26:22.599968",
     "exception": false,
     "start_time": "2025-11-04T11:26:21.480067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp -r /kaggle/input/lmsys-modules-0805 human_pref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62f94758",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T11:26:22.610907Z",
     "iopub.status.busy": "2025-11-04T11:26:22.609978Z",
     "iopub.status.idle": "2025-11-04T11:26:22.819944Z",
     "shell.execute_reply": "2025-11-04T11:26:22.819047Z"
    },
    "papermill": {
     "duration": 0.218498,
     "end_time": "2025-11-04T11:26:22.822996",
     "exception": false,
     "start_time": "2025-11-04T11:26:22.604498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/some-pack/balanced_transformed_dataset.csv\n",
      "/kaggle/input/some-pack/faiss_cpu_downloads/faiss_cpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/some-pack/sentence-transformer-model/config.json\n",
      "/kaggle/input/some-pack/sentence-transformer-model/README.md\n",
      "/kaggle/input/some-pack/sentence-transformer-model/tokenizer.json\n",
      "/kaggle/input/some-pack/sentence-transformer-model/tokenizer_config.json\n",
      "/kaggle/input/some-pack/sentence-transformer-model/sentence_bert_config.json\n",
      "/kaggle/input/some-pack/sentence-transformer-model/config_sentence_transformers.json\n",
      "/kaggle/input/some-pack/sentence-transformer-model/model.safetensors\n",
      "/kaggle/input/some-pack/sentence-transformer-model/modules.json\n",
      "/kaggle/input/some-pack/sentence-transformer-model/special_tokens_map.json\n",
      "/kaggle/input/some-pack/sentence-transformer-model/vocab.txt\n",
      "/kaggle/input/some-pack/sentence-transformer-model/1_Pooling/config.json\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/pillow-11.0.0-cp310-cp310-manylinux_2_28_x86_64.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/certifi-2024.12.14-py3-none-any.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/tqdm-4.67.1-py3-none-any.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/sentence_transformers-3.3.1-py3-none-any.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/jinja2-3.1.4-py3-none-any.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/scikit_learn-1.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/idna-3.10-py3-none-any.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/mpmath-1.3.0-py3-none-any.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/fsspec-2024.10.0-py3-none-any.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/networkx-3.4.2-py3-none-any.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/transformers-4.47.0-py3-none-any.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/filelock-3.16.1-py3-none-any.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/threadpoolctl-3.5.0-py3-none-any.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/numpy-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/requests-2.32.3-py3-none-any.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/joblib-1.4.2-py3-none-any.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/urllib3-2.2.3-py3-none-any.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/typing_extensions-4.12.2-py3-none-any.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/sympy-1.13.1-py3-none-any.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/huggingface_hub-0.26.5-py3-none-any.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/packaging-24.2-py3-none-any.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl\n",
      "/kaggle/input/some-pack/sentence_transformers_packages/charset_normalizer-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/73zap2gx/checkpoint-4800/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-4800/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-4800/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-4800/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-4800/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-4800/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-4800/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-4800/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-4800/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-4800/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-4800/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-4800/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-2000/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-2000/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-2000/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-2000/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-2000/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-2000/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-2000/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-2000/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-2000/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-2000/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-2000/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-2000/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-3600/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-3600/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-3600/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-3600/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-3600/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-3600/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-3600/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-3600/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-3600/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-3600/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-3600/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-3600/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-2200/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-2200/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-2200/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-2200/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-2200/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-2200/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-2200/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-2200/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-2200/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-2200/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-2200/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-2200/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-400/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-400/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-400/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-400/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-400/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-400/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-400/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-400/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-400/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-400/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-400/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-400/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-5600/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-5600/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-5600/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-5600/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-5600/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-5600/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-5600/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-5600/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-5600/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-5600/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-5600/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-5600/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-5400/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-5400/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-5400/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-5400/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-5400/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-5400/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-5400/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-5400/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-5400/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-5400/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-5400/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-5400/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-1200/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-1200/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-1200/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-1200/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-1200/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-1200/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-1200/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-1200/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-1200/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-1200/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-1200/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-1200/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-1400/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-1400/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-1400/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-1400/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-1400/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-1400/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-1400/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-1400/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-1400/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-1400/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-1400/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-1400/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-3000/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-3000/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-3000/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-3000/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-3000/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-3000/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-3000/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-3000/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-3000/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-3000/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-3000/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-3000/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-4400/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-4400/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-4400/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-4400/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-4400/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-4400/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-4400/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-4400/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-4400/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-4400/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-4400/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-4400/tokenizer.model\n",
      "/kaggle/input/73zap2gx/.ipynb_checkpoints/dataset-metadata-checkpoint.json\n",
      "/kaggle/input/73zap2gx/checkpoint-600/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-600/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-600/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-600/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-600/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-600/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-600/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-600/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-600/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-600/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-600/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-600/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-5748/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-5748/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-5748/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-5748/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-5748/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-5748/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-5748/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-5748/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-5748/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-5748/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-5748/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-5748/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-5000/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-5000/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-5000/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-5000/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-5000/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-5000/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-5000/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-5000/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-5000/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-5000/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-5000/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-5000/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-4600/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-4600/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-4600/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-4600/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-4600/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-4600/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-4600/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-4600/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-4600/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-4600/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-4600/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-4600/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-2400/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-2400/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-2400/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-2400/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-2400/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-2400/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-2400/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-2400/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-2400/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-2400/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-2400/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-2400/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-4200/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-4200/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-4200/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-4200/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-4200/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-4200/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-4200/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-4200/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-4200/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-4200/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-4200/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-4200/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-3400/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-3400/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-3400/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-3400/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-3400/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-3400/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-3400/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-3400/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-3400/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-3400/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-3400/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-3400/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-1800/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-1800/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-1800/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-1800/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-1800/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-1800/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-1800/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-1800/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-1800/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-1800/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-1800/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-1800/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-200/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-200/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-200/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-200/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-200/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-200/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-200/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-200/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-200/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-200/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-200/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-200/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-3800/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-3800/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-3800/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-3800/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-3800/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-3800/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-3800/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-3800/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-3800/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-3800/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-3800/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-3800/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-800/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-800/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-800/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-800/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-800/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-800/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-800/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-800/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-800/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-800/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-800/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-800/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-1600/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-1600/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-1600/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-1600/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-1600/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-1600/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-1600/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-1600/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-1600/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-1600/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-1600/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-1600/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-4000/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-4000/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-4000/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-4000/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-4000/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-4000/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-4000/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-4000/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-4000/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-4000/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-4000/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-4000/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-3200/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-3200/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-3200/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-3200/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-3200/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-3200/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-3200/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-3200/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-3200/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-3200/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-3200/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-3200/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-1000/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-1000/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-1000/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-1000/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-1000/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-1000/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-1000/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-1000/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-1000/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-1000/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-1000/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-1000/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-5200/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-5200/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-5200/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-5200/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-5200/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-5200/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-5200/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-5200/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-5200/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-5200/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-5200/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-5200/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-2800/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-2800/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-2800/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-2800/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-2800/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-2800/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-2800/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-2800/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-2800/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-2800/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-2800/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-2800/tokenizer.model\n",
      "/kaggle/input/73zap2gx/checkpoint-2600/adapter_model.safetensors\n",
      "/kaggle/input/73zap2gx/checkpoint-2600/trainer_state.json\n",
      "/kaggle/input/73zap2gx/checkpoint-2600/training_args.bin\n",
      "/kaggle/input/73zap2gx/checkpoint-2600/adapter_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-2600/README.md\n",
      "/kaggle/input/73zap2gx/checkpoint-2600/tokenizer.json\n",
      "/kaggle/input/73zap2gx/checkpoint-2600/tokenizer_config.json\n",
      "/kaggle/input/73zap2gx/checkpoint-2600/scheduler.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-2600/special_tokens_map.json\n",
      "/kaggle/input/73zap2gx/checkpoint-2600/optimizer.pt\n",
      "/kaggle/input/73zap2gx/checkpoint-2600/rng_state.pth\n",
      "/kaggle/input/73zap2gx/checkpoint-2600/tokenizer.model\n",
      "/kaggle/input/pppppppp/final_model_dir/config.json\n",
      "/kaggle/input/pppppppp/merged_model_dir/spm.model\n",
      "/kaggle/input/pppppppp/merged_model_dir/config.json\n",
      "/kaggle/input/pppppppp/merged_model_dir/tokenizer.json\n",
      "/kaggle/input/pppppppp/merged_model_dir/tokenizer_config.json\n",
      "/kaggle/input/pppppppp/merged_model_dir/custom_model.pth\n",
      "/kaggle/input/pppppppp/merged_model_dir/special_tokens_map.json\n",
      "/kaggle/input/pppppppp/merged_model_dir/added_tokens.json\n",
      "/kaggle/input/gemma-2/transformers/gemma-2-9b-it-4bit/1/gemma-2-9b-it-4bit/model.safetensors.index.json\n",
      "/kaggle/input/gemma-2/transformers/gemma-2-9b-it-4bit/1/gemma-2-9b-it-4bit/config.json\n",
      "/kaggle/input/gemma-2/transformers/gemma-2-9b-it-4bit/1/gemma-2-9b-it-4bit/model-00001-of-00002.safetensors\n",
      "/kaggle/input/gemma-2/transformers/gemma-2-9b-it-4bit/1/gemma-2-9b-it-4bit/model-00002-of-00002.safetensors\n",
      "/kaggle/input/gemma-2/transformers/gemma-2-9b-it-4bit/1/gemma-2-9b-it-4bit/tokenizer.json\n",
      "/kaggle/input/gemma-2/transformers/gemma-2-9b-it-4bit/1/gemma-2-9b-it-4bit/tokenizer_config.json\n",
      "/kaggle/input/gemma-2/transformers/gemma-2-9b-it-4bit/1/gemma-2-9b-it-4bit/special_tokens_map.json\n",
      "/kaggle/input/gemma-2/transformers/gemma-2-9b-it-4bit/1/gemma-2-9b-it-4bit/tokenizer.model\n",
      "/kaggle/input/lmsys-packages/triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/lmsys-packages/xformers-0.0.24042abc8.d20240802-cp310-cp310-linux_x86_64.whl\n",
      "/kaggle/input/lmsys-modules-0805/utils.py\n",
      "/kaggle/input/lmsys-modules-0805/models/modeling_gemma2.py\n",
      "/kaggle/input/lmsys-modules-0805/models/modeling_llama.py\n",
      "/kaggle/input/lmsys-modules-0805/models/ops/triton_utils.py\n",
      "/kaggle/input/lmsys-modules-0805/models/ops/rms_norm.py\n",
      "/kaggle/input/lmsys-modules-0805/models/ops/flash_attention_nopad.py\n",
      "/kaggle/input/lmsys-modules-0805/models/ops/fused_rotary_emb.py\n",
      "/kaggle/input/lmsys-modules-0805/models/ops/gelu_and_mul.py\n",
      "/kaggle/input/lmsys-modules-0805/models/ops/silu_and_mul.py\n",
      "/kaggle/input/lmsys-modules-0805/data/collators.py\n",
      "/kaggle/input/lmsys-modules-0805/data/dataset.py\n",
      "/kaggle/input/lmsys-modules-0805/data/processors.py\n",
      "/kaggle/input/lmsys-checkpoints-0-0805/model.safetensors.index.json\n",
      "/kaggle/input/lmsys-checkpoints-0-0805/model-00003-of-00004.safetensors\n",
      "/kaggle/input/lmsys-checkpoints-0-0805/config.json\n",
      "/kaggle/input/lmsys-checkpoints-0-0805/model-00001-of-00004.safetensors\n",
      "/kaggle/input/lmsys-checkpoints-0-0805/tokenizer.json\n",
      "/kaggle/input/lmsys-checkpoints-0-0805/tokenizer_config.json\n",
      "/kaggle/input/lmsys-checkpoints-0-0805/model-00004-of-00004.safetensors\n",
      "/kaggle/input/lmsys-checkpoints-0-0805/special_tokens_map.json\n",
      "/kaggle/input/lmsys-checkpoints-0-0805/model-00002-of-00004.safetensors\n",
      "/kaggle/input/lmsys-checkpoints-0-0805/tokenizer.model\n",
      "/kaggle/input/lmsys-checkpoints-3-0805/model.safetensors.index.json\n",
      "/kaggle/input/lmsys-checkpoints-3-0805/model-00003-of-00004.safetensors\n",
      "/kaggle/input/lmsys-checkpoints-3-0805/config.json\n",
      "/kaggle/input/lmsys-checkpoints-3-0805/model-00001-of-00004.safetensors\n",
      "/kaggle/input/lmsys-checkpoints-3-0805/tokenizer.json\n",
      "/kaggle/input/lmsys-checkpoints-3-0805/tokenizer_config.json\n",
      "/kaggle/input/lmsys-checkpoints-3-0805/model-00004-of-00004.safetensors\n",
      "/kaggle/input/lmsys-checkpoints-3-0805/special_tokens_map.json\n",
      "/kaggle/input/lmsys-checkpoints-3-0805/model-00002-of-00004.safetensors\n",
      "/kaggle/input/llm-classification-finetuning/sample_submission.csv\n",
      "/kaggle/input/llm-classification-finetuning/train.csv\n",
      "/kaggle/input/llm-classification-finetuning/test.csv\n",
      "/kaggle/input/lmsys-wheel-files/peft-0.11.1-py3-none-any.whl\n",
      "/kaggle/input/lmsys-wheel-files/transformers-4.42.3-py3-none-any.whl\n",
      "/kaggle/input/lmsys-wheel-files/sympy-1.12.1-py3-none-any.whl\n",
      "/kaggle/input/lmsys-wheel-files/numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/urllib3-2.2.2-py3-none-any.whl\n",
      "/kaggle/input/lmsys-wheel-files/triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/tqdm-4.66.4-py3-none-any.whl\n",
      "/kaggle/input/lmsys-wheel-files/nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/idna-3.7-py3-none-any.whl\n",
      "/kaggle/input/lmsys-wheel-files/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/jinja2-3.1.4-py3-none-any.whl\n",
      "/kaggle/input/lmsys-wheel-files/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/mpmath-1.3.0-py3-none-any.whl\n",
      "/kaggle/input/lmsys-wheel-files/networkx-3.3-py3-none-any.whl\n",
      "/kaggle/input/lmsys-wheel-files/torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/psutil-6.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/filelock-3.15.4-py3-none-any.whl\n",
      "/kaggle/input/lmsys-wheel-files/regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/certifi-2024.7.4-py3-none-any.whl\n",
      "/kaggle/input/lmsys-wheel-files/MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/accelerate-0.32.1-py3-none-any.whl\n",
      "/kaggle/input/lmsys-wheel-files/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/packaging-24.1-py3-none-any.whl\n",
      "/kaggle/input/lmsys-wheel-files/nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/requests-2.32.3-py3-none-any.whl\n",
      "/kaggle/input/lmsys-wheel-files/charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/typing_extensions-4.12.2-py3-none-any.whl\n",
      "/kaggle/input/lmsys-wheel-files/huggingface_hub-0.23.4-py3-none-any.whl\n",
      "/kaggle/input/lmsys-wheel-files/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/fsspec-2024.6.1-py3-none-any.whl\n",
      "/kaggle/input/lmsys-wheel-files/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/amodellll/deberta-v3-small-local/spm.model\n",
      "/kaggle/input/amodellll/deberta-v3-small-local/config.json\n",
      "/kaggle/input/amodellll/deberta-v3-small-local/tokenizer.json\n",
      "/kaggle/input/amodellll/deberta-v3-small-local/tokenizer_config.json\n",
      "/kaggle/input/amodellll/deberta-v3-small-local/model.safetensors\n",
      "/kaggle/input/amodellll/deberta-v3-small-local/special_tokens_map.json\n",
      "/kaggle/input/amodellll/deberta-v3-small-local/added_tokens.json\n",
      "/kaggle/input/akemiiiiii/balanced_transformed_dataset.csv\n",
      "/kaggle/input/akemiiiiii/custom_model_dir/spm.model\n",
      "/kaggle/input/akemiiiiii/custom_model_dir/custom_model_complete.pth\n",
      "/kaggle/input/akemiiiiii/custom_model_dir/tokenizer.json\n",
      "/kaggle/input/akemiiiiii/custom_model_dir/tokenizer_config.json\n",
      "/kaggle/input/akemiiiiii/custom_model_dir/model_config.pth\n",
      "/kaggle/input/akemiiiiii/custom_model_dir/special_tokens_map.json\n",
      "/kaggle/input/akemiiiiii/custom_model_dir/custom_model_weights.pth\n",
      "/kaggle/input/akemiiiiii/custom_model_dir/added_tokens.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7509daa5",
   "metadata": {
    "papermill": {
     "duration": 0.005096,
     "end_time": "2025-11-04T11:26:22.833384",
     "exception": false,
     "start_time": "2025-11-04T11:26:22.828288",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prepare test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83c974df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T11:26:22.845254Z",
     "iopub.status.busy": "2025-11-04T11:26:22.844542Z",
     "iopub.status.idle": "2025-11-04T11:26:22.850742Z",
     "shell.execute_reply": "2025-11-04T11:26:22.849892Z"
    },
    "papermill": {
     "duration": 0.01427,
     "end_time": "2025-11-04T11:26:22.852640",
     "exception": false,
     "start_time": "2025-11-04T11:26:22.838370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing prepare_test_file.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile prepare_test_file.py\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"/kaggle/input/llm-classification-finetuning/test.csv\")\n",
    "df[\"winner_model_a\"] = 1\n",
    "df[\"winner_model_b\"] = 0\n",
    "df[\"winner_tie\"] = 0\n",
    "df.to_parquet(\"test.parquet\", index=False)\n",
    "\n",
    "df[\"response_a\"], df[\"response_b\"] = df[\"response_b\"], df[\"response_a\"]\n",
    "df.to_parquet(\"test_swap.parquet\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71b6e385",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T11:26:22.864669Z",
     "iopub.status.busy": "2025-11-04T11:26:22.863928Z",
     "iopub.status.idle": "2025-11-04T11:26:25.092034Z",
     "shell.execute_reply": "2025-11-04T11:26:25.090688Z"
    },
    "papermill": {
     "duration": 2.237048,
     "end_time": "2025-11-04T11:26:25.094974",
     "exception": false,
     "start_time": "2025-11-04T11:26:22.857926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python prepare_test_file.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebdf23b",
   "metadata": {
    "papermill": {
     "duration": 0.005935,
     "end_time": "2025-11-04T11:26:25.106219",
     "exception": false,
     "start_time": "2025-11-04T11:26:25.100284",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference: gemma2-9b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82e2a134",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T11:26:25.118445Z",
     "iopub.status.busy": "2025-11-04T11:26:25.118119Z",
     "iopub.status.idle": "2025-11-04T11:26:25.125466Z",
     "shell.execute_reply": "2025-11-04T11:26:25.124645Z"
    },
    "papermill": {
     "duration": 0.016184,
     "end_time": "2025-11-04T11:26:25.127363",
     "exception": false,
     "start_time": "2025-11-04T11:26:25.111179",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing predict_m0.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile predict_m0.py\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from xformers.ops.fmha.attn_bias import BlockDiagonalCausalMask\n",
    "from human_pref.models.modeling_gemma2 import Gemma2ForSequenceClassification\n",
    "from human_pref.data.processors import ProcessorPAB\n",
    "from human_pref.data.dataset import LMSYSDataset\n",
    "from human_pref.data.collators import VarlenCollator, ShardedMaxTokensCollator\n",
    "from human_pref.utils import to_device\n",
    "\n",
    "\n",
    "model_name_or_path = \"/kaggle/input/lmsys-checkpoints-0-0805\"\n",
    "csv_path = \"test.parquet\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "processor = ProcessorPAB(\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=4096,\n",
    "    support_system_role=False,\n",
    ")\n",
    "dataset = LMSYSDataset(\n",
    "    csv_file=csv_path,\n",
    "    query=None,\n",
    "    processor=processor,\n",
    "    include_swap=False,\n",
    "    is_parquet=True,\n",
    ")\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=80,\n",
    "    num_workers=4,\n",
    "    collate_fn=ShardedMaxTokensCollator(\n",
    "        max_tokens=8192, base_collator=VarlenCollator()\n",
    "    ),\n",
    ")\n",
    "\n",
    "# model for pipelined inference\n",
    "num_hidden_layers = 42\n",
    "device_map = {\n",
    "    \"model.embed_tokens\": \"cuda:0\",\n",
    "    \"model.norm\": \"cuda:1\",\n",
    "    \"score\": \"cuda:1\",\n",
    "}\n",
    "for i in range(num_hidden_layers // 2):\n",
    "    device_map[f\"model.layers.{i}\"] = \"cuda:0\"\n",
    "for i in range(num_hidden_layers // 2, num_hidden_layers):\n",
    "    device_map[f\"model.layers.{i}\"] = \"cuda:1\"\n",
    "\n",
    "model = Gemma2ForSequenceClassification.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=device_map,\n",
    ")\n",
    "\n",
    "# inv_freq clones for each device\n",
    "config = model.config\n",
    "dim = config.head_dim\n",
    "inv_freq = 1.0 / (\n",
    "    config.rope_theta ** (torch.arange(0, dim, 2, dtype=torch.float32) / dim)\n",
    ")\n",
    "inv_freq0 = inv_freq.to(\"cuda:0\")\n",
    "inv_freq1 = inv_freq.to(\"cuda:1\")\n",
    "\n",
    "\n",
    "# for name, p in model.named_parameters():\n",
    "#     print(name, p.device)\n",
    "# for name, b in model.model.named_buffers():\n",
    "#     print(name, b.device)\n",
    "\n",
    "# pipeline parallelism with two GPUs\n",
    "is_first = True\n",
    "hidden_states = None\n",
    "outs = []\n",
    "for batch in tqdm(dataloader):\n",
    "    for micro_batch in batch:\n",
    "        input_ids = to_device(micro_batch[\"input_ids\"], \"cuda:0\")\n",
    "        seq_info = dict(\n",
    "            cu_seqlens=micro_batch[\"cu_seqlens\"],\n",
    "            position_ids=micro_batch[\"position_ids\"],\n",
    "            max_seq_len=micro_batch[\"max_seq_len\"],\n",
    "            attn_bias=BlockDiagonalCausalMask.from_seqlens(micro_batch[\"seq_lens\"]),\n",
    "        )\n",
    "        seq_info = to_device(seq_info, \"cuda:0\")\n",
    "        if is_first:\n",
    "            with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "                prev_hidden_states = model.forward_part1(input_ids, seq_info, inv_freq0)\n",
    "            is_first = False\n",
    "            prev_seq_info, prev_hidden_states = to_device(\n",
    "                [seq_info, prev_hidden_states], \"cuda:1\"\n",
    "            )\n",
    "            continue\n",
    "        with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "            logits = model.forward_part2(prev_hidden_states, prev_seq_info, inv_freq1)\n",
    "            hidden_states = model.forward_part1(input_ids, seq_info, inv_freq0)\n",
    "\n",
    "            prev_seq_info, prev_hidden_states = to_device(\n",
    "                [seq_info, hidden_states], \"cuda:1\"\n",
    "            )\n",
    "            outs.append(logits.cpu())\n",
    "\n",
    "# last micro-batch\n",
    "with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "    logits = model.forward_part2(prev_hidden_states, prev_seq_info, inv_freq1)\n",
    "    outs.append(logits.cpu())\n",
    "\n",
    "pred = torch.cat(outs, dim=0)\n",
    "prob = pred.softmax(-1)\n",
    "print(dataset.evaluate(prob.numpy()))\n",
    "\n",
    "np.save('prob_m0.npy', prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "982dbd10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T11:26:25.139169Z",
     "iopub.status.busy": "2025-11-04T11:26:25.138808Z",
     "iopub.status.idle": "2025-11-04T11:32:03.883632Z",
     "shell.execute_reply": "2025-11-04T11:32:03.882880Z"
    },
    "papermill": {
     "duration": 338.753127,
     "end_time": "2025-11-04T11:32:03.885719",
     "exception": false,
     "start_time": "2025-11-04T11:26:25.132592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|| 4/4 [05:09<00:00, 77.48s/it]\r\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]2025-11-04 11:31:45.615568: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "2025-11-04 11:31:45.615771: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2025-11-04 11:31:45.754276: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "100%|| 1/1 [00:16<00:00, 16.23s/it]\r\n",
      "{'log_loss': 3.094615495202658}\r\n"
     ]
    }
   ],
   "source": [
    "!python predict_m0.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7ee619",
   "metadata": {
    "papermill": {
     "duration": 0.005833,
     "end_time": "2025-11-04T11:32:03.897703",
     "exception": false,
     "start_time": "2025-11-04T11:32:03.891870",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference: llama3-8b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad506e9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T11:32:03.909606Z",
     "iopub.status.busy": "2025-11-04T11:32:03.909100Z",
     "iopub.status.idle": "2025-11-04T11:32:03.916072Z",
     "shell.execute_reply": "2025-11-04T11:32:03.915276Z"
    },
    "papermill": {
     "duration": 0.014874,
     "end_time": "2025-11-04T11:32:03.917698",
     "exception": false,
     "start_time": "2025-11-04T11:32:03.902824",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing predict_m3.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile predict_m3.py\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from xformers.ops.fmha.attn_bias import BlockDiagonalCausalMask\n",
    "from human_pref.models.modeling_llama import LlamaForSequenceClassification\n",
    "from human_pref.data.processors import ProcessorPAB\n",
    "from human_pref.data.dataset import LMSYSDataset\n",
    "from human_pref.data.collators import VarlenCollator, ShardedMaxTokensCollator\n",
    "from human_pref.utils import to_device\n",
    "\n",
    "\n",
    "model_name_or_path = \"/kaggle/input/lmsys-checkpoints-3-0805\"\n",
    "csv_path = \"test_swap.parquet\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "tokenizer.deprecation_warnings[\n",
    "    \"sequence-length-is-longer-than-the-specified-maximum\"\n",
    "] = True\n",
    "processor = ProcessorPAB(\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=4096,\n",
    "    support_system_role=True,\n",
    ")\n",
    "dataset = LMSYSDataset(\n",
    "    csv_file=csv_path,\n",
    "    query=None,\n",
    "    processor=processor,\n",
    "    include_swap=False,\n",
    "    is_parquet=True,\n",
    ")\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=80,\n",
    "    num_workers=4,\n",
    "    collate_fn=ShardedMaxTokensCollator(\n",
    "        max_tokens=8192, base_collator=VarlenCollator()\n",
    "    ),\n",
    ")\n",
    "\n",
    "# model for pipelined inference\n",
    "num_hidden_layers = 32\n",
    "device_map = {\n",
    "    \"model.embed_tokens\": \"cuda:0\",\n",
    "    \"model.norm\": \"cuda:1\",\n",
    "    \"score\": \"cuda:1\",\n",
    "}\n",
    "for i in range(num_hidden_layers // 2):\n",
    "    device_map[f\"model.layers.{i}\"] = \"cuda:0\"\n",
    "for i in range(num_hidden_layers // 2, num_hidden_layers):\n",
    "    device_map[f\"model.layers.{i}\"] = \"cuda:1\"\n",
    "\n",
    "model = LlamaForSequenceClassification.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=device_map,\n",
    ")\n",
    "\n",
    "# inv_freq clones for each device\n",
    "config = model.config\n",
    "dim = config.hidden_size // config.num_attention_heads\n",
    "inv_freq = 1.0 / (\n",
    "    config.rope_theta ** (torch.arange(0, dim, 2, dtype=torch.float32) / dim)\n",
    ")\n",
    "inv_freq0 = inv_freq.to(\"cuda:0\")\n",
    "inv_freq1 = inv_freq.to(\"cuda:1\")\n",
    "\n",
    "is_first = True\n",
    "hidden_states = None\n",
    "outs = []\n",
    "for batch in tqdm(dataloader):\n",
    "    for micro_batch in batch:\n",
    "        input_ids = to_device(micro_batch[\"input_ids\"], \"cuda:0\")\n",
    "        seq_info = dict(\n",
    "            cu_seqlens=micro_batch[\"cu_seqlens\"],\n",
    "            position_ids=micro_batch[\"position_ids\"],\n",
    "            max_seq_len=micro_batch[\"max_seq_len\"],\n",
    "            attn_bias=BlockDiagonalCausalMask.from_seqlens(micro_batch[\"seq_lens\"]),\n",
    "        )\n",
    "        seq_info = to_device(seq_info, \"cuda:0\")\n",
    "        if is_first:\n",
    "            with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "                prev_hidden_states = model.forward_part1(input_ids, seq_info, inv_freq0)\n",
    "            is_first = False\n",
    "            prev_seq_info, prev_hidden_states = to_device(\n",
    "                [seq_info, prev_hidden_states], \"cuda:1\"\n",
    "            )\n",
    "            continue\n",
    "        with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "            logits = model.forward_part2(prev_hidden_states, prev_seq_info, inv_freq1)\n",
    "            hidden_states = model.forward_part1(input_ids, seq_info, inv_freq0)\n",
    "\n",
    "            prev_seq_info, prev_hidden_states = to_device(\n",
    "                [seq_info, hidden_states], \"cuda:1\"\n",
    "            )\n",
    "            outs.append(logits.cpu())\n",
    "\n",
    "# last micro-batch\n",
    "with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "    logits = model.forward_part2(prev_hidden_states, prev_seq_info, inv_freq1)\n",
    "    outs.append(logits.cpu())\n",
    "\n",
    "\n",
    "pred = torch.cat(outs, dim=0)\n",
    "prob = pred.softmax(-1)\n",
    "print(dataset.evaluate(prob.numpy()))\n",
    "\n",
    "np.save('prob_m3.npy', prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f89a8d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T11:32:03.929236Z",
     "iopub.status.busy": "2025-11-04T11:32:03.928687Z",
     "iopub.status.idle": "2025-11-04T11:36:10.593135Z",
     "shell.execute_reply": "2025-11-04T11:36:10.591987Z"
    },
    "papermill": {
     "duration": 246.672665,
     "end_time": "2025-11-04T11:36:10.595526",
     "exception": false,
     "start_time": "2025-11-04T11:32:03.922861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\r\n",
      "Loading checkpoint shards: 100%|| 4/4 [03:52<00:00, 58.05s/it]\r\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]2025-11-04 11:36:01.431266: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "2025-11-04 11:36:01.431363: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2025-11-04 11:36:01.433865: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "100%|| 1/1 [00:06<00:00,  6.60s/it]\r\n",
      "{'log_loss': 0.7582519183970864}\r\n"
     ]
    }
   ],
   "source": [
    "!python predict_m3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2cd8317",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T11:36:10.611074Z",
     "iopub.status.busy": "2025-11-04T11:36:10.610328Z",
     "iopub.status.idle": "2025-11-04T11:36:10.617690Z",
     "shell.execute_reply": "2025-11-04T11:36:10.616766Z"
    },
    "papermill": {
     "duration": 0.017378,
     "end_time": "2025-11-04T11:36:10.619749",
     "exception": false,
     "start_time": "2025-11-04T11:36:10.602371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.98613375 0.0021362  0.01173002]\n",
      " [0.13743691 0.5760938  0.28646934]\n",
      " [0.7586595  0.09096359 0.1503769 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "prob = np.load('prob_m3.npy')\n",
    "\n",
    "print(prob[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d7e85d",
   "metadata": {
    "papermill": {
     "duration": 0.005985,
     "end_time": "2025-11-04T11:36:10.632797",
     "exception": false,
     "start_time": "2025-11-04T11:36:10.626812",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Make submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f1c3107",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T11:36:10.646742Z",
     "iopub.status.busy": "2025-11-04T11:36:10.646130Z",
     "iopub.status.idle": "2025-11-04T11:36:11.205136Z",
     "shell.execute_reply": "2025-11-04T11:36:11.204112Z"
    },
    "papermill": {
     "duration": 0.568626,
     "end_time": "2025-11-04T11:36:11.207507",
     "exception": false,
     "start_time": "2025-11-04T11:36:10.638881",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  winner_model_a  winner_model_b  winner_tie\n",
      "0   136060        0.002253        0.981807    0.015940\n",
      "1   211333        0.527081        0.128636    0.344282\n",
      "2  1233961        0.085258        0.765311    0.149431\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_parquet(\"test.parquet\")\n",
    "\n",
    "\n",
    "prob_m0 = np.load(\"prob_m0.npy\")  # Gemma2\n",
    "prob_m3 = np.load(\"prob_m3.npy\")[:, [1, 0, 2]]  # Llama3 (swap response_a and response_b)\n",
    "\n",
    "# Combine predictions with weights\n",
    "# Adjust weights as needed for optimal performance\n",
    "preds = np.average(\n",
    "    [\n",
    "        prob_m0,       # Gemma2 results\n",
    "        prob_m3,       # Llama3 results\n",
    "    ],\n",
    "    axis=0,\n",
    "    weights=[0.57, 0.43]  # Weights for each model\n",
    ")\n",
    "\n",
    "# Create submission DataFrame\n",
    "sub = pd.DataFrame({\n",
    "    \"id\": df[\"id\"],\n",
    "    \"winner_model_a\": preds[:, 0],\n",
    "    \"winner_model_b\": preds[:, 1],\n",
    "    \"winner_tie\": preds[:, 2],\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "sub.to_csv(\"submission.csv\", index=False)\n",
    "print(sub.head())\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 9809560,
     "sourceId": 86518,
     "sourceType": "competition"
    },
    {
     "datasetId": 5297895,
     "sourceId": 8897601,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5369301,
     "sourceId": 8926343,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5493674,
     "sourceId": 9102725,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5496762,
     "sourceId": 9107824,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5496847,
     "sourceId": 9107963,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5496920,
     "sourceId": 9108069,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6265978,
     "sourceId": 10150018,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6267026,
     "sourceId": 10214229,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6266300,
     "sourceId": 10236316,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6265823,
     "sourceId": 10302322,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 86587,
     "modelInstanceId": 63082,
     "sourceId": 75103,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 687.094978,
   "end_time": "2025-11-04T11:36:11.635105",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-04T11:24:44.540127",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
