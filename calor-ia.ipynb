{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91716,"databundleVersionId":11893428,"sourceType":"competition"}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# \"What if üéØüöÄ we build an AI Agent ü§ñ who can compete for me in this Kaggle competition üèÜüìä?\"\n\n","metadata":{}},{"cell_type":"code","source":"#Remove conflicting packages from the Kaggle base environment.¬∂\n!pip uninstall -qqy kfp jupyterlab libpysal thinc spacy fastai ydata-profiling google-cloud-bigquery google-generativeai\n!pip install -qU 'langgraph==0.3.21' 'langchain-google-genai==2.1.2' 'langgraph-prebuilt==0.1.7'\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T03:59:11.934703Z","iopub.execute_input":"2025-05-05T03:59:11.93499Z","iopub.status.idle":"2025-05-05T03:59:49.535829Z","shell.execute_reply.started":"2025-05-05T03:59:11.93497Z","shell.execute_reply":"2025-05-05T03:59:49.534575Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nimport operator\nimport re # Import regex for parsing\nimport json\nimport io\nimport sys\n\n\n\nfrom langchain_core.messages import BaseMessage, HumanMessage, AIMessage # Import AIMessage\n# from langchain_openai import ChatOpenAI # Replace with your desired LLM provider\nfrom langgraph.graph import StateGraph, END\n# Kaggle and Google AI\nfrom kaggle_secrets import UserSecretsClient\nfrom langchain_google_genai import ChatGoogleGenerativeAI\nfrom google import genai\nfrom google.genai import types\nfrom google.api_core import retry\n\n# IPython Display\nfrom IPython.display import Markdown, Image, display\n\n# PDF Processing\nimport pypdf\n\n# ChromaDB\n#import chromadb\n#from chromadb import Documents, EmbeddingFunction, Embeddings\n\n\nfrom typing import TypedDict, Annotated, Optional, Literal, List, Dict, Any\nfrom typing_extensions import TypedDict # \nfrom langchain_core.messages import BaseMessage \nfrom contextlib import redirect_stdout\n\n# Langchain and Langgraph\nfrom langgraph.graph import StateGraph, START, END\nfrom langgraph.graph.message import add_messages\nfrom langchain_core.messages import BaseMessage, HumanMessage, AIMessage # Ensure these are imported\n\n\n# Pretty Print\nfrom pprint import pprint\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"GOOGLE_API_KEY\")\n\n\ntrain, test, submission = pd.read_csv('/kaggle/input/playground-series-s5e5/train.csv'),pd.read_csv('/kaggle/input/playground-series-s5e5/test.csv'),pd.read_csv('/kaggle/input/playground-series-s5e5/sample_submission.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T03:59:49.53814Z","iopub.execute_input":"2025-05-05T03:59:49.538594Z","iopub.status.idle":"2025-05-05T03:59:55.392751Z","shell.execute_reply.started":"2025-05-05T03:59:49.538549Z","shell.execute_reply":"2025-05-05T03:59:55.391447Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **üéØüöÄWe will defined an agent who will coordinate our data analyst with out data scienctistüéØüöÄ**\n# **Lets build a ü§ñ herarchical ü§ñ architecture**\n# 1. supervisor\n# 2. data scientist\n# 3. data analyst\n# 4. outputs to Human interpreter ","metadata":{}},{"cell_type":"code","source":"# Using simple dicts for messages initially for clarity, but BaseMessage[] is better practice# Example: messages: Annotated[list[BaseMessage], add_messages]\n# --- State Definition ---\nclass GraphState(TypedDict):\n    \"\"\"\n    üóÇÔ∏è Central state definition for the CALOR-IA multi-agent workflow.\n    Reflects using DataFrame variable names instead of file paths.\n    \"\"\"\n    messages: Annotated[List[BaseMessage], operator.add]\n    supervisor_tasks: Optional[List[str]]\n    current_task_description: Optional[str]\n    analyst_output: Optional[Dict[str, Any]]\n    scientist_output: Optional[Dict[str, Any]]\n    intermediate_data_path: Optional[str] # Removed - using variable names now\n    processed_df_name: Optional[str]       # Name of the DataFrame variable ready for the scientist\n    error: Optional[str]\n    next_agent: Optional[Literal[\"DataAnalyst\",  \"DataScientist\", \"Supervisor\", \"HumanInterpreter\", \"__end__\"]] \n    final_answer_generated: bool # Added for clarity\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T03:59:55.393603Z","iopub.execute_input":"2025-05-05T03:59:55.393947Z","iopub.status.idle":"2025-05-05T03:59:55.401755Z","shell.execute_reply.started":"2025-05-05T03:59:55.393917Z","shell.execute_reply":"2025-05-05T03:59:55.400344Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"CALOR_IA_SUPERVISOR_SYSINT = (\n    \"system\",\n    \"\"\"\n    ü§ñ You are CALOR-IA Supervisor Bot, the orchestrator of a data science team.\n\n    üéØ Mission\n    1Ô∏è‚É£ Receive user requests and break them down into actionable steps for your team.\n    2Ô∏è‚É£ Coordinate two AI workers:\n        - CALOR-IA_DATA_ANALYST_SYSINT: Handles data exploration, cleaning, visualization, and preparation.\n        - CALOR-IA_DATA_SCIENTIST_SYSINT: Handles model building, training, evaluation, and prediction.\n    3Ô∏è‚É£ Decide which worker should handle the *next* step based on the conversation history and the overall goal (Kaggle win üèÜ).\n    4Ô∏è‚É£ Formulate a clear, specific `current_task_description` for the assigned worker.\n    5Ô∏è‚É£ Review the `analyst_output` or `scientist_output` provided by the workers.\n    6Ô∏è‚É£ Synthesize results, manage the overall `supervisor_tasks` list, and communicate progress or final results back to the user via the `messages` state.\n    7Ô∏è‚É£ Determine the `next_agent` required: \"DataAnalyst\", \"DataScientist\", \"Supervisor\" (if waiting for user clarification or summarizing), or \"__end__\" when the overall task is complete.\n    8Ô∏è‚É£ Guide the human user üßë‚Äçüíª and AI agents ü§ñ towards success.\n\n    üìù Workflow & Rules\n    - Analyze the latest message(s) in the `messages` state.\n    - Check `analyst_output` and `scientist_output` for recent worker results.\n    - Based on the goal and current state:\n        - If data analysis/prep is needed -> `next_agent` = \"DataAnalyst\". Create a task in `current_task_description`.\n        - If modeling/prediction is needed (and data is ready, possibly using `intermediate_data_path`) -> `next_agent` = \"DataScientist\". Create a task in `current_task_description`.\n        - If results need summarizing for the user or clarification is needed -> `next_agent` = \"Supervisor\". Update `messages`.\n        - If the user's request is fully addressed -> `next_agent` = \"__end__\". Set `final_answer_generated` = True.\n    - Provide clear, step-by-step instructions in `current_task_description`.\n    - If workers need data from each other, ensure the relevant `intermediate_data_path` is mentioned or available.\n    - Keep track of high-level goals in `supervisor_tasks`.\n    - Stick to data science topics relevant to the user's goal.\n    - Assign tasks in json format for better understanding\n    - You will compile all python code used and returned to the user \n\n    Let‚Äôs coordinate this project to victory! ‚ú®\n    \"\"\"\n)\nCALOR_IA_DATA_ANALYST_SYSINT = (\n    \"system\",\n    \"\"\"\n    ü§ñ You are CALOR-IA Data Analyst Bot.\n\n    üéØ Mission\n    1Ô∏è‚É£ Execute the data analysis task provided in the `current_task_description` from the Supervisor.\n    2Ô∏è‚É£ Write clean, runnable Python üêç code for data loading, cleaning, exploration, and visualization (using pandas, matplotlib, seaborn, etc.).\n    3Ô∏è‚É£ Analyze data (potentially loaded from `intermediate_data_path` if provided) and extract valuable insights.\n    4Ô∏è‚É£ Prepare data for the Data Scientist if requested (e.g., creating features, splitting data) and potentially save it, updating `intermediate_data_path`.\n    5Ô∏è‚É£ Place your results (code, summary of findings, paths to saved plots or data) into the `analyst_output` dictionary in the graph state.\n    6Ô∏è‚É£ Collaborate with CALOR_IA_DATA_SCIENTIST_SYSINT via the Supervisor by providing necessary data artifacts and insights.\n\n    üìù Style & Rules\n    - Focus solely on the task in `current_task_description`.\n    - Separate numerical and categorical data for better handling \n    - Output results clearly structured within the `analyst_output` dictionary (e.g., `{\"code\": \"...\", \"summary\": \"...\", \"plot_path\": \"/path/to/plot.png\", \"data_preview\": \"...\"}`).\n    - Generate runnable Python code within markdown code blocks (```python ... ```).\n    - Explain your code and findings concisely.\n    - If you save data or plots, mention the path clearly in your output summary.\n    - Use matplotlib/seaborn for plots.\n    - Stick to data analysis/preparation; defer modeling to the Scientist.\n    - Return the task to supervisor in json format for better understanding and the python code used to develop the task\n    - Return Just the python code\n    \n    Let‚Äôs crunch some data! ‚ú®\n    \"\"\"\n)\n\nCALOR_IA_DATA_SCIENTIST_SYSINT = (\n    \"system\",\n    \"\"\"\n    ü§ñ You are CALOR-IA Data Scientist Bot.\n\n    üéØ Mission\n    1Ô∏è‚É£ Execute the machine learning task provided in the `current_task_description` from the Supervisor.\n    2Ô∏è‚É£ Use data provided (potentially loaded from `intermediate_data_path` prepared by the Analyst) to build, train, and evaluate ML models (using scikit-learn, TensorFlow, PyTorch, etc.).\n    3Ô∏è‚É£ Perform feature engineering if required and not already done by the Analyst.\n    4Ô∏è‚É£ Generate predictions on test data as requested.\n    5Ô∏è‚É£ Place your results (model summary, performance metrics, paths to saved models or predictions) into the `scientist_output` dictionary in the graph state.\n    6Ô∏è‚É£ Collaborate with CALOR_IA_DATA_ANALYST_SYSINT via the Supervisor by requesting specific data views or providing model insights.\n\n    üìù Style & Rules\n    - Focus solely on the task in `current_task_description`.\n    - Output results clearly structured within the `scientist_output` dictionary (e.g., `{\"model_description\": \"...\", \"metrics\": {\"accuracy\": 0.95, ...}, \"predictions_path\": \"/path/to/preds.csv\", \"code\": \"...\"}`).\n    - Generate runnable Python code for model definition, training, and prediction within markdown code blocks (```python ... ```).\n    - Explain your model choices, training procedures, and evaluation metrics step-by-step.\n    - If you save models or predictions, mention the path clearly in your output summary.\n    - Aim for models that generalize well.\n    - Stick to machine learning tasks; defer data prep/exploration to the Analyst unless specified.\n    - Return the task to supervisor in json format for better understanding and the python code used to develop the task\n    - All models must be scored in RMSLE=n1‚Äãi=1‚àën‚Äã(log(1+y^‚Äãi‚Äã)‚àílog(1+yi‚Äã))2\n    - You will run the models on test data\n    Let‚Äôs build some high-performing models! ‚ú®\n    \"\"\"\n)\nCALOR_IA_HUMAN_REDACTR_SYSINT = (\"\"\"\n    \"system\"\n    You are an expert on python code your task is gather all code and blen them to make it ready to be copy and paste, So you must create a proffesional pipeline of code that explain step by step \n    \"\"\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T03:59:55.404169Z","iopub.execute_input":"2025-05-05T03:59:55.404491Z","iopub.status.idle":"2025-05-05T03:59:55.432167Z","shell.execute_reply.started":"2025-05-05T03:59:55.404464Z","shell.execute_reply":"2025-05-05T03:59:55.430858Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def supervisor_node(state: GraphState) -> Dict[str, Any]:\n    \"\"\"\n    Central decision-making node. Routes tasks to appropriate agents\n    or ends the workflow based on the current state. Handles DataFrame variable names.\n    \"\"\"\n    print(\"\\n--- SUPERVISOR ---\")\n    messages = state.get(\"messages\", [])\n    last_message = messages[-1] if messages else None\n    print(f\"Supervisor reviewing state. Last message type: {type(last_message).__name__ if last_message else 'None'}\")\n    if hasattr(last_message, 'content'):\n         content_display = str(last_message.content)\n         print(f\"Supervisor received content: {content_display[:200]}{'...' if len(content_display) > 200 else ''}\")\n\n    analyst_output_data = state.get('analyst_output')\n    scientist_output_data = state.get('scientist_output')\n    tasks = state.get('supervisor_tasks', [])\n\n    print(f\"Analyst output available: {analyst_output_data is not None}\")\n    print(f\"Scientist output available: {scientist_output_data is not None}\")\n    print(f\"Final answer requested: {state.get('final_answer_generated', False)}\") # Add print for clarity\n\n    next_agent = None\n    task = None\n    new_message_content = \"\"\n    error_flag = None\n\n    # --- Decision Logic ---\n\n    # Check for final answer request first\n    if state.get(\"final_answer_generated\", False):\n        print(\"Supervisor: Final answer signal received. Ending workflow.\")\n        next_agent = \"__end__\" # Explicitly route to the end state\n        # No need for a new message here, the Interpreter already sent the final one\n        # new_message_content = \"Workflow complete.\" # Optional: if you want a final message *from* supervisor\n\n    # If not ending, proceed with normal routing based on agent outputs\n    elif scientist_output_data is not None:\n        if scientist_output_data.get('error') is not None:\n            error_msg = f\"Scientist encountered an error: {scientist_output_data['error']}\"\n            print(f\"Supervisor: {error_msg}\")\n            error_flag = error_msg\n            next_agent = \"HumanInterpreter\" # Still go to interpreter on error\n            new_message_content = \"There was an issue during model training/prediction. Preparing final report.\"\n        else:\n            # Scientist succeeded\n            print(\"Supervisor: Scientist completed work successfully.\")\n            next_agent = \"HumanInterpreter\" # Go to interpreter to compile final script\n            new_message_content = \"Scientist workflow complete. Preparing final report.\"\n\n    elif analyst_output_data is not None:\n        if analyst_output_data.get('error') is not None:\n            error_msg = f\"Analyst encountered an error: {analyst_output_data['error']}\"\n            print(f\"Supervisor: {error_msg}\")\n            error_flag = error_msg\n            next_agent = \"HumanInterpreter\" # Go to interpreter on error\n            new_message_content = \"There was an issue during data analysis. Preparing final report.\"\n        else:\n            # Analyst Succeeded\n            print(\"Supervisor: Analyst successfully generated code and data names.\")\n            task = \"Build and evaluate LightGBM and XGBoost models\"\n            next_agent = \"DataScientist\"\n            new_message_content = f\"Analyst processing complete. Routing to Data Scientist.\"\n\n    else: # Initial state or unexpected state\n        if last_message and isinstance(last_message, HumanMessage):\n            task = \"Perform initial EDA and preprocessing on train/test data.\"\n            next_agent = \"DataAnalyst\"\n            new_message_content = \"Assigning Analyst to initial task based on user request.\"\n        else:\n            print(\"Supervisor: Unexpected state - no initial message or prior agent output. Ending.\")\n            error_flag = \"Unexpected workflow state reached.\"\n            next_agent = \"__end__\"\n            new_message_content = \"Unexpected workflow state. Finalizing.\"\n\n    # --- Prepare Return Dictionary ---\n    updated_messages = state.get(\"messages\", [])\n    # Only add a new message if next_agent is NOT __end__ (Interpreter already added the final one)\n    if next_agent != \"__end__\" and new_message_content and (not updated_messages or updated_messages[-1].content != new_message_content):\n         updated_messages = updated_messages + [AIMessage(content=str(new_message_content))]\n\n    # Ensure node name matches if needed by your framework (though LangGraph usually uses function name strings)\n    # if next_agent == \"BotToHumanInterpreter\": # This correction logic is likely not needed if using string names directly\n    #     print(\"Supervisor correcting agent name to 'HumanInterpreter'\")\n    #     next_agent = \"HumanInterpreter\"\n\n\n    return_dict = {\n        \"messages\": updated_messages,\n        \"supervisor_tasks\": tasks,\n        \"current_task_description\": task,\n        \"next_agent\": next_agent, # This is the crucial return value for the graph to follow\n        \"error\": error_flag,\n    }\n\n    print(f\"Supervisor decision: next_agent='{next_agent}', task='{task}'\")\n    return return_dict","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T03:59:55.43323Z","iopub.execute_input":"2025-05-05T03:59:55.433732Z","iopub.status.idle":"2025-05-05T03:59:55.46174Z","shell.execute_reply.started":"2025-05-05T03:59:55.433699Z","shell.execute_reply":"2025-05-05T03:59:55.460518Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_log_error, mean_squared_error # Added RMSE for XGBoost metric\nimport lightgbm as lgb\nimport xgboost as xgb\n\ndef data_analyst_node(state: GraphState) -> Dict[str, Any]:\n    \"\"\"Data Analyst Node - Updated for DataFrame variable names.\"\"\"\n    print(\"\\n--- DATA ANALYST ---\")\n    task = state.get('current_task_description')\n    # Assume initial DFs are named 'train_df' and 'test_df' for clarity\n    # Adjust these names if your actual initial variables are different (e.g., 'train', 'test')\n    initial_train_name = 'train_df' # <-- Adjust if your initial var is different\n    initial_test_name = 'test_df'   # <-- Adjust if your initial var is different\n\n    if not task:\n        error_output = {\"error\": \"Data Analyst received no task.\", \"next_agent\": \"Supervisor\"}\n        print(\"Returning error output:\", error_output)\n        return error_output\n\n    # Simulate the names of the DataFrames that the processing code will create\n    processed_train_name = f\"processed_{initial_train_name}\" # e.g., 'processed_train_df'\n    processed_test_name = f\"processed_{initial_test_name}\"   # e.g., 'processed_test_df'\n\n    print(f\"Analyst expects input DataFrame variable: '{initial_train_name}'\")\n    print(f\"Analyst expects input DataFrame variable: '{initial_test_name}'\")\n    print(f\"Analyst will simulate creating output DataFrames: '{processed_train_name}' and '{processed_test_name}'\")\n\n    # --- Simulate Code (Make sure variable names match below) ---\n    simulated_code = f\"\"\"\n    import pandas as pd\n    import numpy as np\n    from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n    from sklearn.impute import KNNImputer\n    from sklearn.compose import ColumnTransformer\n    from sklearn.pipeline import Pipeline\n\n    # Assume these two exist already in the notebook/environment with names:\n    # {initial_train_name}  # Your initial training DataFrame\n    # {initial_test_name}   # Your initial test DataFrame\n\n    # Ensure correct variable names are used in the code\n    train = {initial_train_name}\n    test = {initial_test_name} # Use the initial test name here\n\n    # 1) Identify numerical vs. categorical columns\n    num_cols = train.select_dtypes(include=[np.number]).columns.tolist()\n    cat_cols = train.select_dtypes(include=['object', 'category']).columns.tolist()\n\n    print(\"Numerical columns:\", num_cols)\n    print(\"Categorical columns:\", cat_cols)\n\n    # 2) Build preprocessing pipelines\n    # ... (rest of your pipeline code, unchanged)\n    num_pipeline = Pipeline([\n        ('scaler', MinMaxScaler())\n    ])\n    cat_pipeline = Pipeline([\n        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))\n    ])\n\n    preprocessor = ColumnTransformer(transformers=[\n        ('num', num_pipeline, num_cols),\n        ('cat', cat_pipeline, cat_cols)\n    ])\n\n    # 3) KNN imputer for any remaining NaNs\n    imputer = KNNImputer()\n\n    # 4) Fit on train, transform both train & test\n    train_array = preprocessor.fit_transform(train)\n    train_array = imputer.fit_transform(train_array)\n\n    test_array = preprocessor.transform(test) # Use 'test' variable name here\n    test_array = imputer.transform(test_array)\n\n    # 5) Recover feature names so we can build nice DataFrames\n    # ... (rest of your feature name recovery code, unchanged)\n    num_feats = preprocessor.named_transformers_['num'] \\\n                   .named_steps['scaler'].feature_names_in_\n    cat_feats = preprocessor.named_transformers_['cat'] \\\n                   .named_steps['onehot'].get_feature_names_out(cat_cols)\n    all_feats = list(num_feats) + list(cat_feats)\n\n    # Create the processed DataFrames using the intended variable names\n    {processed_train_name} = pd.DataFrame(train_array, columns=all_feats)\n    {processed_test_name}  = pd.DataFrame(test_array,  columns=all_feats)\n\n    print(f\"Processed train shape: {{{processed_train_name}.shape}}\") # Print using the variable name\n    print(f\"Processed test shape:  {{{processed_test_name}.shape}}\")   # Print using the variable name\n    \"\"\"\n\n    # --- Return Dictionary (CORRECTED) ---\n    output = {\n        \"analyst_output\":{\n            \"code\": simulated_code,\n            # Store the *names* of the output DataFrames under the expected keys\n            \"processed_train_df_name\": processed_train_name, # e.g., 'processed_train_df'\n            \"processed_test_df_name\": processed_test_name,   # e.g., 'processed_test_df'\n            # You can keep X and X_test if other parts of your system use them, but\n            # the Scientist error indicates it expects the 'processed_..._name' keys\n            # \"X\": train, # Probably not needed here if you pass the names\n            # \"X_test\": test, # Probably not needed here if you pass the names\n        },\n         \"current_task_description\": None, # Task is complete for Analyst\n    }\n\n    print(\"Analyst returning output:\", output) # Added for debugging\n    return output\n\ndef process_update(update: Dict[str, Any]) -> None:\n    if not isinstance(update, dict):\n        print(\"Update is not a dictionary.\")\n        return\n\n    if 'messages' in update:\n        messages = update['messages']\n        print(\"Messages from update:\")\n        for message in messages:\n            print(message)\n\n    if 'code' in update:\n        print(\"Code snippet provided in update:\")\n        print(update['code'])\n\n    if 'summary' in update:\n        print(\"Summary from update:\")\n        print(update['summary'])\n\n    if 'error' in update:\n        print(\"Error encountered:\")\n        print(update['error'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T03:59:55.463046Z","iopub.execute_input":"2025-05-05T03:59:55.463371Z","iopub.status.idle":"2025-05-05T04:00:02.165934Z","shell.execute_reply.started":"2025-05-05T03:59:55.463348Z","shell.execute_reply":"2025-05-05T04:00:02.164237Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfrom typing import Dict, Any\n\n# Assuming GraphState class is defined elsewhere\n# Assuming necessary library imports (like pandas, numpy etc.) are at the top level of your script\n\ndef data_scientist_node(state: GraphState) -> Dict[str, Any]:\n    \"\"\"\n    Data Scientist Node - Generates modeling code (LightGBM, XGBoost)\n    using processed data names provided by the DataAnalyst node via the state.\n    This version DOES NOT execute the generated code.\n    \"\"\"\n    print(\"\\n--- DATA SCIENTIST (Code Generation Only) ---\")\n    task = state.get('current_task_description')\n    if not task:\n        print(\"Scientist: No task received.\")\n        # Return an error structure within the expected output key\n        return {\n            \"scientist_output\": {\"error\": \"Data Scientist received no task.\"},\n            \"next_agent\": \"Supervisor\"\n            }\n\n    # --- Get processed DataFrame names from the analyst's output in state ---\n    analyst_result = state.get('analyst_output')\n    if not analyst_result or not isinstance(analyst_result, dict):\n        error_msg = \"Scientist Error: Analyst output not found or invalid in state.\"\n        print(error_msg)\n        return {\n            \"scientist_output\": {\"error\": error_msg},\n            \"next_agent\": \"Supervisor\"\n            }\n\n    processed_train_name = analyst_result.get('processed_train_df_name')\n    processed_test_name = analyst_result.get('processed_test_df_name')\n\n    if not processed_train_name or not processed_test_name:\n        error_msg = \"Scientist Error: Processed DataFrame names not found within analyst output in state.\"\n        print(error_msg)\n        return {\n            \"scientist_output\": {\"error\": error_msg},\n             \"next_agent\": \"Supervisor\"\n             }\n\n    print(f\"Scientist generating code for task: {task}\")\n    print(f\"Will use processed train DataFrame variable: '{processed_train_name}'\")\n    print(f\"Will use processed test DataFrame variable : '{processed_test_name}'\")\n\n    # --- Generate Code String ---\n    # Use single braces {} ONLY for variables substituted NOW ({processed_train_name}, {processed_test_name})\n    # Use double braces {{}} for f-strings intended for LATER execution within the generated code.\n    generated_code =f'''\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_log_error, mean_squared_error # Added RMSE for XGBoost metric\nimport lightgbm as lgb\nimport xgboost as xgb\nimport warnings\nimport os # Import os to create directories if needed\n\n# --- Suppress Warnings ---\nwarnings.filterwarnings('ignore', category=UserWarning, module='lightgbm')\nwarnings.filterwarnings('ignore', category=FutureWarning)\n\nprint(\"\\\\n--- Data Scientist Code Execution Started ---\")\n\n# --- Configuration ---\n# These names are substituted when the string is created\nPROCESSED_TRAIN_NAME = '{processed_train_name}'\nPROCESSED_TEST_NAME  = '{processed_test_name}'\nTARGET_COL = 'Calories' # !! IMPORTANT: Adjust this if your target column name is different !!\nOUTPUT_DIR = 'model_outputs'\n\n# --- Setup ---\nos.makedirs(OUTPUT_DIR, exist_ok=True)\nprint(f\"Ensuring output directory exists: {{OUTPUT_DIR}}\") # Inner f-string: Use {{}}\n\n# --- Data Loading ---\nprint(f\"Loading data: train='{{PROCESSED_TRAIN_NAME}}', test='{{PROCESSED_TEST_NAME}}'\") # Inner f-string: Use {{}}\ntry:\n    # Attempt to load from the global scope where exec runs\n    train_df = globals()[PROCESSED_TRAIN_NAME]\n    test_df  = globals()[PROCESSED_TEST_NAME]\n    print(f\"Loaded train shape: {{train_df.shape}}\") # Inner f-string: Use {{}}\n    print(f\"Loaded test shape: {{test_df.shape}}\")   # Inner f-string: Use {{}}\nexcept KeyError as e:\n    print(f\"[ERROR] Processed DataFrame '{{e}}' not found in the execution environment.\") # Inner f-string: Use {{}}\n    print(\"Please ensure the Data Analyst code ran successfully and created these variables.\")\n    # Decide how to proceed: raise error, exit, or try to continue? For now, exit.\n    exit(1) # Exit the executed script with an error code\n\n# --- Feature/Target Split ---\nif TARGET_COL not in train_df.columns:\n    print(f\"[ERROR] Target column '{{TARGET_COL}}' not found in training data ('{{PROCESSED_TRAIN_NAME}}')\") # Inner f-string: Use {{}}\n    exit(1) # Exit if target column is missing\n\nX = train_df.drop(TARGET_COL, axis=1)\ny = train_df[TARGET_COL]\n\n# --- Align Test Columns ---\ntrain_cols_expected = X.columns # Get columns in order from X\nX_test = test_df.copy() # Start with a copy of the test set\n\n# Add missing columns with NaN\nfor col in train_cols_expected:\n    if col not in X_test.columns:\n        print(f\"[Warning] Column '{{col}}' missing in test set. Adding with NaN.\") # Inner f-string: Use {{}}\n        X_test[col] = np.nan\n\n# Select and reorder columns to match training data exactly\nX_test = X_test[train_cols_expected]\n\nprint(f\"Feature shape (X): {{X.shape}}\")             # Inner f-string: Use {{}}\nprint(f\"Test Feature shape (X_test): {{X_test.shape}}\") # Inner f-string: Use {{}}\n\n# --- Train/Validation Split ---\nX_tr, X_val, y_tr, y_val = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\nprint(f\"Train split shape: {{X_tr.shape}}, Validation split shape: {{X_val.shape}}\") # Inner f-string: Use {{}}\n\n# --- Metrics ---\ndef rmsle(y_true, y_pred):\n    y_pred_safe = np.maximum(0, y_pred) # Ensure non-negative predictions\n    epsilon = 1e-9 # Add epsilon to avoid log(0)\n    return np.sqrt(mean_squared_log_error(y_true + epsilon, y_pred_safe + epsilon))\n\ndef rmse(y_true, y_pred):\n     return np.sqrt(mean_squared_error(y_true, y_pred))\n\n# --- Model Flags ---\nlgbm_success = False\nxgb_success = False\ncan_run_xgb = True # Assume XGBoost can run initially\nlgb_error = None\nxgb_error = None\ngbm = None # Initialize model variables\nbst = None\n\n# --- LightGBM ---\nprint(\"\\\\n>>> Training LightGBM...\")\ntry:\n    lgb_train = lgb.Dataset(X_tr, label=y_tr)\n    lgb_val   = lgb.Dataset(X_val, label=y_val, reference=lgb_train)\n    lgb_params = {{ # Dictionary literal, braces are fine\n        'objective':'regression_l1', 'metric':'rmsle', 'verbosity':-1,\n        'n_estimators': 1000, 'learning_rate':0.05, 'feature_fraction': 0.8,\n        'bagging_fraction': 0.8, 'bagging_freq': 1, 'seed': 42, 'n_jobs': -1,\n        'boosting_type': 'gbdt',\n    }}\n    lgb_evals = {{}} # Dictionary literal, braces are fine\n    callbacks = [\n        lgb.log_evaluation(period=100, show_stdv=False),\n        lgb.early_stopping(stopping_rounds=50, verbose=False)\n    ]\n\n    gbm = lgb.train(\n        params=lgb_params, train_set=lgb_train, valid_sets=[lgb_train, lgb_val],\n        valid_names=['train','val'], callbacks=callbacks, evals_result=lgb_evals\n    )\n    print(\"LightGBM training complete.\")\n    lgbm_success = True # Mark success\n\n    # Plotting\n    metrics_to_plot = [lgb_params['metric']] if isinstance(lgb_params['metric'], str) else lgb_params['metric']\n    valid_metrics_to_plot = [m for m in metrics_to_plot if m in lgb_evals.get('train', {{}})]\n\n    if valid_metrics_to_plot:\n        metric_key = valid_metrics_to_plot[0]\n        plt.figure(figsize=(8, 5))\n        plt.plot(lgb_evals['train'][metric_key], label=f'train {{metric_key}}') # Inner f-string: Use {{}}\n        plt.plot(lgb_evals['val'][metric_key],   label=f'val {{metric_key}}')   # Inner f-string: Use {{}}\n        plt.title(f'LightGBM {{metric_key.upper()}}')                          # Inner f-string: Use {{}}\n        plt.legend()\n        plt.xlabel('Boosting Rounds')\n        plt.ylabel(metric_key.upper())\n        plt.grid(True)\n        lgb_plot_path = os.path.join(OUTPUT_DIR, 'lgb_metric_plot.png')\n        plt.savefig(lgb_plot_path)\n        plt.close()\n        print(f\"Saved LightGBM plot to {{lgb_plot_path}}\")                     # Inner f-string: Use {{}}\n    else:\n        print(f\"[Warning] Metrics {{metrics_to_plot}} not found in LightGBM evals results for plotting.\") # Inner f-string: Use {{}}\n\n    # Predictions & Validation\n    best_iter = gbm.best_iteration if gbm.best_iteration else lgb_params.get('n_estimators', 1000)\n    y_val_pred_lgb  = gbm.predict(X_val, num_iteration=best_iter)\n    y_test_pred_lgb = gbm.predict(X_test, num_iteration=best_iter)\n    y_test_pred_lgb_safe = np.maximum(0, y_test_pred_lgb) # Ensure non-negative\n    val_rmsle_lgb = rmsle(y_val, y_val_pred_lgb)\n    print(f\"LightGBM Validation RMSLE = {{val_rmsle_lgb:.5f}} (using best iter: {{best_iter}})\") # Inner f-string: Use {{}}\n    lgb_pred_path = os.path.join(OUTPUT_DIR, 'lgb_test_preds.csv')\n    pd.DataFrame({{'prediction': y_test_pred_lgb_safe}}).to_csv(lgb_pred_path, index=False) # Dict literal OK\n    print(f\"Saved LightGBM predictions to {{lgb_pred_path}}\") # Inner f-string: Use {{}}\n\nexcept Exception as e:\n    lgb_error = str(e)\n    print(f\"[ERROR] During LightGBM training or prediction: {{e}}\") # Inner f-string: Use {{}}\n\n# --- XGBoost ---\nprint(\"\\\\n>>> Training XGBoost...\")\ntry:\n    # Check if DMatrix creation is possible\n    dtrain = xgb.DMatrix(X_tr, label=y_tr)\n    dval   = xgb.DMatrix(X_val, label=y_val)\n    dtest  = xgb.DMatrix(X_test)\nexcept Exception as e:\n    xgb_error = f\"DMatrix creation failed: {{e}}\" # Use {{e}} for escaping\n    print(f\"[ERROR] Creating XGBoost DMatrix: {{e}}\") # Inner f-string: Use {{}}\n    can_run_xgb = False # Cannot run XGBoost if DMatrix fails\n\nif can_run_xgb:\n    try:\n        xgb_params = {{ # Dictionary literal, braces are fine\n            'objective':'reg:squarederror', 'eval_metric':'rmse', 'eta':0.05,\n            'max_depth': 6, 'subsample': 0.8, 'colsample_bytree': 0.8, 'seed': 42\n        }}\n        xgb_evals = {{}} # Dictionary literal, braces are fine\n\n        bst = xgb.train(\n            params=xgb_params, dtrain=dtrain, num_boost_round=1000,\n            evals=[(dtrain,'train'), (dval,'val')], early_stopping_rounds=50,\n            evals_result=xgb_evals, verbose_eval=100\n        )\n        print(\"XGBoost training complete.\")\n        xgb_success = True # Mark success\n\n        # Plotting\n        metrics_to_plot_xgb = [xgb_params['eval_metric']] if isinstance(xgb_params['eval_metric'], str) else xgb_params['eval_metric']\n        valid_metrics_to_plot_xgb = [m for m in metrics_to_plot_xgb if m in xgb_evals.get('train', {{}})]\n\n        if valid_metrics_to_plot_xgb:\n            metric_key_xgb = valid_metrics_to_plot_xgb[0]\n            plt.figure(figsize=(8, 5))\n            plt.plot(xgb_evals['train'][metric_key_xgb], label=f'train {{metric_key_xgb}}') # Inner f-string: Use {{}}\n            plt.plot(xgb_evals['val'][metric_key_xgb],   label=f'val {{metric_key_xgb}}')   # Inner f-string: Use {{}}\n            plt.title(f'XGBoost {{metric_key_xgb.upper()}}')                              # Inner f-string: Use {{}}\n            plt.legend()\n            plt.xlabel('Boosting Rounds')\n            plt.ylabel(metric_key_xgb.upper())\n            plt.grid(True)\n            xgb_plot_path = os.path.join(OUTPUT_DIR, 'xgb_metric_plot.png')\n            plt.savefig(xgb_plot_path)\n            plt.close()\n            print(f\"Saved XGBoost plot to {{xgb_plot_path}}\")                         # Inner f-string: Use {{}}\n        else:\n            print(f\"[Warning] Metrics {{metrics_to_plot_xgb}} not found in XGBoost evals results for plotting.\") # Inner f-string: Use {{}}\n\n        # Predictions & Validation\n        best_iter_xgb = bst.best_iteration\n        y_val_pred_xgb  = bst.predict(dval, iteration_range=(0, best_iter_xgb))\n        y_test_pred_xgb = bst.predict(dtest, iteration_range=(0, best_iter_xgb))\n        y_test_pred_xgb_safe = np.maximum(0, y_test_pred_xgb) # Ensure non-negative\n        val_rmsle_xgb = rmsle(y_val, y_val_pred_xgb)\n        print(f\"XGBoost Validation RMSLE = {{val_rmsle_xgb:.5f}} (using best iter: {{best_iter_xgb}})\") # Inner f-string: Use {{}}\n        xgb_pred_path = os.path.join(OUTPUT_DIR, 'xgb_test_preds.csv')\n        pd.DataFrame({{'prediction': y_test_pred_xgb_safe}}).to_csv(xgb_pred_path, index=False) # Dict literal OK\n        print(f\"Saved XGBoost predictions to {{xgb_pred_path}}\") # Inner f-string: Use {{}}\n\n    except Exception as e:\n        xgb_error = str(e)\n        print(f\"[ERROR] During XGBoost training or prediction: {{e}}\") # Inner f-string: Use {{}}\nelse:\n    print(\"Skipping XGBoost training due to previous error.\")\n\n# --- Final Summary ---\nif lgb_error:\n    print(f\"LightGBM Error Summary: {{lgb_error}}\") # Inner f-string: Use {{}}\nif xgb_error:\n    print(f\"XGBoost Error Summary: {{xgb_error}}\") # Inner f-string: Use {{}}\n\nprint(\"\\\\n--- Data Scientist Code Execution Finished ---\")\n''' # End of the generated_code f-string literal\n\n    # --- Code Generation Complete ---\n    print(\"--- Code Generation Complete ---\")\n\n    # --- Prepare Results (Code Only) ---\n    # Since we are not executing, we only return the generated code.\n    # No stdout, error capture, or artifact paths from execution.\n    scientist_result = {\n        \"code\": generated_code,\n        \"stdout\": None, # No execution, no stdout\n        \"error\": None, # No execution attempt, no execution error\n        \"execution_success\": None, # Execution was not attempted\n        \"lgb_predictions_path\": None,\n        \"xgb_predictions_path\": None,\n        \"lgb_plot_path\": None,\n        \"xgb_plot_path\": None,\n    }\n\n    # --- Return state update ---\n    return {\n        \"scientist_output\": scientist_result,\n        \"current_task_description\": None, # Clear task description\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T04:00:02.16911Z","iopub.execute_input":"2025-05-05T04:00:02.17031Z","iopub.status.idle":"2025-05-05T04:00:02.192822Z","shell.execute_reply.started":"2025-05-05T04:00:02.17026Z","shell.execute_reply":"2025-05-05T04:00:02.190596Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def bot_to_human_interpreter(state: GraphState) -> Dict[str, Any]:\n    \"\"\"\n    Gathers code from Analyst and Scientist outputs, blends them into a single script,\n    adds explanations within the code, and formats it for copy-pasting.\n    Returns an update dict with the combined code message and signals the end of the workflow.\n    \"\"\"\n    print(\"\\n--- BOT TO HUMAN INTERPRETER (Code Compiler) ---\")\n\n    # --- Robustly retrieve and validate outputs from the state ---\n    analyst_output_raw = state.get('analyst_output')\n    scientist_output_raw = state.get('scientist_output')\n\n    # Ensure they are dictionaries before proceeding; default to empty dict otherwise\n    analyst_output = analyst_output_raw if isinstance(analyst_output_raw, dict) else {}\n    # --- THIS LINE IS CORRECTED ---\n    scientist_output = scientist_output_raw if isinstance(scientist_output_raw, dict) else {}\n    # --- End of robust retrieval ---\n\n    # Initialize a list to hold parts of the combined script\n    combined_code_parts = []\n\n    # Add an introductory comment/header to the script\n    combined_code_parts.append(\"# Combined Data Science Workflow Script\\n\")\n    combined_code_parts.append(\"# Generated by CALOR-IA's Agent Team\\n\\n\")\n    combined_code_parts.append(\"# This script combines preprocessing and modeling steps.\\n\")\n    combined_code_parts.append(\"# Ensure you have the necessary libraries installed (e.g., pandas, numpy, sklearn, lightgbm, xgboost, matplotlib).\\n\")\n    combined_code_parts.append(\"# Make sure your initial 'train' and 'test' DataFrames (or equivalent data loading) exist before running.\\n\\n\")\n\n\n    # --- Section 1: Data Preprocessing (from Data Analyst) ---\n    combined_code_parts.append(\"# --- 1. Data Preprocessing ---\\n\")\n    combined_code_parts.append(\"# This section handles steps like identifying column types, imputation, scaling, and encoding.\\n\")\n    combined_code_parts.append(\"# It prepares the raw data into processed DataFrames ready for modeling.\\n\\n\")\n\n    # Get the Analyst's code and error status (safe now due to checks above)\n    analyst_code = analyst_output.get('code', '')\n    analyst_error = analyst_output.get('error')\n    processed_train_name = analyst_output.get('processed_train_df_name', \"'processed_train_variable_name_unavailable'\") # Get expected output name\n    processed_test_name = analyst_output.get('processed_test_df_name', \"'processed_test_variable_name_unavailable'\")   # Get expected output name\n\n\n    if analyst_error:\n        combined_code_parts.append(f\"# !!! Data Analyst Error during preprocessing execution.\\n\")\n        combined_code_parts.append(f\"# !!! Error Details: {analyst_error}\\n\\n\")\n    elif not analyst_code:\n         combined_code_parts.append(\"# Data preprocessing code was not provided by the Analyst.\\n\\n\")\n    else:\n        # Append the analyst's code\n        combined_code_parts.append(analyst_code.strip())\n        combined_code_parts.append(\"\\n\\n\") # Add spacing after the code block\n        # Add comments explaining the *expected output variables*\n        combined_code_parts.append(\"# Expected outputs from this section (as variables in your environment):\\n\")\n        combined_code_parts.append(f\"# - {processed_train_name}: Processed training features (potentially including target)\\n\")\n        combined_code_parts.append(f\"# - {processed_test_name}: Processed test features\\n\\n\")\n\n\n    # --- Section 2: Model Training and Evaluation (from Data Scientist) ---\n    combined_code_parts.append(\"# --- 2. Model Training and Evaluation ---\\n\")\n    combined_code_parts.append(\"# This section uses the processed data to train machine learning models (LightGBM, XGBoost) and evaluate them.\\n\")\n    combined_code_parts.append(f\"# It assumes the variables '{processed_train_name}' and '{processed_test_name}' exist from the previous section.\\n\\n\")\n\n    # Get the Scientist's code and error status (safe now due to checks above)\n    scientist_code = scientist_output.get('code', '')\n    scientist_error = scientist_output.get('error') # Captures generation or execution errors\n    scientist_stdout = scientist_output.get('stdout', '') # Get captured output from execution\n\n    if scientist_error:\n        combined_code_parts.append(f\"# !!! Data Scientist Error during modeling execution or code generation.\\n\")\n        combined_code_parts.append(f\"# !!! Error Details: {scientist_error}\\n\\n\")\n        # Optionally include stdout even if there was an error, might contain clues\n        if scientist_stdout:\n             combined_code_parts.append(\"# Captured output (may contain error details):\\n\")\n             commented_stdout = \"\\n\".join([f\"# {line}\" for line in scientist_stdout.strip().split('\\n')])\n             combined_code_parts.append(commented_stdout + \"\\n\\n\")\n\n    elif not scientist_code:\n        combined_code_parts.append(\"# Model training code was not provided by the Scientist.\\n\\n\")\n    else:\n        # Append the scientist's code\n        combined_code_parts.append(scientist_code.strip())\n        combined_code_parts.append(\"\\n\\n\") # Add spacing after the code block\n        # Add comments explaining expected outputs/artifacts\n        combined_code_parts.append(\"# Expected outputs/artifacts from this section:\\n\")\n        combined_code_parts.append(\"# - Console output showing training progress and validation scores.\\n\")\n        combined_code_parts.append(\"# - 'lgb_metric_plot.png', 'xgb_metric_plot.png': Plots showing model performance during training.\\n\")\n        combined_code_parts.append(\"# - 'lgb_test_preds.csv', 'xgb_test_preds.csv': CSV files with predictions on the test set.\\n\\n\")\n        # Include captured stdout as comments if available\n        if scientist_stdout:\n             combined_code_parts.append(\"# Captured Output from Model Training Execution:\\n\")\n             commented_stdout = \"\\n\".join([f\"# {line}\" for line in scientist_stdout.strip().split('\\n')])\n             combined_code_parts.append(commented_stdout + \"\\n\\n\")\n\n\n    # --- Section 3: Summary Notes ---\n    combined_code_parts.append(\"# --- 3. Summary Notes ---\\n\")\n    if analyst_error or scientist_error:\n         combined_code_parts.append(\"# NOTE: Errors occurred during the automated workflow. Please review the script and error messages carefully.\\n\")\n    else:\n         combined_code_parts.append(\"# NOTE: The automated workflow appears to have completed. Review the generated files and console output.\\n\")\n\n    combined_code_parts.append(\"\\n# --- End of Script ---\")\n    combined_code_parts.append(\"\\n# Copy and paste the entire block above into your environment/notebook to run the workflow!\\n\")\n\n\n    # Combine all parts into a single string representing the full script\n    final_python_script = \"\".join(combined_code_parts)\n\n    # Wrap the entire script in a single markdown code block for easy copy-pasting\n    human_message_content = \"Here is the complete Python script generated by the workflow, combining preprocessing and modeling steps:\\n\\n\"\n    human_message_content += \"```python\\n\" # Start markdown code block\n    human_message_content += final_python_script\n    human_message_content += \"```\\n\"       # End markdown code block\n\n    print(\"Interpreter compiled code and generated final message for human.\")\n\n    # Prepare the state update dictionary to return\n    # Append the new AI message and signal the end\n    return {\n        \"messages\": state.get(\"messages\", []) + [AIMessage(content=human_message_content)],\n        \"final_answer_generated\": True,\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T04:00:02.195112Z","iopub.execute_input":"2025-05-05T04:00:02.19547Z","iopub.status.idle":"2025-05-05T04:00:02.245954Z","shell.execute_reply.started":"2025-05-05T04:00:02.195432Z","shell.execute_reply":"2025-05-05T04:00:02.24432Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def route_tasks(state: GraphState) -> Literal[\"DataAnalyst\", \"DataScientist\", \"Supervisor\", \"__end__\"]:\n    \"\"\"Determines the next node to execute.\"\"\"\n    next_agent = state.get('next_agent')\n    print(f\"\\n--- ROUTING ---\")\n    # Handle potential None value gracefully before checking membership\n    if next_agent is None:\n        print(\"Routing Error: next_agent is None. Ending.\")\n        return \"__end__\"\n    print(f\"Supervisor decided next step is: {next_agent}\")\n    if next_agent not in [\"DataAnalyst\", \"DataScientist\", \"Supervisor\", \"__end__\"]: #  \n        print(f\"Routing Error: Invalid next_agent '{next_agent}'. Ending.\")\n        return \"__end__\" # Default to end if invalid state\n    return next_agent\n\n# --- Build the Graph (Corrected Edges) ---\n\nworkflow = StateGraph(GraphState)\n\n# Add nodes\nworkflow.add_node(\"Supervisor\", supervisor_node)\nworkflow.add_node(\"DataAnalyst\", data_analyst_node)\nworkflow.add_node(\"DataScientist\", data_scientist_node)\nworkflow.add_node(\"HumanInterpreter\", bot_to_human_interpreter) # Use this exact name\n\n# Define entry point\nworkflow.set_entry_point(\"Supervisor\")\n\n# --- ADD THESE EDGES ---\n# After Analyst runs, go back to Supervisor\nworkflow.add_edge(\"DataAnalyst\", \"Supervisor\")\n# After Scientist runs, go back to Supervisor\nworkflow.add_edge(\"DataScientist\", \"Supervisor\")\n# After Interpreter runs, go back to Supervisor (it will then check final_answer_generated)\nworkflow.add_edge(\"HumanInterpreter\", \"Supervisor\")\n# --- END OF ADDED EDGES ---\n\n# Define conditional edges FROM SUPERVISOR ONLY\nworkflow.add_conditional_edges(\n    \"Supervisor\",\n    # Function to decide route based on supervisor's decision\n    lambda state: state.get(\"next_agent\"),\n    # Mapping decision to node name\n    {\n        \"DataAnalyst\": \"DataAnalyst\",\n        \"DataScientist\": \"DataScientist\",\n        \"HumanInterpreter\": \"HumanInterpreter\", # Ensure this matches add_node name\n        \"Supervisor\": \"Supervisor\", # Allow looping back if needed (e.g., waiting)\n        \"__end__\": END # Map \"__end__\" string to the graph's end state\n    }\n)\n\n# Compile the graph\napp = workflow.compile()\n# --- Visualize the Graph (Optional, Unchanged) ---\ntry:\n    from PIL import Image\n    import io\n    img_bytes = app.get_graph().draw_mermaid_png()\n    img = Image.open(io.BytesIO(img_bytes))\nexcept Exception as e:\n    print(f\"\\nCould not generate graph visualization: {e}. (Might need `pip install pygraphviz` and graphviz system library)\")\n\nimg","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T04:00:02.248313Z","iopub.execute_input":"2025-05-05T04:00:02.248937Z","iopub.status.idle":"2025-05-05T04:00:02.514028Z","shell.execute_reply.started":"2025-05-05T04:00:02.248894Z","shell.execute_reply":"2025-05-05T04:00:02.51248Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json # Make sure json is imported if you haven't already\n\n# Assuming imports, node definitions, graph setup, and compilation are done above\n\n# --- Run the Graph ---\n\n# Initial state setup (unchanged)\ninitial_input_message = f\"\"\"Alright team! Let's kick off this project to build a model predicting 'Calories'.\n\nHere's the plan, broken down into stages, leveraging our expert \"agents\":\n\n1.  üöÄ  **Data Setup & Target ID:**\n    *   We're starting with our training data (`train`) and test data (`test).\n    *   Your first step is to identify the 'Calories' column within `train_df`. This is our target variable!\n\n2.  üõ†Ô∏è  **Data Preprocessing (with Data Analyst):**\n    *   Now, collaborate closely with the **Data Analyst** persona.\n    *   Focus on cleaning and preparing *both* `train_df` and `test_df` for modeling. This involves tasks like handling missing values, encoding, feature engineering, etc.\n    *   We need to iterate on these steps until we achieve high-quality, model-ready data.\n\n3.  üß†  **Model Building (with Data Scientist):**\n    *   Once the preprocessing is solid, pass the *processed* data over to the **Data Scientist** persona.\n    *   Their mission is to train *two* predictive models: a LightGBM model and an XGBoost model, using the high-quality training data.\n\n4.  üß©  **Code Integration (with HumanInterpreter):**\n    *   Finally, gather the distinct code sections generated by the Data Analyst (preprocessing) and the Data Scientist (modeling).\n    *   Use the **HumanInterpreter** to seamlessly integrate these sections into one complete, executable Python script that represents the full workflow.\n\nYour final output should be this complete, integrated Python code. Let's build something awesome! üí™\n\"\"\"\ninitial_state = {\n    \"messages\": [HumanMessage(content=initial_input_message)],\n    \"final_answer_generated\": False,\n    \"current_task_description\": \"Preprocess and analyze training and test data.\", \n}\n\nprint(\"\\n--- STARTING WORKFLOW (Using DataFrame Variable Names) ---\")\n\n# Keep track of seen message contents to avoid reprinting supervisor messages repeatedly\nseen_message_contents = set()\n\n\nfor step, event in enumerate(app.stream(initial_state, {\"recursion_limit\":15})):\n    print(f\"\\n--- Workflow Step {step + 1} ---\")\n    for node_name, update in event.items():\n        print(f\"Processing update from node: {node_name}\")\n\n        # Check if the update is valid and process messages\n        if update is None:\n            print(\"Node returned None, no state update.\")\n            continue # Skip processing if the node returned None\n\n        # Process messages added in this update\n        if 'messages' in update:\n            new_messages_in_update = [\n                msg for msg in update['messages']\n                if isinstance(msg, (AIMessage, HumanMessage)) and msg.content not in seen_message_contents\n            ]\n            for msg in new_messages_in_update:\n                if isinstance(msg, AIMessage):\n                    print(f\"ü§ñ {node_name} says: {msg.content}\")\n                elif isinstance(msg, HumanMessage):\n                    print(f\"üßë‚Äçüíª User says (via state): {msg.content}\") # User messages might reappear if state is passed\n                seen_message_contents.add(msg.content)\n\n\n        # The HumanInterpreter output is already formatted with the code block\n        # We don't need special processing here if it's added to messages\n        # The loop above processing 'messages' will print it when the HumanInterpreter runs\n        # If you wanted to handle HumanInterpreter output *differently* here, you could add:\n        # if node_name == 'HumanInterpreter':\n        #     # Access the state after the update to get the new message\n        #     final_message = update.get('messages', [])[-1] if update.get('messages') else None\n        #     if final_message and isinstance(final_message, AIMessage):\n        #          print(\"\\n--- FINAL REPORT ---\")\n        #          print(final_message.content) # Print the full markdown content\n        #          print(\"--- END FINAL REPORT ---\")\n\n\n    print(\"\\n\" + \"=\"*50 + \"\\n\")\n\n# After the loop finishes, the graph execution has completed (__end__ reached or limit hit)\nprint(\"\\n--- Workflow Finished ---\")\n# You can optionally print the final state\n# print(\"Final State:\")\n# final_state = app.get_state(initial_state) # This might not work directly depending on runner config\n# print(final_state)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T04:00:02.516949Z","iopub.execute_input":"2025-05-05T04:00:02.517245Z","iopub.status.idle":"2025-05-05T04:00:02.57531Z","shell.execute_reply.started":"2025-05-05T04:00:02.517223Z","shell.execute_reply":"2025-05-05T04:00:02.573905Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Ready to Run!**\n\n**This code is designed to be copied directly into a cell in your Kaggle notebook. Just make sure you have already loaded your initial train.csv and test.csv files into DataFrames named train_df and test_df respectively, before this code block.**\n\n**The script will then:**\n\n**üöÄ Preprocess train_df and test_df using the defined pipelines and KNN Imputer, saving the results as processed_train_df and processed_test_df.**\n**üß† Train both LightGBM and XGBoost models on the processed training data.**\n**üìä Evaluate models on a validation split and Save performance plots.**\n**üíæ Generate predictions on the processed test data and save them to CSV files (lgb_test_preds.csv, xgb_test_preds.csv) in an model_outputs directory.**\n**What's Next?**\n\n**After running this code, you'll have the test predictions saved. The final step for your Kaggle submission would be to load one of the prediction CSVs (e.g., lgb_test_preds.csv), merge it with the original test.csv's 'id' column, and save it in the required submission.csv format. You could even explore averaging the predictions from both models for potentially better results!**\n\n**This workflow shows just how powerful collaborative AI agents can be in jumpstarting your machine learning projects. Go ahead, copy the code, run it, and see the magic happen! ‚ú® Let us know what you build next!**\n\n**Note** If u are here is because you are watching a version wheere i took the output and use it with a simple prompt on cluade 3.5 Sonnet","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import OneHotEncoder, MinMaxScaler\nfrom sklearn.impute import KNNImputer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_log_error, mean_squared_error\nimport lightgbm as lgb\nimport xgboost as xgb\nimport matplotlib.pyplot as plt\nimport warnings\nimport os\n\n# Suppress warnings\nwarnings.filterwarnings('ignore')\n\ndef preprocess_data(train, test, target_col='Calories'):\n    # Identify columns\n    num_cols = train.select_dtypes(include=[np.number]).columns.tolist()\n    num_cols.remove(target_col)\n    cat_cols = train.select_dtypes(include=['object', 'category']).columns.tolist()\n    \n    # Create preprocessor\n    preprocessor = ColumnTransformer(transformers=[\n        ('num', MinMaxScaler(), num_cols),\n        ('cat', OneHotEncoder(handle_unknown='ignore', sparse=False), cat_cols)\n    ])\n    \n    # Prepare data\n    X = train.drop(target_col, axis=1)\n    y = train[target_col]\n    \n    # Transform data\n    X_processed = preprocessor.fit_transform(X)\n    X_test_processed = preprocessor.transform(test)\n    \n    return X_processed, X_test_processed, y, preprocessor\n\ndef train_lightgbm(X_train, y_train, X_val, y_val):\n    train_data = lgb.Dataset(X_train, label=y_train)\n    val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n    \n    params = {\n        'objective': 'regression',\n        'metric': 'rmse',\n        'boosting_type': 'gbdt',\n        'learning_rate': 0.05,\n        'num_leaves': 31,\n        'feature_fraction': 0.8,\n        'bagging_fraction': 0.8,\n        'bagging_freq': 1,\n        'verbose': -1\n    }\n    \n    model = lgb.train(\n        params,\n        train_data,\n        num_boost_round=1000,\n        valid_sets=[train_data, val_data],\n        callbacks=[\n            lgb.early_stopping(stopping_rounds=50),\n            lgb.log_evaluation(period=100)\n        ]\n    )\n    \n    return model\n\ndef train_xgboost(X_train, y_train, X_val, y_val):\n    dtrain = xgb.DMatrix(X_train, label=y_train)\n    dval = xgb.DMatrix(X_val, label=y_val)\n    \n    params = {\n        'objective': 'reg:squarederror',\n        'eval_metric': 'rmse',\n        'learning_rate': 0.05,\n        'max_depth': 6,\n        'subsample': 0.8,\n        'colsample_bytree': 0.8\n    }\n    \n    model = xgb.train(\n        params,\n        dtrain,\n        num_boost_round=1000,\n        evals=[(dtrain, 'train'), (dval, 'val')],\n        early_stopping_rounds=50,\n        verbose_eval=100\n    )\n    \n    return model\n\ndef rmsle(y_true, y_pred):\n    return np.sqrt(mean_squared_log_error(y_true, np.maximum(0, y_pred)))\n\n# Load data\ntrain, test, submission = (\n    pd.read_csv('/kaggle/input/playground-series-s5e5/train.csv'),\n    pd.read_csv('/kaggle/input/playground-series-s5e5/test.csv'),\n    pd.read_csv('/kaggle/input/playground-series-s5e5/sample_submission.csv')\n)\n\n# Create output directory\nos.makedirs('model_outputs', exist_ok=True)\n\n# Preprocess data\nX_processed, X_test_processed, y, preprocessor = preprocess_data(train, test)\n\n# Split data\nX_train, X_val, y_train, y_val = train_test_split(X_processed, y, test_size=0.2, random_state=42)\n\n# Train LightGBM\nprint(\"Training LightGBM...\")\nlgb_model = train_lightgbm(X_train, y_train, X_val, y_val)\nlgb_val_pred = lgb_model.predict(X_val)\nlgb_test_pred = lgb_model.predict(X_test_processed)\n\n# Train XGBoost\nprint(\"\\nTraining XGBoost...\")\nxgb_model = train_xgboost(X_train, y_train, X_val, y_val)\nxgb_val_pred = xgb_model.predict(xgb.DMatrix(X_val))\nxgb_test_pred = xgb_model.predict(xgb.DMatrix(X_test_processed))\n\n# Print validation scores\nprint(f\"\\nLightGBM Validation RMSLE: {rmsle(y_val, lgb_val_pred):.5f}\")\nprint(f\"XGBoost Validation RMSLE: {rmsle(y_val, xgb_val_pred):.5f}\")\n\n# Create submission\nsubmission['Calories'] = (lgb_test_pred + xgb_test_pred) / 2\nsubmission.to_csv('submission.csv', index=False)\nprint(\"\\nSubmission file created!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T04:20:11.714401Z","iopub.execute_input":"2025-05-05T04:20:11.714836Z","iopub.status.idle":"2025-05-05T04:21:33.336301Z","shell.execute_reply.started":"2025-05-05T04:20:11.714811Z","shell.execute_reply":"2025-05-05T04:21:33.33536Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T04:09:38.256702Z","iopub.execute_input":"2025-05-05T04:09:38.25724Z","iopub.status.idle":"2025-05-05T04:09:38.296141Z","shell.execute_reply.started":"2025-05-05T04:09:38.257196Z","shell.execute_reply":"2025-05-05T04:09:38.294671Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}