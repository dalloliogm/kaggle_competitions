{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":87793,"databundleVersionId":12276181,"sourceType":"competition"},{"sourceId":11661237,"sourceType":"datasetVersion","datasetId":7317710},{"sourceId":11759715,"sourceType":"datasetVersion","datasetId":7382011},{"sourceId":11775973,"sourceType":"datasetVersion","datasetId":7393299},{"sourceId":11837219,"sourceType":"datasetVersion","datasetId":7436926},{"sourceId":224830487,"sourceType":"kernelVersion"}],"dockerImageVersionId":30919,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport sys\nimport os\nos.environ['CUDA_VISIBLE_DEVICES'] = '0'\n\nsys.argv = ['notebook', 'cuda' if torch.cuda.is_available() else 'cpu', 'fp32'] #'fp16' #'fp32'# 'bf16' #\ndevice = sys.argv[1]\nsys_dtype = sys.argv[2] if len(sys.argv) > 2 else 'fp32'\n\nprint('Using device:', device)\nprint('Using dtype:', sys_dtype)\n\n# dr settings\nNUM_CONF=5\nMAX_LENGTH=480\nMAX_CAT_LENGTH=2400\n\nCFG_DIR='cfg_97'\nCFG_MERGE=False\nDR_SCORE=False\nOP_SCORE=True\n\nNO_SORT=False\nGET_CENTER=False\n\nFULL_ENERGY=True\n\nOPTIM_LENGTH=0\n\nDEVICE=device #'cuda' #'cpu'#\nPREC=sys_dtype\n\n# ARENA='./Arena/Arena'\nARENA_DIR='/kaggle/input/drfold-model-bf16/Arena'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T05:32:36.054338Z","iopub.execute_input":"2025-05-22T05:32:36.054769Z","iopub.status.idle":"2025-05-22T05:32:39.966766Z","shell.execute_reply.started":"2025-05-22T05:32:36.054737Z","shell.execute_reply":"2025-05-22T05:32:39.965621Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\ndst = os.path.join(os.getcwd(), 'Arena') \n\nif os.path.exists(dst):\n    shutil.rmtree(dst)\n\nshutil.copytree(ARENA_DIR, dst)\nprint(f\"Arena 目录已拷贝到：{dst}\")\narena_exec = os.path.join(dst, 'Arena')\nos.chmod(arena_exec, 0o755)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T05:32:39.968268Z","iopub.execute_input":"2025-05-22T05:32:39.968853Z","iopub.status.idle":"2025-05-22T05:32:40.468259Z","shell.execute_reply.started":"2025-05-22T05:32:39.968808Z","shell.execute_reply":"2025-05-22T05:32:40.467202Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if PREC=='fp16':\n    torch.set_default_dtype(torch.float16)\nif PREC=='bf16':\n    torch.set_default_dtype(torch.bfloat16)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T05:32:40.47016Z","iopub.execute_input":"2025-05-22T05:32:40.470475Z","iopub.status.idle":"2025-05-22T05:32:40.474953Z","shell.execute_reply.started":"2025-05-22T05:32:40.470448Z","shell.execute_reply":"2025-05-22T05:32:40.473804Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Install requirements ","metadata":{}},{"cell_type":"code","source":"#rhofold+\n#!pip install --no-deps '/kaggle/input/rhofold/wheels_py311/python_box-7.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl'\n!pip install --no-deps '/kaggle/input/rhofold/wheels_py311/gprofiler_official-1.0.0-py3-none-any.whl'\n!pip install --no-deps '/kaggle/input/rhofold/wheels_py311/mygene-3.2.2-py2.py3-none-any.whl'\n!pip install --no-deps '/kaggle/input/rhofold/wheels_py311/biothings_client-0.4.1-py3-none-any.whl'\n#!pip install --no-deps '/kaggle/input/rhofold/wheels_py311/dm_tree-0.1.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl'\n!pip install --no-deps '/kaggle/input/rhofold/wheels_py311/einops-0.8.1-py3-none-any.whl'\n#!pip install --no-deps '/kaggle/input/rhofold/wheels_py311/openmm-7.7.0-py3-none-any.whl'\n!pip install --no-deps '/kaggle/input/rhofold/wheels_py311/bio-1.8.0-py3-none-any.whl'\n!pip install --no-deps '/kaggle/input/rhofold/wheels_py311/absl_py-2.2.2-py3-none-any.whl'\n!pip install --no-deps '/kaggle/input/rhofold/wheels_py311/OpenMM-8.2.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl'\nprint(\"-------------------------------------------------------------------------------\")\nprint(\"-------------------------------------------------------------------------------\")\nprint(\"-------------------------------------------------------------------------------\")\n\n!pip install --no-deps '/kaggle/input/dependencies-tr-pr/protenix-0.4.6-py3-none-any.whl'\n!pip install --no-deps '/kaggle/input/dependencies-tr-pr/rdkit-2024.9.6-cp310-cp310-manylinux_2_28_x86_64.whl'\n!pip install --no-deps '/kaggle/input/dependencies-tr-pr/ml_collections-1.1.0-py3-none-any.whl'\n!pip install --no-deps '/kaggle/input/dependencies-tr-pr/biopython-1.85-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl'\n!pip install --no-deps '/kaggle/input/dependencies-tr-pr/pyrosetta-2025.13-cp310-cp310-linux_x86_64.whl'\n!pip install --no-deps '/kaggle/input/dependencies-tr-pr/blosc-1.11.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl'\n!pip install --no-deps '/kaggle/input/dependencies-tr-pr/ml_collections-1.1.0-py3-none-any.whl'\n!pip install --no-deps '/kaggle/input/dependencies-tr-pr/biotraj-1.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl'\n!pip install --no-deps '/kaggle/input/dependencies-tr-pr/biotite-1.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl'\n!pip install --no-deps '/kaggle/input/dependencies-tr-pr/biopandas-0.5.1-py3-none-any.whl'\n!pip install --no-deps '/kaggle/input/dependencies-tr-pr/looseversion-1.1.2-py3-none-any.whl'\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T05:32:40.476514Z","iopub.execute_input":"2025-05-22T05:32:40.476852Z","iopub.status.idle":"2025-05-22T05:33:52.393911Z","shell.execute_reply.started":"2025-05-22T05:32:40.476822Z","shell.execute_reply":"2025-05-22T05:33:52.392715Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python --version","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T05:33:52.395334Z","iopub.execute_input":"2025-05-22T05:33:52.395786Z","iopub.status.idle":"2025-05-22T05:33:52.530826Z","shell.execute_reply.started":"2025-05-22T05:33:52.395736Z","shell.execute_reply":"2025-05-22T05:33:52.529326Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Drfold2","metadata":{}},{"cell_type":"code","source":"from datetime import datetime\nimport pytz\nprint('LOGGING TIME OF START:',  datetime.strftime(datetime.now(pytz.timezone('Asia/Singapore')), \"%Y-%m-%d %H:%M:%S\"))\n\n\nprint('PIP INSTALL OK !!!!')\nimport os,sys\n\nimport pandas as pd\npd.set_option('display.max_columns', 20)\npd.set_option('display.expand_frame_repr', False)\n\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom timeit import default_timer as timer\n\n\n\n# helper--\nclass dotdict(dict):\n\t__setattr__ = dict.__setitem__\n\t__delattr__ = dict.__delitem__\n\n\tdef __getattr__(self, name):\n\t\ttry:\n\t\t\treturn self[name]\n\t\texcept KeyError:\n\t\t\traise AttributeError(name)\n\ndef time_to_str(t, mode='min'):\n\tif mode=='min':\n\t\tt  = int(t)/60\n\t\thr = t//60\n\t\tmin = t%60\n\t\treturn '%2d hr %02d min'%(hr,min) \n\telif mode=='sec':\n\t\tt   = int(t)\n\t\tmin = t//60\n\t\tsec = t%60\n\t\treturn '%2d min %02d sec'%(min,sec)\n\n\telse:\n\t\traise NotImplementedError\n\ndef gpu_memory_use():\n    if torch.cuda.is_available():\n        device = torch.device(0)\n        free, total = torch.cuda.mem_get_info(device)\n        used= (total - free) / 1024 ** 3\n        return round(used,2)\n    else:\n        return 0\n\ndef set_aspect_equal(ax):\n\tx_limits = ax.get_xlim()\n\ty_limits = ax.get_ylim()\n\tz_limits = ax.get_zlim()\n\n\t# Compute the mean of each axis\n\tx_middle = np.mean(x_limits)\n\ty_middle = np.mean(y_limits)\n\tz_middle = np.mean(z_limits)\n\n\t# Compute the max range across all axes\n\tmax_range = max(x_limits[1] - x_limits[0],\n\t\t\t\t\ty_limits[1] - y_limits[0],\n\t\t\t\t\tz_limits[1] - z_limits[0]) / 2.0\n\n\t# Set the new limits to ensure equal scaling\n\tax.set_xlim(x_middle - max_range, x_middle + max_range)\n\tax.set_ylim(y_middle - max_range, y_middle + max_range)\n\tax.set_zlim(z_middle - max_range, z_middle + max_range)\n\n\nprint('torch',torch.__version__)\nprint('torch.cuda',torch.version.cuda)\n\nprint('IMPORT OK!!!')\nMODE = 'submit' #'local' # submit\n\nDATA_KAGGLE_DIR = '/kaggle/input/stanford-rna-3d-folding'\n\nif MODE == 'local':\n    valid_df = pd.read_csv(f'{DATA_KAGGLE_DIR}/validation_sequences.csv')\n    label_df = pd.read_csv(f'{DATA_KAGGLE_DIR}/validation_labels.csv')\n    label_df['target_id'] = label_df['ID'].apply(lambda x: '_'.join(x.split('_')[:-1]))\n\nif MODE == 'submit':\n\tvalid_df = pd.read_csv(f'{DATA_KAGGLE_DIR}/test_sequences.csv')\n\nprint('len(valid_df)',len(valid_df))\nprint(valid_df.iloc[0])\nprint('')\n\n\nprint('MODE:', MODE)\nprint('SETTING OK!!!')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T05:33:52.914466Z","iopub.execute_input":"2025-05-22T05:33:52.914836Z","iopub.status.idle":"2025-05-22T05:33:53.35025Z","shell.execute_reply.started":"2025-05-22T05:33:52.91479Z","shell.execute_reply":"2025-05-22T05:33:53.349315Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sys.path.append('/kaggle/input/drfold-model-bf16/PotentialFold')\nimport a2b\n\ndef frame_coor_to_C1(coor, seq, BASE_COOR, OTHER_COOR):\n    \"\"\"\n    Use batch quaternion operations to directly convert model-predicted local frame coordinates\n    into the global coordinates of each site's C1' atom.\n\n    Parameters\n    ----------\n    coor : numpy.ndarray or torch.Tensor, shape=(L, 3, 3)\n        Local coordinates of three atoms (P, C4', N) predicted by the model for each site.\n    seq : str, length=L\n        Nucleotide sequence.\n    BASE_COOR : dict\n        Template coordinates (constants) for the three backbone atoms required by Get_base.\n    OTHER_COOR : dict\n        Template coordinates (constants) for the five sugar ring atoms required by Get_base.\n\n    Returns\n    -------\n    c1_xyz : numpy.ndarray, shape=(L, 3)\n        The global XYZ coordinates of the C1' atom for each site.\n    \"\"\"\n    # 1. Convert to torch.Tensor\n    tx = torch.as_tensor(coor, dtype=torch.float32)\n    basex = torch.from_numpy(Get_base(seq, BASE_COOR)).to(tx.dtype)\n    otherx = torch.from_numpy(Get_base(seq, OTHER_COOR)).to(tx.dtype)\n    L = len(seq)\n\n    # 2. Initialize parameter vector x: 21 dimensions.\n    #    The first 18 are for rotation projection, the last 3 for translation.\n    x = torch.rand((L, 21), dtype=tx.dtype, device=tx.device)\n\n    # 3. Centering: compute centroid biasq, and obtain zero-mean coordinates q\n    biasq = tx.mean(dim=1, keepdim=True)            # (L, 1, 3)\n    q = tx - biasq                                  # (L, 3, 3)\n\n    # 4. Compute rotation projection m and fill it into the first two 9-dim groups of x\n    m = torch.einsum('bnz,bny->bzy', basex, q).reshape(L, -1)\n    x[:, :9] = m\n    x[:, 9:18] = m\n\n    # 5. Fill translation parameters (use biasq as translation vector)\n    x[:, 18:] = biasq.squeeze(1)\n    rama = x.double()  # Quaternion parameters require double precision\n\n    # 6. Call quat2b: perform rotation + translation for all sugar ring atoms in the template\n    #    otherx: (L, 5, 3) -> other_xyz: (L, 5, 3)\n    other_xyz = a2b.quat2b(otherx.double(), rama[:, 9:]).float().cpu().numpy()\n\n    # 7. Extract the 5th atom (C1') and return\n    c1_xyz = other_xyz[:, 4, :]\n    return c1_xyz\n\n\ndef concat_coor(out1: dict, out2: dict) -> np.ndarray:\n    \"\"\"\n    Align out2 to the end of out1 using quaternion-based rotation + translation (quat2b),\n    then concatenate (removing the duplicated first base).\n\n    out1/out2 are both dicts containing:\n        'coor': np.ndarray, shape=(L, 3, 3)  —— coordinates of P, C4, N for each base.\n\n    Returns the concatenated coordinate array, shape = (L1 + L2 - 1, 3, 3)\n    \"\"\"\n    # 1. Convert to torch.DoubleTensor\n    coor1 = torch.as_tensor(out1['coor'], dtype=torch.float64)   # (L1,3,3)\n    coor2 = torch.as_tensor(out2['coor'], dtype=torch.float64)   # (L2,3,3)\n\n    # 2. Take the shared base frames: last of out1, first of out2\n    f1 = coor1[-1]   # (3,3)\n    f2 = coor2[0]    # (3,3)\n\n    # 3. Centering: remove each centroid\n    bias1 = f1.mean(dim=0)   # (3,)\n    bias2 = f2.mean(dim=0)   # (3,)\n    basex = f1 - bias1       # (3,3)\n    q     = f2 - bias2       # (3,3)\n\n    # 4. Use einsum to compute rotation matrix R = basex · q^T\n    #    R_{ij} = sum_z basex_{iz} * q_{jz}\n    R = torch.einsum('iz,jz->ij', basex, q)   # (3,3)\n\n    # 5. Compute translation vector t, so that R·bias2 + t = bias1  ⇒  t = bias1 - R·bias2\n    t = bias1 - (R @ bias2)                  # (3,)\n\n    # 6. Construct rama parameters (L2, 12): first 9 for R.flatten, last 3 for t\n    L2 = coor2.shape[0]\n    rama = torch.empty((L2, 12), dtype=torch.float64, device=coor2.device)\n    R_flat = R.reshape(1, 9).repeat(L2, 1)    # (L2,9)\n    t_rep  = t.reshape(1, 3).repeat(L2, 1)    # (L2,3)\n    rama[:, :9] = R_flat\n    rama[:, 9:] = t_rep\n\n    # 7. Call quat2b: apply rigid-body transformation to all coordinates in out2\n    #    Input coord=(L2,3,3), rama=(L2,12), output has same shape\n    coor2_aligned = a2b.quat2b(coor2, rama)   # torch.Tensor (L2,3,3)\n\n    # 8. Concatenate (skip coor2_aligned[0], since it overlaps with coor1[-1])\n    coor_cat = torch.cat([coor1, coor2_aligned[1:]], dim=0)  # (L1+L2-1,3,3)\n\n    return coor_cat.cpu().numpy()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T05:33:53.352906Z","iopub.execute_input":"2025-05-22T05:33:53.35322Z","iopub.status.idle":"2025-05-22T05:33:53.422015Z","shell.execute_reply.started":"2025-05-22T05:33:53.353193Z","shell.execute_reply":"2025-05-22T05:33:53.42107Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def Get_base(seq, basenpy_standard):\n    n_atoms = basenpy_standard.shape[1]\n    basenpy = np.zeros([len(seq), n_atoms, 3])\n    seqnpy = np.array(list(seq))\n    basenpy[seqnpy=='A'] = basenpy_standard[0]\n    basenpy[seqnpy=='a'] = basenpy_standard[0]\n    basenpy[seqnpy=='G'] = basenpy_standard[1]\n    basenpy[seqnpy=='g'] = basenpy_standard[1]\n    basenpy[seqnpy=='C'] = basenpy_standard[2]\n    basenpy[seqnpy=='c'] = basenpy_standard[2]\n    basenpy[seqnpy=='U'] = basenpy_standard[3]\n    basenpy[seqnpy=='u'] = basenpy_standard[3]\n    basenpy[seqnpy=='T'] = basenpy_standard[3]\n    basenpy[seqnpy=='t'] = basenpy_standard[3]\n    return basenpy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T05:33:53.423329Z","iopub.execute_input":"2025-05-22T05:33:53.4237Z","iopub.status.idle":"2025-05-22T05:33:53.430154Z","shell.execute_reply.started":"2025-05-22T05:33:53.423672Z","shell.execute_reply":"2025-05-22T05:33:53.428923Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\ndef score_energy_one_simple(seq, target_id, out):\n    \"\"\"\n    Compute a coarse-grained free energy for an RNA structure, based only on each base's\n    P–C4'–N (N1 or N9) local coordinate frame.\n\n    Parameters:\n      seq:       RNA sequence string of length L\n      target_id: structure identifier (used only for logging/output; does not affect computation)\n      out:       model output dict, must contain:\n                 out['coor']: numpy array, shape (L, 3, 3)\n                               coor[i,0] = P coordinates\n                               coor[i,1] = C4′ coordinates\n                               coor[i,2] = N1/N9 coordinates\n\n    Returns:\n      total_energy: float, estimated free energy (lower => more stable)\n    \"\"\"\n\n    coor = out['coor']  # (L, 3, 3)\n    L = len(seq)\n\n    # — I. Bond-length energy — #\n    # Ideal bond lengths (Å): P–C4′ ~ 1.60, C4′–N ~ 1.47 (typical values; adjust from empirical/crystal data if needed)\n    d0_P_C4  = 1.60\n    d0_C4_N  = 1.47\n    k_bond   = 100.0  # Bond force constant (kcal/mol/Å²)\n\n    energy_bond = 0.0\n    for i in range(L):\n        P  = coor[i,0]\n        C4 = coor[i,1]\n        N  = coor[i,2]\n        d_PC4 = np.linalg.norm(P - C4)\n        d_C4N = np.linalg.norm(C4 - N)\n        energy_bond += k_bond * (d_PC4 - d0_P_C4)**2\n        energy_bond += k_bond * (d_C4N - d0_C4_N)**2\n\n    # — II. Bond-angle energy — #\n    # Ideal angle P–C4′–N ~ 109.5° (tetrahedral angle), modeled with a harmonic potential\n    theta0   = np.deg2rad(109.5)\n    k_angle  = 20.0   # Angle force constant (kcal/mol/rad²)\n\n    energy_angle = 0.0\n    for i in range(L):\n        P  = coor[i,0]\n        C4 = coor[i,1]\n        N  = coor[i,2]\n        v1 = P  - C4\n        v2 = N  - C4\n        cos_theta = np.dot(v1, v2) / (np.linalg.norm(v1)*np.linalg.norm(v2) + 1e-8)\n        theta = np.arccos(np.clip(cos_theta, -1.0, 1.0))\n        energy_angle += k_angle * (theta - theta0)**2\n\n    # — III. Stacking interaction — #\n    # Penalize deviations of adjacent base C4′–C4′ distance to encourage stacking:\n    #   ideal in-plane distance ~ 3.4 Å\n    d0_stack = 3.4\n    k_stack  = 5.0   # (kcal/mol/Å²)\n\n    energy_stack = 0.0\n    for i in range(L-1):\n        C4_i   = coor[i  ,1]\n        C4_ip1 = coor[i+1,1]\n        d = np.linalg.norm(C4_i - C4_ip1)\n        energy_stack += k_stack * (d - d0_stack)**2\n\n    # — IV. Total — #\n    total_energy = energy_bond + energy_angle + energy_stack\n\n    # (Optional) Debug print\n    # print(f\"[{target_id}] bond={energy_bond:.2f}, angle={energy_angle:.2f}, stack={energy_stack:.2f} → total={total_energy:.2f}\")\n\n    return total_energy\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T05:33:53.431423Z","iopub.execute_input":"2025-05-22T05:33:53.431745Z","iopub.status.idle":"2025-05-22T05:33:53.452247Z","shell.execute_reply.started":"2025-05-22T05:33:53.431719Z","shell.execute_reply":"2025-05-22T05:33:53.451228Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\ndef score_energy_one_full(seq, target_id, out, paired=None,\n                               # stacking parameters (optional if needed)\n                               d0_stack=3.4, k_stack=5.0,\n                               # dihedral parameters\n                               phi0=np.deg2rad(180.0), k_dihedral=5.0,\n                               # hydrogen-bond parameters\n                               d0_hb=2.9, k_hb=10.0,\n                               # Lennard-Jones parameters\n                               sigma=4.0, epsilon=0.1,\n                               # implicit solvation (ASA) coefficient\n                               k_solv=0.05,\n                               # Debye–Hückel electrostatics\n                               q_P=-1.0, epsilon_r=80.0, kappa=10.0,\n                               k_e=332.0637,\n                               # statistical potential map: dict of (i,j)->energy\n                               stat_potentials=None,\n                               # numerical stability\n                               r_min=1.0):\n    \"\"\"\n    Coarse-grained energy function aimed at maximizing TM-score, including:\n      - backbone torsion\n      - hydrogen bonding\n      - van der Waals + implicit solvation (LJ + solvation)\n      - electrostatics\n      - knowledge-based statistical potentials\n    Bond-length and bond-angle terms have been removed.\n    \"\"\"\n    coor = out['coor']\n    L = len(seq)\n    if paired is None:\n        paired = out.get('paired', [])\n\n    # — I. Backbone torsion energy — #\n    def torsion_angle(a, b, c, d):\n        b1, b2, b3 = b - a, c - b, d - c\n        n1 = np.cross(b1, b2); n2 = np.cross(b2, b3)\n        n1 /= (np.linalg.norm(n1) + 1e-8); n2 /= (np.linalg.norm(n2) + 1e-8)\n        cos_phi = np.dot(n1, n2)\n        return np.arccos(np.clip(cos_phi, -1, 1))\n\n    E_dihedral = 0.0\n    for i in range(L - 1):\n        a, b, c = coor[i,0], coor[i,1], coor[i,2]\n        d = coor[i+1,0]\n        phi = torsion_angle(a, b, c, d)\n        E_dihedral += k_dihedral * (phi - phi0)**2\n\n    # — II. Hydrogen-bond potential — #\n    E_hb = 0.0\n    for i, j in paired:\n        r = np.linalg.norm(coor[i,2] - coor[j,2])\n        E_hb += k_hb * (r - d0_hb)**2\n\n    # — III. van der Waals + implicit solvation — #\n    # E_LJ = 0.0\n    # E_solv = 0.0\n    # for i in range(L):\n    #     for j in range(i + 2, L):\n    #         r = np.linalg.norm(coor[i,1] - coor[j,1])\n    #         r_clamped = max(r, r_min)\n    #         sr6 = (sigma / r_clamped)**6\n    #         sr12 = sr6 * sr6\n            # E_LJ += 4 * epsilon * (sr12 - sr6)\n            # Implicit solvation: proportional to ASA; simplified here as r^-2\n            # E_solv += k_solv / (r_clamped**2)\n\n    # — IV. Electrostatics (Debye–Hückel) — #\n    E_elec = 0.0\n    prefac = k_e * q_P * q_P / epsilon_r\n    for i in range(L):\n        for j in range(i + 1, L):\n            r = np.linalg.norm(coor[i,0] - coor[j,0])\n            r_clamped = max(r, r_min)\n            E_elec += prefac * np.exp(-r_clamped / kappa) / r_clamped\n\n    # — V. Knowledge-based statistical potentials — #\n    E_stat = 0.0\n    if stat_potentials:\n        for (i, j), Eij in stat_potentials.items():\n            E_stat += Eij\n\n    # total_energy = E_dihedral + E_hb + E_LJ + E_solv + E_elec + E_stat\n    total_energy = E_dihedral + E_hb + E_elec + E_stat\n\n    # print(f\"[{target_id}] torsion={E_dihedral:.2f}, hb={E_hb:.2f}, LJ={E_LJ:.2f}, \"\n    #       f\"solv={E_solv:.2f}, elec={E_elec:.2f}, stat={E_stat:.2f} -> total={total_energy:.2f}\")\n    # print(f\"[{target_id}] torsion={E_dihedral:.2f}, hb={E_hb:.2f}, \"\n    #       f\"elec={E_elec:.2f}, stat={E_stat:.2f} -> total={total_energy:.2f}\")\n    \n    return -total_energy\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T05:33:53.453283Z","iopub.execute_input":"2025-05-22T05:33:53.453705Z","iopub.status.idle":"2025-05-22T05:33:53.477124Z","shell.execute_reply.started":"2025-05-22T05:33:53.453659Z","shell.execute_reply":"2025-05-22T05:33:53.476067Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pyrosetta\nfrom pyrosetta import pose_from_pdb, create_score_function\nfrom pyrosetta.rosetta import core\n\n# 1. Initialize PyRosetta (run once)\npyrosetta.init(options='-mute all')  # Silent mode, suppress extra logs\n\n# 3. Create and customize ScoreFunction\nop_score = create_score_function('ref2015')\n# 3.1 Constraint weights\nop_score.set_weight(core.scoring.atom_pair_constraint, 9.0)\nop_score.set_weight(core.scoring.dihedral_constraint, 4.0)\nop_score.set_weight(core.scoring.angle_constraint, 4.0)\n# 3.2 Physical/statistical energy term weights\nop_score.set_weight(core.scoring.fa_rep, 9.0)\nop_score.set_weight(core.scoring.rna_sugar_close, 9.0)\nop_score.set_weight(core.scoring.fa_intra_rep, 9.0)\nop_score.set_weight(core.scoring.rna_base_pair, 9.0)\nop_score.set_weight(core.scoring.rna_base_stack, 9.0)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T05:33:53.478109Z","iopub.execute_input":"2025-05-22T05:33:53.478433Z","iopub.status.idle":"2025-05-22T05:33:58.310434Z","shell.execute_reply.started":"2025-05-22T05:33:53.478405Z","shell.execute_reply":"2025-05-22T05:33:58.309292Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport pickle\nfrom subprocess import PIPE, STDOUT, Popen\nimport numpy as np\nimport tempfile\nfrom Bio.PDB import PDBParser\nsys.path.append('/kaggle/input/drfold-model/DRfold2/PotentialFold')\nfrom Optimization import Structure\n\ndef score_energy_one(seq, target_id, out):\n    with tempfile.TemporaryDirectory() as tmpdirname:\n        # Write temporary FASTA\n        fastafile = os.path.join(tmpdirname, 'tmp.fasta')\n        with open(fastafile, 'w') as f:\n            f.write(f'>{target_id}\\n{seq}\\n')\n        # Write temporary ret\n        retfile = os.path.join(tmpdirname, 'tmp.ret')\n        with open(retfile, 'wb') as f:\n            f.write(pickle.dumps(out))\n        # foldconfig = '/kaggle/input/drfold-model/DRfold2/cfg_for_selection.json'\n        # foldconfig = '/kaggle/input/drfold-model/DRfold2/cfg_for_folding.json'\n        foldconfig = '/kaggle/input/drfold-model-bf16/cfg_for_folding.json'\n        # foldconfig = 'cfg_for_folding.json'\n        save_prefix = os.path.join(tmpdirname, 'tmp.json')\n        stru = Structure(fastafile, [retfile], save_prefix, 0, foldconfig)\n        rama = stru.init_quat(0).data.numpy()\n        energy = stru.obj_func_np(rama)\n        return energy\n    \ndef score_energy_one_op(seq, target_id, out):\n    with tempfile.TemporaryDirectory() as tmpdirname:\n        # Write temporary FASTA\n        fastafile = os.path.join(tmpdirname, 'tmp.fasta')\n        with open(fastafile, 'w') as f:\n            f.write(f'>{target_id}\\n{seq}\\n')\n        # Write temporary ret\n        retfile = os.path.join(tmpdirname, 'tmp.ret')\n        with open(retfile, 'wb') as f:\n            f.write(pickle.dumps(out))\n        # foldconfig = '/kaggle/input/drfold-model/DRfold2/cfg_for_selection.json'\n        # foldconfig = '/kaggle/input/drfold-model/DRfold2/cfg_for_folding.json'\n        foldconfig = '/kaggle/input/drfold-model-bf16/cfg_for_folding.json'\n        # foldconfig = 'cfg_for_folding.json'\n        save_prefix = os.path.join(tmpdirname, 'tmp.json')\n        stru = Structure(fastafile, [retfile], save_prefix, 0, foldconfig)\n        rama = stru.init_quat(0).data.numpy()\n        \n        cgpdb = os.path.join(tmpdirname, 'tmp.pdb')\n        # print(rama)\n        newrama = torch.DoubleTensor(rama) \n        stru.outpdb(newrama, cgpdb)\n        \n        savepdb = os.path.join(tmpdirname, 'tmp_full.pdb')\n        \n        exp_dir = os.getcwd()\n        arena = os.path.join(exp_dir, 'Arena', 'Arena')\n        cmd = f'{arena} {cgpdb} {savepdb} 7'\n        p = Popen(cmd, shell=True, stdin=PIPE, stdout=PIPE, stderr=STDOUT)\n        output, error = p.communicate()\n        pose = pose_from_pdb(savepdb)\n        \n        score = op_score(pose)\n        return score\n\n\ndef optimize_coor(seq, target_id, out):\n    print('Optimizing structure for ', target_id)\n    if len(out['coor']) > len(out['plddt']):\n        # Fill missing pLDDT values\n        if len(out['plddt']) > 0:\n            mean_plddt = np.mean(out['plddt'])\n            out['plddt'] = np.concatenate(\n                [out['plddt'], np.full((len(out['coor']) - len(out['plddt'])), mean_plddt)]\n            )\n        else:\n            out['plddt'] = np.full((len(out['coor'])), 0.0)\n            \n    if len(out['coor']) < len(out['plddt']):\n        mean_plddt = np.mean(out['plddt'])\n        out['plddt'] = np.full((len(out['coor'])), mean_plddt)\n    \n    with tempfile.TemporaryDirectory() as tmpdirname:\n        # 1) Write temporary FASTA\n        fastafile = os.path.join(tmpdirname, 'tmp.fasta')\n        with open(fastafile, 'w') as f:\n            f.write(f'>{target_id}\\n{seq}\\n')\n\n        # 2) Write temporary ret\n        retfile = os.path.join(tmpdirname, 'tmp.ret')\n        with open(retfile, 'wb') as f:\n            pickle.dump(out, f)\n\n        # 3) Call Structure to perform folding optimization\n        foldconfig = '/kaggle/input/drfold-model/DRfold2/cfg_for_folding.json'\n        # foldconfig = 'cfg_for_folding.json'\n        save_prefix = os.path.join(tmpdirname, 'tmp')\n        stru = Structure(fastafile, [retfile], save_prefix, 0, foldconfig)\n        stru.foldning()\n\n        # 4) Parse the output PDB\n        pdb_file = save_prefix + '.pdb'\n        parser = PDBParser(QUIET=True)\n        structure = parser.get_structure(target_id, pdb_file)\n\n        # 5) Collect all standard residues (exclude HETATM)\n        residues = [\n            res for res in structure.get_residues()\n            if res.id[0] == ' '\n        ]\n        # Check residue count equals sequence length\n        L = len(seq)\n        if len(residues) != L:\n            raise ValueError(f\"Number of residues in PDB ({len(residues)}) != sequence length ({L})\")\n\n        # 6) Extract three atom coordinates\n        atom_order = ['P', \"C4'\", 'N1/N9']\n        coor = np.zeros((L, 3, 3), dtype=float)\n\n        for i, res in enumerate(residues):\n            coor[i, :, :] = np.nan  # Initialize as NaN\n            \n            if 'P' in res:\n                coord = res['P'].get_vector().get_array()\n                coor[i, 0, :] = coord\n            if \"C4'\" in res:\n                # If missing, keep NaN for easier debugging\n                coord = res[\"C4'\"].get_vector().get_array()\n                coor[i, 1, :] = coord\n            if 'N1' in res:\n                # If missing, keep NaN for easier debugging\n                coord = res['N1'].get_vector().get_array()\n                coor[i, 2, :] = coord\n            elif 'N9' in res:\n                # If missing, keep NaN for easier debugging\n                coord = res['N9'].get_vector().get_array()\n                coor[i, 2, :] = coord\n\n        return coor\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T05:33:58.311735Z","iopub.execute_input":"2025-05-22T05:33:58.31215Z","iopub.status.idle":"2025-05-22T05:33:58.639953Z","shell.execute_reply.started":"2025-05-22T05:33:58.31211Z","shell.execute_reply":"2025-05-22T05:33:58.639044Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import sys\nimport os\nimport numpy as np\nimport sys\nsys.path.append('/kaggle/input/drfold-model-bf16')\nsys.path.append('/kaggle/input/drfold-model-bf16/PotentialFold')\n# Add custom code paths\nsys.path.append(f'/kaggle/input/drfold-model-bf16/{CFG_DIR}')\nsys.path.append(f'/kaggle/input/drfold-model-bf16/{CFG_DIR}/RNALM2')\n\nBASE_COOR = np.load('/kaggle/input/drfold-model-bf16/PotentialFold/lib/base.npy')\nOTHER_COOR = np.load('/kaggle/input/drfold-model-bf16/PotentialFold/lib/other2.npy')\nSIDE_COOR = np.load('/kaggle/input/drfold-model-bf16/PotentialFold/lib/side.npy')\n\n\nfrom EvoMSA2XYZ import MSA2XYZ\nfrom RNALM2.Model import RNA2nd\nfrom data import parse_seq\n\n\n\n# data helper\ndef make_data(seq, device):\n    aa_type = parse_seq(seq)\n    base = Get_base(seq, BASE_COOR)\n    seq_idx = np.arange(len(seq)) + 1\n\n    msa = aa_type[None, :]\n    msa = torch.from_numpy(msa)\n    msa = torch.cat([msa, msa], 0)  # ???\n    msa = F.one_hot(msa.long(), 6).float()\n\n    base_x = torch.from_numpy(base).float()\n    seq_idx = torch.from_numpy(seq_idx).long()\n\n    msa, base_x, seq_idx = msa.to(device), base_x.to(device), seq_idx.to(device)\n    return msa, base_x, seq_idx\n\n\ndef solution_to_submit_df(solution):\n    submit_df = []\n    for k, s in solution.items():\n        df = coord_to_df(s.sequence, s.coord, s.target_id)\n        submit_df.append(df)\n    \n    submit_df = pd.concat(submit_df)\n    return submit_df\n \n\ndef coord_to_df(sequence, coord, target_id):\n    L = len(sequence)\n    df = pd.DataFrame()\n    df['ID'] = [f'{target_id}_{i + 1}' for i in range(L)]\n    df['resname'] = [s for s in sequence]\n    df['resid'] = [i + 1 for i in range(L)]\n\n    num_coord = len(coord)\n    for j in range(num_coord):\n        df[f'x_{j+1}'] = coord[j][:, 0]\n        df[f'y_{j+1}'] = coord[j][:, 1]\n        df[f'z_{j+1}'] = coord[j][:, 2]\n    return df\n\n\nout_dir = '/kaggle/working/model-output'\nos.makedirs(out_dir, exist_ok=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T05:33:58.64092Z","iopub.execute_input":"2025-05-22T05:33:58.641438Z","iopub.status.idle":"2025-05-22T05:34:01.825149Z","shell.execute_reply.started":"2025-05-22T05:33:58.641409Z","shell.execute_reply":"2025-05-22T05:34:01.824289Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\ndef run_submit(valid_df):\n    \n    #load model (these are moified versions, not the same from their github repo)\n    rnalm = RNA2nd(dict(\n        s_in_dim=5,\n        z_in_dim=2,\n        s_dim= 512,\n        z_dim= 128,\n        N_elayers=18,\n    ))\n    rnalm_file = '/kaggle/input/drfold-model-bf16/model_hub/RCLM/epoch_67000'\n    print(rnalm_file)\n    print(\n        rnalm.load_state_dict(torch.load(rnalm_file, map_location='cpu', weights_only=True), strict=False)\n        #Unexpected key(s) in state_dict: \"ss_head.linear.weight\", \"ss_head.linear.bias\".\n    )\n    rnalm = rnalm.to(DEVICE)\n    if(PREC=='fp16'):\n        rnalm=rnalm.half()\n        \n    if PREC=='bf16':\n        rnalm = rnalm.bfloat16()\n        \n    rnalm = rnalm.eval()\n\n    #---\n    msa2xyz = MSA2XYZ(\n        seq_dim=6,\n        msa_dim=7,\n        N_ensemble=1,\n        N_cycle=8,  # 8\n        m_dim=64,\n        s_dim=64,\n        z_dim=64,\n    )\n    msa2xyz_file = [f'/kaggle/input/drfold-model-bf16/model_hub/{CFG_DIR}/model_{i}' for i in range(20)]\n    if CFG_MERGE:\n        msa2xyz_file = [\n            f'/kaggle/input/drfold-model-bf16/model_hub/cfg_97/model_{i}'\n            for i in range(20)\n        ] + [\n            f'/kaggle/input/drfold-model-bf16/model_hub/cfg_95/model_{i}'\n            for i in range(20)\n        ] + [\n            f'/kaggle/input/drfold-model-bf16/model_hub/cfg_96/model_{i}'\n            for i in range(20)\n        ] + [\n            f'/kaggle/input/drfold-model-bf16/model_hub/cfg_99/model_{i}'\n            for i in range(20)\n        ]\n    num_msa2xyz = len(msa2xyz_file) \n    msa2xyz_state_dict = []\n    for c in range(num_msa2xyz):\n        if c==0: print(msa2xyz_file[c])\n        m = torch.load(msa2xyz_file[c], map_location='cpu', weights_only=True)\n        msa2xyz_state_dict.append(m)\n        \n    #print(msa2xyz.load_state_dict(msa2xyz_state_dict[0], strict=True))\n    print(msa2xyz.load_state_dict(msa2xyz_state_dict[0], strict=False))\n    msa2xyz = msa2xyz.to(DEVICE)\n    if(PREC=='fp16'):\n        msa2xyz=msa2xyz.half()\n\n    if PREC=='bf16':\n        msa2xyz = msa2xyz.bfloat16()\n    msa2xyz = msa2xyz.eval()\n    \n    msa2xyz.msaxyzone.premsa.rnalm = rnalm\n\n    #---\n    # start here !!!!!!!!!!!!!!!!!!!!!!\n    #valid_df = valid_df.iloc[[0,1]].reset_index(drop=True)\n\n\n    submit_df = [] \n    total_time_taken = 0\n    max_gpu_mem_used = 0\n\n    for i, row in valid_df.iterrows():\n        start_timer = timer()\n        target_id = row.target_id  # 'R1116' #casp15 R1116: len(157)\n        sequence = row.sequence\n        seq = row.sequence  \n        L = len(seq)\n        if L > MAX_CAT_LENGTH:\n            seq = seq[:MAX_CAT_LENGTH]\n        # else:\n        #     continue\n        print(i, target_id, L, len(seq), seq[:75] + '...')\n\n        \n        if len(seq)>480:\n            model_to_try=[16, 9, 1, 2, 0]\n        elif len(seq)>200:\n            # model_to_try = [0,1,2,8,9]\n            model_to_try = [13, 6, 14, 5, 3]\n        elif  len(seq)>100:\n            # model_to_try = [0,2,4,6,8,10,12,14,16,18]#list(range(min(num_msa2xyz,10)))\n            model_to_try = [13, 6, 14, 12, 7, 2, 5, 19, 10, 9]\n            if CFG_MERGE:\n                model_to_try = [24, 34, 20, 13, 6, 37, 28, 25, 14, 39]\n        else:\n            # model_to_try = list(range(num_msa2xyz))\n            \n            # model_to_try = list(range(20))\n            model_to_try = [1, 2, 0, 8, 7, 5, 6, 14, 10, 18, 4, 13, 3, 17, 19, 11, 12, 15, 16, 9]\n            \n            # if CFG_MERGE:\n            #     model_to_try = list(range(20)) + list(range(40,60)) + list(range(60, 80))\n            \n        if NO_SORT:\n            model_to_try=model_to_try[:5]\n\n\n        # 分段预测\n        def predict_segment(seq):\n            msa, base_x, seq_idx = make_data(seq, DEVICE)\n            with torch.no_grad():\n                if PREC=='fp16':\n                    msa, base_x = msa.half(), base_x.half()\n                if PREC=='bf16':\n                    msa, base_x = msa.bfloat16(), base_x.bfloat16()\n                return msa2xyz.pred(msa, seq_idx, None, base_x, np.array(list(seq)))\n\n                \n        energy = []\n        coordinate=[]\n        outputs=[]\n        for c in model_to_try:\n            msa2xyz.load_state_dict(msa2xyz_state_dict[c], strict=False)\n\n            if len(seq) <= MAX_LENGTH:\n                outs = [ predict_segment(seq) ]\n            else:\n                step = MAX_LENGTH - 1\n                outs = []\n                for s in range(0, len(seq), step):\n                    seg = seq[s : min(s+MAX_LENGTH, len(seq))]\n                    outs.append(predict_segment(seg))\n                    \n            out_cat = outs[0]\n            for out_seg in outs[1:]:\n                out_cat = {'coor': concat_coor(out_cat, out_seg)}\n                    \n            if NO_SORT:\n                e=0\n            elif len(model_to_try)>5 and DR_SCORE:\n                e = score_energy_one(seq, target_id, out_cat)\n            elif len(model_to_try)>5 and OP_SCORE:\n                e = score_energy_one_op(seq, target_id, out_cat)\n            elif FULL_ENERGY:\n                e = score_energy_one_full(seq, target_id, out_cat)\n            else:\n                e = score_energy_one_simple(seq, target_id, out_cat)\n            energy.append(e) #tranucated sequence\n            \n            if L != len(seq):\n                out_cat['coor'] = np.pad(out_cat['coor'], ((0, L - len(seq)), (0, 0), (0, 0)), 'constant', constant_values=0)\n                \n            outputs.append(out_cat)\n            \n            \n            xyz = frame_coor_to_C1(out_cat['coor'], sequence, BASE_COOR, OTHER_COOR)\n            \n            coordinate.append(xyz)\n            \n\n            time_taken = timer() - start_timer\n            total_time_taken += time_taken\n            #print('time_taken:', time_to_str(time_taken, mode='sec'))\n\n            gpu_mem_used = gpu_memory_use()\n            max_gpu_mem_used = max(max_gpu_mem_used,gpu_mem_used)\n            #print('gpu_mem_used:', gpu_mem_used, 'GB')\n\n            print(f'{c:02d}   energy:{e:10.0f}   out_cat{str(out_cat[\"coor\"].shape)}  time:{time_to_str(time_taken, mode=\"sec\")}   gpu={gpu_mem_used} gb')\n\n            \n        #------- \n        torch.cuda.empty_cache()\n        \n        if GET_CENTER:\n            energy = np.array(energy)\n            energy_mean = np.mean(energy)\n            energy= np.abs(energy - energy_mean)\n        #select top5\n        argsort = np.array(energy).argsort()\n        argsort = argsort[:5]\n        \n        if L <= OPTIM_LENGTH:\n            out_opt= outputs[argsort[0]]\n            out_opt['coor'] = optimize_coor(seq, target_id, out_opt)\n            coordinate[argsort[0]] = frame_coor_to_C1(out_opt['coor'], sequence, BASE_COOR, OTHER_COOR)\n            torch.cuda.empty_cache()\n            \n        df = coord_to_df(row.sequence, [coordinate[k] for k in argsort], row.target_id)\n        submit_df.append(df)\n    \n    print('----------------------------------------')\n    print('MAX_LENGTH', MAX_LENGTH)\n    print('### total_time_taken:', time_to_str(total_time_taken, mode='min'))\n    print('### max_gpu_mem_used:', max_gpu_mem_used, 'GB')\n    print('')\n\n    submit_df = pd.concat(submit_df)\n    submit_df.to_csv(f'submission.csv', index=False)\n    print(submit_df)\n    return submit_df\n\nrun_submit(valid_df)\n\nprint('SUBMIT OK!!!')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T05:34:01.826215Z","iopub.execute_input":"2025-05-22T05:34:01.82684Z","execution_failed":"2025-05-22T05:45:48.897Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"display(pd.read_csv('submission.csv'))","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-22T05:45:48.897Z"}},"outputs":[],"execution_count":null}]}