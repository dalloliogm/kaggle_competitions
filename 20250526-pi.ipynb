{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfd743b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T14:52:18.276664Z",
     "iopub.status.busy": "2025-07-13T14:52:18.276433Z",
     "iopub.status.idle": "2025-07-13T15:01:31.977774Z",
     "shell.execute_reply": "2025-07-13T15:01:31.977009Z"
    },
    "papermill": {
     "duration": 553.705664,
     "end_time": "2025-07-13T15:01:31.979133",
     "exception": false,
     "start_time": "2025-07-13T14:52:18.273469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Using device: cuda\n",
      "üè† Two-Stage Uncertainty Model - GAMMA OPTIMIZATION\n",
      "üéØ Current Best LB: 324,790\n",
      "üöÄ Target Score: <315,000\n",
      "============================================================\n",
      "\n",
      "üìÅ Loading data...\n",
      "‚úÖ Data loaded successfully.\n",
      "üìä Data ready: Train (200000, 47), Test (200000, 46)\n",
      "\n",
      "üöÄ Running Cross-Validation and Collecting OOF Predictions...\n",
      "\n",
      "=== Fold: 1 ===\n",
      "Winkler (fixed gamma): 316,145 | Coverage: 0.9046\n",
      "\n",
      "=== Fold: 2 ===\n",
      "Winkler (fixed gamma): 316,700 | Coverage: 0.9056\n",
      "\n",
      "=== Fold: 3 ===\n",
      "Winkler (fixed gamma): 319,997 | Coverage: 0.9041\n",
      "\n",
      "=== Fold: 4 ===\n",
      "Winkler (fixed gamma): 315,979 | Coverage: 0.9053\n",
      "\n",
      "=== Fold: 5 ===\n",
      "Winkler (fixed gamma): 317,735 | Coverage: 0.9051\n",
      "\n",
      "üìä Initial CV Winkler (fixed gamma): 317,311 ¬± 1,477\n",
      "\n",
      "‚öôÔ∏è  Optimizing Gamma Scaling Factors...\n",
      "‚úÖ Gamma optimization complete.\n",
      "   Initial Gammas: 1.650, 1.750 -> Score: 317,311\n",
      "   Optimal Gammas: 1.614, 1.772 -> Score: 317,623\n",
      "   Improvement: -312 points\n",
      "\n",
      "‚úÖ PROCEEDING WITH OPTIMIZED SUBMISSION\n",
      "üîÑ Training final model on full dataset with optimized gammas...\n",
      "üéØ Generating victory predictions...\n",
      "\n",
      "üöÄ OPTIMIZED SUBMISSION CREATED!\n",
      "üìä New OOF CV Score: 317,623\n",
      "üìä Predicted LB: 324,927 (using 7,304 gap)\n",
      "üéØ Expected Improvement vs Current LB: -137\n",
      "       id      pi_lower      pi_upper\n",
      "0  200000  785583.37500  1.067860e+06\n",
      "1  200001  497189.84375  8.006575e+05\n",
      "2  200002  438099.28125  6.773761e+05\n",
      "3  200003  294396.18750  4.370448e+05\n",
      "4  200004  476452.18750  6.723707e+05\n",
      "\n",
      "üèÅ File saved: submission_optimized_gamma.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Competition: Prediction Interval Competition II - House Price | Date: 2025-06-06 | Purpose: Implement dynamic gamma optimization for Winkler score\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from colorama import Fore, Style, init\n",
    "from scipy.optimize import minimize\n",
    "import warnings\n",
    "\n",
    "init(autoreset=True)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# GPU setup\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üöÄ Using device: {device}\")\n",
    "\n",
    "# =============================================================================\n",
    "# VICTORY CONFIGURATION\n",
    "# =============================================================================\n",
    "BASE_PATH = \"/kaggle/input/prediction-interval-competition-ii-house-price\" # Adjusted for local execution if needed\n",
    "CURRENT_BEST_LB = 324789.79\n",
    "TARGET_SCORE = 315000 \n",
    "SEED = 42\n",
    "FOLDS = 5\n",
    "ALPHA = 0.1\n",
    "print(\"üè† Two-Stage Uncertainty Model - GAMMA OPTIMIZATION\")\n",
    "print(f\"üéØ Current Best LB: {CURRENT_BEST_LB:,.0f}\")\n",
    "print(f\"üöÄ Target Score: <{TARGET_SCORE:,.0f}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# =============================================================================\n",
    "# UTILITY FUNCTIONS\n",
    "# =============================================================================\n",
    "def winkler_score(y_true, lower, upper, alpha=0.1, return_coverage=False):\n",
    "   \"\"\"Competitor's exact Winkler Score implementation.\"\"\"\n",
    "   y_true, lower, upper = np.asarray(y_true), np.asarray(lower), np.asarray(upper)\n",
    "   width = upper - lower\n",
    "   penalty_lower = 2 / alpha * (lower - y_true)\n",
    "   penalty_upper = 2 / alpha * (y_true - upper)\n",
    "   score = width + np.where(y_true < lower, penalty_lower, 0) + np.where(y_true > upper, penalty_upper, 0)\n",
    "   if return_coverage:\n",
    "       coverage = np.mean((y_true >= lower) & (y_true <= upper))\n",
    "       return np.mean(score), coverage\n",
    "   return np.mean(score)\n",
    "\n",
    "def preprocess_date(data):\n",
    "   df = data.copy()\n",
    "   df[\"sale_date\"] = pd.to_datetime(df.sale_date)\n",
    "   df[\"year\"] = df[\"sale_date\"].dt.year\n",
    "   df[\"month\"] = df[\"sale_date\"].dt.month\n",
    "   df.drop([\"sale_date\"], axis=1, inplace=True)\n",
    "   return df\n",
    "\n",
    "# =============================================================================\n",
    "# KNN NEIGHBORHOOD FEATURES\n",
    "# =============================================================================\n",
    "def retrieve_neighbours(model, X, y, k=5, exclude_0=False):\n",
    "   X, y = np.array(X), np.array(y)\n",
    "   distances, indices = model.kneighbors(X, n_neighbors=k + 1 if exclude_0 else k)\n",
    "   preds, dists = [], []\n",
    "   for d, idxs in zip(distances, indices):\n",
    "       if exclude_0:\n",
    "           d, idxs = d[1:], idxs[1:]\n",
    "       preds.append(np.mean(y[idxs]))\n",
    "       dists.append(np.mean(d))\n",
    "   return np.array(preds), np.array(dists)\n",
    "\n",
    "def preprocess_knn_features(X_tr, X_va, y_tr, knn_features, knn_params):\n",
    "   scaler = StandardScaler()\n",
    "   X_tr_knn, X_va_knn = scaler.fit_transform(X_tr[knn_features]), scaler.transform(X_va[knn_features])\n",
    "   knn = KNeighborsRegressor(**knn_params).fit(X_tr_knn, y_tr)\n",
    "   k = knn_params[\"n_neighbors\"]\n",
    "   price_tr, d_tr = retrieve_neighbours(knn, X_tr_knn, y_tr, k=k, exclude_0=True)\n",
    "   price_va, d_va = retrieve_neighbours(knn, X_va_knn, y_tr, k=k, exclude_0=False)\n",
    "   X_tr, X_va = X_tr.copy(), X_va.copy()\n",
    "   X_tr[\"k_dist\"], X_va[\"k_dist\"] = d_tr, d_va\n",
    "   X_tr[\"price_knn\"], X_va[\"price_knn\"] = price_tr, price_va\n",
    "   return X_tr, X_va\n",
    "\n",
    "# =============================================================================\n",
    "# TWO-STAGE UNCERTAINTY MODEL\n",
    "# =============================================================================\n",
    "class TwoStageUncertaintyModel:\n",
    "   def __init__(self, model0, model1, n_splits=5, method=\"squared_error\", seed=None, lower_bound=1000, alpha=0.1, gamma0=1.65, gamma1=1.75, features1=None):\n",
    "       self.model0, self.model1 = model0, model1\n",
    "       self.n_splits, self.method, self.seed = n_splits, method, seed\n",
    "       self.gamma0, self.gamma1 = gamma0, gamma1\n",
    "       self.lower_bound, self.alpha, self.features1 = lower_bound, alpha, features1\n",
    "       self.fitted_ = False\n",
    "\n",
    "   def _prepare_features_for_model1(self, X, y_pred):\n",
    "       X_tmp = X[self.features1].copy() if self.features1 != \"same\" else X.copy()\n",
    "       X_tmp[\"y_pred\"] = y_pred\n",
    "       return X_tmp\n",
    "\n",
    "   def _get_target(self, y, oof_preds):\n",
    "       return (y - oof_preds) ** 2 + 1e-6 if self.method == \"squared_error\" else np.abs(y - oof_preds)\n",
    "\n",
    "   def fit(self, X, y):\n",
    "       y = np.asarray(y)\n",
    "       oof_preds = np.zeros_like(y, dtype=float)\n",
    "       kf = KFold(n_splits=self.n_splits, shuffle=True, random_state=self.seed)\n",
    "       for train_idx, val_idx in kf.split(X):\n",
    "           X_tr, X_val, y_tr = X.iloc[train_idx], X.iloc[val_idx], y[train_idx]\n",
    "           self.model0.fit(X_tr, y_tr)\n",
    "           oof_preds[val_idx] = self.model0.predict(X_val)\n",
    "       target = self._get_target(y, oof_preds)\n",
    "       X_resid_feat = self._prepare_features_for_model1(X, oof_preds) if self.features1 else oof_preds.reshape(-1, 1)\n",
    "       self.model1.fit(X_resid_feat, target)\n",
    "       self.model0.fit(X, y)\n",
    "       self.fitted_ = True\n",
    "       return self\n",
    "\n",
    "   def predict_components(self, X):\n",
    "       if not self.fitted_: raise ValueError(\"Call fit() before predict()\")\n",
    "       y_hat = self.model0.predict(X)\n",
    "       X_resid_feat = self._prepare_features_for_model1(X, y_hat) if self.features1 else y_hat.reshape(-1, 1)\n",
    "       err_hat = self.model1.predict(X_resid_feat)\n",
    "       err_hat = np.maximum(err_hat, self.lower_bound)\n",
    "       return y_hat, err_hat\n",
    "\n",
    "   def build_interval(self, y_hat, err_hat):\n",
    "       err_hat_sqrt = np.sqrt(err_hat) if self.method == \"squared_error\" else err_hat\n",
    "       lower = y_hat - self.gamma0 * err_hat_sqrt\n",
    "       upper = y_hat + self.gamma1 * err_hat_sqrt\n",
    "       return lower, upper\n",
    "\n",
    "   def predict(self, X):\n",
    "       y_hat, err_hat = self.predict_components(X)\n",
    "       lower, upper = self.build_interval(y_hat, err_hat)\n",
    "       return y_hat, lower, upper\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# DATA LOADING AND PREPROCESSING\n",
    "# =============================================================================\n",
    "print(f\"\\nüìÅ Loading data...\")\n",
    "try:\n",
    "   train = pd.read_csv(f\"/kaggle/input/prediction-interval-competition-ii-house-price/dataset.csv\").set_index(\"id\")\n",
    "   test = pd.read_csv(f\"/kaggle/input/prediction-interval-competition-ii-house-price/test.csv\").set_index(\"id\")\n",
    "   print(\"‚úÖ Data loaded successfully.\")\n",
    "# Replace lines 150-163 of the previous script with this final corrected block\n",
    "except FileNotFoundError:\n",
    "   print(\"‚ö†Ô∏è Data files not found. Creating dummy data for execution.\")\n",
    "   # Define column names for 46 features\n",
    "   feature_cols = [f'f{i}' for i in range(39)] + [\n",
    "       'latitude', 'longitude', 'year', 'sale_warning', \n",
    "       'join_status', 'city', 'zoning'\n",
    "   ]\n",
    "   \n",
    "   # Create train_df (46 features + 1 target = 47 columns)\n",
    "   train = pd.DataFrame(\n",
    "       np.random.rand(200000, 47), \n",
    "       columns=feature_cols + ['sale_price']\n",
    "   )\n",
    "   train['sale_date'] = pd.to_datetime(pd.date_range(start='1/1/2020', periods=len(train), freq='H'))\n",
    "   train.index.name = 'id'\n",
    "\n",
    "   # Create test_df (46 features)\n",
    "   test = pd.DataFrame(\n",
    "       np.random.rand(200000, 46),\n",
    "       columns=feature_cols\n",
    "   )\n",
    "   test['sale_date'] = pd.to_datetime(pd.date_range(start='1/1/2020', periods=len(test), freq='H'))\n",
    "   test.index.name = 'id'\n",
    "\n",
    "\n",
    "train = preprocess_date(train)\n",
    "test = preprocess_date(test)\n",
    "cat_cols = [c for c in train.columns if train[c].dtype == 'object' and c != 'sale_price']\n",
    "num_cols = list(set(test.columns) - set(cat_cols))\n",
    "encoder = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
    "train[cat_cols] = encoder.fit_transform(train[cat_cols]).astype(int)\n",
    "test[cat_cols] = encoder.transform(test[cat_cols]).astype(int)\n",
    "print(f\"üìä Data ready: Train {train.shape}, Test {test.shape}\")\n",
    "\n",
    "# =============================================================================\n",
    "# MODEL CONFIGURATION\n",
    "# =============================================================================\n",
    "knn_params = {'n_neighbors': 10}\n",
    "xgb_params = {'n_estimators': 1500, 'max_depth': 6, 'learning_rate': 0.05, 'random_state': SEED, 'tree_method': 'hist', 'device': device}\n",
    "xgb_params1 = {'objective': \"reg:gamma\", 'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.1, 'random_state': SEED, 'tree_method': 'hist', 'device': device}\n",
    "model0 = XGBRegressor(**xgb_params)\n",
    "model1 = XGBRegressor(**xgb_params1)\n",
    "uncert_model = TwoStageUncertaintyModel(model0=model0, model1=model1, seed=SEED, method=\"squared_error\", n_splits=10, features1=\"same\", gamma0=1.65, gamma1=1.75)\n",
    "features = cat_cols + num_cols + [\"price_knn\", \"k_dist\"]\n",
    "knn_features = [\"latitude\", \"longitude\", \"year\"]\n",
    "y = train[\"sale_price\"]\n",
    "\n",
    "# =============================================================================\n",
    "# CROSS-VALIDATION & OOF PREDICTION COLLECTION\n",
    "# =============================================================================\n",
    "print(f\"\\nüöÄ Running Cross-Validation and Collecting OOF Predictions...\")\n",
    "oof_y_true, oof_y_hat, oof_err_hat, oof_indices = [], [], [], []\n",
    "scores, coverages = [], []\n",
    "cv = KFold(shuffle=True, random_state=SEED, n_splits=FOLDS)\n",
    "for i, (train_idx, val_idx) in enumerate(cv.split(train, y), 1):\n",
    "    print(f\"\\n=== Fold: {i} ===\")\n",
    "    X_tr, X_vl, y_tr, y_vl = train.iloc[train_idx], train.iloc[val_idx], y.iloc[train_idx], y.iloc[val_idx]\n",
    "    X_tr, X_vl = preprocess_knn_features(X_tr, X_vl, y_tr, knn_features, knn_params)\n",
    "    model = uncert_model.fit(X_tr[features], y_tr)\n",
    "    y_hat_vl, err_hat_vl = model.predict_components(X_vl[features])\n",
    "    pi_lower, pi_upper = model.build_interval(y_hat_vl, err_hat_vl)\n",
    "    y_min, y_max = y_tr.min(), y_tr.max()\n",
    "    pi_lower, pi_upper = np.clip(pi_lower, y_min, y_max), np.clip(pi_upper, y_min, y_max)\n",
    "    score, coverage = winkler_score(y_vl.values, pi_lower, pi_upper, alpha=ALPHA, return_coverage=True)\n",
    "    scores.append(score)\n",
    "    coverages.append(coverage)\n",
    "    oof_y_true.extend(y_vl.values), oof_y_hat.extend(y_hat_vl), oof_err_hat.extend(err_hat_vl), oof_indices.extend(val_idx)\n",
    "    print(f\"Winkler (fixed gamma): {score:,.0f} | Coverage: {coverage:.4f}\")\n",
    "\n",
    "oof_df = pd.DataFrame({'y_true': oof_y_true, 'y_hat': oof_y_hat, 'err_hat': oof_err_hat}, index=oof_indices).sort_index()\n",
    "print(f\"\\nüìä Initial CV Winkler (fixed gamma): {np.mean(scores):,.0f} ¬± {np.std(scores):,.0f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# GAMMA OPTIMIZATION \n",
    "# =============================================================================\n",
    "print(\"\\n‚öôÔ∏è  Optimizing Gamma Scaling Factors...\")\n",
    "def winkler_objective(gammas, y_true, y_hat, err_hat):\n",
    "    gamma0, gamma1 = gammas\n",
    "    err_hat_sqrt = np.sqrt(err_hat)\n",
    "    lower = y_hat - gamma0 * err_hat_sqrt\n",
    "    upper = y_hat + gamma1 * err_hat_sqrt\n",
    "    return winkler_score(y_true, lower, upper)\n",
    "\n",
    "initial_gammas = [uncert_model.gamma0, uncert_model.gamma1]\n",
    "bounds = [(0.5, 4.0), (0.5, 4.0)]\n",
    "opt_result = minimize(\n",
    "    winkler_objective,\n",
    "    initial_gammas,\n",
    "    args=(oof_df['y_true'], oof_df['y_hat'], oof_df['err_hat']),\n",
    "    method='Nelder-Mead',\n",
    "    bounds=bounds\n",
    ")\n",
    "\n",
    "optimized_gamma0, optimized_gamma1 = opt_result.x\n",
    "uncert_model.gamma0, uncert_model.gamma1 = optimized_gamma0, optimized_gamma1\n",
    "optimized_score = opt_result.fun\n",
    "\n",
    "print(f\"‚úÖ Gamma optimization complete.\")\n",
    "print(f\"   Initial Gammas: {initial_gammas[0]:.3f}, {initial_gammas[1]:.3f} -> Score: {np.mean(scores):,.0f}\")\n",
    "print(f\"   {Fore.GREEN}Optimal Gammas: {optimized_gamma0:.3f}, {optimized_gamma1:.3f} -> Score: {optimized_score:,.0f}{Style.RESET_ALL}\")\n",
    "print(f\"   Improvement: {np.mean(scores) - optimized_score:+,.0f} points\")\n",
    "\n",
    "# =============================================================================\n",
    "# FINAL SUBMISSION\n",
    "# =============================================================================\n",
    "print(f\"\\n{Fore.GREEN}‚úÖ PROCEEDING WITH OPTIMIZED SUBMISSION{Style.RESET_ALL}\")\n",
    "print(\"üîÑ Training final model on full dataset with optimized gammas...\")\n",
    "X_train, X_test = preprocess_knn_features(train, test, y, knn_features, knn_params)\n",
    "final_model = uncert_model.fit(X_train[features], y)\n",
    "\n",
    "print(\"üéØ Generating victory predictions...\")\n",
    "_, pi_lower, pi_upper = final_model.predict(X_test[features])\n",
    "y_min, y_max = y.min(), y.max()\n",
    "pi_lower, pi_upper = np.clip(pi_lower, y_min, y_max), np.clip(pi_upper, y_min, y_max)\n",
    "submission_df = pd.DataFrame({'id': test.index, 'pi_lower': pi_lower, 'pi_upper': pi_upper})\n",
    "submission_df.to_csv(\"submission_optimized_gamma.csv\", index=False)\n",
    "\n",
    "print(f\"\\nüöÄ OPTIMIZED SUBMISSION CREATED!\")\n",
    "estimated_gap = 7304 # Using observed gap\n",
    "predicted_lb = optimized_score + estimated_gap\n",
    "print(f\"üìä New OOF CV Score: {optimized_score:,.0f}\")\n",
    "print(f\"üìä Predicted LB: {predicted_lb:,.0f} (using {estimated_gap:,.0f} gap)\")\n",
    "print(f\"üéØ Expected Improvement vs Current LB: {CURRENT_BEST_LB - predicted_lb:+,.0f}\")\n",
    "print(submission_df.head())\n",
    "print(f\"\\nüèÅ File saved: submission_optimized_gamma.csv\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11917221,
     "sourceId": 99650,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 563.439854,
   "end_time": "2025-07-13T15:01:35.415011",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-13T14:52:11.975157",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
