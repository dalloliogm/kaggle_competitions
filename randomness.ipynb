{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "585d42e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T09:12:23.273453Z",
     "iopub.status.busy": "2025-05-07T09:12:23.273173Z",
     "iopub.status.idle": "2025-05-07T09:12:23.277567Z",
     "shell.execute_reply": "2025-05-07T09:12:23.276857Z"
    },
    "papermill": {
     "duration": 0.010124,
     "end_time": "2025-05-07T09:12:23.278786",
     "exception": false,
     "start_time": "2025-05-07T09:12:23.268662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_TYPE='protenix'\n",
    "VALIDATION=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e18c3f0",
   "metadata": {
    "papermill": {
     "duration": 0.002584,
     "end_time": "2025-05-07T09:12:23.284821",
     "exception": false,
     "start_time": "2025-05-07T09:12:23.282237",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Install requirements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c16a0a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T09:12:23.291108Z",
     "iopub.status.busy": "2025-05-07T09:12:23.290796Z",
     "iopub.status.idle": "2025-05-07T09:12:23.408550Z",
     "shell.execute_reply": "2025-05-07T09:12:23.407566Z"
    },
    "papermill": {
     "duration": 0.12282,
     "end_time": "2025-05-07T09:12:23.410302",
     "exception": false,
     "start_time": "2025-05-07T09:12:23.287482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if MODEL_TYPE=='protenix' and VALIDATION:\n",
    "    !pip install --no-deps protenix\n",
    "    !pip install biopython\n",
    "    !pip install ml-collections\n",
    "    !pip install biotite==1.0.1\n",
    "    !pip install rdkit\n",
    "!export PROTENIX_DATA_ROOT_DIR=/kaggle/input/protenix-checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5ba9290",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T09:12:23.417252Z",
     "iopub.status.busy": "2025-05-07T09:12:23.416898Z",
     "iopub.status.idle": "2025-05-07T09:12:23.767066Z",
     "shell.execute_reply": "2025-05-07T09:12:23.765960Z"
    },
    "papermill": {
     "duration": 0.355428,
     "end_time": "2025-05-07T09:12:23.768876",
     "exception": false,
     "start_time": "2025-05-07T09:12:23.413448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "components.v20240608.cif\t\tmodel_v0.2.0.pt\r\n",
      "components.v20240608.cif.rdkit_mol.pkl\r\n"
     ]
    }
   ],
   "source": [
    "! mkdir /af3-dev \n",
    "! ln -s /kaggle/input/protenix-checkpoints /af3-dev/release_data\n",
    "! ls /af3-dev/release_data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8e56aa",
   "metadata": {
    "papermill": {
     "duration": 0.002545,
     "end_time": "2025-05-07T09:12:23.774628",
     "exception": false,
     "start_time": "2025-05-07T09:12:23.772083",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Helper scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9bd7993",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-07T09:12:23.781212Z",
     "iopub.status.busy": "2025-05-07T09:12:23.780908Z",
     "iopub.status.idle": "2025-05-07T09:12:28.024212Z",
     "shell.execute_reply": "2025-05-07T09:12:28.023268Z"
    },
    "papermill": {
     "duration": 4.248141,
     "end_time": "2025-05-07T09:12:28.025562",
     "exception": false,
     "start_time": "2025-05-07T09:12:23.777421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORT OK !!!!\n"
     ]
    }
   ],
   "source": [
    "import Bio\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import pandas as pd\n",
    "from Bio.PDB import Atom, Model, Chain, Residue, Structure, PDBParser\n",
    "from Bio import SeqIO\n",
    "import os, sys\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "time0=time.time()\n",
    "\n",
    "print('IMPORT OK !!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2efab839",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T09:12:28.032891Z",
     "iopub.status.busy": "2025-05-07T09:12:28.032492Z",
     "iopub.status.idle": "2025-05-07T09:12:28.154476Z",
     "shell.execute_reply": "2025-05-07T09:12:28.153352Z"
    },
    "papermill": {
     "duration": 0.127339,
     "end_time": "2025-05-07T09:12:28.156108",
     "exception": false,
     "start_time": "2025-05-07T09:12:28.028769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PYTHON /usr/bin/python3\n",
      "HELPER OK!!!\n"
     ]
    }
   ],
   "source": [
    "PYTHON = sys.executable\n",
    "print('PYTHON',PYTHON)\n",
    "\n",
    "RHONET_DIR=\\\n",
    "'/kaggle/input/data-for-demo-for-rhofold-plus-with-kaggle-msa/RhoFold-main'\n",
    "#'<your downloaded rhofold repo>/RhoFold-main'\n",
    "\n",
    "USALIGN = \\\n",
    "'/kaggle/working//USalign'\n",
    "#'<your us align path>/USalign'\n",
    "\n",
    "os.system('cp /kaggle/input/usalign/USalign /kaggle/working/')\n",
    "os.system('sudo chmod u+x /kaggle/working//USalign')\n",
    "sys.path.append(RHONET_DIR)\n",
    "\n",
    "\n",
    "DATA_KAGGLE_DIR = '/kaggle/input/stanford-rna-3d-folding'\n",
    "\n",
    "\n",
    "# helper ----\n",
    "class dotdict(dict):\n",
    "\t__setattr__ = dict.__setitem__\n",
    "\t__delattr__ = dict.__delitem__\n",
    "\n",
    "\tdef __getattr__(self, name):\n",
    "\t\ttry:\n",
    "\t\t\treturn self[name]\n",
    "\t\texcept KeyError:\n",
    "\t\t\traise AttributeError(name)\n",
    "\n",
    "# visualisation helper ----\n",
    "def set_aspect_equal(ax):\n",
    "\tx_limits = ax.get_xlim()\n",
    "\ty_limits = ax.get_ylim()\n",
    "\tz_limits = ax.get_zlim()\n",
    "\n",
    "\t# Compute the mean of each axis\n",
    "\tx_middle = np.mean(x_limits)\n",
    "\ty_middle = np.mean(y_limits)\n",
    "\tz_middle = np.mean(z_limits)\n",
    "\n",
    "\t# Compute the max range across all axes\n",
    "\tmax_range = max(x_limits[1] - x_limits[0],\n",
    "\t\t\t\t\ty_limits[1] - y_limits[0],\n",
    "\t\t\t\t\tz_limits[1] - z_limits[0]) / 2.0\n",
    "\n",
    "\t# Set the new limits to ensure equal scaling\n",
    "\tax.set_xlim(x_middle - max_range, x_middle + max_range)\n",
    "\tax.set_ylim(y_middle - max_range, y_middle + max_range)\n",
    "\tax.set_zlim(z_middle - max_range, z_middle + max_range)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# xyz df helper --------------------\n",
    "def get_truth_df(target_id):\n",
    "    truth_df = LABEL_DF[LABEL_DF['target_id'] == target_id]\n",
    "    truth_df = truth_df.reset_index(drop=True)\n",
    "    return truth_df\n",
    "\n",
    "def parse_output_to_df(output, seq, target_id):\n",
    "    df = []\n",
    "    chain_data = []\n",
    "    for i, res in enumerate(seq):\n",
    "        d=dict(ID = target_id,\n",
    "                    resname=res,\n",
    "                    resid=i+1)\n",
    "        for n in range(len(output)):\n",
    "            d={**d, f'x_{n+1}': round(output[n,i,0].item(),3),\n",
    "                     f'y_{n+1}': round(output[n,i,1].item(),3),\n",
    "                     f'z_{n+1}': round(output[n,i,2].item(),3)}\n",
    "        chain_data.append(d)\n",
    "\n",
    "    if len(chain_data)!=0:\n",
    "        chain_df = pd.DataFrame(chain_data)\n",
    "        df.append(chain_df)\n",
    "        ##print(chain_df)\n",
    "    return df\n",
    "\n",
    "def parse_pdb_to_df(pdb_file, target_id):\n",
    "    parser = PDBParser()\n",
    "    structure = parser.get_structure('', pdb_file)\n",
    "\n",
    "    df = []\n",
    "    for model in structure:\n",
    "        for chain in model:\n",
    "            print(chain)\n",
    "            chain_data = []\n",
    "            for residue in chain:\n",
    "                # print(residue)\n",
    "                if residue.get_resname() in ['A', 'U', 'G', 'C']:\n",
    "                    # Check if the residue has a C1' atom\n",
    "                    if 'C1\\'' in residue:\n",
    "                        atom = residue['C1\\'']\n",
    "                        xyz = atom.get_coord()\n",
    "                        resname = residue.get_resname()\n",
    "                        resid = residue.get_id()[1]\n",
    "\n",
    "                        #todo detect discontinous: resid = prev_resid+1\n",
    "                        #ID\tresname\tresid\tx_1\ty_1\tz_1\n",
    "                        chain_data.append(dict(\n",
    "                            ID = target_id+'_'+str(resid),\n",
    "                            resname=resname,\n",
    "                            resid=resid,\n",
    "                            x_1=xyz[0],\n",
    "                            y_1=xyz[1],\n",
    "                            z_1=xyz[2],\n",
    "                        ))\n",
    "                        ##print(f\"Residue {resname} {resid}, Atom: {atom.get_name()}, xyz: {xyz}\")\n",
    "\n",
    "            if len(chain_data)!=0:\n",
    "                chain_df = pd.DataFrame(chain_data)\n",
    "                df.append(chain_df)\n",
    "                ##print(chain_df)\n",
    "    return df\n",
    "\n",
    "# usalign helper --------------------\n",
    "def write_target_line(\n",
    "    atom_name, atom_serial, residue_name, chain_id, residue_num, x_coord, y_coord, z_coord, occupancy=1.0, b_factor=0.0, atom_type='P'\n",
    "):\n",
    "    \"\"\"\n",
    "    Writes a single line of PDB format based on provided atom information.\n",
    "\n",
    "    Args:\n",
    "        atom_name (str): Name of the atom (e.g., \"N\", \"CA\").\n",
    "        atom_serial (int): Atom serial number.\n",
    "        residue_name (str): Residue name (e.g., \"ALA\").\n",
    "        chain_id (str): Chain identifier.\n",
    "        residue_num (int): Residue number.\n",
    "        x_coord (float): X coordinate.\n",
    "        y_coord (float): Y coordinate.\n",
    "        z_coord (float): Z coordinate.\n",
    "        occupancy (float, optional): Occupancy value (default: 1.0).\n",
    "        b_factor (float, optional): B-factor value (default: 0.0).\n",
    "\n",
    "    Returns:\n",
    "        str: A single line of PDB string.\n",
    "    \"\"\"\n",
    "    return f'ATOM  {atom_serial:>5d}  {atom_name:<5s} {residue_name:<3s} {residue_num:>3d}    {x_coord:>8.3f}{y_coord:>8.3f}{z_coord:>8.3f}{occupancy:>6.2f}{b_factor:>6.2f}           {atom_type}\\n'\n",
    "\n",
    "def write_xyz_to_pdb(df, pdb_file, xyz_id = 1):\n",
    "    resolved_cnt = 0\n",
    "    with open(pdb_file, 'w') as target_file:\n",
    "        for _, row in df.iterrows():\n",
    "            x_coord = row[f'x_{xyz_id}']\n",
    "            y_coord = row[f'y_{xyz_id}']\n",
    "            z_coord = row[f'z_{xyz_id}']\n",
    "\n",
    "            if x_coord > -1e17 and y_coord > -1e17 and z_coord > -1e17:\n",
    "                resolved_cnt += 1\n",
    "                target_line = write_target_line(\n",
    "                    atom_name=\"C1'\",\n",
    "                    atom_serial=int(row['resid']),\n",
    "                    residue_name=row['resname'],\n",
    "                    chain_id='0',\n",
    "                    residue_num=int(row['resid']),\n",
    "                    x_coord=x_coord,\n",
    "                    y_coord=y_coord,\n",
    "                    z_coord=z_coord,\n",
    "                    atom_type='C',\n",
    "                )\n",
    "                target_file.write(target_line)\n",
    "    return resolved_cnt\n",
    "\n",
    "def parse_usalign_for_tm_score(output):\n",
    "    # Extract TM-score based on length of reference structure (second)\n",
    "    tm_score_match = re.findall(r'TM-score=\\s+([\\d.]+)', output)[1]\n",
    "    if not tm_score_match:\n",
    "        raise ValueError('No TM score found')\n",
    "    return float(tm_score_match)\n",
    "\n",
    "def parse_usalign_for_transform(output):\n",
    "    # Locate the rotation matrix section\n",
    "    matrix_lines = []\n",
    "    found_matrix = False\n",
    "\n",
    "    for line in output.splitlines():\n",
    "        if \"The rotation matrix to rotate Structure_1 to Structure_2\" in line:\n",
    "            found_matrix = True\n",
    "        elif found_matrix and re.match(r'^\\d+\\s+[-\\d.]+\\s+[-\\d.]+\\s+[-\\d.]+\\s+[-\\d.]+$', line):\n",
    "            matrix_lines.append(line)\n",
    "        elif found_matrix and not line.strip():\n",
    "            break  # Stop parsing if an empty line is encountered after the matrix\n",
    "\n",
    "    # Parse the rotation matrix values\n",
    "    rotation_matrix = []\n",
    "    for line in matrix_lines:\n",
    "        parts = line.split()\n",
    "        row_values = list(map(float, parts[1:]))  # Skip the first column (index)\n",
    "        rotation_matrix.append(row_values)\n",
    "\n",
    "    return np.array(rotation_matrix)\n",
    "\n",
    "def call_usalign(predict_df, truth_df, verbose=1):\n",
    "    truth_pdb = '~truth.pdb'\n",
    "    predict_pdb = '~predict.pdb'\n",
    "    write_xyz_to_pdb(predict_df, predict_pdb, xyz_id=1)\n",
    "    write_xyz_to_pdb(truth_df, truth_pdb, xyz_id=1)\n",
    "\n",
    "    command = f'{USALIGN} {predict_pdb} {truth_pdb} -atom \" C1\\'\" -m -'\n",
    "    output = os.popen(command).read()\n",
    "    if verbose==1:\n",
    "        print(output)\n",
    "    tm_score = parse_usalign_for_tm_score(output)\n",
    "    transform = parse_usalign_for_transform(output)\n",
    "    return tm_score, transform\n",
    "\n",
    "print('HELPER OK!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c3699a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T09:12:28.166843Z",
     "iopub.status.busy": "2025-05-07T09:12:28.166556Z",
     "iopub.status.idle": "2025-05-07T09:12:33.059059Z",
     "shell.execute_reply": "2025-05-07T09:12:33.058242Z"
    },
    "papermill": {
     "duration": 4.898736,
     "end_time": "2025-05-07T09:12:33.060851",
     "exception": false,
     "start_time": "2025-05-07T09:12:28.162115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if MODEL_TYPE=='protenix':\n",
    "    \n",
    "    \n",
    "    from runner.batch_inference import get_default_runner\n",
    "    from runner.inference import update_inference_configs, InferenceRunner\n",
    "\n",
    "    from protenix.data.infer_data_pipeline import InferenceDataset\n",
    "\n",
    "    np.random.seed(0)\n",
    "    torch.random.manual_seed(0)\n",
    "    torch.cuda.manual_seed_all(0)\n",
    "\n",
    "    class DictDataset(InferenceDataset):\n",
    "        def __init__(\n",
    "            self,\n",
    "            seq_list: list,\n",
    "            dump_dir: str,\n",
    "            id_list: list = None,\n",
    "            use_msa: bool = False,\n",
    "        ) -> None:\n",
    "\n",
    "            self.dump_dir = dump_dir\n",
    "            self.use_msa = use_msa\n",
    "            if isinstance(id_list,type(None)):\n",
    "                self.inputs = [{\"sequences\": \n",
    "                                [{\"rnaSequence\": \n",
    "                                  {\"sequence\": seq, \n",
    "                                   \"count\": 1}}],\n",
    "                                \"name\": \"query\"} for seq in seq_list]\n",
    "            else:\n",
    "                self.inputs = [{\"sequences\": \n",
    "                                [{\"rnaSequence\": \n",
    "                                  {\"sequence\": seq, \n",
    "                                   \"count\": 1}}],\n",
    "                                \"name\": i} for i, seq in zip(id_list,seq_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94778d08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T09:12:33.068764Z",
     "iopub.status.busy": "2025-05-07T09:12:33.068245Z",
     "iopub.status.idle": "2025-05-07T09:12:53.497899Z",
     "shell.execute_reply": "2025-05-07T09:12:53.496910Z"
    },
    "papermill": {
     "duration": 20.435382,
     "end_time": "2025-05-07T09:12:53.499969",
     "exception": false,
     "start_time": "2025-05-07T09:12:33.064587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train scheduler 16.0\n",
      "inference scheduler 16.0\n",
      "Diffusion Module has 16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/runner/inference.py:107: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, self.device)\n"
     ]
    }
   ],
   "source": [
    "if MODEL_TYPE=='protenix':\n",
    "\n",
    "    from configs.configs_base import configs as configs_base\n",
    "    from configs.configs_data import data_configs\n",
    "    from configs.configs_inference import inference_configs\n",
    "    from protenix.config.config import parse_configs\n",
    "\n",
    "    configs_base[\"use_deepspeed_evo_attention\"] = (\n",
    "    os.environ.get(\"USE_DEEPSPEED_EVO_ATTENTION\", False) == \"true\")\n",
    "    configs_base[\"model\"][\"N_cycle\"] = 10 #10\n",
    "    configs_base[\"sample_diffusion\"][\"N_sample\"] = (1 if VALIDATION else 5)\n",
    "    configs_base[\"sample_diffusion\"][\"N_step\"] = 200\n",
    "    inference_configs['load_checkpoint_path']='/kaggle/input/protenix-checkpoints/model_v0.2.0.pt'\n",
    "    configs = {**configs_base, **{\"data\": data_configs}, **inference_configs}\n",
    "\n",
    "    configs = parse_configs(\n",
    "            configs=configs,\n",
    "            fill_required_with_null=True,\n",
    "        )\n",
    "    \n",
    "    runner=InferenceRunner(configs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7e353f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T09:12:53.508337Z",
     "iopub.status.busy": "2025-05-07T09:12:53.507973Z",
     "iopub.status.idle": "2025-05-07T09:12:53.512430Z",
     "shell.execute_reply": "2025-05-07T09:12:53.511555Z"
    },
    "papermill": {
     "duration": 0.010123,
     "end_time": "2025-05-07T09:12:53.513743",
     "exception": false,
     "start_time": "2025-05-07T09:12:53.503620",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if VALIDATION:\n",
    "    LABEL_DF = pd.read_csv('/kaggle/input/stanford-rna-3d-folding/train_labels.csv')\n",
    "    LABEL_DF['target_id'] = LABEL_DF['ID'].apply(lambda x: '_'.join(x.split('_')[:-1]))\n",
    "    train_df=pd.read_csv('/kaggle/input/stanford-rna-3d-folding/train_sequences.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7916ede",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T09:12:53.521355Z",
     "iopub.status.busy": "2025-05-07T09:12:53.521056Z",
     "iopub.status.idle": "2025-05-07T09:12:53.528225Z",
     "shell.execute_reply": "2025-05-07T09:12:53.527320Z"
    },
    "papermill": {
     "duration": 0.012564,
     "end_time": "2025-05-07T09:12:53.529715",
     "exception": false,
     "start_time": "2025-05-07T09:12:53.517151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "if MODEL_TYPE=='protenix' and VALIDATION:\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")  \n",
    "    \n",
    "    train_df['protenix_tm_score']=None\n",
    "    dataset = DictDataset(train_df.sequence, dump_dir='output', id_list=train_df.target_id, use_msa=False)\n",
    "    num_data = len(dataset)\n",
    "    for i, seq in tqdm(enumerate(train_df.sequence),total=num_data):\n",
    "        if train_df.loc[i,'protenix_tm_score']!=None:\n",
    "            continue\n",
    "        if len(seq)>300:\n",
    "            continue\n",
    "        target_id = train_df.loc[i,'target_id']\n",
    "        truth_df = get_truth_df(target_id)\n",
    "        if sum(~np.isnan(truth_df.x_1))<3:\n",
    "            continue\n",
    "        data, atom_array, data_error_message=dataset[i]\n",
    "        if data_error_message!='':\n",
    "            continue\n",
    "        new_configs = update_inference_configs(configs, data[\"N_token\"].item())\n",
    "        runner.update_model_configs(new_configs)\n",
    "        prediction = runner.predict(data)\n",
    "        prediction=prediction['coordinate'][:,data['input_feature_dict']['atom_to_tokatom_idx']==12]       \n",
    "        result = parse_output_to_df(prediction[:1], seq, target_id)[0]\n",
    "        try:\n",
    "            tm_score, transform = call_usalign(result, truth_df, verbose=0)\n",
    "            train_df.loc[i,'protenix_tm_score']=tm_score\n",
    "        except:\n",
    "            pass\n",
    "        if (time.time()-time0)>(12*3600-360):\n",
    "            break\n",
    "    train_df.to_csv('tm_scores.csv', index=False)\n",
    "    print(train_df.protenix_tm_score.mean())\n",
    "    display(train_df.protenix_tm_score.hist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5504d469",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T09:12:53.537170Z",
     "iopub.status.busy": "2025-05-07T09:12:53.536869Z",
     "iopub.status.idle": "2025-05-07T09:47:55.330455Z",
     "shell.execute_reply": "2025-05-07T09:47:55.329705Z"
    },
    "papermill": {
     "duration": 2101.798818,
     "end_time": "2025-05-07T09:47:55.331917",
     "exception": false,
     "start_time": "2025-05-07T09:12:53.533099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [35:01<00:00, 175.14s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>resname</th>\n",
       "      <th>resid</th>\n",
       "      <th>x_1</th>\n",
       "      <th>y_1</th>\n",
       "      <th>z_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>y_2</th>\n",
       "      <th>z_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>y_3</th>\n",
       "      <th>z_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>y_4</th>\n",
       "      <th>z_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>y_5</th>\n",
       "      <th>z_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R1107_1</td>\n",
       "      <td>G</td>\n",
       "      <td>1</td>\n",
       "      <td>-16.326</td>\n",
       "      <td>-2.149</td>\n",
       "      <td>-8.688</td>\n",
       "      <td>-4.305</td>\n",
       "      <td>11.490</td>\n",
       "      <td>6.499</td>\n",
       "      <td>-0.930</td>\n",
       "      <td>-6.443</td>\n",
       "      <td>-4.336</td>\n",
       "      <td>1.629</td>\n",
       "      <td>14.907</td>\n",
       "      <td>10.238</td>\n",
       "      <td>0.554</td>\n",
       "      <td>-7.409</td>\n",
       "      <td>7.368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R1107_2</td>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "      <td>-12.937</td>\n",
       "      <td>-4.985</td>\n",
       "      <td>-4.963</td>\n",
       "      <td>-9.733</td>\n",
       "      <td>9.653</td>\n",
       "      <td>7.015</td>\n",
       "      <td>-3.702</td>\n",
       "      <td>-4.285</td>\n",
       "      <td>-8.890</td>\n",
       "      <td>-4.094</td>\n",
       "      <td>15.674</td>\n",
       "      <td>9.945</td>\n",
       "      <td>1.594</td>\n",
       "      <td>-12.692</td>\n",
       "      <td>6.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R1107_3</td>\n",
       "      <td>G</td>\n",
       "      <td>3</td>\n",
       "      <td>-9.708</td>\n",
       "      <td>-9.187</td>\n",
       "      <td>-2.685</td>\n",
       "      <td>-14.595</td>\n",
       "      <td>7.871</td>\n",
       "      <td>4.670</td>\n",
       "      <td>-8.354</td>\n",
       "      <td>-2.016</td>\n",
       "      <td>-11.459</td>\n",
       "      <td>-8.970</td>\n",
       "      <td>15.885</td>\n",
       "      <td>6.777</td>\n",
       "      <td>0.782</td>\n",
       "      <td>-16.931</td>\n",
       "      <td>2.348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R1107_4</td>\n",
       "      <td>G</td>\n",
       "      <td>4</td>\n",
       "      <td>-7.033</td>\n",
       "      <td>-14.259</td>\n",
       "      <td>-3.392</td>\n",
       "      <td>-17.694</td>\n",
       "      <td>6.126</td>\n",
       "      <td>0.232</td>\n",
       "      <td>-13.406</td>\n",
       "      <td>0.173</td>\n",
       "      <td>-11.102</td>\n",
       "      <td>-11.780</td>\n",
       "      <td>14.906</td>\n",
       "      <td>1.925</td>\n",
       "      <td>-1.095</td>\n",
       "      <td>-19.134</td>\n",
       "      <td>-2.561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R1107_5</td>\n",
       "      <td>G</td>\n",
       "      <td>5</td>\n",
       "      <td>-4.828</td>\n",
       "      <td>-18.121</td>\n",
       "      <td>-7.207</td>\n",
       "      <td>-18.401</td>\n",
       "      <td>4.206</td>\n",
       "      <td>-4.914</td>\n",
       "      <td>-17.864</td>\n",
       "      <td>2.180</td>\n",
       "      <td>-8.592</td>\n",
       "      <td>-12.433</td>\n",
       "      <td>12.721</td>\n",
       "      <td>-3.195</td>\n",
       "      <td>-2.966</td>\n",
       "      <td>-18.972</td>\n",
       "      <td>-7.620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2510</th>\n",
       "      <td>R1190_114</td>\n",
       "      <td>U</td>\n",
       "      <td>114</td>\n",
       "      <td>16.332</td>\n",
       "      <td>-1.873</td>\n",
       "      <td>6.200</td>\n",
       "      <td>13.129</td>\n",
       "      <td>-10.450</td>\n",
       "      <td>8.518</td>\n",
       "      <td>9.928</td>\n",
       "      <td>-16.681</td>\n",
       "      <td>-4.868</td>\n",
       "      <td>-24.976</td>\n",
       "      <td>4.826</td>\n",
       "      <td>2.178</td>\n",
       "      <td>10.686</td>\n",
       "      <td>15.750</td>\n",
       "      <td>-6.246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2511</th>\n",
       "      <td>R1190_115</td>\n",
       "      <td>U</td>\n",
       "      <td>115</td>\n",
       "      <td>11.631</td>\n",
       "      <td>-3.884</td>\n",
       "      <td>6.195</td>\n",
       "      <td>11.267</td>\n",
       "      <td>-15.020</td>\n",
       "      <td>6.880</td>\n",
       "      <td>11.437</td>\n",
       "      <td>-13.469</td>\n",
       "      <td>-1.108</td>\n",
       "      <td>-21.822</td>\n",
       "      <td>1.421</td>\n",
       "      <td>4.462</td>\n",
       "      <td>15.498</td>\n",
       "      <td>17.068</td>\n",
       "      <td>-7.773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2512</th>\n",
       "      <td>R1190_116</td>\n",
       "      <td>U</td>\n",
       "      <td>116</td>\n",
       "      <td>7.671</td>\n",
       "      <td>-7.510</td>\n",
       "      <td>6.938</td>\n",
       "      <td>11.459</td>\n",
       "      <td>-20.181</td>\n",
       "      <td>4.985</td>\n",
       "      <td>12.039</td>\n",
       "      <td>-11.354</td>\n",
       "      <td>4.060</td>\n",
       "      <td>-17.907</td>\n",
       "      <td>-2.282</td>\n",
       "      <td>4.872</td>\n",
       "      <td>19.854</td>\n",
       "      <td>19.667</td>\n",
       "      <td>-10.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2513</th>\n",
       "      <td>R1190_117</td>\n",
       "      <td>U</td>\n",
       "      <td>117</td>\n",
       "      <td>5.182</td>\n",
       "      <td>-11.464</td>\n",
       "      <td>9.552</td>\n",
       "      <td>13.790</td>\n",
       "      <td>-25.092</td>\n",
       "      <td>4.798</td>\n",
       "      <td>12.804</td>\n",
       "      <td>-11.837</td>\n",
       "      <td>9.471</td>\n",
       "      <td>-13.177</td>\n",
       "      <td>-4.457</td>\n",
       "      <td>3.434</td>\n",
       "      <td>22.360</td>\n",
       "      <td>24.200</td>\n",
       "      <td>-12.089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2514</th>\n",
       "      <td>R1190_118</td>\n",
       "      <td>U</td>\n",
       "      <td>118</td>\n",
       "      <td>4.662</td>\n",
       "      <td>-13.912</td>\n",
       "      <td>14.084</td>\n",
       "      <td>17.030</td>\n",
       "      <td>-28.368</td>\n",
       "      <td>7.306</td>\n",
       "      <td>14.192</td>\n",
       "      <td>-15.010</td>\n",
       "      <td>13.426</td>\n",
       "      <td>-8.440</td>\n",
       "      <td>-3.578</td>\n",
       "      <td>1.292</td>\n",
       "      <td>22.401</td>\n",
       "      <td>29.350</td>\n",
       "      <td>-11.677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2515 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID resname  resid     x_1     y_1     z_1     x_2     y_2    z_2  \\\n",
       "0       R1107_1       G      1 -16.326  -2.149  -8.688  -4.305  11.490  6.499   \n",
       "1       R1107_2       G      2 -12.937  -4.985  -4.963  -9.733   9.653  7.015   \n",
       "2       R1107_3       G      3  -9.708  -9.187  -2.685 -14.595   7.871  4.670   \n",
       "3       R1107_4       G      4  -7.033 -14.259  -3.392 -17.694   6.126  0.232   \n",
       "4       R1107_5       G      5  -4.828 -18.121  -7.207 -18.401   4.206 -4.914   \n",
       "...         ...     ...    ...     ...     ...     ...     ...     ...    ...   \n",
       "2510  R1190_114       U    114  16.332  -1.873   6.200  13.129 -10.450  8.518   \n",
       "2511  R1190_115       U    115  11.631  -3.884   6.195  11.267 -15.020  6.880   \n",
       "2512  R1190_116       U    116   7.671  -7.510   6.938  11.459 -20.181  4.985   \n",
       "2513  R1190_117       U    117   5.182 -11.464   9.552  13.790 -25.092  4.798   \n",
       "2514  R1190_118       U    118   4.662 -13.912  14.084  17.030 -28.368  7.306   \n",
       "\n",
       "         x_3     y_3     z_3     x_4     y_4     z_4     x_5     y_5     z_5  \n",
       "0     -0.930  -6.443  -4.336   1.629  14.907  10.238   0.554  -7.409   7.368  \n",
       "1     -3.702  -4.285  -8.890  -4.094  15.674   9.945   1.594 -12.692   6.000  \n",
       "2     -8.354  -2.016 -11.459  -8.970  15.885   6.777   0.782 -16.931   2.348  \n",
       "3    -13.406   0.173 -11.102 -11.780  14.906   1.925  -1.095 -19.134  -2.561  \n",
       "4    -17.864   2.180  -8.592 -12.433  12.721  -3.195  -2.966 -18.972  -7.620  \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...  \n",
       "2510   9.928 -16.681  -4.868 -24.976   4.826   2.178  10.686  15.750  -6.246  \n",
       "2511  11.437 -13.469  -1.108 -21.822   1.421   4.462  15.498  17.068  -7.773  \n",
       "2512  12.039 -11.354   4.060 -17.907  -2.282   4.872  19.854  19.667 -10.397  \n",
       "2513  12.804 -11.837   9.471 -13.177  -4.457   3.434  22.360  24.200 -12.089  \n",
       "2514  14.192 -15.010  13.426  -8.440  -3.578   1.292  22.401  29.350 -11.677  \n",
       "\n",
       "[2515 rows x 18 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if MODEL_TYPE=='protenix' and not VALIDATION:\n",
    "    test_df=pd.read_csv('/kaggle/input/stanford-rna-3d-folding/test_sequences.csv')\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")  \n",
    "    \n",
    "    dataset = DictDataset(test_df.sequence, dump_dir='output', id_list=test_df.target_id, use_msa=False)\n",
    "    num_data = len(dataset)\n",
    "    for i, seq in tqdm(enumerate(test_df.sequence),total=num_data):\n",
    "        try:\n",
    "            data, atom_array, data_error_message=dataset[i]\n",
    "            target_id = data[\"sample_name\"]\n",
    "            assert target_id==test_df.target_id[i]\n",
    "            assert data_error_message==''\n",
    "            \n",
    "            new_configs = update_inference_configs(configs, data[\"N_token\"].item())\n",
    "            runner.update_model_configs(new_configs)\n",
    "            prediction = runner.predict(data)\n",
    "            prediction=prediction['coordinate'][:,data['input_feature_dict']['atom_to_tokatom_idx']==12]\n",
    "\n",
    "            result = parse_output_to_df(prediction, seq, target_id)[0]\n",
    "        except:\n",
    "            target_id==test_df.target_id[i]\n",
    "            print('Failed to predict', target_id)\n",
    "            result=pd.DataFrame(columns=['ID', 'resname', 'resid', \n",
    "                                         'x_1', 'y_1', 'z_1', \n",
    "                                         'x_2', 'y_2', 'z_2',\n",
    "                                         'x_3', 'y_3', 'z_3', \n",
    "                                         'x_4', 'y_4', 'z_4', \n",
    "                                         'x_5', 'y_5', 'z_5'], \n",
    "                                         data=[[target_id, x, j+1] + [0.0]*15 for j, x in enumerate(seq)])\n",
    "            \n",
    "        result['ID']=result.apply(lambda x: x.ID + '_' + str(x.resid), axis=1)\n",
    "        result.to_csv('submission.csv', index=False, mode='a', header=(i==0))\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    display(pd.read_csv('submission.csv'))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 12024591,
     "sourceId": 87793,
     "sourceType": "competition"
    },
    {
     "datasetId": 6742586,
     "sourceId": 10855324,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6933267,
     "sourceId": 11118830,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 224830487,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2137.859358,
   "end_time": "2025-05-07T09:47:58.388343",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-07T09:12:20.528985",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
