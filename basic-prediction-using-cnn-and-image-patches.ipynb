{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a82a188a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-30T18:18:37.324404Z",
     "iopub.status.busy": "2025-03-30T18:18:37.324067Z",
     "iopub.status.idle": "2025-03-30T20:22:34.166195Z",
     "shell.execute_reply": "2025-03-30T20:22:34.165316Z"
    },
    "papermill": {
     "duration": 7436.849132,
     "end_time": "2025-03-30T20:22:34.169722",
     "exception": false,
     "start_time": "2025-03-30T18:18:37.320590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "CNN feature extractor initialized.\n",
      "Training spot data loaded successfully.\n",
      "Training images loaded successfully.\n",
      "Extracted CNN features for slide S_1.\n",
      "Regression model training complete.\n",
      "Test spot data for slide S_7 loaded successfully.\n",
      "Test image for slide S_7 loaded successfully.\n",
      "Submission file 'submission.csv' created!\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Functions for Patch Extraction and CNN Features\n",
    "# -----------------------------\n",
    "def extract_patch(image, center, patch_size):\n",
    "    \"\"\"\n",
    "    Extract a square patch from the image centered at the given coordinate.\n",
    "    Assumes image shape is (height, width, channels) and center is (x, y).\n",
    "    \"\"\"\n",
    "    x, y = int(center[0]), int(center[1])\n",
    "    half_size = patch_size // 2\n",
    "    # Ensure indices are within bounds\n",
    "    y_min = max(y - half_size, 0)\n",
    "    y_max = min(y + half_size, image.shape[0])\n",
    "    x_min = max(x - half_size, 0)\n",
    "    x_max = min(x + half_size, image.shape[1])\n",
    "    patch = image[y_min:y_max, x_min:x_max, :]\n",
    "    return patch\n",
    "\n",
    "def extract_cnn_features(patch, cnn_model):\n",
    "    \"\"\"\n",
    "    Resize, preprocess, and extract CNN features from a given image patch.\n",
    "    \n",
    "    Parameters:\n",
    "      patch (ndarray): The image patch to process.\n",
    "      cnn_model (Model): The pre-trained CNN model for feature extraction.\n",
    "      \n",
    "    Returns:\n",
    "      features (ndarray): Flattened feature vector from the CNN.\n",
    "    \"\"\"\n",
    "    # Resize patch to the input size expected by ResNet50 (e.g., 224x224)\n",
    "    patch_resized = cv2.resize(patch, (224, 224))\n",
    "    patch_preprocessed = preprocess_input(np.expand_dims(patch_resized, axis=0))\n",
    "    features = cnn_model.predict(patch_preprocessed, verbose=0)\n",
    "    return features.flatten()\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Custom Transformer to Extract CNN Features from Patches\n",
    "# -----------------------------\n",
    "class PatchFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, image, patch_size, cnn_model):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "          image (ndarray): The whole-slide HE image as a numpy array.\n",
    "          patch_size (int): Size (in pixels) of the square patch to extract.\n",
    "          cnn_model (Model): Pre-trained CNN model for feature extraction.\n",
    "        \"\"\"\n",
    "        self.image = image\n",
    "        self.patch_size = patch_size\n",
    "        self.cnn_model = cnn_model\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        features = []\n",
    "        # X is expected to be an array of shape (n_samples, 2) containing [x, y] coordinates.\n",
    "        for coord in X:\n",
    "            patch = extract_patch(self.image, coord, self.patch_size)\n",
    "            feat = extract_cnn_features(patch, self.cnn_model)\n",
    "            features.append(feat)\n",
    "        return np.array(features)\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Pipeline Class for the Elucidata Challenge\n",
    "# -----------------------------\n",
    "class CellTypePipeline:\n",
    "    \"\"\"\n",
    "    Pipeline for loading data, extracting image patch features using a CNN,\n",
    "    training a multi-output regression model, and generating a submission file.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, h5_file_path, patch_size=64):\n",
    "        self.h5_file_path = h5_file_path\n",
    "        self.patch_size = patch_size\n",
    "        self.train_spot_tables = {}\n",
    "        self.train_images = {}\n",
    "        self.cell_type_columns = None\n",
    "        self.cnn_model = None  # To be initialized\n",
    "        self.feature_extractor_pipeline = None\n",
    "\n",
    "    def initialize_cnn_model(self):\n",
    "        \"\"\"\n",
    "        Initialize a pre-trained ResNet50 model (without top layers) for feature extraction.\n",
    "        \"\"\"\n",
    "        base_model = ResNet50(weights='imagenet', include_top=False, pooling='avg')\n",
    "        self.cnn_model = Model(inputs=base_model.input, outputs=base_model.output)\n",
    "        print(\"CNN feature extractor initialized.\")\n",
    "\n",
    "    def load_train_data(self):\n",
    "        \"\"\"\n",
    "        Load training spot data from the H5 file and store each slide as a DataFrame.\n",
    "        \"\"\"\n",
    "        with h5py.File(self.h5_file_path, \"r\") as f:\n",
    "            train_spots = f[\"spots/Train\"]\n",
    "            for slide_name in train_spots.keys():\n",
    "                spot_array = np.array(train_spots[slide_name])\n",
    "                df = pd.DataFrame(spot_array)\n",
    "                self.train_spot_tables[slide_name] = df\n",
    "        print(\"Training spot data loaded successfully.\")\n",
    "        \n",
    "    def load_train_images(self):\n",
    "        \"\"\"\n",
    "        Load training HE images from the H5 file.\n",
    "        Adjust the key if your H5 file uses a different naming convention.\n",
    "        \"\"\"\n",
    "        with h5py.File(self.h5_file_path, \"r\") as f:\n",
    "            # Adjust key if necessary. For example, try f[\"images/Train\"] if \"Images/Train\" is not found.\n",
    "            train_imgs = f[\"images/Train\"]\n",
    "            for slide_name in train_imgs.keys():\n",
    "                image_array = np.array(train_imgs[slide_name])\n",
    "                self.train_images[slide_name] = image_array\n",
    "        print(\"Training images loaded successfully.\")\n",
    "\n",
    "    def load_test_data(self, slide_id):\n",
    "        \"\"\"\n",
    "        Load test spot data for a given slide.\n",
    "        \"\"\"\n",
    "        with h5py.File(self.h5_file_path, \"r\") as f:\n",
    "            test_spots = f[\"spots/Test\"]\n",
    "            if slide_id not in test_spots:\n",
    "                raise ValueError(f\"Slide {slide_id} not found in test spot data.\")\n",
    "            spot_array = np.array(test_spots[slide_id])\n",
    "            test_df = pd.DataFrame(spot_array)\n",
    "        print(f\"Test spot data for slide {slide_id} loaded successfully.\")\n",
    "        return test_df\n",
    "\n",
    "    def load_test_image(self, slide_id):\n",
    "        \"\"\"\n",
    "        Load test HE image for a given slide.\n",
    "        \"\"\"\n",
    "        with h5py.File(self.h5_file_path, \"r\") as f:\n",
    "            test_imgs = f[\"images/Test\"]\n",
    "            if slide_id not in test_imgs:\n",
    "                raise ValueError(f\"Slide {slide_id} not found in test images.\")\n",
    "            image_array = np.array(test_imgs[slide_id])\n",
    "        print(f\"Test image for slide {slide_id} loaded successfully.\")\n",
    "        return image_array\n",
    "\n",
    "    def prepare_training_set(self, slide_id='S_1'):\n",
    "        \"\"\"\n",
    "        Prepare training features and targets using image patches for a given slide.\n",
    "        Uses the HE image to extract patches and then CNN features.\n",
    "        \"\"\"\n",
    "        if slide_id not in self.train_spot_tables:\n",
    "            raise ValueError(f\"Slide {slide_id} not found in training spot data.\")\n",
    "        if slide_id not in self.train_images:\n",
    "            raise ValueError(f\"Slide {slide_id} image not loaded.\")\n",
    "            \n",
    "        df = self.train_spot_tables[slide_id]\n",
    "        # Assume first two columns are coordinates and the rest are cell type abundances.\n",
    "        feature_cols = ['x', 'y']\n",
    "        target_cols = [col for col in df.columns if col not in feature_cols]\n",
    "        self.cell_type_columns = target_cols\n",
    "        \n",
    "        # Extract coordinates (for patch extraction)\n",
    "        X_coords = df[feature_cols].values.astype(float)\n",
    "        # Cell type abundance targets\n",
    "        y = df[target_cols].values.astype(float)\n",
    "        \n",
    "        # Build a feature extractor pipeline that will extract CNN features from each patch.\n",
    "        he_image = self.train_images[slide_id]\n",
    "        patch_extractor = PatchFeatureExtractor(he_image, self.patch_size, self.cnn_model)\n",
    "        self.feature_extractor_pipeline = Pipeline([\n",
    "            ('patch_extractor', patch_extractor),\n",
    "            ('scaler', StandardScaler())\n",
    "        ])\n",
    "        # Extract features for training\n",
    "        X_features = self.feature_extractor_pipeline.fit_transform(X_coords)\n",
    "        print(f\"Extracted CNN features for slide {slide_id}.\")\n",
    "        return X_features, y\n",
    "\n",
    "    def build_regression_pipeline(self):\n",
    "        \"\"\"\n",
    "        Build and return a regression pipeline that uses the pre-extracted CNN features.\n",
    "        \"\"\"\n",
    "        pipeline = Pipeline([\n",
    "            ('regressor', MultiOutputRegressor(RandomForestRegressor(n_estimators=100, random_state=42)))\n",
    "        ])\n",
    "        return pipeline\n",
    "\n",
    "    def train(self, X, y):\n",
    "        \"\"\"\n",
    "        Train the regression model on the provided features and targets.\n",
    "        \"\"\"\n",
    "        reg_pipeline = self.build_regression_pipeline()\n",
    "        reg_pipeline.fit(X, y)\n",
    "        print(\"Regression model training complete.\")\n",
    "        return reg_pipeline\n",
    "\n",
    "    def predict(self, reg_model, X_test):\n",
    "        \"\"\"\n",
    "        Predict cell type abundances on test features.\n",
    "        \"\"\"\n",
    "        predictions = reg_model.predict(X_test)\n",
    "        return predictions\n",
    "\n",
    "    def create_submission(self, test_df, predictions, submission_filename=\"submission.csv\"):\n",
    "        \"\"\"\n",
    "        Create a submission CSV file with predicted cell type abundances.\n",
    "        \"\"\"\n",
    "        pred_df = pd.DataFrame(predictions, columns=self.cell_type_columns, index=test_df.index)\n",
    "        pred_df.insert(0, 'ID', pred_df.index)\n",
    "        pred_df.to_csv(submission_filename, index=False)\n",
    "        print(f\"Submission file '{submission_filename}' created!\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Example Usage\n",
    "# -----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Path to the provided H5 data file\n",
    "    h5_file_path = \"/kaggle/input/el-hackathon-2025/elucidata_ai_challenge_data.h5\"\n",
    "    \n",
    "    # Initialize the pipeline with desired patch size (in pixels)\n",
    "    pipeline_obj = CellTypePipeline(h5_file_path, patch_size=64)\n",
    "    \n",
    "    # Initialize the CNN feature extractor (ResNet50)\n",
    "    pipeline_obj.initialize_cnn_model()\n",
    "    \n",
    "    # Load training spots and images\n",
    "    pipeline_obj.load_train_data()\n",
    "    pipeline_obj.load_train_images()\n",
    "    \n",
    "    # Prepare training features and targets from one slide (e.g., 'S_1')\n",
    "    X_train, y_train = pipeline_obj.prepare_training_set(slide_id='S_1')\n",
    "    \n",
    "    # Train regression model on extracted CNN features\n",
    "    reg_model = pipeline_obj.train(X_train, y_train)\n",
    "    \n",
    "    # Load test data and image for slide S_7 (as per challenge description)\n",
    "    test_df = pipeline_obj.load_test_data(slide_id='S_7')\n",
    "    test_image = pipeline_obj.load_test_image(slide_id='S_7')\n",
    "    \n",
    "    # Build a feature extractor for test slide using its HE image\n",
    "    test_patch_extractor = PatchFeatureExtractor(test_image, pipeline_obj.patch_size, pipeline_obj.cnn_model)\n",
    "    test_feature_pipeline = Pipeline([\n",
    "        ('patch_extractor', test_patch_extractor),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    X_test_coords = test_df[['x', 'y']].values.astype(float)\n",
    "    X_test_features = test_feature_pipeline.fit_transform(X_test_coords)\n",
    "    \n",
    "    # Predict cell type abundances for test data\n",
    "    predictions = pipeline_obj.predict(reg_model, X_test_features)\n",
    "    \n",
    "    # Create submission file\n",
    "    pipeline_obj.create_submission(test_df, predictions, submission_filename=\"submission.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11390004,
     "sourceId": 94147,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7442.367653,
   "end_time": "2025-03-30T20:22:37.024394",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-30T18:18:34.656741",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
