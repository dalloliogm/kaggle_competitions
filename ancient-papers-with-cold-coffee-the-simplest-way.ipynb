{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d57a7bce",
   "metadata": {
    "papermill": {
     "duration": 0.002967,
     "end_time": "2025-11-22T15:02:34.424602",
     "exception": false,
     "start_time": "2025-11-22T15:02:34.421635",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Let's Read Ancient Papers with Cold Coffee: The Simplest Way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c31ae4",
   "metadata": {
    "papermill": {
     "duration": 0.001813,
     "end_time": "2025-11-22T15:02:34.428703",
     "exception": false,
     "start_time": "2025-11-22T15:02:34.426890",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## The Ancient Coffee Mystery â˜•ðŸº\n",
    "\n",
    "**Picture this:** You're a barista-archaeologist staring at a coffee scroll (papyrus) that's been carbonized into volcanic ash toast for 2,000 years. \n",
    "â˜ ï¸ It's so fragile that touching it = instant coffee dust. \n",
    "\n",
    "But inside? Priceless Roman coffee recipes!\n",
    "\n",
    "**Your Mission:** Use CT scans (X-ray vision for coffee!) to find the papyrus layers without physically unrolling. You're mapping the coffee surface through folds, gaps, and ash damage, like finding a single coffee bean in a crumpled napkin! ðŸŽ¯"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec8280f",
   "metadata": {
    "papermill": {
     "duration": 0.001788,
     "end_time": "2025-11-22T15:02:34.432380",
     "exception": false,
     "start_time": "2025-11-22T15:02:34.430592",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Why This is HARD :**\n",
    "\n",
    "Super fragile - One wrong move = â˜ ï¸\n",
    "\n",
    "Burnt to a crisp - Looks like ash, hard to distinguish\n",
    "\n",
    "Crazy folded - Like origami from hell\n",
    "\n",
    "Topology matters - Can't glue layers together or split them apart!\n",
    "\n",
    "Noise everywhere - Ash creates fake coffee artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cd248c",
   "metadata": {
    "papermill": {
     "duration": 0.001776,
     "end_time": "2025-11-22T15:02:34.436001",
     "exception": false,
     "start_time": "2025-11-22T15:02:34.434225",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1: â˜•  â˜• Let's Gather Our Coffee Ingredients (Imports & Setup)\n",
    "Load all necessary libraries and define global parameters used throughout the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64e91681",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T15:02:34.440868Z",
     "iopub.status.busy": "2025-11-22T15:02:34.440622Z",
     "iopub.status.idle": "2025-11-22T15:02:40.557775Z",
     "shell.execute_reply": "2025-11-22T15:02:40.557136Z"
    },
    "papermill": {
     "duration": 6.121223,
     "end_time": "2025-11-22T15:02:40.559115",
     "exception": false,
     "start_time": "2025-11-22T15:02:34.437892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from PIL import Image, ImageSequence\n",
    "from io import BytesIO\n",
    "import zipfile\n",
    "from scipy import ndimage\n",
    "\n",
    "\n",
    "# Our coffee recipe parameters\n",
    "\n",
    "TOP_PERCENT = 25.0          # How much coffee foam to keep (top 25% brightest)\n",
    "MIN_COMPONENT_VOXELS = 400  # Remove tiny coffee grounds (noise)\n",
    "CLOSING_ITERS = 1           # Gentle stirring (gap filling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c83040",
   "metadata": {
    "papermill": {
     "duration": 0.00197,
     "end_time": "2025-11-22T15:02:40.563297",
     "exception": false,
     "start_time": "2025-11-22T15:02:40.561327",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2: ðŸ—ï¸ Building Our Espresso Machine (Neural Network)\n",
    "Every great cold coffee needs a powerful espresso machine! This is our 3D U-Net - it's like a super smart coffee filter that knows exactly which beans (voxels) are the good stuff :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b25881c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T15:02:40.568532Z",
     "iopub.status.busy": "2025-11-22T15:02:40.568175Z",
     "iopub.status.idle": "2025-11-22T15:02:40.578984Z",
     "shell.execute_reply": "2025-11-22T15:02:40.578256Z"
    },
    "papermill": {
     "duration": 0.014915,
     "end_time": "2025-11-22T15:02:40.580153",
     "exception": false,
     "start_time": "2025-11-22T15:02:40.565238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DoubleConv3D(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv3d(in_ch, out_ch, 4, padding=2),\n",
    "            nn.BatchNorm3d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(out_ch, out_ch, 4, padding=2),\n",
    "            nn.BatchNorm3d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet3D(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1, init_features=24):\n",
    "        super().__init__()\n",
    "        f = init_features\n",
    "        self.enc1 = DoubleConv3D(in_channels, f)\n",
    "        self.pool1 = nn.MaxPool3d(2)\n",
    "        self.enc2 = DoubleConv3D(f, f*2)\n",
    "        self.pool2 = nn.MaxPool3d(2)\n",
    "        self.enc3 = DoubleConv3D(f*2, f*4)\n",
    "        self.pool3 = nn.MaxPool3d(2)\n",
    "        self.bottleneck = DoubleConv3D(f*4, f*8)\n",
    "        self.upconv3 = nn.ConvTranspose3d(f*8, f*4, 2, stride=2)\n",
    "        self.dec3 = DoubleConv3D(f*8, f*4)\n",
    "        self.upconv2 = nn.ConvTranspose3d(f*4, f*2, 2, stride=2)\n",
    "        self.dec2 = DoubleConv3D(f*4, f*2)\n",
    "        self.upconv1 = nn.ConvTranspose3d(f*2, f, 2, stride=2)\n",
    "        self.dec1 = DoubleConv3D(f*2, f)\n",
    "        self.out = nn.Conv3d(f, out_channels, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.pool1(e1))\n",
    "        e3 = self.enc3(self.pool2(e2))\n",
    "        b = self.bottleneck(self.pool3(e3))\n",
    "        d3 = self.upconv3(b)\n",
    "        d3 = torch.cat([d3, e3], 1)\n",
    "        d3 = self.dec3(d3)\n",
    "        d2 = self.upconv2(d3)\n",
    "        d2 = torch.cat([d2, e2], 1)\n",
    "        d2 = self.dec2(d2)\n",
    "        d1 = self.upconv1(d2)\n",
    "        d1 = torch.cat([d1, e1], 1)\n",
    "        d1 = self.dec1(d1)\n",
    "        return torch.sigmoid(self.out(d1))\n",
    "\n",
    "def load_tiff(path):\n",
    "    with Image.open(path) as tif:\n",
    "        return np.stack([np.array(frame) for frame in ImageSequence.Iterator(tif)])\n",
    "\n",
    "def save_to_zip(volume, zip_file, filename):\n",
    "    volume = (np.clip(volume, 0, 1) * 255).astype(np.uint8)\n",
    "    pages = [Image.fromarray(v) for v in volume]\n",
    "    buffer = BytesIO()\n",
    "    pages[0].save(buffer, format='TIFF', save_all=True, append_images=pages[1:])\n",
    "    zip_file.writestr(filename, buffer.getvalue())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80ef530",
   "metadata": {
    "papermill": {
     "duration": 0.001902,
     "end_time": "2025-11-22T15:02:40.584014",
     "exception": false,
     "start_time": "2025-11-22T15:02:40.582112",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##  3: âš¡ Our Coffee Grinding & Brewing Tools (Core Functions)\n",
    "\n",
    "Time to grind those coffee beans! These functions are our coffee grinder, blender, and strainer, turning raw CT scans into perfect predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b10211c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T15:02:40.588917Z",
     "iopub.status.busy": "2025-11-22T15:02:40.588513Z",
     "iopub.status.idle": "2025-11-22T15:02:40.598765Z",
     "shell.execute_reply": "2025-11-22T15:02:40.598019Z"
    },
    "papermill": {
     "duration": 0.014138,
     "end_time": "2025-11-22T15:02:40.599959",
     "exception": false,
     "start_time": "2025-11-22T15:02:40.585821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dl_inference_fast(volume, model, device, stride=72):\n",
    "    vol = (volume - volume.mean()) / (volume.std() + 1e-8)\n",
    "    Z,H,W = vol.shape\n",
    "    ps = 96\n",
    "    out = np.zeros((Z,H,W), dtype=np.float32)\n",
    "    cnt = np.zeros((Z,H,W), dtype=np.float32)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for z in range(0, max(1,Z-ps+1), stride):\n",
    "            for y in range(0, max(1,H-ps+1), stride):\n",
    "                for x in range(0, max(1,W-ps+1), stride):\n",
    "                    ze,ye,xe = min(z+ps,Z), min(y+ps,H), min(x+ps,W)\n",
    "                    patch = vol[z:ze,y:ye,x:xe]\n",
    "                    if patch.shape != (ps,ps,ps):\n",
    "                        pad = np.zeros((ps,ps,ps))\n",
    "                        pad[:patch.shape[0],:patch.shape[1],:patch.shape[2]] = patch\n",
    "                        patch = pad\n",
    "                    pred = model(torch.from_numpy(patch[None,None]).float().to(device))[0,0].cpu().numpy()\n",
    "                    out[z:ze,y:ye,x:xe] += pred[:ze-z,:ye-y,:xe-x]\n",
    "                    cnt[z:ze,y:ye,x:xe] += 1\n",
    "    \n",
    "    return out / np.maximum(cnt, 1)\n",
    "\n",
    "def classical_cv_slice_adaptive(volume):\n",
    "    filtered = ndimage.median_filter(volume, size=(1, 3, 3))\n",
    "    masks = []\n",
    "    percentile_cutoff = 100.0 - TOP_PERCENT\n",
    "    for sl in filtered:\n",
    "        t = np.percentile(sl, percentile_cutoff)\n",
    "        masks.append((sl > t).astype(np.float32))\n",
    "    return np.stack(masks)\n",
    "\n",
    "def slice_adaptive_ensemble(classical, dl):\n",
    "    ensemble = np.zeros_like(classical)\n",
    "    for i in range(classical.shape[0]):\n",
    "        slice_classical = classical[i]\n",
    "        slice_dl = dl[i]\n",
    "        weight = 0.7 + 0.2 * np.abs(slice_classical - 0.5)\n",
    "        ensemble[i] = weight * slice_classical + (1 - weight) * slice_dl\n",
    "    return ensemble\n",
    "\n",
    "def topology_aware_clean(mask):\n",
    "    cc_structure = ndimage.generate_binary_structure(rank=3, connectivity=1)\n",
    "    labeled, num = ndimage.label(mask, structure=cc_structure)\n",
    "    \n",
    "    if num == 0:\n",
    "        return mask.astype(np.uint8)\n",
    "    \n",
    "    component_sizes = ndimage.sum(mask, labeled, index=np.arange(1, num + 1))\n",
    "    keep_labels = np.where(component_sizes >= MIN_COMPONENT_VOXELS)[0] + 1\n",
    "    cleaned = np.isin(labeled, keep_labels).astype(np.uint8)\n",
    "    \n",
    "    if CLOSING_ITERS > 0:\n",
    "        closing_structure = np.zeros((3, 3, 3), dtype=np.uint8)\n",
    "        closing_structure[1, :, :] = 1\n",
    "        cleaned = ndimage.binary_closing(cleaned, structure=closing_structure, iterations=CLOSING_ITERS).astype(np.uint8)\n",
    "    \n",
    "    return cleaned.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3f297f",
   "metadata": {
    "papermill": {
     "duration": 0.001971,
     "end_time": "2025-11-22T15:02:40.603861",
     "exception": false,
     "start_time": "2025-11-22T15:02:40.601890",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##  4: ðŸš€ Brewing Our Perfect Cold Coffee (Main Pipeline)\n",
    "\n",
    "Time to brew! Load the model, grab the test data, and run our coffee making factory to create the submission.zip!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "692825cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T15:02:40.608845Z",
     "iopub.status.busy": "2025-11-22T15:02:40.608630Z",
     "iopub.status.idle": "2025-11-22T15:02:48.772095Z",
     "shell.execute_reply": "2025-11-22T15:02:48.771233Z"
    },
    "papermill": {
     "duration": 8.167415,
     "end_time": "2025-11-22T15:02:48.773199",
     "exception": false,
     "start_time": "2025-11-22T15:02:40.605784",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1ï¸âƒ£/3ï¸âƒ£Loading model\n",
      "\n",
      "[2ï¸âƒ£/3ï¸âƒ£] Now test data\n",
      "Test volumes: 1\n",
      "\n",
      "[3ï¸âƒ£/3ï¸âƒ£] Just 30 sec everthing completed --> Slice-adaptive + DL + Topology\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f52fb648f8b145afbca02d4656f2f6c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR 1407735: Sizes of tensors must match except in dimension 1. Expected size 30 but got size\n",
      "\n",
      "_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-\n",
      "DONE! submission.zip (0.0 MB)\n",
      "_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n 1ï¸âƒ£/3ï¸âƒ£Loading model\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')#mill jaye to gpu na mille to cpu\n",
    "model = UNet3D(in_channels=1, out_channels=1, init_features=24).to(device)\n",
    "\n",
    "model_path = Path('/kaggle/input/model11/best_model_fast.pth')\n",
    "if model_path.exists():\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    print(f\"Loaded: {model_path}\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "print(\"\\n[2ï¸âƒ£/3ï¸âƒ£] Now test data\")\n",
    "ROOT = Path('/kaggle/input/vesuvius-challenge-surface-detection')\n",
    "test_df = pd.read_csv(ROOT / 'test.csv')\n",
    "test_imgs = ROOT / 'test_images'\n",
    "print(f\"Test volumes: {len(test_df)}\")\n",
    "\n",
    "print(\"\\n[3ï¸âƒ£/3ï¸âƒ£] Just 30 sec everthing completed --> Slice-adaptive + DL + Topology\")\n",
    "\n",
    "submission_zip = Path('/kaggle/working/submission.zip')\n",
    "\n",
    "with zipfile.ZipFile(submission_zip, 'w', compression=zipfile.ZIP_DEFLATED, compresslevel=9) as zf:\n",
    "    for idx, row in tqdm(test_df.iterrows(), total=len(test_df), desc='Processing'):\n",
    "        image_id = row['id']\n",
    "        img_path = test_imgs / f'{image_id}.tif'\n",
    "        \n",
    "        if not img_path.exists():\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            volume = load_tiff(img_path).astype(np.float32)\n",
    "            \n",
    "            classical_pred = classical_cv_slice_adaptive(volume)\n",
    "            \n",
    "            dl_pred = dl_inference_fast(volume, model, device, stride=72)\n",
    "            \n",
    "            ensemble = slice_adaptive_ensemble(classical_pred, dl_pred)\n",
    "            \n",
    "            binary_mask = (ensemble > 0.5).astype(np.uint8)\n",
    "            final = topology_aware_clean(binary_mask)\n",
    "            \n",
    "            save_to_zip(final, zf, f'{image_id}.tif')\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"ERROR {image_id}: {str(e)[:80]}\")\n",
    "\n",
    "zip_size = submission_zip.stat().st_size / 1e6\n",
    "\n",
    "\n",
    "print(f\"\\n{'_-'*60}\")\n",
    "print(f\"DONE! submission.zip ({zip_size:.1f} MB)\")\n",
    "print(f\"{'_-'*60}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0756db5",
   "metadata": {
    "papermill": {
     "duration": 0.002154,
     "end_time": "2025-11-22T15:02:48.777749",
     "exception": false,
     "start_time": "2025-11-22T15:02:48.775595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 14443416,
     "sourceId": 117682,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17.575427,
   "end_time": "2025-11-22T15:02:49.999573",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-22T15:02:32.424146",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "10776319b83345c4af3235650eaf8c80": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "12d74f53a25f458e871e0d690411595a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "19dfda28abf04950a8d4a48f50b11ecb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1fa5923dc19a4aada5bb026858279c52": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_cf480acf79974e2b94636014352052de",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_10776319b83345c4af3235650eaf8c80",
       "tabbable": null,
       "tooltip": null,
       "value": 1.0
      }
     },
     "24000b3ac1434a0ea8643c8bea659ba0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "28da5d1702be476bbbf35c8ee6ee7e85": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "319cdb0cc5144011bf360162fe954728": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a289d452e5a44456b482fc8bc6038892": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_28da5d1702be476bbbf35c8ee6ee7e85",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_19dfda28abf04950a8d4a48f50b11ecb",
       "tabbable": null,
       "tooltip": null,
       "value": "Processing:â€‡100%"
      }
     },
     "cf480acf79974e2b94636014352052de": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e0c151ed31ff47ad8837fabba5a8a989": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_319cdb0cc5144011bf360162fe954728",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_12d74f53a25f458e871e0d690411595a",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡1/1â€‡[00:07&lt;00:00,â€‡â€‡7.74s/it]"
      }
     },
     "f52fb648f8b145afbca02d4656f2f6c1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a289d452e5a44456b482fc8bc6038892",
        "IPY_MODEL_1fa5923dc19a4aada5bb026858279c52",
        "IPY_MODEL_e0c151ed31ff47ad8837fabba5a8a989"
       ],
       "layout": "IPY_MODEL_24000b3ac1434a0ea8643c8bea659ba0",
       "tabbable": null,
       "tooltip": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
