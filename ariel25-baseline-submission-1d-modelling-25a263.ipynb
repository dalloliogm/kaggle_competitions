{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d35da196",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T13:32:28.811181Z",
     "iopub.status.busy": "2025-07-10T13:32:28.810480Z",
     "iopub.status.idle": "2025-07-10T13:32:31.786715Z",
     "shell.execute_reply": "2025-07-10T13:32:31.785914Z"
    },
    "papermill": {
     "duration": 2.984408,
     "end_time": "2025-07-10T13:32:31.789130",
     "exception": false,
     "start_time": "2025-07-10T13:32:28.804722",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: /kaggle/input/ariel24-pip-installs\r\n",
      "\u001b[33mWARNING: Location '/kaggle/input/ariel24-pip-installs' is ignored: it is either a non-existing path or lacks a specific scheme.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement scikit_learn==1.5.1 (from versions: none)\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for scikit_learn==1.5.1\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install scikit_learn==1.5.1 --no-index --find-links=/kaggle/input/ariel24-pip-installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1c2a981",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T13:32:31.799158Z",
     "iopub.status.busy": "2025-07-10T13:32:31.798840Z",
     "iopub.status.idle": "2025-07-10T13:32:31.803015Z",
     "shell.execute_reply": "2025-07-10T13:32:31.802182Z"
    },
    "papermill": {
     "duration": 0.011208,
     "end_time": "2025-07-10T13:32:31.804810",
     "exception": false,
     "start_time": "2025-07-10T13:32:31.793602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set to \"1\" to directly force test df, this is much quicker to commit\n",
    "os.environ[\"KAGGLE_IS_COMPETITION_RERUN\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad0ae6ba",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-10T13:32:31.814754Z",
     "iopub.status.busy": "2025-07-10T13:32:31.814540Z",
     "iopub.status.idle": "2025-07-10T13:32:31.825601Z",
     "shell.execute_reply": "2025-07-10T13:32:31.824759Z"
    },
    "papermill": {
     "duration": 0.01791,
     "end_time": "2025-07-10T13:32:31.827159",
     "exception": false,
     "start_time": "2025-07-10T13:32:31.809249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing preprocess.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile preprocess.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import multiprocessing as mp\n",
    "from astropy.stats import sigma_clip\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "ROOT = \"/kaggle/input/ariel-data-challenge-2025/\"\n",
    "VERSION = \"v2\"\n",
    "\n",
    "BINNING = 15\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    MODE = \"test\"\n",
    "else:\n",
    "    MODE = \"train\"\n",
    "\n",
    "\n",
    "sensor_sizes_dict = {\n",
    "    \"AIRS-CH0\": [[11250, 32, 356], [32, 356]],\n",
    "    \"FGS1\": [[135000, 32, 32], [32, 32]],\n",
    "}  # input, mask\n",
    "\n",
    "# 16 center pixels, rest is just noise\n",
    "cl = 8\n",
    "cr = 24\n",
    "\n",
    "\n",
    "def get_gain_offset():\n",
    "    \"\"\"\n",
    "    Get the gain and offset for a given planet and sensor\n",
    "\n",
    "    Unlike last year's challenge, all planets use the same adc_info.\n",
    "    We can just hard code it.\n",
    "    \"\"\"\n",
    "    gain = 0.4369\n",
    "    offset = -1000.0\n",
    "    return gain, offset\n",
    "\n",
    "\n",
    "def read_data(planet_id, sensor, mode):\n",
    "    \"\"\"\n",
    "    Read the data for a given planet and sensor\n",
    "    \"\"\"\n",
    "    # get all noise correction frames and signal\n",
    "    signal = pd.read_parquet(\n",
    "        f\"{ROOT}/{mode}/{planet_id}/{sensor}_signal_0.parquet\",\n",
    "        engine=\"pyarrow\",\n",
    "    )\n",
    "    dark_frame = pd.read_parquet(\n",
    "        f\"{ROOT}/{mode}/{planet_id}/{sensor}_calibration_0/dark.parquet\",\n",
    "        engine=\"pyarrow\",\n",
    "    )\n",
    "    dead_frame = pd.read_parquet(\n",
    "        f\"{ROOT}/{mode}/{planet_id}/{sensor}_calibration_0/dead.parquet\",\n",
    "        engine=\"pyarrow\",\n",
    "    )\n",
    "    linear_corr_frame = pd.read_parquet(\n",
    "        f\"{ROOT}/{mode}/{planet_id}/{sensor}_calibration_0/linear_corr.parquet\",\n",
    "        engine=\"pyarrow\",\n",
    "    )\n",
    "    flat_frame = pd.read_parquet(\n",
    "        f\"{ROOT}/{mode}/{planet_id}/{sensor}_calibration_0/flat.parquet\",\n",
    "        engine=\"pyarrow\",\n",
    "    )\n",
    "    # read_frame = pd.read_parquet(\n",
    "    #     f\"{ROOT}/{mode}/{planet_id}/{sensor}_calibration/read.parquet\",\n",
    "    #     engine=\"pyarrow\",\n",
    "    # )\n",
    "\n",
    "    # reshape to sensor shape and cast to float64\n",
    "    signal = signal.values.astype(np.float64).reshape(sensor_sizes_dict[sensor][0])[\n",
    "        :, cl:cr, :\n",
    "    ]\n",
    "    dark_frame = dark_frame.values.astype(np.float64).reshape(\n",
    "        sensor_sizes_dict[sensor][1]\n",
    "    )[cl:cr, :]\n",
    "    dead_frame = dead_frame.values.reshape(sensor_sizes_dict[sensor][1])[cl:cr, :]\n",
    "    flat_frame = flat_frame.values.astype(np.float64).reshape(\n",
    "        sensor_sizes_dict[sensor][1]\n",
    "    )[cl:cr, :]\n",
    "    # read_frame = read_frame.values.reshape(sensor_sizes_dict[sensor][1])\n",
    "    linear_corr = linear_corr_frame.values.astype(np.float64).reshape(\n",
    "        [6] + sensor_sizes_dict[sensor][1]\n",
    "    )[:, cl:cr, :]\n",
    "\n",
    "    return (\n",
    "        signal,\n",
    "        dark_frame,\n",
    "        dead_frame,\n",
    "        linear_corr,\n",
    "        flat_frame,\n",
    "        # read_frame,\n",
    "    )\n",
    "\n",
    "\n",
    "def ADC_convert(signal, gain, offset):\n",
    "    \"\"\"\n",
    "    Step 1: Analog-to-Digital Conversion (ADC) correction\n",
    "\n",
    "    The Analog-to-Digital Conversion (adc) is performed by the detector to convert the\n",
    "    pixel voltage into an integer number. We revert this operation by using the gain\n",
    "    and offset for the calibration files 'train_adc_info.csv'.\n",
    "    \"\"\"\n",
    "\n",
    "    return signal / gain + offset\n",
    "\n",
    "\n",
    "def mask_hot_dead(signal, dead, dark):\n",
    "    \"\"\"\n",
    "    Step 2: Mask hot/dead pixel\n",
    "\n",
    "    The dead pixels map is a map of the pixels that do not respond to light and, thus,\n",
    "    can't be accounted for any calculation. In all these frames the dead pixels are\n",
    "    masked using python masked arrays. The bad pixels are thus masked but left\n",
    "    uncorrected. Some methods can be used to correct bad-pixels but this task,\n",
    "    if needed, is left to the participants.\n",
    "    \"\"\"\n",
    "\n",
    "    hot = sigma_clip(dark, sigma=5, maxiters=5).mask\n",
    "    hot = np.tile(hot, (signal.shape[0], 1, 1))\n",
    "    dead = np.tile(dead, (signal.shape[0], 1, 1))\n",
    "\n",
    "    # Set values to np.nan where dead or hot pixels are found\n",
    "    signal[dead] = np.nan\n",
    "    signal[hot] = np.nan\n",
    "    return signal\n",
    "\n",
    "\n",
    "def apply_linear_corr(c, signal):\n",
    "    \"\"\"\n",
    "    Step 3: linearity Correction\n",
    "\n",
    "    The non-linearity of the pixels' response can be explained as capacitive leakage\n",
    "    on the readout electronics of each pixel during the integration time. The number\n",
    "    of electrons in the well is proportional to the number of photons that hit the\n",
    "    pixel, with a quantum efficiency coefficient. However, the response of the pixel\n",
    "    is not linear with the number of electrons in the well. This effect can be\n",
    "    described by a polynomial function of the number of electrons actually in the well.\n",
    "    The data is provided with calibration files linear_corr.parquet that are the\n",
    "    coefficients of the inverse polynomial function and can be used to correct this\n",
    "    non-linearity effect.\n",
    "    Using horner's method to evaluate the polynomial\n",
    "    \"\"\"\n",
    "    assert c.shape[0] == 6  # Ensure the polynomial is of degree 5\n",
    "\n",
    "    return (\n",
    "        (((c[5] * signal + c[4]) * signal + c[3]) * signal + c[2]) * signal + c[1]\n",
    "    ) * signal + c[0]\n",
    "\n",
    "\n",
    "def clean_dark(signal, dark, dt):\n",
    "    \"\"\"\n",
    "    Step 4: dark current subtraction\n",
    "\n",
    "    The data provided include calibration for dark current estimation, which can be\n",
    "    used to pre-process the observations. Dark current represents a constant signal\n",
    "    that accumulates in each pixel during the integration time, independent of the\n",
    "    incoming light. To obtain the corrected image, the following conventional approach\n",
    "    is applied: The data provided include calibration files such as dark frames or\n",
    "    dead pixels' maps. They can be used to pre-process the observations. The dark frame\n",
    "    is a map of the detector response to a very short exposure time, to correct for the\n",
    "    dark current of the detector.\n",
    "\n",
    "    image - (dark * dt)\n",
    "\n",
    "    The corrected image is conventionally obtained via the following: where the dark\n",
    "    current map is first corrected for the dead pixel.\n",
    "    \"\"\"\n",
    "\n",
    "    dark = torch.tile(dark, (signal.shape[0], 1, 1))\n",
    "    signal -= dark * dt[:, None, None]\n",
    "    return signal\n",
    "\n",
    "\n",
    "def get_cds(signal):\n",
    "    \"\"\"\n",
    "    Step 5: Get Correlated Double Sampling (CDS)\n",
    "\n",
    "    The science frames are alternating between the start of the exposure and the end of\n",
    "    the exposure. The lecture scheme is a ramp with a double sampling, called\n",
    "    Correlated Double Sampling (CDS), the detector is read twice, once at the start\n",
    "    of the exposure and once at the end of the exposure. The final CDS is the\n",
    "    difference (End of exposure) - (Start of exposure).\n",
    "    \"\"\"\n",
    "\n",
    "    return torch.subtract(signal[1::2, :, :], signal[::2, :, :])\n",
    "\n",
    "\n",
    "def bin_obs(signal, binning):\n",
    "    \"\"\"\n",
    "    Step 5.1: Bin Observations\n",
    "\n",
    "    The data provided are binned in the time dimension. The binning is performed by\n",
    "    summing the signal over the time dimension.\n",
    "    \"\"\"\n",
    "\n",
    "    assert signal.shape[0] % binning == 0  # Ensure the binning is possible\n",
    "\n",
    "    # cds_transposed = signal.transpose(0, 2, 1)\n",
    "    cds_binned = torch.zeros(\n",
    "        (\n",
    "            signal.shape[0] // binning,\n",
    "            signal.shape[1],\n",
    "            signal.shape[2],\n",
    "        ),\n",
    "        device=\"cuda:0\",\n",
    "    )\n",
    "    for i in range(signal.shape[0] // binning):\n",
    "        cds_binned[i, :, :] = torch.sum(\n",
    "            signal[i * binning : (i + 1) * binning, :, :], axis=0\n",
    "        )\n",
    "    return cds_binned\n",
    "\n",
    "\n",
    "def correct_flat_field(flat, signal):\n",
    "    \"\"\"\n",
    "    Step 6: Flat Field Correction\n",
    "\n",
    "    The flat field is a map of the detector response to uniform illumination, to\n",
    "    correct for the pixel-to-pixel variations of the detector, for example the\n",
    "    different quantum efficiencies of each pixel.\n",
    "    \"\"\"\n",
    "\n",
    "    return signal / flat\n",
    "\n",
    "\n",
    "def nan_interpolation(tensor):\n",
    "    # Assume tensor is of shape (batch, height, width)\n",
    "    nan_mask = torch.isnan(tensor)\n",
    "\n",
    "    # Replace NaNs with zero temporarily\n",
    "    tensor_filled = torch.where(\n",
    "        nan_mask, torch.tensor(0.0, device=tensor.device), tensor\n",
    "    )\n",
    "\n",
    "    # Create a binary mask (0 where NaNs were and 1 elsewhere)\n",
    "    ones = torch.ones_like(tensor, device=tensor.device)\n",
    "    weight = torch.where(nan_mask, torch.tensor(0.0, device=tensor.device), ones)\n",
    "\n",
    "    # Perform interpolation by convolving with a kernel\n",
    "    # using bilinear interpolation\n",
    "    kernel = torch.ones(1, 1, 1, 3, device=tensor.device, dtype=tensor.dtype)\n",
    "\n",
    "    # Apply padding to the tensor and weight to prevent boundary issues\n",
    "    tensor_padded = F.pad(\n",
    "        tensor_filled.unsqueeze(1), (1, 1, 0, 0), mode=\"replicate\"\n",
    "    ).squeeze(1)\n",
    "    weight_padded = F.pad(weight.unsqueeze(1), (1, 1, 0, 0), mode=\"replicate\").squeeze(\n",
    "        1\n",
    "    )\n",
    "\n",
    "    # Convolve the filled tensor and the weight mask\n",
    "    tensor_conv = F.conv2d(tensor_padded.unsqueeze(1), kernel, stride=1)\n",
    "    weight_conv = F.conv2d(weight_padded.unsqueeze(1), kernel, stride=1)\n",
    "\n",
    "    # Compute interpolated values (normalized by weights)\n",
    "    interpolated_tensor = tensor_conv / weight_conv\n",
    "\n",
    "    # Apply the interpolated values only to the positions of NaNs\n",
    "    result = torch.where(nan_mask, interpolated_tensor.squeeze(1), tensor)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def process_planet(planet_id):\n",
    "    \"\"\"\n",
    "    Process a single planet's data\n",
    "    \"\"\"\n",
    "    axis_info = pd.read_parquet(ROOT + \"axis_info.parquet\")\n",
    "    dt_airs = axis_info[\"AIRS-CH0-integration_time\"].dropna().values\n",
    "\n",
    "    for sensor in [\"FGS1\", \"AIRS-CH0\"]:\n",
    "        # load all data for this planet and sensor\n",
    "        signal, dark_frame, dead_frame, linear_corr, flat_frame = read_data(\n",
    "            planet_id, sensor, mode=MODE\n",
    "        )\n",
    "        gain, offset = get_gain_offset()\n",
    "\n",
    "        # Step 1: ADC correction\n",
    "        signal = ADC_convert(signal, gain, offset)\n",
    "\n",
    "        # Step 2: Mask hot/dead pixel\n",
    "        signal = mask_hot_dead(signal, dead_frame, dark_frame)\n",
    "\n",
    "        # clip at 0\n",
    "        signal = signal.clip(0)\n",
    "\n",
    "        # Step 3: linearity Correction\n",
    "        signal = apply_linear_corr(\n",
    "            torch.tensor(linear_corr).to(\"cuda:0\"), torch.tensor(signal).to(\"cuda:0\")\n",
    "        )\n",
    "\n",
    "        # Step 4: dark current subtraction\n",
    "        if sensor == \"FGS1\":\n",
    "            dt = torch.ones(len(signal), device=\"cuda:0\") * 0.1\n",
    "            dt[1::2] += 4.5\n",
    "        elif sensor == \"AIRS-CH0\":\n",
    "            dt = torch.tensor(dt_airs).to(\"cuda:0\")\n",
    "            dt[1::2] += 0.1\n",
    "\n",
    "        signal = clean_dark(signal, torch.tensor(dark_frame).to(\"cuda:0\"), dt)\n",
    "\n",
    "        # Step 5: Get Correlated Double Sampling (CDS)\n",
    "        signal = get_cds(signal)\n",
    "\n",
    "        # Step 5.1: Bin Observations\n",
    "        if sensor == \"FGS1\":\n",
    "            signal = bin_obs(signal, binning=BINNING * 12)\n",
    "        elif sensor == \"AIRS-CH0\":\n",
    "            signal = bin_obs(signal, binning=BINNING)\n",
    "\n",
    "        # Step 6: Flat Field Correction\n",
    "        signal = correct_flat_field(torch.tensor(flat_frame).to(\"cuda:0\"), signal)\n",
    "\n",
    "        # Step 7: Interpolate NaNs (twice!)\n",
    "        signal = nan_interpolation(signal)\n",
    "        signal = nan_interpolation(signal)\n",
    "\n",
    "        # Step 8: Sum over spatial axis\n",
    "        if sensor == \"FGS1\":\n",
    "            signal = torch.nanmean(signal, axis=[1, 2]).cpu().numpy()\n",
    "        elif sensor == \"AIRS-CH0\":\n",
    "            signal = torch.nanmean(signal, axis=1).cpu().numpy()\n",
    "\n",
    "        # save the processed signal\n",
    "        np.save(\n",
    "            f\"{planet_id}_{sensor}_signal_{VERSION}.npz\",\n",
    "            signal.astype(np.float64),\n",
    "        )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    star_info = pd.read_csv(ROOT + f\"/{MODE}_star_info.csv\")\n",
    "    star_info[\"planet_id\"] = star_info[\"planet_id\"].astype(int)\n",
    "    star_info = star_info.set_index(\"planet_id\")\n",
    "    planet_ids = star_info.index.tolist()\n",
    "\n",
    "    with mp.Pool(processes=4) as pool:\n",
    "        list(tqdm(pool.imap(process_planet, planet_ids), total=len(planet_ids)))\n",
    "\n",
    "    signal_train = []\n",
    "\n",
    "    for planet_id in planet_ids:\n",
    "        f_raw = np.load(f\"{planet_id}_FGS1_signal_{VERSION}.npz.npy\")\n",
    "        a_raw = np.load(f\"{planet_id}_AIRS-CH0_signal_{VERSION}.npz.npy\")\n",
    "\n",
    "        # flip a_raw\n",
    "        signal = np.concatenate([f_raw[:, None], a_raw[:, ::-1]], axis=1)\n",
    "        signal_train.append(signal)\n",
    "\n",
    "    signal_train = np.array(signal_train)\n",
    "    np.save(f\"signal_{VERSION}.npy\", signal_train, allow_pickle=False)\n",
    "\n",
    "    print(\"Processing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc22b00b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T13:32:31.836614Z",
     "iopub.status.busy": "2025-07-10T13:32:31.836389Z",
     "iopub.status.idle": "2025-07-10T13:32:52.523423Z",
     "shell.execute_reply": "2025-07-10T13:32:52.522614Z"
    },
    "papermill": {
     "duration": 20.694097,
     "end_time": "2025-07-10T13:32:52.525570",
     "exception": false,
     "start_time": "2025-07-10T13:32:31.831473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:08<00:00,  8.50s/it]\r\n",
      "Processing complete!\r\n"
     ]
    }
   ],
   "source": [
    "!python preprocess.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a88be43b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T13:32:52.537098Z",
     "iopub.status.busy": "2025-07-10T13:32:52.536812Z",
     "iopub.status.idle": "2025-07-10T13:32:53.550044Z",
     "shell.execute_reply": "2025-07-10T13:32:53.549065Z"
    },
    "papermill": {
     "duration": 1.02122,
     "end_time": "2025-07-10T13:32:53.552019",
     "exception": false,
     "start_time": "2025-07-10T13:32:52.530799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -rf *FGS1_signal*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6a1d2fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T13:32:53.563014Z",
     "iopub.status.busy": "2025-07-10T13:32:53.562518Z",
     "iopub.status.idle": "2025-07-10T13:32:54.584406Z",
     "shell.execute_reply": "2025-07-10T13:32:54.583194Z"
    },
    "papermill": {
     "duration": 1.029829,
     "end_time": "2025-07-10T13:32:54.586526",
     "exception": false,
     "start_time": "2025-07-10T13:32:53.556697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -rf *AIRS-CH0_signal*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b9a40d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T13:32:54.596948Z",
     "iopub.status.busy": "2025-07-10T13:32:54.596664Z",
     "iopub.status.idle": "2025-07-10T13:32:55.627270Z",
     "shell.execute_reply": "2025-07-10T13:32:55.626488Z"
    },
    "papermill": {
     "duration": 1.037886,
     "end_time": "2025-07-10T13:32:55.629068",
     "exception": false,
     "start_time": "2025-07-10T13:32:54.591182",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__notebook__.ipynb  preprocess.py  signal_v2.npy\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee6676a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T13:32:55.640173Z",
     "iopub.status.busy": "2025-07-10T13:32:55.639884Z",
     "iopub.status.idle": "2025-07-10T13:32:58.581004Z",
     "shell.execute_reply": "2025-07-10T13:32:58.579949Z"
    },
    "papermill": {
     "duration": 2.948556,
     "end_time": "2025-07-10T13:32:58.582663",
     "exception": false,
     "start_time": "2025-07-10T13:32:55.634107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 375, 283)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 117.48it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.optimize import curve_fit\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "MODEL_VERSION = \"v1\"\n",
    "DATA_VERSION = \"v2\"\n",
    "PRE_BINNED_TIME = 15\n",
    "\n",
    "ROOT = \"/kaggle/input/ariel-data-challenge-2025/\"\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    MODE = \"test\"\n",
    "else:\n",
    "    MODE = \"train\"\n",
    "\n",
    "star_info = pd.read_csv(ROOT + f\"/{MODE}_star_info.csv\")\n",
    "star_info[\"planet_id\"] = star_info[\"planet_id\"].astype(int)\n",
    "star_info = star_info.set_index(\"planet_id\")\n",
    "wavelengths = pd.read_csv(ROOT + \"/wavelengths.csv\")\n",
    "\n",
    "signal_train = np.load(f\"signal_{DATA_VERSION}.npy\")\n",
    "cut_inf, cut_sup = 36, 318\n",
    "signal_train = np.concatenate(\n",
    "    [signal_train[:, :, 0][:, :, None], signal_train[:, :, cut_inf:cut_sup]], axis=2\n",
    ")\n",
    "print(signal_train.shape)\n",
    "# signal_train = signal_train.mean(axis=2)\n",
    "\n",
    "def smooth_data(data, window_size):\n",
    "    return savgol_filter(data, window_size, 3)  # window size 51, polynomial order 3\n",
    "\n",
    "\n",
    "# find transit zones\n",
    "def phase_detector(signal_orig, binning=15, smooth_window=11, verbose=False):\n",
    "    signal = signal_orig.reshape(-1, binning).mean(-1)  # collapse by 15; 375\n",
    "    signal = savgol_filter(signal, smooth_window, 2)  # smooth\n",
    "    first_derivative = np.gradient(signal)\n",
    "    phase1 = np.argmin(first_derivative)\n",
    "    phase2 = np.argmax(first_derivative)\n",
    "\n",
    "    if verbose:\n",
    "        plt.plot(signal_orig, color=\"grey\", alpha=0.5, label=\"original\")\n",
    "        plt.plot(signal, color=\"blue\", alpha=0.9, label=\"smoothed\")\n",
    "        plt.axvline(phase1, color=\"r\")\n",
    "        plt.axvline(phase2, color=\"r\")\n",
    "        plt.show()\n",
    "        plt.plot(first_derivative, color=\"green\", alpha=0.9, label=\"first derivative\")\n",
    "        plt.show()\n",
    "\n",
    "    assert phase1 < phase2\n",
    "    assert phase1 >= 0\n",
    "    assert phase2 <= signal.shape[0]\n",
    "    return phase1 * binning, phase2 * binning\n",
    "\n",
    "\n",
    "def get_breakpoints(x, pre_binned_time, verbose=False):\n",
    "    bp = np.zeros(x.shape[0], dtype=np.int32)\n",
    "    bp2 = np.zeros(x.shape[0], dtype=np.int32)\n",
    "    for i in range(x.shape[0]):\n",
    "        signal = x[i].mean(-1)\n",
    "        p1, p2 = phase_detector(\n",
    "            signal, binning=15 // pre_binned_time, smooth_window=19, verbose=verbose\n",
    "        )\n",
    "        bp[i] = p1\n",
    "        bp2[i] = p2\n",
    "\n",
    "    return [bp, bp2]\n",
    "\n",
    "\n",
    "# breakpoint detection\n",
    "all_bp, all_bp2 = get_breakpoints(signal_train, PRE_BINNED_TIME, verbose=False)\n",
    "\n",
    "\n",
    "def poly_exp_fit(data, optimized_breakpoints, buffer_size, degree=3):\n",
    "    # Define the three regions\n",
    "    x1 = np.arange(optimized_breakpoints[0] - buffer_size)\n",
    "    y1 = data[: optimized_breakpoints[0] - buffer_size]\n",
    "\n",
    "    x2 = np.arange(\n",
    "        optimized_breakpoints[0] + buffer_size,\n",
    "        optimized_breakpoints[1] - buffer_size,\n",
    "    )\n",
    "    y2 = data[\n",
    "        optimized_breakpoints[0] + buffer_size : optimized_breakpoints[1] - buffer_size\n",
    "    ]\n",
    "\n",
    "    x3 = np.arange(optimized_breakpoints[1] + buffer_size, len(data))\n",
    "    y3 = data[optimized_breakpoints[1] + buffer_size :]\n",
    "\n",
    "    # Concatenate the x-values and y-values for regions 1 and 3\n",
    "    x_combined = np.concatenate([x1, x3])\n",
    "    y_combined = np.concatenate([y1, y3])\n",
    "\n",
    "    def fit_function(x, *params):\n",
    "        poly_params = params[: degree + 1]\n",
    "        y_fit = np.polyval(poly_params, x)\n",
    "        return y_fit\n",
    "\n",
    "    # Define the polynomial fit function with an additional shift parameter for region 2\n",
    "    def fit_function_with_shift(x, shift, *poly_params):\n",
    "        x1_adjusted = x[: len(x1)]\n",
    "        x2_adjusted = x[len(x1) : len(x1) + len(x2)]\n",
    "        x3_adjusted = x[len(x1) + len(x2) :]\n",
    "        y1_fit = np.polyval(poly_params, x1_adjusted)\n",
    "        y2_fit = np.polyval(poly_params, x2_adjusted) * shift\n",
    "        y3_fit = np.polyval(poly_params, x3_adjusted)\n",
    "        return np.concatenate([y1_fit, y2_fit, y3_fit])\n",
    "\n",
    "    # Define the combined x-values (including region 2)\n",
    "    x_combined_with_region2 = np.concatenate([x1, x2, x3])\n",
    "    y_combined_with_region2 = np.concatenate([y1, y2, y3])\n",
    "\n",
    "    # Initial guesses for the polynomial coefficients and shift\n",
    "    poly_guess = np.polyfit(x_combined, y_combined, degree)\n",
    "\n",
    "    p0 = list(poly_guess)\n",
    "\n",
    "    initial_shift_guess = 1.0\n",
    "    p0 = [initial_shift_guess] + list(p0)\n",
    "\n",
    "    # Fit the polynomial and the shift using curve_fit\n",
    "    popt, _ = curve_fit(\n",
    "        fit_function_with_shift,\n",
    "        x_combined_with_region2,\n",
    "        y_combined_with_region2,\n",
    "        p0=p0,\n",
    "        maxfev=10000,\n",
    "    )\n",
    "\n",
    "    # Extract the optimized shift and polynomial coefficients\n",
    "    optimized_shift = popt[0]\n",
    "    assert optimized_shift > 0.8\n",
    "    optimized_poly_params = popt[1:]\n",
    "\n",
    "    return fit_function, optimized_poly_params, optimized_shift\n",
    "\n",
    "\n",
    "def feature_engineering(signal_train):\n",
    "    \"\"\"Create a dataframe with two features from the raw data.\n",
    "\n",
    "    Parameters:\n",
    "    f_raw: ndarray of shape (n_planets, 67500)\n",
    "    a_raw: ndarray of shape (n_planets, 5625)\n",
    "\n",
    "    Return value:\n",
    "    df: DataFrame of shape (n_planets, 2)\n",
    "    \"\"\"\n",
    "\n",
    "    y_shifts = []\n",
    "\n",
    "    for IDX in tqdm(range(len(signal_train))):\n",
    "        data = signal_train[IDX]\n",
    "\n",
    "        buffer_size_poly = 150 // PRE_BINNED_TIME\n",
    "\n",
    "        optimized_breakpoints = [all_bp[IDX].item(), all_bp2[IDX].item()]\n",
    "\n",
    "        fit_func, params, y_shift = poly_exp_fit(\n",
    "            data[:, 1:].mean(1) / data[:, 1:].mean(1).mean(),\n",
    "            optimized_breakpoints,\n",
    "            buffer_size_poly,\n",
    "            degree=2,\n",
    "        )\n",
    "\n",
    "        y_shifts.append(y_shift)\n",
    "\n",
    "    y_shifts = np.array(y_shifts)\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        1 - y_shifts,\n",
    "        index=star_info.index,\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = feature_engineering(signal_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf696d5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T13:32:58.594424Z",
     "iopub.status.busy": "2025-07-10T13:32:58.594168Z",
     "iopub.status.idle": "2025-07-10T13:32:58.606606Z",
     "shell.execute_reply": "2025-07-10T13:32:58.605842Z"
    },
    "papermill": {
     "duration": 0.020716,
     "end_time": "2025-07-10T13:32:58.608199",
     "exception": false,
     "start_time": "2025-07-10T13:32:58.587483",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>planet_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1103775</th>\n",
       "      <td>0.016606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "planet_id          \n",
       "1103775    0.016606"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a052a2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T13:32:58.618963Z",
     "iopub.status.busy": "2025-07-10T13:32:58.618719Z",
     "iopub.status.idle": "2025-07-10T13:32:58.622203Z",
     "shell.execute_reply": "2025-07-10T13:32:58.621525Z"
    },
    "papermill": {
     "duration": 0.010599,
     "end_time": "2025-07-10T13:32:58.623775",
     "exception": false,
     "start_time": "2025-07-10T13:32:58.613176",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d642b7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T13:32:58.634613Z",
     "iopub.status.busy": "2025-07-10T13:32:58.634380Z",
     "iopub.status.idle": "2025-07-10T13:32:58.638842Z",
     "shell.execute_reply": "2025-07-10T13:32:58.638133Z"
    },
    "papermill": {
     "duration": 0.011786,
     "end_time": "2025-07-10T13:32:58.640414",
     "exception": false,
     "start_time": "2025-07-10T13:32:58.628628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c4b8e66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T13:32:58.651316Z",
     "iopub.status.busy": "2025-07-10T13:32:58.650793Z",
     "iopub.status.idle": "2025-07-10T13:32:58.670123Z",
     "shell.execute_reply": "2025-07-10T13:32:58.669328Z"
    },
    "papermill": {
     "duration": 0.026653,
     "end_time": "2025-07-10T13:32:58.671874",
     "exception": false,
     "start_time": "2025-07-10T13:32:58.645221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rs</th>\n",
       "      <th>Ms</th>\n",
       "      <th>Ts</th>\n",
       "      <th>Mp</th>\n",
       "      <th>e</th>\n",
       "      <th>P</th>\n",
       "      <th>sma</th>\n",
       "      <th>i</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>planet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1103775</th>\n",
       "      <td>0.965432</td>\n",
       "      <td>0.9591</td>\n",
       "      <td>5539.03037</td>\n",
       "      <td>1.665007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.932871</td>\n",
       "      <td>15.43293</td>\n",
       "      <td>89.533139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Rs      Ms          Ts        Mp    e         P       sma  \\\n",
       "planet_id                                                                    \n",
       "1103775    0.965432  0.9591  5539.03037  1.665007  0.0  6.932871  15.43293   \n",
       "\n",
       "                   i  \n",
       "planet_id             \n",
       "1103775    89.533139  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "star_info = pd.read_csv(ROOT + f\"/{MODE}_star_info.csv\")\n",
    "star_info[\"planet_id\"] = star_info[\"planet_id\"].astype(int)\n",
    "star_info = star_info.set_index(\"planet_id\")\n",
    "star_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b451731f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T13:32:58.683132Z",
     "iopub.status.busy": "2025-07-10T13:32:58.682646Z",
     "iopub.status.idle": "2025-07-10T13:32:58.688544Z",
     "shell.execute_reply": "2025-07-10T13:32:58.687749Z"
    },
    "papermill": {
     "duration": 0.013401,
     "end_time": "2025-07-10T13:32:58.690263",
     "exception": false,
     "start_time": "2025-07-10T13:32:58.676862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def postprocessing(pred_array, index, sigma_pred):\n",
    "    \"\"\"Create a submission dataframe from its components\n",
    "\n",
    "    Parameters:\n",
    "    pred_array: ndarray of shape (n_samples, 283)\n",
    "    index: pandas.Index of length n_samples with name 'planet_id'\n",
    "    sigma_pred: series of length n_samples or float\n",
    "\n",
    "    Return value:\n",
    "    df: DataFrame of shape (n_samples, 566) with planet_id as index\n",
    "    \"\"\"\n",
    "    if isinstance(sigma_pred, float):\n",
    "        expanded_sigmas = np.ones(len(pred_array)) * sigma_pred\n",
    "    else:\n",
    "        expanded_sigmas = sigma_pred\n",
    "\n",
    "    expanded_sigmas = np.repeat(expanded_sigmas[:, np.newaxis], 283, axis=1)\n",
    "    if pred_array.shape[1] == 1:\n",
    "        pred_array = np.repeat(pred_array, 283, axis=1)\n",
    "    return pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(\n",
    "                pred_array.clip(0, None), index=index, columns=wavelengths.columns\n",
    "            ),\n",
    "            pd.DataFrame(\n",
    "                expanded_sigmas,\n",
    "                index=index,\n",
    "                columns=[f\"sigma_{i}\" for i in range(1, 284)],\n",
    "            ),\n",
    "        ],\n",
    "        axis=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3e11f42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T13:32:58.701368Z",
     "iopub.status.busy": "2025-07-10T13:32:58.700779Z",
     "iopub.status.idle": "2025-07-10T13:32:58.705351Z",
     "shell.execute_reply": "2025-07-10T13:32:58.704557Z"
    },
    "papermill": {
     "duration": 0.011673,
     "end_time": "2025-07-10T13:32:58.706974",
     "exception": false,
     "start_time": "2025-07-10T13:32:58.695301",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_df = postprocessing(predictions, star_info.index, sigma_pred=0.0008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b2d5604",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T13:32:58.717812Z",
     "iopub.status.busy": "2025-07-10T13:32:58.717382Z",
     "iopub.status.idle": "2025-07-10T13:32:58.735482Z",
     "shell.execute_reply": "2025-07-10T13:32:58.734651Z"
    },
    "papermill": {
     "duration": 0.025125,
     "end_time": "2025-07-10T13:32:58.737038",
     "exception": false,
     "start_time": "2025-07-10T13:32:58.711913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wl_1</th>\n",
       "      <th>wl_2</th>\n",
       "      <th>wl_3</th>\n",
       "      <th>wl_4</th>\n",
       "      <th>wl_5</th>\n",
       "      <th>wl_6</th>\n",
       "      <th>wl_7</th>\n",
       "      <th>wl_8</th>\n",
       "      <th>wl_9</th>\n",
       "      <th>wl_10</th>\n",
       "      <th>...</th>\n",
       "      <th>sigma_274</th>\n",
       "      <th>sigma_275</th>\n",
       "      <th>sigma_276</th>\n",
       "      <th>sigma_277</th>\n",
       "      <th>sigma_278</th>\n",
       "      <th>sigma_279</th>\n",
       "      <th>sigma_280</th>\n",
       "      <th>sigma_281</th>\n",
       "      <th>sigma_282</th>\n",
       "      <th>sigma_283</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>planet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1103775</th>\n",
       "      <td>0.016606</td>\n",
       "      <td>0.016606</td>\n",
       "      <td>0.016606</td>\n",
       "      <td>0.016606</td>\n",
       "      <td>0.016606</td>\n",
       "      <td>0.016606</td>\n",
       "      <td>0.016606</td>\n",
       "      <td>0.016606</td>\n",
       "      <td>0.016606</td>\n",
       "      <td>0.016606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 566 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               wl_1      wl_2      wl_3      wl_4      wl_5      wl_6  \\\n",
       "planet_id                                                               \n",
       "1103775    0.016606  0.016606  0.016606  0.016606  0.016606  0.016606   \n",
       "\n",
       "               wl_7      wl_8      wl_9     wl_10  ...  sigma_274  sigma_275  \\\n",
       "planet_id                                          ...                         \n",
       "1103775    0.016606  0.016606  0.016606  0.016606  ...     0.0008     0.0008   \n",
       "\n",
       "           sigma_276  sigma_277  sigma_278  sigma_279  sigma_280  sigma_281  \\\n",
       "planet_id                                                                     \n",
       "1103775       0.0008     0.0008     0.0008     0.0008     0.0008     0.0008   \n",
       "\n",
       "           sigma_282  sigma_283  \n",
       "planet_id                        \n",
       "1103775       0.0008     0.0008  \n",
       "\n",
       "[1 rows x 566 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36ebd076",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T13:32:58.748457Z",
     "iopub.status.busy": "2025-07-10T13:32:58.747957Z",
     "iopub.status.idle": "2025-07-10T13:32:58.756369Z",
     "shell.execute_reply": "2025-07-10T13:32:58.755749Z"
    },
    "papermill": {
     "duration": 0.015641,
     "end_time": "2025-07-10T13:32:58.757953",
     "exception": false,
     "start_time": "2025-07-10T13:32:58.742312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_df.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "102018b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T13:32:58.769187Z",
     "iopub.status.busy": "2025-07-10T13:32:58.768926Z",
     "iopub.status.idle": "2025-07-10T13:32:58.795442Z",
     "shell.execute_reply": "2025-07-10T13:32:58.794637Z"
    },
    "papermill": {
     "duration": 0.033871,
     "end_time": "2025-07-10T13:32:58.797027",
     "exception": false,
     "start_time": "2025-07-10T13:32:58.763156",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>planet_id</th>\n",
       "      <th>wl_1</th>\n",
       "      <th>wl_2</th>\n",
       "      <th>wl_3</th>\n",
       "      <th>wl_4</th>\n",
       "      <th>wl_5</th>\n",
       "      <th>wl_6</th>\n",
       "      <th>wl_7</th>\n",
       "      <th>wl_8</th>\n",
       "      <th>wl_9</th>\n",
       "      <th>...</th>\n",
       "      <th>sigma_274</th>\n",
       "      <th>sigma_275</th>\n",
       "      <th>sigma_276</th>\n",
       "      <th>sigma_277</th>\n",
       "      <th>sigma_278</th>\n",
       "      <th>sigma_279</th>\n",
       "      <th>sigma_280</th>\n",
       "      <th>sigma_281</th>\n",
       "      <th>sigma_282</th>\n",
       "      <th>sigma_283</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1103775</td>\n",
       "      <td>0.016606</td>\n",
       "      <td>0.016606</td>\n",
       "      <td>0.016606</td>\n",
       "      <td>0.016606</td>\n",
       "      <td>0.016606</td>\n",
       "      <td>0.016606</td>\n",
       "      <td>0.016606</td>\n",
       "      <td>0.016606</td>\n",
       "      <td>0.016606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 567 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   planet_id      wl_1      wl_2      wl_3      wl_4      wl_5      wl_6  \\\n",
       "0    1103775  0.016606  0.016606  0.016606  0.016606  0.016606  0.016606   \n",
       "\n",
       "       wl_7      wl_8      wl_9  ...  sigma_274  sigma_275  sigma_276  \\\n",
       "0  0.016606  0.016606  0.016606  ...     0.0008     0.0008     0.0008   \n",
       "\n",
       "   sigma_277  sigma_278  sigma_279  sigma_280  sigma_281  sigma_282  sigma_283  \n",
       "0     0.0008     0.0008     0.0008     0.0008     0.0008     0.0008     0.0008  \n",
       "\n",
       "[1 rows x 567 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f1d4a63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T13:32:58.809218Z",
     "iopub.status.busy": "2025-07-10T13:32:58.808460Z",
     "iopub.status.idle": "2025-07-10T13:32:59.834719Z",
     "shell.execute_reply": "2025-07-10T13:32:59.833845Z"
    },
    "papermill": {
     "duration": 1.034207,
     "end_time": "2025-07-10T13:32:59.836734",
     "exception": false,
     "start_time": "2025-07-10T13:32:58.802527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'signal_v0.npy': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!rm signal_v0.npy preprocess.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68d42208",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T13:32:59.849258Z",
     "iopub.status.busy": "2025-07-10T13:32:59.848894Z",
     "iopub.status.idle": "2025-07-10T13:33:00.888992Z",
     "shell.execute_reply": "2025-07-10T13:33:00.888153Z"
    },
    "papermill": {
     "duration": 1.048476,
     "end_time": "2025-07-10T13:33:00.890988",
     "exception": false,
     "start_time": "2025-07-10T13:32:59.842512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__notebook__.ipynb  signal_v2.npy  submission.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21d32780",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T13:33:00.903870Z",
     "iopub.status.busy": "2025-07-10T13:33:00.903582Z",
     "iopub.status.idle": "2025-07-10T13:33:00.912995Z",
     "shell.execute_reply": "2025-07-10T13:33:00.912292Z"
    },
    "papermill": {
     "duration": 0.01774,
     "end_time": "2025-07-10T13:33:00.914590",
     "exception": false,
     "start_time": "2025-07-10T13:33:00.896850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Adapted from https://www.kaggle.com/code/metric/ariel-gaussian-log-likelihood\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "\n",
    "\n",
    "class ParticipantVisibleError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "def competition_score(\n",
    "    solution: pd.DataFrame,\n",
    "    submission: pd.DataFrame,\n",
    "    naive_mean: float,\n",
    "    naive_sigma: float,\n",
    "    sigma_true: float = 0.00001,\n",
    "    row_id_column_name: str = \"planet_id\",\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    This is a Gaussian Log Likelihood based metric. For a submission, which contains\n",
    "    the predicted mean (x_hat) and variance (x_hat_std), we calculate the Gaussian\n",
    "    Log-likelihood (GLL) value to the provided ground truth(x). We treat each pair\n",
    "    of x_hat, x_hat_std as a 1D gaussian, meaning there will be 283 1D gaussian\n",
    "    distributions, hence 283 values for each test spectrum, the GLL value for one\n",
    "    spectrum is the sum of all of them.\n",
    "\n",
    "    Inputs:\n",
    "        - solution: Ground Truth spectra (from test set)\n",
    "            - shape: (nsamples, n_wavelengths)\n",
    "        - submission: Predicted spectra and errors (from participants)\n",
    "            - shape: (nsamples, n_wavelengths*2)\n",
    "        naive_mean: (float) mean from the train set.\n",
    "        naive_sigma: (float) standard deviation from the train set.\n",
    "        sigma_true: (float) essentially sets the scale of the outputs.\n",
    "    \"\"\"\n",
    "\n",
    "    del solution[row_id_column_name]\n",
    "    del submission[row_id_column_name]\n",
    "\n",
    "    if submission.min().min() < 0:\n",
    "        raise ParticipantVisibleError(\"Negative values in the submission\")\n",
    "    for col in submission.columns:\n",
    "        if not pd.api.types.is_numeric_dtype(submission[col]):\n",
    "            raise ParticipantVisibleError(f\"Submission column {col} must be a number\")\n",
    "\n",
    "    n_wavelengths = len(solution.columns)\n",
    "    if len(submission.columns) != n_wavelengths * 2:\n",
    "        raise ParticipantVisibleError(\"Wrong number of columns in the submission\")\n",
    "\n",
    "    y_pred = submission.iloc[:, :n_wavelengths].values\n",
    "    # Set a non-zero minimum sigma pred to prevent division by zero errors.\n",
    "    sigma_pred = np.clip(\n",
    "        submission.iloc[:, n_wavelengths:].values, a_min=10**-15, a_max=None\n",
    "    )\n",
    "    y_true = solution.values\n",
    "\n",
    "    GLL_pred = np.sum(scipy.stats.norm.logpdf(y_true, loc=y_pred, scale=sigma_pred))\n",
    "    GLL_true = np.sum(\n",
    "        scipy.stats.norm.logpdf(\n",
    "            y_true, loc=y_true, scale=sigma_true * np.ones_like(y_true)\n",
    "        )\n",
    "    )\n",
    "    GLL_mean = np.sum(\n",
    "        scipy.stats.norm.logpdf(\n",
    "            y_true,\n",
    "            loc=naive_mean * np.ones_like(y_true),\n",
    "            scale=naive_sigma * np.ones_like(y_true),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    submit_score = (GLL_pred - GLL_mean) / (GLL_true - GLL_mean)\n",
    "    return float(np.clip(submit_score, 0.0, 1.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18f044d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T13:33:00.926283Z",
     "iopub.status.busy": "2025-07-10T13:33:00.926012Z",
     "iopub.status.idle": "2025-07-10T13:33:00.930249Z",
     "shell.execute_reply": "2025-07-10T13:33:00.929602Z"
    },
    "papermill": {
     "duration": 0.012032,
     "end_time": "2025-07-10T13:33:00.931904",
     "exception": false,
     "start_time": "2025-07-10T13:33:00.919872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    train_labels = pd.read_csv(ROOT + \"/train.csv\", index_col=\"planet_id\")\n",
    "    \n",
    "    gll_score = competition_score(\n",
    "        train_labels.copy().reset_index(),\n",
    "        sub_df.copy().reset_index(),\n",
    "        naive_mean=train_labels.values.mean(),\n",
    "        naive_sigma=train_labels.values.std(),\n",
    "    )\n",
    "\n",
    "    print(f\"# Estimated competition score: {gll_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f442549",
   "metadata": {
    "papermill": {
     "duration": 0.005114,
     "end_time": "2025-07-10T13:33:00.942299",
     "exception": false,
     "start_time": "2025-07-10T13:33:00.937185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 12846694,
     "sourceId": 101849,
     "sourceType": "competition"
    },
    {
     "datasetId": 5548325,
     "sourceId": 9774816,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 192766898,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 36.323136,
   "end_time": "2025-07-10T13:33:01.364918",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-10T13:32:25.041782",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
