{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b86dbebe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T13:18:17.389171Z",
     "iopub.status.busy": "2025-05-24T13:18:17.388803Z",
     "iopub.status.idle": "2025-05-24T13:18:17.393998Z",
     "shell.execute_reply": "2025-05-24T13:18:17.393056Z"
    },
    "papermill": {
     "duration": 0.011287,
     "end_time": "2025-05-24T13:18:17.395267",
     "exception": false,
     "start_time": "2025-05-24T13:18:17.383980",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "MODEL_TYPE='protenix'\n",
    "VALIDATION=False\n",
    "SEED=42\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afc92ca",
   "metadata": {
    "papermill": {
     "duration": 0.00312,
     "end_time": "2025-05-24T13:18:17.401743",
     "exception": false,
     "start_time": "2025-05-24T13:18:17.398623",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Install requirements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1eb6c989",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T13:18:17.408357Z",
     "iopub.status.busy": "2025-05-24T13:18:17.408099Z",
     "iopub.status.idle": "2025-05-24T13:18:17.410954Z",
     "shell.execute_reply": "2025-05-24T13:18:17.410344Z"
    },
    "papermill": {
     "duration": 0.007326,
     "end_time": "2025-05-24T13:18:17.412006",
     "exception": false,
     "start_time": "2025-05-24T13:18:17.404680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if MODEL_TYPE=='protenix' and VALIDATION:\n",
    "#     !pip install --no-deps protenix\n",
    "#     !pip install biopython\n",
    "#     !pip install ml-collections\n",
    "#     !pip install biotite==1.0.1\n",
    "#     !pip install rdkit\n",
    "# !export PROTENIX_DATA_ROOT_DIR=/kaggle/input/protenix-checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2af41ab7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T13:18:17.418435Z",
     "iopub.status.busy": "2025-05-24T13:18:17.418205Z",
     "iopub.status.idle": "2025-05-24T13:18:32.489826Z",
     "shell.execute_reply": "2025-05-24T13:18:32.488925Z"
    },
    "papermill": {
     "duration": 15.077101,
     "end_time": "2025-05-24T13:18:32.492026",
     "exception": false,
     "start_time": "2025-05-24T13:18:17.414925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/dependencies-tr-pr/protenix-0.4.6-py3-none-any.whl\r\n",
      "Installing collected packages: protenix\r\n",
      "Successfully installed protenix-0.4.6\r\n",
      "Processing /kaggle/input/dependencies-tr-pr/rdkit-2024.9.6-cp310-cp310-manylinux_2_28_x86_64.whl\r\n",
      "Installing collected packages: rdkit\r\n",
      "Successfully installed rdkit-2024.9.6\r\n",
      "Processing /kaggle/input/dependencies-tr-pr/ml_collections-1.1.0-py3-none-any.whl\r\n",
      "Installing collected packages: ml-collections\r\n",
      "Successfully installed ml-collections-1.1.0\r\n",
      "Processing /kaggle/input/dependencies-tr-pr/biopython-1.85-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Installing collected packages: biopython\r\n",
      "Successfully installed biopython-1.85\r\n",
      "Processing /kaggle/input/dependencies-tr-pr/blosc-1.11.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Installing collected packages: blosc\r\n",
      "Successfully installed blosc-1.11.2\r\n",
      "Processing /kaggle/input/dependencies-tr-pr/ml_collections-1.1.0-py3-none-any.whl\r\n",
      "ml-collections is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\r\n",
      "Processing /kaggle/input/dependencies-tr-pr/biotraj-1.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Installing collected packages: biotraj\r\n",
      "Successfully installed biotraj-1.2.2\r\n",
      "Processing /kaggle/input/dependencies-tr-pr/biotite-1.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Installing collected packages: biotite\r\n",
      "Successfully installed biotite-1.0.1\r\n",
      "Processing /kaggle/input/dependencies-tr-pr/biopandas-0.5.1-py3-none-any.whl\r\n",
      "Installing collected packages: biopandas\r\n",
      "Successfully installed biopandas-0.5.1\r\n",
      "Processing /kaggle/input/dependencies-tr-pr/looseversion-1.1.2-py3-none-any.whl\r\n",
      "Installing collected packages: looseversion\r\n",
      "Successfully installed looseversion-1.1.2\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --no-deps '/kaggle/input/dependencies-tr-pr/protenix-0.4.6-py3-none-any.whl'\n",
    "!pip install --no-deps '/kaggle/input/dependencies-tr-pr/rdkit-2024.9.6-cp310-cp310-manylinux_2_28_x86_64.whl'\n",
    "!pip install --no-deps '/kaggle/input/dependencies-tr-pr/ml_collections-1.1.0-py3-none-any.whl'\n",
    "!pip install --no-deps '/kaggle/input/dependencies-tr-pr/biopython-1.85-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl'\n",
    "# !pip install --no-deps '/kaggle/input/dependencies-tr-pr/pyrosetta-2025.13-cp310-cp310-linux_x86_64.whl'\n",
    "!pip install --no-deps '/kaggle/input/dependencies-tr-pr/blosc-1.11.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl'\n",
    "!pip install --no-deps '/kaggle/input/dependencies-tr-pr/ml_collections-1.1.0-py3-none-any.whl'\n",
    "!pip install --no-deps '/kaggle/input/dependencies-tr-pr/biotraj-1.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl'\n",
    "!pip install --no-deps '/kaggle/input/dependencies-tr-pr/biotite-1.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl'\n",
    "!pip install --no-deps '/kaggle/input/dependencies-tr-pr/biopandas-0.5.1-py3-none-any.whl'\n",
    "!pip install --no-deps '/kaggle/input/dependencies-tr-pr/looseversion-1.1.2-py3-none-any.whl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f380e9fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T13:18:32.501601Z",
     "iopub.status.busy": "2025-05-24T13:18:32.501345Z",
     "iopub.status.idle": "2025-05-24T13:18:32.850624Z",
     "shell.execute_reply": "2025-05-24T13:18:32.849488Z"
    },
    "papermill": {
     "duration": 0.355622,
     "end_time": "2025-05-24T13:18:32.852217",
     "exception": false,
     "start_time": "2025-05-24T13:18:32.496595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "components.v20240608.cif\t\tmodel_v0.2.0.pt\r\n",
      "components.v20240608.cif.rdkit_mol.pkl\r\n"
     ]
    }
   ],
   "source": [
    "! mkdir /af3-dev \n",
    "! ln -s /kaggle/input/protenix-checkpoints /af3-dev/release_data\n",
    "! ls /af3-dev/release_data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9693ac9",
   "metadata": {
    "papermill": {
     "duration": 0.004083,
     "end_time": "2025-05-24T13:18:32.860825",
     "exception": false,
     "start_time": "2025-05-24T13:18:32.856742",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Helper scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1a5d0df",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-24T13:18:32.870054Z",
     "iopub.status.busy": "2025-05-24T13:18:32.869768Z",
     "iopub.status.idle": "2025-05-24T13:18:36.781991Z",
     "shell.execute_reply": "2025-05-24T13:18:36.780975Z"
    },
    "papermill": {
     "duration": 3.918457,
     "end_time": "2025-05-24T13:18:36.783377",
     "exception": false,
     "start_time": "2025-05-24T13:18:32.864920",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORT OK !!!!\n"
     ]
    }
   ],
   "source": [
    "import Bio\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import pandas as pd\n",
    "from Bio.PDB import Atom, Model, Chain, Residue, Structure, PDBParser\n",
    "from Bio import SeqIO\n",
    "import os, sys\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "time0=time.time()\n",
    "\n",
    "print('IMPORT OK !!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aba9d17c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T13:18:36.792933Z",
     "iopub.status.busy": "2025-05-24T13:18:36.792550Z",
     "iopub.status.idle": "2025-05-24T13:18:37.038350Z",
     "shell.execute_reply": "2025-05-24T13:18:37.037133Z"
    },
    "papermill": {
     "duration": 0.252127,
     "end_time": "2025-05-24T13:18:37.039939",
     "exception": false,
     "start_time": "2025-05-24T13:18:36.787812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: cd: /kaggle/input/data-for-demo-for-rhofold-plus-with-kaggle-msa/RhoFold-main: No such file or directory\r\n",
      "__notebook__.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!cd /kaggle/input/data-for-demo-for-rhofold-plus-with-kaggle-msa/RhoFold-main\n",
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90392941",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T13:18:37.050063Z",
     "iopub.status.busy": "2025-05-24T13:18:37.049800Z",
     "iopub.status.idle": "2025-05-24T13:18:37.149904Z",
     "shell.execute_reply": "2025-05-24T13:18:37.149179Z"
    },
    "papermill": {
     "duration": 0.106575,
     "end_time": "2025-05-24T13:18:37.151133",
     "exception": false,
     "start_time": "2025-05-24T13:18:37.044558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PYTHON /usr/bin/python3\n",
      "HELPER OK!!!\n"
     ]
    }
   ],
   "source": [
    "PYTHON = sys.executable\n",
    "print('PYTHON',PYTHON)\n",
    "\n",
    "RHONET_DIR=\\\n",
    "'/kaggle/input/data-for-demo-for-rhofold-plus-with-kaggle-msa/RhoFold-main'\n",
    "#'<your downloaded rhofold repo>/RhoFold-main'\n",
    "\n",
    "USALIGN = \\\n",
    "'/kaggle/working//USalign'\n",
    "#'<your us align path>/USalign'\n",
    "\n",
    "os.system('cp /kaggle/input/usalign/USalign /kaggle/working/')\n",
    "os.system('sudo chmod u+x /kaggle/working//USalign')\n",
    "sys.path.append(RHONET_DIR)\n",
    "\n",
    "\n",
    "DATA_KAGGLE_DIR = '/kaggle/input/stanford-rna-3d-folding'\n",
    "\n",
    "\n",
    "# helper ----\n",
    "class dotdict(dict):\n",
    "\t__setattr__ = dict.__setitem__\n",
    "\t__delattr__ = dict.__delitem__\n",
    "\n",
    "\tdef __getattr__(self, name):\n",
    "\t\ttry:\n",
    "\t\t\treturn self[name]\n",
    "\t\texcept KeyError:\n",
    "\t\t\traise AttributeError(name)\n",
    "\n",
    "# visualisation helper ----\n",
    "def set_aspect_equal(ax):\n",
    "\tx_limits = ax.get_xlim()\n",
    "\ty_limits = ax.get_ylim()\n",
    "\tz_limits = ax.get_zlim()\n",
    "\n",
    "\t# Compute the mean of each axis\n",
    "\tx_middle = np.mean(x_limits)\n",
    "\ty_middle = np.mean(y_limits)\n",
    "\tz_middle = np.mean(z_limits)\n",
    "\n",
    "\t# Compute the max range across all axes\n",
    "\tmax_range = max(x_limits[1] - x_limits[0],\n",
    "\t\t\t\t\ty_limits[1] - y_limits[0],\n",
    "\t\t\t\t\tz_limits[1] - z_limits[0]) / 2.0\n",
    "\n",
    "\t# Set the new limits to ensure equal scaling\n",
    "\tax.set_xlim(x_middle - max_range, x_middle + max_range)\n",
    "\tax.set_ylim(y_middle - max_range, y_middle + max_range)\n",
    "\tax.set_zlim(z_middle - max_range, z_middle + max_range)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# xyz df helper --------------------\n",
    "def get_truth_df(target_id):\n",
    "    truth_df = LABEL_DF[LABEL_DF['target_id'] == target_id]\n",
    "    truth_df = truth_df.reset_index(drop=True)\n",
    "    return truth_df\n",
    "\n",
    "def parse_output_to_df(output, seq, target_id):\n",
    "    df = []\n",
    "    chain_data = []\n",
    "    for i, res in enumerate(seq):\n",
    "        d=dict(ID = target_id,\n",
    "                    resname=res,\n",
    "                    resid=i+1)\n",
    "        for n in range(len(output)):\n",
    "            d={**d, f'x_{n+1}': round(output[n,i,0].item(),3),\n",
    "                     f'y_{n+1}': round(output[n,i,1].item(),3),\n",
    "                     f'z_{n+1}': round(output[n,i,2].item(),3)}\n",
    "        chain_data.append(d)\n",
    "\n",
    "    if len(chain_data)!=0:\n",
    "        chain_df = pd.DataFrame(chain_data)\n",
    "        df.append(chain_df)\n",
    "        ##print(chain_df)\n",
    "    return df\n",
    "\n",
    "def parse_pdb_to_df(pdb_file, target_id):\n",
    "    parser = PDBParser()\n",
    "    structure = parser.get_structure('', pdb_file)\n",
    "\n",
    "    df = []\n",
    "    for model in structure:\n",
    "        for chain in model:\n",
    "            print(chain)\n",
    "            chain_data = []\n",
    "            for residue in chain:\n",
    "                # print(residue)\n",
    "                if residue.get_resname() in ['A', 'U', 'G', 'C']:\n",
    "                    # Check if the residue has a C1' atom\n",
    "                    if 'C1\\'' in residue:\n",
    "                        atom = residue['C1\\'']\n",
    "                        xyz = atom.get_coord()\n",
    "                        resname = residue.get_resname()\n",
    "                        resid = residue.get_id()[1]\n",
    "\n",
    "                        #todo detect discontinous: resid = prev_resid+1\n",
    "                        #ID\tresname\tresid\tx_1\ty_1\tz_1\n",
    "                        chain_data.append(dict(\n",
    "                            ID = target_id+'_'+str(resid),\n",
    "                            resname=resname,\n",
    "                            resid=resid,\n",
    "                            x_1=xyz[0],\n",
    "                            y_1=xyz[1],\n",
    "                            z_1=xyz[2],\n",
    "                        ))\n",
    "                        ##print(f\"Residue {resname} {resid}, Atom: {atom.get_name()}, xyz: {xyz}\")\n",
    "\n",
    "            if len(chain_data)!=0:\n",
    "                chain_df = pd.DataFrame(chain_data)\n",
    "                df.append(chain_df)\n",
    "                ##print(chain_df)\n",
    "    return df\n",
    "\n",
    "# usalign helper --------------------\n",
    "def write_target_line(\n",
    "    atom_name, atom_serial, residue_name, chain_id, residue_num, x_coord, y_coord, z_coord, occupancy=1.0, b_factor=0.0, atom_type='P'\n",
    "):\n",
    "    \"\"\"\n",
    "    Writes a single line of PDB format based on provided atom information.\n",
    "\n",
    "    Args:\n",
    "        atom_name (str): Name of the atom (e.g., \"N\", \"CA\").\n",
    "        atom_serial (int): Atom serial number.\n",
    "        residue_name (str): Residue name (e.g., \"ALA\").\n",
    "        chain_id (str): Chain identifier.\n",
    "        residue_num (int): Residue number.\n",
    "        x_coord (float): X coordinate.\n",
    "        y_coord (float): Y coordinate.\n",
    "        z_coord (float): Z coordinate.\n",
    "        occupancy (float, optional): Occupancy value (default: 1.0).\n",
    "        b_factor (float, optional): B-factor value (default: 0.0).\n",
    "\n",
    "    Returns:\n",
    "        str: A single line of PDB string.\n",
    "    \"\"\"\n",
    "    return f'ATOM  {atom_serial:>5d}  {atom_name:<5s} {residue_name:<3s} {residue_num:>3d}    {x_coord:>8.3f}{y_coord:>8.3f}{z_coord:>8.3f}{occupancy:>6.2f}{b_factor:>6.2f}           {atom_type}\\n'\n",
    "\n",
    "def write_xyz_to_pdb(df, pdb_file, xyz_id = 1):\n",
    "    resolved_cnt = 0\n",
    "    with open(pdb_file, 'w') as target_file:\n",
    "        for _, row in df.iterrows():\n",
    "            x_coord = row[f'x_{xyz_id}']\n",
    "            y_coord = row[f'y_{xyz_id}']\n",
    "            z_coord = row[f'z_{xyz_id}']\n",
    "\n",
    "            if x_coord > -1e17 and y_coord > -1e17 and z_coord > -1e17:\n",
    "                resolved_cnt += 1\n",
    "                target_line = write_target_line(\n",
    "                    atom_name=\"C1'\",\n",
    "                    atom_serial=int(row['resid']),\n",
    "                    residue_name=row['resname'],\n",
    "                    chain_id='0',\n",
    "                    residue_num=int(row['resid']),\n",
    "                    x_coord=x_coord,\n",
    "                    y_coord=y_coord,\n",
    "                    z_coord=z_coord,\n",
    "                    atom_type='C',\n",
    "                )\n",
    "                target_file.write(target_line)\n",
    "    return resolved_cnt\n",
    "\n",
    "def parse_usalign_for_tm_score(output):\n",
    "    # Extract TM-score based on length of reference structure (second)\n",
    "    tm_score_match = re.findall(r'TM-score=\\s+([\\d.]+)', output)[1]\n",
    "    if not tm_score_match:\n",
    "        raise ValueError('No TM score found')\n",
    "    return float(tm_score_match)\n",
    "\n",
    "def parse_usalign_for_transform(output):\n",
    "    # Locate the rotation matrix section\n",
    "    matrix_lines = []\n",
    "    found_matrix = False\n",
    "\n",
    "    for line in output.splitlines():\n",
    "        if \"The rotation matrix to rotate Structure_1 to Structure_2\" in line:\n",
    "            found_matrix = True\n",
    "        elif found_matrix and re.match(r'^\\d+\\s+[-\\d.]+\\s+[-\\d.]+\\s+[-\\d.]+\\s+[-\\d.]+$', line):\n",
    "            matrix_lines.append(line)\n",
    "        elif found_matrix and not line.strip():\n",
    "            break  # Stop parsing if an empty line is encountered after the matrix\n",
    "\n",
    "    # Parse the rotation matrix values\n",
    "    rotation_matrix = []\n",
    "    for line in matrix_lines:\n",
    "        parts = line.split()\n",
    "        row_values = list(map(float, parts[1:]))  # Skip the first column (index)\n",
    "        rotation_matrix.append(row_values)\n",
    "\n",
    "    return np.array(rotation_matrix)\n",
    "\n",
    "def call_usalign(predict_df, truth_df, verbose=1):\n",
    "    truth_pdb = '~truth.pdb'\n",
    "    predict_pdb = '~predict.pdb'\n",
    "    write_xyz_to_pdb(predict_df, predict_pdb, xyz_id=1)\n",
    "    write_xyz_to_pdb(truth_df, truth_pdb, xyz_id=1)\n",
    "\n",
    "    command = f'{USALIGN} {predict_pdb} {truth_pdb} -atom \" C1\\'\" -m -'\n",
    "    output = os.popen(command).read()\n",
    "    if verbose==1:\n",
    "        print(output)\n",
    "    tm_score = parse_usalign_for_tm_score(output)\n",
    "    transform = parse_usalign_for_transform(output)\n",
    "    return tm_score, transform\n",
    "\n",
    "print('HELPER OK!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c7094e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T13:18:37.161023Z",
     "iopub.status.busy": "2025-05-24T13:18:37.160776Z",
     "iopub.status.idle": "2025-05-24T13:18:37.165378Z",
     "shell.execute_reply": "2025-05-24T13:18:37.164537Z"
    },
    "papermill": {
     "duration": 0.010756,
     "end_time": "2025-05-24T13:18:37.166568",
     "exception": false,
     "start_time": "2025-05-24T13:18:37.155812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dac3e34d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T13:18:37.176189Z",
     "iopub.status.busy": "2025-05-24T13:18:37.175946Z",
     "iopub.status.idle": "2025-05-24T13:18:42.036853Z",
     "shell.execute_reply": "2025-05-24T13:18:42.036119Z"
    },
    "papermill": {
     "duration": 4.867396,
     "end_time": "2025-05-24T13:18:42.038472",
     "exception": false,
     "start_time": "2025-05-24T13:18:37.171076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if MODEL_TYPE=='protenix':\n",
    "    \n",
    "    \n",
    "    from runner.batch_inference import get_default_runner\n",
    "    from runner.inference import update_inference_configs, InferenceRunner\n",
    "\n",
    "    from protenix.data.infer_data_pipeline import InferenceDataset\n",
    "\n",
    "    seed_everything(SEED)\n",
    "\n",
    "    class DictDataset(InferenceDataset):\n",
    "        def __init__(\n",
    "            self,\n",
    "            seq_list: list,\n",
    "            dump_dir: str,\n",
    "            id_list: list = None,\n",
    "            use_msa: bool = False,\n",
    "        ) -> None:\n",
    "\n",
    "            self.dump_dir = dump_dir\n",
    "            self.use_msa = use_msa\n",
    "            if isinstance(id_list,type(None)):\n",
    "                self.inputs = [{\"sequences\": \n",
    "                                [{\"rnaSequence\": \n",
    "                                  {\"sequence\": seq, \n",
    "                                   \"count\": 1}}],\n",
    "                                \"name\": \"query\"} for seq in seq_list]\n",
    "            else:\n",
    "                self.inputs = [{\"sequences\": \n",
    "                                [{\"rnaSequence\": \n",
    "                                  {\"sequence\": seq, \n",
    "                                   \"count\": 1}}],\n",
    "                                \"name\": i} for i, seq in zip(id_list,seq_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea3e76bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T13:18:42.049521Z",
     "iopub.status.busy": "2025-05-24T13:18:42.049009Z",
     "iopub.status.idle": "2025-05-24T13:18:57.886644Z",
     "shell.execute_reply": "2025-05-24T13:18:57.885934Z"
    },
    "papermill": {
     "duration": 15.844357,
     "end_time": "2025-05-24T13:18:57.888214",
     "exception": false,
     "start_time": "2025-05-24T13:18:42.043857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train scheduler 16.0\n",
      "inference scheduler 16.0\n",
      "Diffusion Module has 16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/runner/inference.py:107: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, self.device)\n"
     ]
    }
   ],
   "source": [
    "if MODEL_TYPE=='protenix':\n",
    "\n",
    "    from configs.configs_base import configs as configs_base\n",
    "    from configs.configs_data import data_configs\n",
    "    from configs.configs_inference import inference_configs\n",
    "    from protenix.config.config import parse_configs\n",
    "\n",
    "    configs_base[\"use_deepspeed_evo_attention\"] = (\n",
    "    os.environ.get(\"USE_DEEPSPEED_EVO_ATTENTION\", False) == \"true\")\n",
    "    configs_base[\"model\"][\"N_cycle\"] = 10 #10\n",
    "    configs_base[\"sample_diffusion\"][\"N_sample\"] = (1 if VALIDATION else 5)\n",
    "    configs_base[\"sample_diffusion\"][\"N_step\"] = 200\n",
    "    inference_configs['load_checkpoint_path']='/kaggle/input/protenix-checkpoints/model_v0.2.0.pt'\n",
    "    configs = {**configs_base, **{\"data\": data_configs}, **inference_configs}\n",
    "\n",
    "    configs = parse_configs(\n",
    "            configs=configs,\n",
    "            fill_required_with_null=True,\n",
    "        )\n",
    "    \n",
    "    runner=InferenceRunner(configs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc545f4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T13:18:57.898898Z",
     "iopub.status.busy": "2025-05-24T13:18:57.898644Z",
     "iopub.status.idle": "2025-05-24T13:18:57.902390Z",
     "shell.execute_reply": "2025-05-24T13:18:57.901726Z"
    },
    "papermill": {
     "duration": 0.010264,
     "end_time": "2025-05-24T13:18:57.903524",
     "exception": false,
     "start_time": "2025-05-24T13:18:57.893260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if VALIDATION:\n",
    "    LABEL_DF = pd.read_csv('/kaggle/input/stanford-rna-3d-folding/train_labels.csv')\n",
    "    LABEL_DF['target_id'] = LABEL_DF['ID'].apply(lambda x: '_'.join(x.split('_')[:-1]))\n",
    "    train_df=pd.read_csv('/kaggle/input/stanford-rna-3d-folding/train_sequences.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31ca1dea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T13:18:57.913212Z",
     "iopub.status.busy": "2025-05-24T13:18:57.913004Z",
     "iopub.status.idle": "2025-05-24T13:18:57.919363Z",
     "shell.execute_reply": "2025-05-24T13:18:57.918709Z"
    },
    "papermill": {
     "duration": 0.012399,
     "end_time": "2025-05-24T13:18:57.920469",
     "exception": false,
     "start_time": "2025-05-24T13:18:57.908070",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "if MODEL_TYPE=='protenix' and VALIDATION:\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")  \n",
    "    \n",
    "    train_df['protenix_tm_score']=None\n",
    "    dataset = DictDataset(train_df.sequence, dump_dir='output', id_list=train_df.target_id, use_msa=False)\n",
    "    num_data = len(dataset)\n",
    "    for i, seq in tqdm(enumerate(train_df.sequence),total=num_data):\n",
    "        if train_df.loc[i,'protenix_tm_score']!=None:\n",
    "            continue\n",
    "        if len(seq)>300:\n",
    "            continue\n",
    "        target_id = train_df.loc[i,'target_id']\n",
    "        truth_df = get_truth_df(target_id)\n",
    "        if sum(~np.isnan(truth_df.x_1))<3:\n",
    "            continue\n",
    "        data, atom_array, data_error_message=dataset[i]\n",
    "        if data_error_message!='':\n",
    "            continue\n",
    "        new_configs = update_inference_configs(configs, data[\"N_token\"].item())\n",
    "        runner.update_model_configs(new_configs)\n",
    "        prediction = runner.predict(data)\n",
    "        prediction=prediction['coordinate'][:,data['input_feature_dict']['atom_to_tokatom_idx']==12]       \n",
    "        result = parse_output_to_df(prediction[:1], seq, target_id)[0]\n",
    "        try:\n",
    "            tm_score, transform = call_usalign(result, truth_df, verbose=0)\n",
    "            train_df.loc[i,'protenix_tm_score']=tm_score\n",
    "        except:\n",
    "            pass\n",
    "        if (time.time()-time0)>(12*3600-360):\n",
    "            break\n",
    "    train_df.to_csv('tm_scores.csv', index=False)\n",
    "    print(train_df.protenix_tm_score.mean())\n",
    "    display(train_df.protenix_tm_score.hist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c119b65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T13:18:57.929991Z",
     "iopub.status.busy": "2025-05-24T13:18:57.929711Z",
     "iopub.status.idle": "2025-05-24T14:05:34.564882Z",
     "shell.execute_reply": "2025-05-24T14:05:34.563826Z"
    },
    "papermill": {
     "duration": 2796.641403,
     "end_time": "2025-05-24T14:05:34.566254",
     "exception": false,
     "start_time": "2025-05-24T13:18:57.924851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [46:36<00:00, 233.05s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>resname</th>\n",
       "      <th>resid</th>\n",
       "      <th>x_1</th>\n",
       "      <th>y_1</th>\n",
       "      <th>z_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>y_2</th>\n",
       "      <th>z_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>y_3</th>\n",
       "      <th>z_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>y_4</th>\n",
       "      <th>z_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>y_5</th>\n",
       "      <th>z_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R1107_1</td>\n",
       "      <td>G</td>\n",
       "      <td>1</td>\n",
       "      <td>8.238</td>\n",
       "      <td>1.237</td>\n",
       "      <td>-3.255</td>\n",
       "      <td>4.066</td>\n",
       "      <td>-0.505</td>\n",
       "      <td>-9.335</td>\n",
       "      <td>-9.482</td>\n",
       "      <td>-2.331</td>\n",
       "      <td>16.518</td>\n",
       "      <td>0.943</td>\n",
       "      <td>-9.468</td>\n",
       "      <td>0.403</td>\n",
       "      <td>8.564</td>\n",
       "      <td>3.232</td>\n",
       "      <td>18.922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R1107_2</td>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "      <td>8.664</td>\n",
       "      <td>-1.611</td>\n",
       "      <td>-8.135</td>\n",
       "      <td>9.846</td>\n",
       "      <td>1.105</td>\n",
       "      <td>-8.665</td>\n",
       "      <td>-13.645</td>\n",
       "      <td>1.595</td>\n",
       "      <td>16.258</td>\n",
       "      <td>0.758</td>\n",
       "      <td>-8.897</td>\n",
       "      <td>-5.204</td>\n",
       "      <td>13.446</td>\n",
       "      <td>5.576</td>\n",
       "      <td>17.157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R1107_3</td>\n",
       "      <td>G</td>\n",
       "      <td>3</td>\n",
       "      <td>6.281</td>\n",
       "      <td>-5.795</td>\n",
       "      <td>-11.245</td>\n",
       "      <td>13.390</td>\n",
       "      <td>5.132</td>\n",
       "      <td>-6.627</td>\n",
       "      <td>-15.242</td>\n",
       "      <td>6.660</td>\n",
       "      <td>13.894</td>\n",
       "      <td>-0.320</td>\n",
       "      <td>-5.572</td>\n",
       "      <td>-9.645</td>\n",
       "      <td>17.675</td>\n",
       "      <td>5.817</td>\n",
       "      <td>13.139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R1107_4</td>\n",
       "      <td>G</td>\n",
       "      <td>4</td>\n",
       "      <td>2.402</td>\n",
       "      <td>-9.920</td>\n",
       "      <td>-12.474</td>\n",
       "      <td>14.514</td>\n",
       "      <td>10.165</td>\n",
       "      <td>-4.289</td>\n",
       "      <td>-14.583</td>\n",
       "      <td>11.442</td>\n",
       "      <td>10.478</td>\n",
       "      <td>-1.439</td>\n",
       "      <td>-0.593</td>\n",
       "      <td>-11.776</td>\n",
       "      <td>20.145</td>\n",
       "      <td>4.348</td>\n",
       "      <td>8.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R1107_5</td>\n",
       "      <td>G</td>\n",
       "      <td>5</td>\n",
       "      <td>-2.642</td>\n",
       "      <td>-12.251</td>\n",
       "      <td>-12.027</td>\n",
       "      <td>13.414</td>\n",
       "      <td>14.756</td>\n",
       "      <td>-1.540</td>\n",
       "      <td>-12.236</td>\n",
       "      <td>13.832</td>\n",
       "      <td>6.126</td>\n",
       "      <td>-2.058</td>\n",
       "      <td>4.978</td>\n",
       "      <td>-12.160</td>\n",
       "      <td>20.124</td>\n",
       "      <td>2.159</td>\n",
       "      <td>3.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2510</th>\n",
       "      <td>R1190_114</td>\n",
       "      <td>U</td>\n",
       "      <td>114</td>\n",
       "      <td>23.637</td>\n",
       "      <td>-15.008</td>\n",
       "      <td>-6.213</td>\n",
       "      <td>-10.847</td>\n",
       "      <td>-0.222</td>\n",
       "      <td>26.654</td>\n",
       "      <td>-7.315</td>\n",
       "      <td>6.439</td>\n",
       "      <td>-14.572</td>\n",
       "      <td>6.368</td>\n",
       "      <td>-9.545</td>\n",
       "      <td>-10.935</td>\n",
       "      <td>17.480</td>\n",
       "      <td>9.050</td>\n",
       "      <td>-6.331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2511</th>\n",
       "      <td>R1190_115</td>\n",
       "      <td>U</td>\n",
       "      <td>115</td>\n",
       "      <td>26.128</td>\n",
       "      <td>-10.615</td>\n",
       "      <td>-6.281</td>\n",
       "      <td>-12.939</td>\n",
       "      <td>3.521</td>\n",
       "      <td>23.809</td>\n",
       "      <td>-7.668</td>\n",
       "      <td>11.021</td>\n",
       "      <td>-12.105</td>\n",
       "      <td>11.084</td>\n",
       "      <td>-10.894</td>\n",
       "      <td>-9.545</td>\n",
       "      <td>15.139</td>\n",
       "      <td>13.215</td>\n",
       "      <td>-8.320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2512</th>\n",
       "      <td>R1190_116</td>\n",
       "      <td>U</td>\n",
       "      <td>116</td>\n",
       "      <td>29.293</td>\n",
       "      <td>-6.456</td>\n",
       "      <td>-4.883</td>\n",
       "      <td>-16.412</td>\n",
       "      <td>5.950</td>\n",
       "      <td>20.393</td>\n",
       "      <td>-7.900</td>\n",
       "      <td>16.520</td>\n",
       "      <td>-11.462</td>\n",
       "      <td>15.622</td>\n",
       "      <td>-13.947</td>\n",
       "      <td>-8.300</td>\n",
       "      <td>14.490</td>\n",
       "      <td>18.377</td>\n",
       "      <td>-10.160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2513</th>\n",
       "      <td>R1190_117</td>\n",
       "      <td>U</td>\n",
       "      <td>117</td>\n",
       "      <td>33.742</td>\n",
       "      <td>-3.671</td>\n",
       "      <td>-3.037</td>\n",
       "      <td>-21.354</td>\n",
       "      <td>7.015</td>\n",
       "      <td>18.014</td>\n",
       "      <td>-9.411</td>\n",
       "      <td>21.423</td>\n",
       "      <td>-13.293</td>\n",
       "      <td>18.974</td>\n",
       "      <td>-18.003</td>\n",
       "      <td>-9.521</td>\n",
       "      <td>16.213</td>\n",
       "      <td>22.734</td>\n",
       "      <td>-12.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2514</th>\n",
       "      <td>R1190_118</td>\n",
       "      <td>U</td>\n",
       "      <td>118</td>\n",
       "      <td>38.908</td>\n",
       "      <td>-3.693</td>\n",
       "      <td>-2.607</td>\n",
       "      <td>-26.592</td>\n",
       "      <td>6.965</td>\n",
       "      <td>18.659</td>\n",
       "      <td>-12.635</td>\n",
       "      <td>23.823</td>\n",
       "      <td>-16.644</td>\n",
       "      <td>20.440</td>\n",
       "      <td>-21.169</td>\n",
       "      <td>-13.324</td>\n",
       "      <td>19.678</td>\n",
       "      <td>24.528</td>\n",
       "      <td>-16.039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2515 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID resname  resid     x_1     y_1     z_1     x_2     y_2  \\\n",
       "0       R1107_1       G      1   8.238   1.237  -3.255   4.066  -0.505   \n",
       "1       R1107_2       G      2   8.664  -1.611  -8.135   9.846   1.105   \n",
       "2       R1107_3       G      3   6.281  -5.795 -11.245  13.390   5.132   \n",
       "3       R1107_4       G      4   2.402  -9.920 -12.474  14.514  10.165   \n",
       "4       R1107_5       G      5  -2.642 -12.251 -12.027  13.414  14.756   \n",
       "...         ...     ...    ...     ...     ...     ...     ...     ...   \n",
       "2510  R1190_114       U    114  23.637 -15.008  -6.213 -10.847  -0.222   \n",
       "2511  R1190_115       U    115  26.128 -10.615  -6.281 -12.939   3.521   \n",
       "2512  R1190_116       U    116  29.293  -6.456  -4.883 -16.412   5.950   \n",
       "2513  R1190_117       U    117  33.742  -3.671  -3.037 -21.354   7.015   \n",
       "2514  R1190_118       U    118  38.908  -3.693  -2.607 -26.592   6.965   \n",
       "\n",
       "         z_2     x_3     y_3     z_3     x_4     y_4     z_4     x_5     y_5  \\\n",
       "0     -9.335  -9.482  -2.331  16.518   0.943  -9.468   0.403   8.564   3.232   \n",
       "1     -8.665 -13.645   1.595  16.258   0.758  -8.897  -5.204  13.446   5.576   \n",
       "2     -6.627 -15.242   6.660  13.894  -0.320  -5.572  -9.645  17.675   5.817   \n",
       "3     -4.289 -14.583  11.442  10.478  -1.439  -0.593 -11.776  20.145   4.348   \n",
       "4     -1.540 -12.236  13.832   6.126  -2.058   4.978 -12.160  20.124   2.159   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "2510  26.654  -7.315   6.439 -14.572   6.368  -9.545 -10.935  17.480   9.050   \n",
       "2511  23.809  -7.668  11.021 -12.105  11.084 -10.894  -9.545  15.139  13.215   \n",
       "2512  20.393  -7.900  16.520 -11.462  15.622 -13.947  -8.300  14.490  18.377   \n",
       "2513  18.014  -9.411  21.423 -13.293  18.974 -18.003  -9.521  16.213  22.734   \n",
       "2514  18.659 -12.635  23.823 -16.644  20.440 -21.169 -13.324  19.678  24.528   \n",
       "\n",
       "         z_5  \n",
       "0     18.922  \n",
       "1     17.157  \n",
       "2     13.139  \n",
       "3      8.075  \n",
       "4      3.016  \n",
       "...      ...  \n",
       "2510  -6.331  \n",
       "2511  -8.320  \n",
       "2512 -10.160  \n",
       "2513 -12.720  \n",
       "2514 -16.039  \n",
       "\n",
       "[2515 rows x 18 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if MODEL_TYPE=='protenix' and not VALIDATION:\n",
    "    test_df=pd.read_csv('/kaggle/input/stanford-rna-3d-folding/test_sequences.csv')\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")  \n",
    "    \n",
    "    dataset = DictDataset(test_df.sequence, dump_dir='output', id_list=test_df.target_id, use_msa=False)\n",
    "    num_data = len(dataset)\n",
    "    for i, seq in tqdm(enumerate(test_df.sequence),total=num_data):\n",
    "        try:\n",
    "            data, atom_array, data_error_message=dataset[i]\n",
    "            target_id = data[\"sample_name\"]\n",
    "            assert target_id==test_df.target_id[i]\n",
    "            assert data_error_message==''\n",
    "            \n",
    "            new_configs = update_inference_configs(configs, data[\"N_token\"].item())\n",
    "            runner.update_model_configs(new_configs)\n",
    "            prediction = runner.predict(data)\n",
    "            prediction=prediction['coordinate'][:,data['input_feature_dict']['atom_to_tokatom_idx']==12]\n",
    "\n",
    "            result = parse_output_to_df(prediction, seq, target_id)[0]\n",
    "        except:\n",
    "            target_id==test_df.target_id[i]\n",
    "            print('Failed to predict', target_id)\n",
    "            result=pd.DataFrame(columns=['ID', 'resname', 'resid', \n",
    "                                         'x_1', 'y_1', 'z_1', \n",
    "                                         'x_2', 'y_2', 'z_2',\n",
    "                                         'x_3', 'y_3', 'z_3', \n",
    "                                         'x_4', 'y_4', 'z_4', \n",
    "                                         'x_5', 'y_5', 'z_5'], \n",
    "                                         data=[[target_id, x, j+1] + [0.0]*15 for j, x in enumerate(seq)])\n",
    "            \n",
    "        result['ID']=result.apply(lambda x: x.ID + '_' + str(x.resid), axis=1)\n",
    "        result.to_csv('submission.csv', index=False, mode='a', header=(i==0))\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    display(pd.read_csv('submission.csv'))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 12276181,
     "sourceId": 87793,
     "sourceType": "competition"
    },
    {
     "datasetId": 6742586,
     "sourceId": 10855324,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6933267,
     "sourceId": 11118830,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7317710,
     "sourceId": 11661237,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 224830487,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "proteniX",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2843.07441,
   "end_time": "2025-05-24T14:05:37.775863",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-24T13:18:14.701453",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
