{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b8dd047",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-29T10:35:08.088602Z",
     "iopub.status.busy": "2025-09-29T10:35:08.087612Z",
     "iopub.status.idle": "2025-09-29T10:56:56.205693Z",
     "shell.execute_reply": "2025-09-29T10:56:56.204170Z"
    },
    "papermill": {
     "duration": 1308.126994,
     "end_time": "2025-09-29T10:56:56.208853",
     "exception": false,
     "start_time": "2025-09-29T10:35:08.081859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading train/test metadata…\n",
      "1. Processing videos with ['body_center', 'ear_left', 'ear_right', 'headpiece_bottombackleft', 'headpiece_bottombackright', 'headpiece_bottomfrontleft', 'headpiece_bottomfrontright', 'headpiece_topbackleft', 'headpiece_topbackright', 'headpiece_topfrontleft', 'headpiece_topfrontright', 'lateral_left', 'lateral_right', 'neck', 'nose', 'tail_base', 'tail_midpoint', 'tail_tip']\n",
      "X_tr.shape=(544859, 40)\n",
      "n_videos: 1\n",
      "video with missing values 438887472 test 1089866 frames\n",
      "- test single 438887472 1\n",
      "- test single 438887472 2\n",
      "- test single 438887472 3\n",
      "- test single 438887472 4\n",
      "X_tr.shape=(1744248, 84)\n",
      "n_videos: 1\n",
      "video with missing values 438887472 test 1089866 frames\n",
      "- test pair 438887472 1 2\n",
      "- test pair 438887472 1 3\n",
      "- test pair 438887472 1 4\n",
      "- test pair 438887472 2 1\n",
      "- test pair 438887472 2 3\n",
      "- test pair 438887472 2 4\n",
      "- test pair 438887472 3 1\n",
      "- test pair 438887472 3 2\n",
      "- test pair 438887472 3 4\n",
      "- test pair 438887472 4 1\n",
      "- test pair 438887472 4 2\n",
      "- test pair 438887472 4 3\n",
      "\n",
      "2. Processing videos with ['body_center', 'ear_left', 'ear_right', 'hip_left', 'hip_right', 'lateral_left', 'lateral_right', 'nose', 'spine_1', 'spine_2', 'tail_base', 'tail_middle_1', 'tail_middle_2', 'tail_tip']\n",
      "X_tr.shape=(478728, 49)\n",
      "n_videos: 0\n",
      "X_tr.shape=(628714, 103)\n",
      "n_videos: 0\n",
      "\n",
      "3. Processing videos with ['body_center', 'ear_left', 'ear_right', 'lateral_left', 'lateral_right', 'neck', 'nose', 'tail_base', 'tail_midpoint', 'tail_tip']\n",
      "X_tr.shape=(1942233, 40)\n",
      "n_videos: 0\n",
      "X_tr.shape=(5881764, 84)\n",
      "n_videos: 0\n",
      "\n",
      "4. Processing videos with ['body_center', 'ear_left', 'ear_right', 'lateral_left', 'lateral_right', 'nose', 'tail_base', 'tail_tip']\n",
      "X_tr.shape=(2534176, 67)\n",
      "n_videos: 0\n",
      "\n",
      "5. Processing videos with ['body_center', 'ear_left', 'ear_right', 'lateral_left', 'lateral_right', 'nose', 'tail_base']\n",
      "X_tr.shape=(1849144, 52)\n",
      "n_videos: 0\n",
      "\n",
      "6. Processing videos with ['body_center', 'ear_left', 'ear_right', 'nose', 'tail_base']\n",
      "X_tr.shape=(708496, 14)\n",
      "n_videos: 0\n",
      "X_tr.shape=(10212910, 28)\n",
      "n_videos: 0\n",
      "\n",
      "7. Processing videos with ['ear_left', 'ear_right', 'head', 'tail_base']\n",
      "X_tr.shape=(899134, 10)\n",
      "n_videos: 0\n",
      "X_tr.shape=(899134, 19)\n",
      "n_videos: 0\n",
      "\n",
      "8. Processing videos with ['ear_left', 'ear_right', 'hip_left', 'hip_right', 'neck', 'nose', 'tail_base']\n",
      "X_tr.shape=(3020371, 25)\n",
      "n_videos: 0\n",
      "X_tr.shape=(23086736, 52)\n",
      "n_videos: 0\n",
      "\n",
      "9. Processing videos with ['ear_left', 'ear_right', 'nose', 'tail_base', 'tail_tip']\n",
      "X_tr.shape=(329777, 14)\n",
      "n_videos: 0\n",
      "X_tr.shape=(1774618, 28)\n",
      "n_videos: 0\n",
      "\n",
      "[DONE] Wrote submission.csv with 6 rows.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# MABe - Refactored Submit-Only Pipeline \n",
    "# ============================================================\n",
    "\n",
    "from __future__ import annotations\n",
    "import os\n",
    "import gc\n",
    "import json\n",
    "import itertools\n",
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Iterable, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, clone\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# tree models (legacy uses LightGBM)\n",
    "try:\n",
    "    from lightgbm import LGBMClassifier\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\"LightGBM is required. Please ensure it's available on Kaggle.\") from e\n",
    "\n",
    "\n",
    "# ========================\n",
    "# Global flags (unchanged)\n",
    "# ========================\n",
    "validate_or_submit = 'submit'   # FORCE SUBMIT-ONLY\n",
    "verbose = True                  # keep legacy verbosity\n",
    "\n",
    "\n",
    "# ========================\n",
    "# Logging (lightweight)\n",
    "# ========================\n",
    "def log(msg: str):\n",
    "    if verbose:\n",
    "        print(msg, flush=True)\n",
    "\n",
    "# ===== Insight-driven toggles (safe defaults) =====\n",
    "ENABLE_COORD_CLIP = True          # clip (x,y) vào [0, W/H] trước khi pivot\n",
    "USE_HYSTERESIS_DECODER = True     # dùng decoder hysteresis thay vì argmax thuần\n",
    "FILL_EMPTY_VIDEOS = False         # tắt Rule3 'fill empty videos' trong robustify\n",
    "\n",
    "# Labs có nhiều nhãn 1–2 frame (cho phép min_len thấp)\n",
    "SHORT_LABEL_LABS = {'CRIM13', 'CalMS21_task1', 'CalMS21_task2', 'CalMS21_supplemental'}\n",
    "\n",
    "STATE_ACTIONS = {\n",
    "    'rest','sniff','sniffface','sniffgenital','mount','intromit','reciprocalsniff'\n",
    "}\n",
    "EVENT_ACTIONS = {\n",
    "    'approach','avoid','follow','chase','chaseattack','attack','defend','flinch',\n",
    "    'tussle','dominance','escape','submit','attemptmount'\n",
    "}\n",
    "\n",
    "# Tham số decoder mặc định (có thể tinh chỉnh thêm)\n",
    "DEFAULT_PER_ACTION = {\n",
    "    # state-like: dài, mượt hơn\n",
    "    'sniff':        dict(t_on=0.55, t_off=0.40, min_len=6,  merge_gap=6,  smooth_k=11),\n",
    "    'sniffface':    dict(t_on=0.55, t_off=0.40, min_len=6,  merge_gap=6,  smooth_k=11),\n",
    "    'sniffgenital': dict(t_on=0.60, t_off=0.45, min_len=8,  merge_gap=8,  smooth_k=13),\n",
    "    'rest':         dict(t_on=0.60, t_off=0.45, min_len=12, merge_gap=8,  smooth_k=13),\n",
    "    'mount':        dict(t_on=0.60, t_off=0.45, min_len=8,  merge_gap=6,  smooth_k=11),\n",
    "    'intromit':     dict(t_on=0.65, t_off=0.50, min_len=6,  merge_gap=4,  smooth_k=9),\n",
    "    # events nhanh: ngắn hơn\n",
    "    'approach':     dict(t_on=0.60, t_off=0.45, min_len=4,  merge_gap=4,  smooth_k=9),\n",
    "    'avoid':        dict(t_on=0.60, t_off=0.45, min_len=4,  merge_gap=4,  smooth_k=9),\n",
    "    'follow':       dict(t_on=0.60, t_off=0.45, min_len=5,  merge_gap=5,  smooth_k=9),\n",
    "    'chase':        dict(t_on=0.60, t_off=0.45, min_len=5,  merge_gap=5,  smooth_k=9),\n",
    "    'chaseattack':  dict(t_on=0.62, t_off=0.48, min_len=5,  merge_gap=4,  smooth_k=9),\n",
    "    'attack':       dict(t_on=0.65, t_off=0.50, min_len=3,  merge_gap=3,  smooth_k=7),\n",
    "    'defend':       dict(t_on=0.62, t_off=0.48, min_len=3,  merge_gap=3,  smooth_k=7),\n",
    "    'flinch':       dict(t_on=0.62, t_off=0.48, min_len=2,  merge_gap=2,  smooth_k=7),\n",
    "}\n",
    "\n",
    "# ===== Empty-video fill strategy =====\n",
    "# 'none'    : không fill gì (có thể gây error trong scorer)\n",
    "# 'minimal' : mỗi video trống thêm đúng 1 dòng 1-frame cho 1 action hợp lệ\n",
    "# 'legacy'  : hành vi cũ, chia cả video cho mọi action (rất nhiều FP)\n",
    "FILL_EMPTY_MODE = 'minimal'\n",
    "\n",
    "# ========================\n",
    "# Config\n",
    "# ========================\n",
    "@dataclass\n",
    "class Config:\n",
    "    data_root: Path = Path(\"/kaggle/input/MABe-mouse-behavior-detection\")\n",
    "    submission_file: str = \"submission.csv\"\n",
    "    row_id_col: str = \"row_id\"\n",
    "    # safety caps for training subset to avoid OOM\n",
    "    max_train_samples_per_action: int = 100_000\n",
    "\n",
    "    @property\n",
    "    def train_csv(self) -> Path: return self.data_root / \"train.csv\"\n",
    "    @property\n",
    "    def test_csv(self) -> Path: return self.data_root / \"test.csv\"\n",
    "    @property\n",
    "    def train_track_dir(self) -> Path: return self.data_root / \"train_tracking\"\n",
    "    @property\n",
    "    def train_ann_dir(self) -> Path: return self.data_root / \"train_annotation\"\n",
    "    @property\n",
    "    def test_track_dir(self) -> Path: return self.data_root / \"test_tracking\"\n",
    "\n",
    "\n",
    "CFG = Config()\n",
    "\n",
    "\n",
    "# ========================\n",
    "# Utils\n",
    "# ========================\n",
    "def safe_json_loads(s: Any) -> List[str]:\n",
    "    if s is None:\n",
    "        return []\n",
    "    if isinstance(s, list):\n",
    "        return [str(x) for x in s]\n",
    "    try:\n",
    "        return list(json.loads(s))\n",
    "    except Exception:\n",
    "        # fallback (rare malformed strings)\n",
    "        s = str(s).replace(\"'\", '\"')\n",
    "        return list(json.loads(s))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Legacy Section (DO NOT CHANGE LOGIC)\n",
    "# ============================================================\n",
    "\n",
    "# Legacy: body parts to drop (as seen in original code)\n",
    "drop_body_parts = [\n",
    "    'headpiece_bottombackleft','headpiece_bottombackright','headpiece_bottomfrontleft',\n",
    "    'headpiece_bottomfrontright','headpiece_topbackleft','headpiece_topbackright',\n",
    "    'headpiece_topfrontleft','headpiece_topfrontright','spine_1','spine_2',\n",
    "    'tail_middle_1','tail_middle_2','tail_midpoint'\n",
    "]\n",
    "\n",
    "def _pick_safe_stub(behaviors_df: pd.DataFrame) -> Tuple[str,str,str]:\n",
    "    \"\"\"\n",
    "    Chọn (agent, target, action) 'ít rủi ro' từ whitelist của video.\n",
    "    Ưu tiên self-state (rest/sniff), rồi đến sniff, rồi đến cặp đầu tiên.\n",
    "    \"\"\"\n",
    "    # ưu tiên self với state-like\n",
    "    pref_states = ['rest', 'sniff', 'sniffface', 'sniffgenital']\n",
    "    self_rows = behaviors_df.query(\"target == 'self'\")\n",
    "    for a in pref_states:\n",
    "        hit = self_rows[self_rows['action'] == a]\n",
    "        if len(hit) > 0:\n",
    "            r = hit.iloc[0]\n",
    "            return r['agent'], r['target'], r['action']\n",
    "\n",
    "    # nếu không có self-state, ưu tiên sniff (pair)\n",
    "    pair_rows = behaviors_df.query(\"target != 'self'\")\n",
    "    for a in ['sniff', 'sniffface', 'sniffgenital']:\n",
    "        hit = pair_rows[pair_rows['action'] == a]\n",
    "        if len(hit) > 0:\n",
    "            r = hit.iloc[0]\n",
    "            return r['agent'], r['target'], r['action']\n",
    "\n",
    "    # fallback: lấy bản ghi đầu tiên\n",
    "    r = behaviors_df.iloc[0]\n",
    "    return r['agent'], r['target'], r['action']\n",
    "\n",
    "def generate_mouse_data(dataset: pd.DataFrame,\n",
    "                        traintest: str,\n",
    "                        traintest_directory: Optional[str] = None,\n",
    "                        generate_single: bool = True,\n",
    "                        generate_pair: bool = True):\n",
    "    \"\"\"\n",
    "    Legacy generator from the baseline.\n",
    "    - Yields tuples for 'single' and 'pair' with (data, meta, label/actions)\n",
    "    - Reads parquet under /train_tracking or /test_tracking\n",
    "    - Respects behaviors_labeled whitelist\n",
    "    \"\"\"\n",
    "    assert traintest in ['train', 'test']\n",
    "    if traintest_directory is None:\n",
    "        traintest_directory = f\"{CFG.data_root}/{traintest}_tracking\"\n",
    "\n",
    "    import pandas as pd  # local import to keep environment parity\n",
    "\n",
    "    for _, row in dataset.iterrows():\n",
    "        lab_id = row.lab_id\n",
    "        if traintest == 'train' and str(lab_id).startswith('MABe22'):\n",
    "            # Legacy skip: MABe22 has no annotations in train\n",
    "            continue\n",
    "\n",
    "        video_id = row.video_id\n",
    "        behaviors = row.behaviors_labeled\n",
    "        if type(behaviors) != str:\n",
    "            if verbose and traintest == 'test':\n",
    "                print('No labeled behaviors:', lab_id, video_id, type(behaviors), behaviors)\n",
    "            continue\n",
    "\n",
    "        path = f\"{traintest_directory}/{lab_id}/{video_id}.parquet\"\n",
    "        vid = pd.read_parquet(path)\n",
    "        # pivot to (video_frame x features)\n",
    "        # columns multiindex: ('x'/'y', mouse_id, bodypart) -> reorder to (mouse_id, bodypart, xy)\n",
    "        pvid = vid.pivot(columns=['mouse_id', 'bodypart'], index='video_frame', values=['x', 'y'])\n",
    "        if len(np.unique(vid.bodypart)) > 5:\n",
    "            # drop some noisy parts for memory\n",
    "            try:\n",
    "                pvid = pvid.drop(columns=[('x', slice(None), b) for b in drop_body_parts], errors='ignore')\n",
    "                pvid = pvid.drop(columns=[('y', slice(None), b) for b in drop_body_parts], errors='ignore')\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        if pvid.isna().any().any():\n",
    "            if verbose and traintest == 'test':\n",
    "                print('video with missing values', video_id, traintest, len(vid), 'frames')\n",
    "        else:\n",
    "            if verbose and traintest == 'test':\n",
    "                print('video with all values', video_id, traintest, len(vid), 'frames')\n",
    "\n",
    "        pvid = pvid.reorder_levels([1, 2, 0], axis=1).T.sort_index().T  # (mouse_id, bodypart, xy)\n",
    "        # convert to cm\n",
    "        pvid = pvid / row.pix_per_cm_approx\n",
    "\n",
    "        # behaviors in this video\n",
    "        vid_behaviors = sorted(list({b.replace(\"'\", \"\") for b in json.loads(row.behaviors_labeled)}))\n",
    "        vid_behaviors = [b.split(',') for b in vid_behaviors]\n",
    "        vid_behaviors = pd.DataFrame(vid_behaviors, columns=['agent', 'target', 'action'])\n",
    "\n",
    "        # load annotations (train only)\n",
    "        if traintest == 'train':\n",
    "            try:\n",
    "                annot = pd.read_parquet(path.replace('train_tracking', 'train_annotation'))\n",
    "            except FileNotFoundError:\n",
    "                # missing annotations; skip video\n",
    "                continue\n",
    "\n",
    "        # SINGLE\n",
    "        if generate_single:\n",
    "            vid_b_single = vid_behaviors.query(\"target == 'self'\")\n",
    "            for mouse_id_str in np.unique(vid_b_single.agent):\n",
    "                try:\n",
    "                    mouse_id = int(mouse_id_str[-1])\n",
    "                    vid_agent_actions = np.unique(vid_b_single.query(\"agent == @mouse_id_str\").action)\n",
    "                    single_mouse = pvid.loc[:, mouse_id]\n",
    "                    single_mouse_meta = pd.DataFrame({\n",
    "                        'video_id': video_id,\n",
    "                        'agent_id': mouse_id_str,\n",
    "                        'target_id': 'self',\n",
    "                        'video_frame': single_mouse.index,\n",
    "                        'lab_id': lab_id,    \n",
    "                    })\n",
    "                    if traintest == 'train':\n",
    "                        single_mouse_label = pd.DataFrame(0.0, columns=vid_agent_actions, index=single_mouse.index)\n",
    "                        annot_subset = annot.query(\"(agent_id == @mouse_id) & (target_id == @mouse_id)\")\n",
    "                        for i in range(len(annot_subset)):\n",
    "                            r = annot_subset.iloc[i]\n",
    "                            single_mouse_label.loc[r['start_frame']:r['stop_frame'], r.action] = 1.0\n",
    "                        yield 'single', single_mouse, single_mouse_meta, single_mouse_label\n",
    "                    else:\n",
    "                        if verbose: print('- test single', video_id, mouse_id)\n",
    "                        yield 'single', single_mouse, single_mouse_meta, vid_agent_actions\n",
    "                except KeyError:\n",
    "                    # no data for this agent mouse – skip\n",
    "                    pass\n",
    "\n",
    "        # PAIR\n",
    "        if generate_pair:\n",
    "            vid_b_pair = vid_behaviors.query(\"target != 'self'\")\n",
    "            if len(vid_b_pair) > 0:\n",
    "                # permutations of available mice (ids in columns)\n",
    "                avail = np.unique(pvid.columns.get_level_values('mouse_id'))\n",
    "                for agent, target in itertools.permutations(avail, 2):\n",
    "                    agent_str = f\"mouse{agent}\"\n",
    "                    target_str = f\"mouse{target}\"\n",
    "                    vid_agent_actions = np.unique(vid_b_pair.query(\"(agent == @agent_str) & (target == @target_str)\").action)\n",
    "                    mouse_pair = pd.concat([pvid[agent], pvid[target]], axis=1, keys=['A', 'B'])\n",
    "                    mouse_pair_meta = pd.DataFrame({\n",
    "                        'video_id': video_id,\n",
    "                        'agent_id': agent_str,\n",
    "                        'target_id': target_str,\n",
    "                        'video_frame': mouse_pair.index,\n",
    "                        'lab_id': lab_id,                 # NEW\n",
    "                    })\n",
    "                    if traintest == 'train':\n",
    "                        annot_subset = annot.query(\"(agent_id == @agent) & (target_id == @target)\")\n",
    "                        mouse_pair_label = pd.DataFrame(0.0, columns=vid_agent_actions, index=mouse_pair.index)\n",
    "                        for i in range(len(annot_subset)):\n",
    "                            r = annot_subset.iloc[i]\n",
    "                            mouse_pair_label.loc[r['start_frame']:r['stop_frame'], r.action] = 1.0\n",
    "                        yield 'pair', mouse_pair, mouse_pair_meta, mouse_pair_label\n",
    "                    else:\n",
    "                        if verbose: print('- test pair', video_id, agent, target)\n",
    "                        yield 'pair', mouse_pair, mouse_pair_meta, vid_agent_actions\n",
    "\n",
    "# ===== Hysteresis multiclass decoder (lab-aware) =====\n",
    "def _smooth_probs(x, k):\n",
    "    if k <= 1: return x\n",
    "    pad = k // 2\n",
    "    xx = np.pad(x, (pad, pad), mode='edge')\n",
    "    w = np.ones(k) / k\n",
    "    return np.convolve(xx, w, mode='valid')\n",
    "\n",
    "def _decode_one_series(scores_df, actions, per_action):\n",
    "    frames = scores_df.index.values\n",
    "    current = None\n",
    "    events = []\n",
    "    last_end = {}\n",
    "\n",
    "    # collect per-action parameters\n",
    "    t_on  = {a: per_action.get(a, {}).get('t_on',  0.55) for a in actions}\n",
    "    t_off = {a: per_action.get(a, {}).get('t_off', 0.40) for a in actions}\n",
    "    minl  = {a: per_action.get(a, {}).get('min_len', 4)  for a in actions}\n",
    "    mgap  = {a: per_action.get(a, {}).get('merge_gap', 4)for a in actions}\n",
    "\n",
    "    # run\n",
    "    for i, f in enumerate(frames):\n",
    "        row = scores_df.iloc[i].values\n",
    "        a_idx = int(np.argmax(row))\n",
    "        a = actions[a_idx]\n",
    "        s = row[a_idx]\n",
    "\n",
    "        if current is None:\n",
    "            if s >= t_on[a]:\n",
    "                current = [a, f]\n",
    "        else:\n",
    "            act_on, st = current\n",
    "            if a == act_on and s >= t_off[act_on]:\n",
    "                pass\n",
    "            else:\n",
    "                en = f\n",
    "                if en > st and (en - st) >= minl[act_on]:\n",
    "                    if act_on in last_end and (st - last_end[act_on][1]) <= mgap[act_on]:\n",
    "                        last_end[act_on][1] = en\n",
    "                    else:\n",
    "                        last_end[act_on] = [st, en]\n",
    "                current = None\n",
    "                if s >= t_on[a]:\n",
    "                    current = [a, f]\n",
    "\n",
    "    if current is not None:\n",
    "        a, st = current\n",
    "        en = frames[-1] + 1\n",
    "        if (en - st) >= minl[a]:\n",
    "            if a in last_end and (st - last_end[a][1]) <= mgap[a]:\n",
    "                last_end[a][1] = en\n",
    "            else:\n",
    "                last_end[a] = [st, en]\n",
    "\n",
    "    out = []\n",
    "    for a, (st, en) in last_end.items():\n",
    "        out.append((a, st, en))\n",
    "    return out\n",
    "\n",
    "def _lab_params(lab_id: str, actions: List[str]) -> dict:\n",
    "    # base\n",
    "    per_action = {a: DEFAULT_PER_ACTION.get(a, dict(t_on=0.60, t_off=0.45, min_len=4, merge_gap=4, smooth_k=9))\n",
    "                  for a in actions}\n",
    "    if lab_id in SHORT_LABEL_LABS:\n",
    "        # Cho phép segment ngắn hơn cho event actions\n",
    "        for a in actions:\n",
    "            if a in EVENT_ACTIONS:\n",
    "                p = per_action[a].copy()\n",
    "                p['min_len'] = max(1, min(p.get('min_len', 4), 2))\n",
    "                p['smooth_k'] = max(5, p.get('smooth_k', 9) - 2)\n",
    "                p['t_on']  = max(0.50, p.get('t_on', 0.60) - 0.05)\n",
    "                p['t_off'] = max(0.35, p.get('t_off',0.45) - 0.05)\n",
    "                per_action[a] = p\n",
    "    return per_action\n",
    "\n",
    "def predict_multiclass_hysteresis(pred: pd.DataFrame, meta: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Group-by (video_id, agent_id, target_id), smooth + hysteresis decode,\n",
    "    lab-aware min_len/thresholds.\n",
    "    \"\"\"\n",
    "    if pred.shape[1] == 0:\n",
    "        return pd.DataFrame(columns=['video_id','agent_id','target_id','action','start_frame','stop_frame'])\n",
    "\n",
    "    pieces = []\n",
    "    gcols = ['video_id','agent_id','target_id']\n",
    "    # meta đã có lab_id (ở trên)\n",
    "    idx_df = meta.assign(_idx=np.arange(len(meta)))\n",
    "    for keys, sub_idx in idx_df.groupby(gcols)['_idx']:\n",
    "        ii = sub_idx.values\n",
    "        meta_g = meta.iloc[ii]\n",
    "        pred_g = pred.iloc[ii].copy()\n",
    "        actions = list(pred_g.columns)\n",
    "\n",
    "        # smooth từng action\n",
    "        lab = str(meta_g['lab_id'].iloc[0]) if 'lab_id' in meta_g.columns else ''\n",
    "        per_action = _lab_params(lab, actions)\n",
    "        sm = {}\n",
    "        for a in actions:\n",
    "            k = per_action.get(a, {}).get('smooth_k', 9)\n",
    "            sm[a] = _smooth_probs(pred_g[a].values, k)\n",
    "        sm = pd.DataFrame(sm, index=pred_g.index, columns=actions)\n",
    "\n",
    "        evs = _decode_one_series(sm, actions, per_action)\n",
    "        if not evs: \n",
    "            continue\n",
    "        g = meta_g.iloc[0]\n",
    "        out = pd.DataFrame(evs, columns=['action','start_frame','stop_frame'])\n",
    "        out.insert(0,'target_id', g['target_id'])\n",
    "        out.insert(0,'agent_id', g['agent_id'])\n",
    "        out.insert(0,'video_id', g['video_id'])\n",
    "        pieces.append(out)\n",
    "\n",
    "    return pd.concat(pieces, ignore_index=True) if pieces else \\\n",
    "        pd.DataFrame(columns=['video_id','agent_id','target_id','action','start_frame','stop_frame'])\n",
    "\n",
    "def transform_single(single_mouse: pd.DataFrame, body_parts_tracked: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Legacy feature: pairwise squared distances + simple speeds on ears/tail_base (shift 10)\n",
    "    \"\"\"\n",
    "    available_body_parts = single_mouse.columns.get_level_values(0)\n",
    "    feats = {}\n",
    "    for part1, part2 in itertools.combinations(body_parts_tracked, 2):\n",
    "        if part1 in available_body_parts and part2 in available_body_parts:\n",
    "            dif = single_mouse[part1] - single_mouse[part2]\n",
    "            feats[f\"{part1}+{part2}\"] = np.square(dif).sum(axis=1, skipna=False)\n",
    "\n",
    "    X = pd.DataFrame(feats, index=single_mouse.index)\n",
    "    # add simple temporal speeds if available\n",
    "    try:\n",
    "        if ('ear_left' in available_body_parts) and ('ear_right' in available_body_parts) and ('tail_base' in available_body_parts):\n",
    "            shifted = single_mouse[['ear_left', 'ear_right', 'tail_base']].shift(10)\n",
    "            X2 = pd.DataFrame({\n",
    "                'speed_left':  np.square(single_mouse['ear_left']  - shifted['ear_left']).sum(axis=1, skipna=False),\n",
    "                'speed_right': np.square(single_mouse['ear_right'] - shifted['ear_right']).sum(axis=1, skipna=False),\n",
    "                'speed_left2': np.square(single_mouse['ear_left']  - shifted['tail_base']).sum(axis=1, skipna=False),\n",
    "                'speed_right2':np.square(single_mouse['ear_right'] - shifted['tail_base']).sum(axis=1, skipna=False),\n",
    "            }, index=single_mouse.index)\n",
    "            X = pd.concat([X, X2], axis=1)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return X\n",
    "\n",
    "\n",
    "def transform_pair(mouse_pair: pd.DataFrame, body_parts_tracked: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Legacy feature: cross-mouse pairwise squared distances + simple speed variants\n",
    "    \"\"\"\n",
    "    available_A = mouse_pair['A'].columns.get_level_values(0)\n",
    "    available_B = mouse_pair['B'].columns.get_level_values(0)\n",
    "\n",
    "    feats = {}\n",
    "    for p1, p2 in itertools.product(body_parts_tracked, repeat=2):\n",
    "        if p1 in available_A and p2 in available_B:\n",
    "            dif = mouse_pair['A'][p1] - mouse_pair['B'][p2]\n",
    "            feats[f\"12+{p1}+{p2}\"] = np.square(dif).sum(axis=1, skipna=False)\n",
    "    X = pd.DataFrame(feats, index=mouse_pair.index)\n",
    "\n",
    "    try:\n",
    "        if ('A', 'ear_left') in mouse_pair.columns and ('B', 'ear_left') in mouse_pair.columns:\n",
    "            shifted_A = mouse_pair['A']['ear_left'].shift(10)\n",
    "            shifted_B = mouse_pair['B']['ear_left'].shift(10)\n",
    "            X2 = pd.DataFrame({\n",
    "                'speed_left_A':  np.square(mouse_pair['A']['ear_left'] - shifted_A).sum(axis=1, skipna=False),\n",
    "                'speed_left_AB': np.square(mouse_pair['A']['ear_left'] - shifted_B).sum(axis=1, skipna=False),\n",
    "                'speed_left_B':  np.square(mouse_pair['B']['ear_left'] - shifted_B).sum(axis=1, skipna=False),\n",
    "            }, index=mouse_pair.index)\n",
    "            X = pd.concat([X, X2], axis=1)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return X\n",
    "\n",
    "\n",
    "def predict_multiclass(pred: pd.DataFrame, meta: pd.DataFrame, threshold: float = 0.27) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Legacy multiclass decoding (argmax + threshold + change detection)\n",
    "    \"\"\"\n",
    "    ama = np.argmax(pred.values, axis=1)\n",
    "    ama = np.where(pred.max(axis=1).values >= threshold, ama, -1)\n",
    "    ama = pd.Series(ama, index=meta.video_frame.values)\n",
    "\n",
    "    # keep only changes\n",
    "    changes_mask = (ama != ama.shift(1)).values\n",
    "    ama_changes = ama[changes_mask]\n",
    "    meta_changes = meta[changes_mask]\n",
    "\n",
    "    mask = ama_changes.values >= 0\n",
    "    mask[-1] = False\n",
    "    submission_part = pd.DataFrame({\n",
    "        'video_id':  meta_changes['video_id'][mask].values,\n",
    "        'agent_id':  meta_changes['agent_id'][mask].values,\n",
    "        'target_id': meta_changes['target_id'][mask].values,\n",
    "        'action':    pred.columns[ama_changes[mask].values],\n",
    "        'start_frame': ama_changes.index[mask],\n",
    "        'stop_frame':   ama_changes.index[1:][mask[:-1]]\n",
    "    })\n",
    "\n",
    "    # repair stop if group changed\n",
    "    stop_video_id = meta_changes['video_id'][1:][mask[:-1]].values\n",
    "    stop_agent_id = meta_changes['agent_id'][1:][mask[:-1]].values\n",
    "    stop_target_id = meta_changes['target_id'][1:][mask[:-1]].values\n",
    "    for i in range(len(submission_part)):\n",
    "        v = submission_part.video_id.iloc[i]\n",
    "        a = submission_part.agent_id.iloc[i]\n",
    "        t = submission_part.target_id.iloc[i]\n",
    "        if stop_video_id[i] != v or stop_agent_id[i] != a or stop_target_id[i] != t:\n",
    "            new_stop_frame = meta.query(\"(video_id == @v)\").video_frame.max() + 1\n",
    "            submission_part.iat[i, submission_part.columns.get_loc('stop_frame')] = new_stop_frame\n",
    "\n",
    "    assert (submission_part.stop_frame > submission_part.start_frame).all(), 'stop <= start'\n",
    "    if verbose: print('  actions found:', len(submission_part))\n",
    "    return submission_part\n",
    "\n",
    "\n",
    "def robustify(submission: pd.DataFrame,\n",
    "              dataset: pd.DataFrame,\n",
    "              traintest: str,\n",
    "              traintest_directory: Optional[str] = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Legacy robustify with 3 rules:\n",
    "      1) drop start>=stop\n",
    "      2) avoid overlaps within (video,agent,target) by greedy\n",
    "      3) fill empty videos with synthetic spans (kept intact per user's request)\n",
    "    \"\"\"\n",
    "    if traintest_directory is None:\n",
    "        traintest_directory = f\"{CFG.data_root}/{traintest}_tracking\"\n",
    "\n",
    "    # Rule 1\n",
    "    old_submission = submission.copy()\n",
    "    submission = submission[submission.start_frame < submission.stop_frame]\n",
    "    if len(submission) != len(old_submission):\n",
    "        print(\"ERROR: Dropped frames with start >= stop\")\n",
    "\n",
    "    # Rule 2\n",
    "    old_submission = submission.copy()\n",
    "    group_list = []\n",
    "    for _, group in submission.groupby(['video_id', 'agent_id', 'target_id']):\n",
    "        group = group.sort_values('start_frame')\n",
    "        mask = np.ones(len(group), dtype=bool)\n",
    "        last_stop_frame = -1\n",
    "        for i, (_, row) in enumerate(group.iterrows()):\n",
    "            if row['start_frame'] < last_stop_frame:\n",
    "                mask[i] = False\n",
    "            else:\n",
    "                last_stop_frame = row['stop_frame']\n",
    "        group_list.append(group[mask])\n",
    "    submission = pd.concat(group_list)\n",
    "    if len(submission) != len(old_submission):\n",
    "        print(\"ERROR: Dropped duplicate frames\")\n",
    "\n",
    "    # Rule 3: handle empty videos per mode\n",
    "    if FILL_EMPTY_MODE != 'none':\n",
    "        s_list = []\n",
    "        for _, row in dataset.iterrows():\n",
    "            lab_id = row['lab_id']\n",
    "            if str(lab_id).startswith('MABe22'):\n",
    "                continue\n",
    "            video_id = row['video_id']\n",
    "            if (submission.video_id == video_id).any():\n",
    "                continue\n",
    "\n",
    "            if verbose: print(f\"Video {video_id} has no predictions.\")\n",
    "\n",
    "            path = f\"{traintest_directory}/{lab_id}/{video_id}.parquet\"\n",
    "            vid = pd.read_parquet(path)\n",
    "\n",
    "            # whitelist behaviors of this video\n",
    "            vid_behaviors = eval(row['behaviors_labeled'])\n",
    "            vid_behaviors = sorted(list({b.replace(\"'\", \"\") for b in vid_behaviors}))\n",
    "            vid_behaviors = [b.split(',') for b in vid_behaviors]\n",
    "            behaviors_df = pd.DataFrame(vid_behaviors, columns=['agent','target','action'])\n",
    "\n",
    "            start_frame = int(vid.video_frame.min())\n",
    "            stop_bound = int(vid.video_frame.max()) + 1\n",
    "\n",
    "            if FILL_EMPTY_MODE == 'legacy':\n",
    "                # giữ nguyên cách cũ (nhiều FP)\n",
    "                for (agent, target), actions in behaviors_df.groupby(['agent','target']):\n",
    "                    batch_length = int(np.ceil((stop_bound - start_frame) / len(actions)))\n",
    "                    for i, (_, action_row) in enumerate(actions.iterrows()):\n",
    "                        batch_start = start_frame + i * batch_length\n",
    "                        batch_stop  = min(batch_start + batch_length, stop_bound)\n",
    "                        s_list.append((video_id, agent, target, action_row['action'], batch_start, batch_stop))\n",
    "\n",
    "            elif FILL_EMPTY_MODE == 'minimal':\n",
    "                # chỉ tạo 1 frame duy nhất cho 1 hành vi hợp lệ\n",
    "                agent, target, action = _pick_safe_stub(behaviors_df)\n",
    "                stub_start = start_frame\n",
    "                stub_stop  = min(stub_start + 1, stop_bound)  # 1 frame\n",
    "                # đảm bảo start < stop (trong mọi trường hợp sẽ đúng)\n",
    "                if stub_stop > stub_start:\n",
    "                    s_list.append((video_id, agent, target, action, stub_start, stub_stop))\n",
    "\n",
    "        if len(s_list) > 0:\n",
    "            submission = pd.concat([\n",
    "                submission,\n",
    "                pd.DataFrame(s_list, columns=['video_id','agent_id','target_id','action','start_frame','stop_frame'])\n",
    "            ], ignore_index=True)\n",
    "            print(f\"Filled {len(s_list)} empty videos with mode={FILL_EMPTY_MODE}\")\n",
    "\n",
    "    submission = submission.reset_index(drop=True)\n",
    "    return submission\n",
    "\n",
    "\n",
    "def submit(body_parts_tracked_str, switch_tr, binary_classifier, X_tr, label, meta, test_df):\n",
    "    # 1) chuẩn cột train để reindex test\n",
    "    train_cols = list(X_tr.columns)\n",
    "\n",
    "    # 2) fit one-vs-rest\n",
    "    model_list = []\n",
    "    for action in label.columns:\n",
    "        action_mask = ~ label[action].isna().values\n",
    "        y_action = label[action][action_mask].values.astype(int)\n",
    "        if not (y_action == 0).all():\n",
    "            model = clone(binary_classifier)\n",
    "            model.fit(X_tr[action_mask], y_action)\n",
    "            model_list.append((action, model))\n",
    "\n",
    "    # 3) infer test theo batches\n",
    "    body_parts_tracked = json.loads(body_parts_tracked_str)\n",
    "    if len(body_parts_tracked) > 5:\n",
    "        body_parts_tracked = [b for b in body_parts_tracked if b not in drop_body_parts]\n",
    "\n",
    "    test_subset = test_df[test_df.body_parts_tracked == body_parts_tracked_str]\n",
    "    generator = generate_mouse_data(test_subset, 'test',\n",
    "                                    generate_single=(switch_tr == 'single'),\n",
    "                                    generate_pair=(switch_tr == 'pair'))\n",
    "    if verbose: print(f\"n_videos: {len(test_subset)}\")\n",
    "\n",
    "    parts = []  # <— local accumulator thay cho submission_list\n",
    "\n",
    "    for switch_te, data_te, meta_te, actions_te in generator:\n",
    "        assert switch_te == switch_tr\n",
    "        try:\n",
    "            # transform\n",
    "            if switch_te == 'single':\n",
    "                X_te = transform_single(data_te, body_parts_tracked)\n",
    "            else:\n",
    "                X_te = transform_pair(data_te, body_parts_tracked)\n",
    "\n",
    "            # đảm bảo cột test == cột train\n",
    "            X_te = X_te.reindex(columns=train_cols)\n",
    "\n",
    "            if verbose and len(X_te) == 0:\n",
    "                print(\"ERROR: X_te is empty\")\n",
    "            del data_te\n",
    "\n",
    "            # predict binary → multiclass\n",
    "            pred = pd.DataFrame(index=meta_te.video_frame)\n",
    "            for action, model in model_list:\n",
    "                if action in actions_te:\n",
    "                    pred[action] = model.predict_proba(X_te)[:, 1]\n",
    "            del X_te\n",
    "\n",
    "            if pred.shape[1] != 0:\n",
    "                if USE_HYSTERESIS_DECODER:\n",
    "                    submission_part = predict_multiclass_hysteresis(pred, meta_te)\n",
    "                else:\n",
    "                    submission_part = predict_multiclass(pred, meta_te, threshold=0.27)\n",
    "                parts.append(submission_part)        # <— append vào local list\n",
    "            else:\n",
    "                if verbose: print(\"  ERROR: no useful training data\")\n",
    "        except KeyError:\n",
    "            if verbose: print(f'  ERROR: KeyError because of missing bodypart ({switch_tr})')\n",
    "            del data_te\n",
    "\n",
    "    # 4) return thay vì đẩy vào biến global\n",
    "    if len(parts) == 0:\n",
    "        return pd.DataFrame(columns=['video_id','agent_id','target_id','action','start_frame','stop_frame'])\n",
    "    return pd.concat(parts, ignore_index=True)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Small helper wrapper (sklearn-compatible) for training subset\n",
    "# ============================================================\n",
    "class TrainOnSubsetClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"\n",
    "    Wrap a sklearn classifier and train on at most `max_samples` randomly\n",
    "    sampled rows to reduce memory/time (faithful to original intent).\n",
    "    \"\"\"\n",
    "    def __init__(self, model: Any, max_samples: int = 100_000, random_state: int = 42):\n",
    "        self.model = model\n",
    "        self.max_samples = int(max_samples)\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n = X.shape[0]\n",
    "        if self.max_samples and n > self.max_samples:\n",
    "            rng = np.random.default_rng(self.random_state)\n",
    "            idx = rng.choice(n, size=self.max_samples, replace=False)\n",
    "            Xs = X.iloc[idx] if hasattr(X, \"iloc\") else X[idx]\n",
    "            ys = y[idx]\n",
    "            self.model.fit(Xs, ys)\n",
    "        else:\n",
    "            self.model.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.model.predict_proba(X)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    @property\n",
    "    def classes_(self):\n",
    "        return self.model.classes_\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Runner (Submit-only orchestration)\n",
    "# ============================================================\n",
    "class SubmitRunner:\n",
    "    def __init__(self, cfg: Config):\n",
    "        self.cfg = cfg\n",
    "        self.submission_parts: List[pd.DataFrame] = []\n",
    "\n",
    "    def load_metadata(self) -> Tuple[pd.DataFrame, pd.DataFrame, List[str]]:\n",
    "        log(\"[INFO] Loading train/test metadata…\")\n",
    "        train = pd.read_csv(self.cfg.train_csv)\n",
    "        test  = pd.read_csv(self.cfg.test_csv)\n",
    "\n",
    "        # preserve legacy computed fields\n",
    "        train['n_mice'] = 4 - train[['mouse1_strain', 'mouse2_strain', 'mouse3_strain', 'mouse4_strain']].isna().sum(axis=1)\n",
    "        body_parts_tracked_list = list(np.unique(train.body_parts_tracked))\n",
    "\n",
    "        return train, test, body_parts_tracked_list\n",
    "\n",
    "    def build_binary_classifier(self) -> Any:\n",
    "        \"\"\"\n",
    "        Faithful to legacy: SimpleImputer + TrainOnSubsetClassifier(LGBM)\n",
    "        \"\"\"\n",
    "        clf = make_pipeline(\n",
    "            SimpleImputer(),\n",
    "            TrainOnSubsetClassifier(\n",
    "                model=LGBMClassifier(\n",
    "                    n_estimators=100,\n",
    "                    learning_rate=0.03,\n",
    "                    min_child_samples=40,\n",
    "                    random_state=42,\n",
    "                    verbose=-1\n",
    "                ),\n",
    "                max_samples=self.cfg.max_train_samples_per_action,\n",
    "                random_state=42\n",
    "            )\n",
    "        )\n",
    "        return clf\n",
    "\n",
    "    def run(self):\n",
    "        assert validate_or_submit == 'submit', \"This script is submit-only by design.\"\n",
    "\n",
    "        train, test, body_parts_tracked_list = self.load_metadata()\n",
    "\n",
    "        # For each unique set of body parts (skip index 0 if it's MABe22 as in legacy)\n",
    "        for section in range(1, len(body_parts_tracked_list)):\n",
    "            body_parts_tracked_str = body_parts_tracked_list[section]\n",
    "            try:\n",
    "                body_parts = json.loads(body_parts_tracked_str)\n",
    "                log(f\"{section}. Processing videos with {body_parts}\")\n",
    "\n",
    "                # reduce body parts if too many (legacy behavior)\n",
    "                if len(body_parts) > 5:\n",
    "                    body_parts = [b for b in body_parts if b not in drop_body_parts]\n",
    "\n",
    "                # match training subset\n",
    "                train_subset = train[train.body_parts_tracked == body_parts_tracked_str]\n",
    "\n",
    "                # collect batches\n",
    "                single_mouse_list, single_label_list, single_meta_list = [], [], []\n",
    "                mouse_pair_list,  mouse_label_list,  mouse_meta_list  = [], [], []\n",
    "\n",
    "                for switch, data, meta, label in generate_mouse_data(train_subset, 'train'):\n",
    "                    if switch == 'single':\n",
    "                        single_mouse_list.append(data)\n",
    "                        single_meta_list.append(meta)\n",
    "                        single_label_list.append(label)\n",
    "                    else:\n",
    "                        mouse_pair_list.append(data)\n",
    "                        mouse_meta_list.append(meta)\n",
    "                        mouse_label_list.append(label)\n",
    "\n",
    "                binary_classifier = self.build_binary_classifier()\n",
    "\n",
    "                # SINGLE head\n",
    "                if len(single_mouse_list) > 0:\n",
    "                    single_mouse = pd.concat(single_mouse_list)\n",
    "                    single_mouse_label = pd.concat(single_label_list)\n",
    "                    single_mouse_meta = pd.concat(single_meta_list)\n",
    "                    del single_mouse_list, single_label_list, single_meta_list\n",
    "                    assert len(single_mouse) == len(single_mouse_label) == len(single_mouse_meta)\n",
    "\n",
    "                    X_tr = transform_single(single_mouse, body_parts)\n",
    "                    del single_mouse\n",
    "                    log(f\"{X_tr.shape=}\")\n",
    "\n",
    "                    sub_part = submit(\n",
    "                        body_parts_tracked_str, 'single',\n",
    "                        binary_classifier, X_tr, single_mouse_label, single_mouse_meta,\n",
    "                        test_df=test\n",
    "                    )\n",
    "                    if len(sub_part):\n",
    "                        self.submission_parts.append(sub_part)\n",
    "                    del X_tr, single_mouse_label, single_mouse_meta\n",
    "                    gc.collect()\n",
    "\n",
    "                # PAIR head\n",
    "                if len(mouse_pair_list) > 0:\n",
    "                    mouse_pair = pd.concat(mouse_pair_list)\n",
    "                    mouse_pair_label = pd.concat(mouse_label_list)\n",
    "                    mouse_pair_meta = pd.concat(mouse_meta_list)\n",
    "                    del mouse_pair_list, mouse_label_list, mouse_meta_list\n",
    "                    assert len(mouse_pair) == len(mouse_pair_label) == len(mouse_pair_meta)\n",
    "\n",
    "                    X_tr = transform_pair(mouse_pair, body_parts)\n",
    "                    del mouse_pair\n",
    "                    log(f\"{X_tr.shape=}\")\n",
    "\n",
    "                    sub_part = submit(\n",
    "                        body_parts_tracked_str, 'pair',\n",
    "                        binary_classifier, X_tr, mouse_pair_label, mouse_pair_meta,\n",
    "                        test_df=test\n",
    "                    )\n",
    "                    if len(sub_part):\n",
    "                        self.submission_parts.append(sub_part)\n",
    "                    del X_tr, mouse_pair_label, mouse_pair_meta\n",
    "                    gc.collect()\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f'***Exception*** {e}')\n",
    "            print()\n",
    "\n",
    "        # stitch submission\n",
    "        if len(self.submission_parts) > 0:\n",
    "            submission = pd.concat(self.submission_parts, ignore_index=True)\n",
    "        else:\n",
    "            # keep exact legacy fallback for safety\n",
    "            submission = pd.DataFrame(dict(\n",
    "                video_id=438887472,\n",
    "                agent_id='mouse1',\n",
    "                target_id='self',\n",
    "                action='rear',\n",
    "                start_frame='278',\n",
    "                stop_frame='500'\n",
    "            ), index=[44])\n",
    "\n",
    "        # robustify (legacy)\n",
    "        submission_robust = robustify(submission, test, 'test')\n",
    "        submission_robust.index.name = self.cfg.row_id_col\n",
    "        submission_robust.to_csv(self.cfg.submission_file)\n",
    "        log(f\"[DONE] Wrote {self.cfg.submission_file} with {len(submission_robust):,} rows.\")\n",
    "\n",
    "\n",
    "# ========================\n",
    "# Entry\n",
    "# ========================\n",
    "if __name__ == \"__main__\":\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    SubmitRunner(CFG).run()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 13874099,
     "sourceId": 59156,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1316.690498,
   "end_time": "2025-09-29T10:56:58.827772",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-29T10:35:02.137274",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
