{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8b0b26b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T14:53:18.823481Z",
     "iopub.status.busy": "2025-04-25T14:53:18.823205Z",
     "iopub.status.idle": "2025-04-25T14:53:23.506381Z",
     "shell.execute_reply": "2025-04-25T14:53:23.505626Z",
     "shell.execute_reply.started": "2025-04-25T14:53:18.823463Z"
    },
    "papermill": {
     "duration": 0.002706,
     "end_time": "2025-05-05T20:03:05.077497",
     "exception": false,
     "start_time": "2025-05-05T20:03:05.074791",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# [GWI] Improved UNet pipepline with larger dataset\n",
    "\n",
    "#### [<u>Initial version</u>](https://www.kaggle.com/code/egortrushin/gwi-improved-unet-pipepline-with-larger-dataset)\n",
    "\n",
    "- We used UNet model as introduced in [<u>5 depth U net with residual</u>](https://www.kaggle.com/code/adhok93/5-depth-u-net-with-residual) Notebook.\n",
    "- We used part of Full OpenWFI dataset, which was introduced in [<u>OpenFWI InversionNet Train with 670G Datasets</u>](https://www.kaggle.com/code/seshurajup/openfwi-inversionnet-train-with-670g-datasets) Notebook.\n",
    "\n",
    "#### <u>Present version</u>\n",
    "\n",
    "- We will use openFWI dataset converted from float32 to float16 ([<u>openfwi_float16_1</u>](https://www.kaggle.com/datasets/egortrushin/open-wfi-1), [<u>openfwi_float16_2</u>](https://www.kaggle.com/datasets/egortrushin/open-wfi-2), and [<u>openfwi_float16_test</u>](https://www.kaggle.com/datasets/egortrushin/open-wfi-test)). Since reading of data from disk is a bottleneck here, the conversion allows us to read data from disk twice faster and to use twice more data in training for the same runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2368f82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:03:05.082988Z",
     "iopub.status.busy": "2025-05-05T20:03:05.082697Z",
     "iopub.status.idle": "2025-05-05T20:03:05.090352Z",
     "shell.execute_reply": "2025-05-05T20:03:05.089630Z"
    },
    "papermill": {
     "duration": 0.011559,
     "end_time": "2025-05-05T20:03:05.091442",
     "exception": false,
     "start_time": "2025-05-05T20:03:05.079883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing config.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile config.yaml\n",
    "\n",
    "data_path: /kaggle/input/waveform-inversion\n",
    "model: \n",
    "    name: UNet\n",
    "    unet_params:\n",
    "        init_features: 32\n",
    "        depth: 5\n",
    "read_weights: null\n",
    "batch_size: 64\n",
    "print_freq: 1000\n",
    "max_epochs: 20\n",
    "es_epochs: 4\n",
    "seed: 100\n",
    "valid_frac: 16\n",
    "train_frac: 2\n",
    "optimizer:\n",
    "    lr: 0.0005\n",
    "    weight_decay: 0.001\n",
    "scheduler:\n",
    "    params:\n",
    "        factor: 0.316227766\n",
    "        patience: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfdd3a74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:03:05.096638Z",
     "iopub.status.busy": "2025-05-05T20:03:05.096430Z",
     "iopub.status.idle": "2025-05-05T20:03:13.505689Z",
     "shell.execute_reply": "2025-05-05T20:03:13.505061Z"
    },
    "papermill": {
     "duration": 8.413471,
     "end_time": "2025-05-05T20:03:13.507208",
     "exception": false,
     "start_time": "2025-05-05T20:03:05.093737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "############ We are going to use Fine tuning model ########\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "def inputs_files_to_output_files(input_files):\n",
    "    return [\n",
    "        Path(str(f).replace('seis', 'vel').replace('data', 'model'))\n",
    "        for f in input_files\n",
    "    ]\n",
    "\n",
    "\n",
    "def get_train_files(data_path):\n",
    "\n",
    "    all_inputs = [\n",
    "        f\n",
    "        for f in\n",
    "        Path(data_path).rglob('*.npy')\n",
    "        if ('seis' in f.stem) or ('data' in f.stem)\n",
    "    ]\n",
    "\n",
    "    all_outputs = inputs_files_to_output_files(all_inputs)\n",
    "\n",
    "    assert all(f.exists() for f in all_outputs)\n",
    "\n",
    "    return all_inputs, all_outputs\n",
    "\n",
    "\n",
    "class SeismicDataset(Dataset):\n",
    "    def __init__(self, inputs_files, output_files, n_examples_per_file=500):\n",
    "        assert len(inputs_files) == len(output_files)\n",
    "        self.inputs_files = inputs_files\n",
    "        self.output_files = output_files\n",
    "        self.n_examples_per_file = n_examples_per_file\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs_files) * self.n_examples_per_file\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Calculate file offset and sample offset within file\n",
    "        file_idx = idx // self.n_examples_per_file\n",
    "        sample_idx = idx % self.n_examples_per_file\n",
    "\n",
    "        X = np.load(self.inputs_files[file_idx], mmap_mode='r')\n",
    "        y = np.load(self.output_files[file_idx], mmap_mode='r')\n",
    "\n",
    "        try:\n",
    "            return X[sample_idx].copy(), y[sample_idx].copy()\n",
    "        finally:\n",
    "            del X, y\n",
    "\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, test_files):\n",
    "        self.test_files = test_files\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.test_files)\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        test_file = self.test_files[i]\n",
    "\n",
    "        return np.load(test_file), test_file.stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1552353b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:03:13.513857Z",
     "iopub.status.busy": "2025-05-05T20:03:13.513503Z",
     "iopub.status.idle": "2025-05-05T20:03:13.533982Z",
     "shell.execute_reply": "2025-05-05T20:03:13.533396Z"
    },
    "papermill": {
     "duration": 0.025203,
     "end_time": "2025-05-05T20:03:13.535098",
     "exception": false,
     "start_time": "2025-05-05T20:03:13.509895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "class ResidualDoubleConv(nn.Module):\n",
    "    \"\"\"(Convolution => [BN] => ReLU) * 2 + Residual Connection\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "\n",
    "        # First convolution layer\n",
    "        self.conv1 = nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(mid_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        # Second convolution layer\n",
    "        self.conv2 = nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        # Shortcut connection to handle potential channel mismatch\n",
    "        if in_channels == out_channels:\n",
    "            self.shortcut = nn.Identity()\n",
    "        else:\n",
    "            # Projection shortcut: 1x1 conv + BN to match output channels\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x  # Store the input for the residual connection\n",
    "\n",
    "        # First conv block\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        # Second conv block (without final ReLU yet)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        # Apply shortcut to the identity path\n",
    "        identity_mapped = self.shortcut(identity)\n",
    "\n",
    "        # Add the residual connection\n",
    "        out += identity_mapped\n",
    "\n",
    "        # Apply final ReLU\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then ResidualDoubleConv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=False)\n",
    "            # Input to ResidualDoubleConv = channels from upsampled layer below + channels from skip connection\n",
    "            # Output of ResidualDoubleConv = desired output channels for this decoder stage\n",
    "            self.conv = ResidualDoubleConv(in_channels + out_channels, out_channels) # Use ResidualDoubleConv\n",
    "\n",
    "        else: # Using ConvTranspose2d\n",
    "            # ConvTranspose halves the channels: in_channels -> in_channels // 2\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            # Input channels to ResidualDoubleConv\n",
    "            conv_in_channels = in_channels // 2 # Channels after ConvTranspose\n",
    "            skip_channels = out_channels       # Channels from skip connection\n",
    "            total_in_channels = conv_in_channels + skip_channels\n",
    "            self.conv = ResidualDoubleConv(total_in_channels, out_channels) # Use ResidualDoubleConv\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        # x1 is the feature map from the layer below (needs upsampling)\n",
    "        # x2 is the skip connection from the corresponding encoder layer\n",
    "        x1 = self.up(x1)\n",
    "\n",
    "        # Pad x1 if its dimensions don't match x2 after upsampling\n",
    "        # Input is CHW\n",
    "        diffY = x2.size(2) - x1.size(2)\n",
    "        diffX = x2.size(3) - x1.size(3)\n",
    "\n",
    "        # Pad format: (padding_left, padding_right, padding_top, padding_bottom)\n",
    "        x1 = F.pad(\n",
    "            x1, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2]\n",
    "        )\n",
    "\n",
    "        # Concatenate along the channel dimension\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    \"\"\"1x1 Convolution for the output layer\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    \"\"\"U-Net architecture implementation with Residual Blocks\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_channels=5,\n",
    "        n_classes=1,\n",
    "        init_features=32,\n",
    "        depth=5, # number of pooling layers\n",
    "        bilinear=True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "        self.depth = depth\n",
    "\n",
    "        self.initial_pool = nn.AvgPool2d(kernel_size=(14, 1), stride=(14, 1))\n",
    "\n",
    "        # --- Encoder ---\n",
    "        self.encoder_convs = nn.ModuleList() # Store conv blocks\n",
    "        self.encoder_pools = nn.ModuleList() # Store pool layers\n",
    "\n",
    "        # Initial conv block (no pooling before it)\n",
    "        # Use ResidualDoubleConv for the initial convolution block\n",
    "        self.inc = ResidualDoubleConv(n_channels, init_features)\n",
    "        self.encoder_convs.append(self.inc)\n",
    "\n",
    "        current_features = init_features\n",
    "        for _ in range(depth):\n",
    "            # Define convolution block for this stage\n",
    "            conv = ResidualDoubleConv(current_features, current_features * 2)\n",
    "            # Define pooling layer for this stage\n",
    "            pool = nn.MaxPool2d(2)\n",
    "            self.encoder_convs.append(conv)\n",
    "            self.encoder_pools.append(pool)\n",
    "            current_features *= 2\n",
    "\n",
    "        # --- Bottleneck ---\n",
    "        # Use ResidualDoubleConv for the bottleneck\n",
    "        self.bottleneck = ResidualDoubleConv(current_features, current_features)\n",
    "\n",
    "        # --- Decoder ---\n",
    "        self.decoder_blocks = nn.ModuleList()\n",
    "        # Input features start from bottleneck output features\n",
    "        # Output features at each stage are halved\n",
    "        for _ in range(depth):\n",
    "            # Up block uses ResidualDoubleConv internally and handles channels\n",
    "            up_block = Up(current_features, current_features // 2, bilinear)\n",
    "            self.decoder_blocks.append(up_block)\n",
    "            current_features //= 2 # Halve features for next Up block input\n",
    "\n",
    "        # --- Output Layer ---\n",
    "        # Input features are the output features of the last Up block\n",
    "        self.outc = OutConv(current_features, n_classes)\n",
    "\n",
    "    def _pad_or_crop(self, x, target_h=70, target_w=70):\n",
    "        \"\"\"Pads or crops input tensor x to target height and width.\"\"\"\n",
    "        _, _, h, w = x.shape\n",
    "        # Pad Height if needed\n",
    "        if h < target_h:\n",
    "            pad_top = (target_h - h) // 2\n",
    "            pad_bottom = target_h - h - pad_top\n",
    "            x = F.pad(x, (0, 0, pad_top, pad_bottom))  # Pad height only\n",
    "            h = target_h\n",
    "        # Pad Width if needed\n",
    "        if w < target_w:\n",
    "            pad_left = (target_w - w) // 2\n",
    "            pad_right = target_w - w - pad_left\n",
    "            x = F.pad(x, (pad_left, pad_right, 0, 0))  # Pad width only\n",
    "            w = target_w\n",
    "        # Crop Height if needed\n",
    "        if h > target_h:\n",
    "            crop_top = (h - target_h) // 2\n",
    "            # Use slicing to crop\n",
    "            x = x[:, :, crop_top : crop_top + target_h, :]\n",
    "            h = target_h\n",
    "        # Crop Width if needed\n",
    "        if w > target_w:\n",
    "            crop_left = (w - target_w) // 2\n",
    "            x = x[:, :, :, crop_left : crop_left + target_w]\n",
    "            w = target_w\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initial pooling and resizing\n",
    "        x_pooled = self.initial_pool(x)\n",
    "        x_resized = self._pad_or_crop(x_pooled, target_h=70, target_w=70)\n",
    "\n",
    "        # --- Encoder Path ---\n",
    "        skip_connections = []\n",
    "        xi = x_resized\n",
    "\n",
    "        # Apply initial conv (inc)\n",
    "        xi = self.encoder_convs[0](xi)\n",
    "        skip_connections.append(xi) # Store output of inc\n",
    "\n",
    "        # Apply subsequent encoder convs and pools\n",
    "        # self.depth is the number of pooling layers\n",
    "        for i in range(self.depth):\n",
    "            # Apply conv block for this stage\n",
    "            xi = self.encoder_convs[i+1](xi)\n",
    "            # Store skip connection *before* pooling\n",
    "            skip_connections.append(xi)\n",
    "            # Apply pooling layer for this stage\n",
    "            xi = self.encoder_pools[i](xi)\n",
    "\n",
    "        # Apply bottleneck conv\n",
    "        xi = self.bottleneck(xi)\n",
    "\n",
    "        # --- Decoder Path ---\n",
    "        xu = xi # Start with bottleneck output\n",
    "        # Iterate through decoder blocks and corresponding skip connections in reverse\n",
    "        for i, block in enumerate(self.decoder_blocks):\n",
    "            # Determine the correct skip connection index from the end\n",
    "            # Example: depth=5. Skips stored: [inc, enc1, enc2, enc3, enc4] (indices 0-4)\n",
    "            # Decoder 0 (Up(1024, 512)) needs skip 4 (enc4)\n",
    "            # Decoder 1 (Up(512, 256)) needs skip 3 (enc3) ...\n",
    "            # Decoder 4 (Up(64, 32)) needs skip 0 (inc)\n",
    "            skip_index = self.depth - 1 - i\n",
    "            skip = skip_connections[skip_index]\n",
    "            xu = block(xu, skip) # Up block combines xu (from below) and skip\n",
    "\n",
    "        # --- Final Output ---\n",
    "        logits = self.outc(xu)\n",
    "        # Apply scaling and offset specific to the problem's target range\n",
    "        output = logits * 1000.0 + 1500.0\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d86107e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:03:13.540869Z",
     "iopub.status.busy": "2025-05-05T20:03:13.540609Z",
     "iopub.status.idle": "2025-05-06T05:04:13.934248Z",
     "shell.execute_reply": "2025-05-06T05:04:13.921444Z"
    },
    "papermill": {
     "duration": 32460.412933,
     "end_time": "2025-05-06T05:04:13.950428",
     "exception": false,
     "start_time": "2025-05-05T20:03:13.537495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: Tesla T4\n",
      "GPU memory: 14.74GB\n",
      "\n",
      "{'batch_size': 64,\n",
      " 'data_path': '/kaggle/input/waveform-inversion',\n",
      " 'es_epochs': 4,\n",
      " 'max_epochs': 20,\n",
      " 'model': {'name': 'UNet', 'unet_params': {'depth': 5, 'init_features': 32}},\n",
      " 'optimizer': {'lr': 0.0005, 'weight_decay': 0.001},\n",
      " 'print_freq': 1000,\n",
      " 'read_weights': None,\n",
      " 'scheduler': {'params': {'factor': 0.316227766, 'patience': 1}},\n",
      " 'seed': 100,\n",
      " 'train_frac': 2,\n",
      " 'valid_frac': 16}\n",
      "\n",
      "Total number of input/output files: 940\n",
      "Number of train files: 441\n",
      "Number of valid files: 59\n",
      "\n",
      "Epoch: 01  Step 1000/3445  Trn Loss: 290.63  LR: 5.00e-04  GPU Usage: 3.28GB  Elapsed Time: 0:07:44\n",
      "Epoch: 01  Step 2000/3445  Trn Loss: 251.13  LR: 5.00e-04  GPU Usage: 3.28GB  Elapsed Time: 0:15:02\n",
      "Epoch: 01  Step 3000/3445  Trn Loss: 230.09  LR: 5.00e-04  GPU Usage: 3.28GB  Elapsed Time: 0:22:16\n",
      "Epoch: 01  Step 3445/3445  Trn Loss: 223.33  LR: 5.00e-04  GPU Usage: 3.28GB  Elapsed Time: 0:25:27\n",
      "\n",
      "Epoch: 01  Trn Loss: 223.33  Val Loss: 174.80  GPU Usage: 7.02GB  Elapsed Time: 0:28:07\n",
      "\n",
      "New best val_loss: 174.80\n",
      "\n",
      "Epoch: 02  Step 1000/3445  Trn Loss: 166.13  LR: 5.00e-04  GPU Usage: 7.02GB  Elapsed Time: 0:35:00\n",
      "Epoch: 02  Step 2000/3445  Trn Loss: 162.38  LR: 5.00e-04  GPU Usage: 7.02GB  Elapsed Time: 0:41:55\n",
      "Epoch: 02  Step 3000/3445  Trn Loss: 158.49  LR: 5.00e-04  GPU Usage: 7.02GB  Elapsed Time: 0:48:41\n",
      "Epoch: 02  Step 3445/3445  Trn Loss: 156.92  LR: 5.00e-04  GPU Usage: 7.02GB  Elapsed Time: 0:51:44\n",
      "\n",
      "Epoch: 02  Trn Loss: 156.92  Val Loss: 163.46  GPU Usage: 7.02GB  Elapsed Time: 0:54:25\n",
      "\n",
      "New best val_loss: 163.46\n",
      "\n",
      "Epoch: 03  Step 1000/3445  Trn Loss: 140.91  LR: 5.00e-04  GPU Usage: 7.02GB  Elapsed Time: 1:01:10\n",
      "Epoch: 03  Step 2000/3445  Trn Loss: 138.68  LR: 5.00e-04  GPU Usage: 7.02GB  Elapsed Time: 1:07:57\n",
      "Epoch: 03  Step 3000/3445  Trn Loss: 136.73  LR: 5.00e-04  GPU Usage: 7.02GB  Elapsed Time: 1:15:29\n",
      "Epoch: 03  Step 3445/3445  Trn Loss: 135.86  LR: 5.00e-04  GPU Usage: 7.02GB  Elapsed Time: 1:18:38\n",
      "\n",
      "Epoch: 03  Trn Loss: 135.86  Val Loss: 137.12  GPU Usage: 7.02GB  Elapsed Time: 1:21:29\n",
      "\n",
      "New best val_loss: 137.12\n",
      "\n",
      "Epoch: 04  Step 1000/3445  Trn Loss: 125.87  LR: 5.00e-04  GPU Usage: 7.02GB  Elapsed Time: 1:28:12\n",
      "Epoch: 04  Step 2000/3445  Trn Loss: 124.78  LR: 5.00e-04  GPU Usage: 7.02GB  Elapsed Time: 1:34:54\n",
      "Epoch: 04  Step 3000/3445  Trn Loss: 123.86  LR: 5.00e-04  GPU Usage: 7.02GB  Elapsed Time: 1:41:40\n",
      "Epoch: 04  Step 3445/3445  Trn Loss: 123.28  LR: 5.00e-04  GPU Usage: 7.02GB  Elapsed Time: 1:44:41\n",
      "\n",
      "Epoch: 04  Trn Loss: 123.28  Val Loss: 128.90  GPU Usage: 7.02GB  Elapsed Time: 1:47:23\n",
      "\n",
      "New best val_loss: 128.90\n",
      "\n",
      "Epoch: 05  Step 1000/3445  Trn Loss: 116.96  LR: 5.00e-04  GPU Usage: 7.02GB  Elapsed Time: 1:54:06\n",
      "Epoch: 05  Step 2000/3445  Trn Loss: 116.06  LR: 5.00e-04  GPU Usage: 7.02GB  Elapsed Time: 2:01:12\n",
      "Epoch: 05  Step 3000/3445  Trn Loss: 115.12  LR: 5.00e-04  GPU Usage: 7.02GB  Elapsed Time: 2:07:55\n",
      "Epoch: 05  Step 3445/3445  Trn Loss: 114.72  LR: 5.00e-04  GPU Usage: 7.02GB  Elapsed Time: 2:10:51\n",
      "\n",
      "Epoch: 05  Trn Loss: 114.72  Val Loss: 113.44  GPU Usage: 7.02GB  Elapsed Time: 2:13:44\n",
      "\n",
      "New best val_loss: 113.44\n",
      "\n",
      "Epoch: 06  Step 1000/3445  Trn Loss: 109.60  LR: 5.00e-04  GPU Usage: 7.02GB  Elapsed Time: 2:20:28\n",
      "Epoch: 06  Step 2000/3445  Trn Loss: 108.95  LR: 5.00e-04  GPU Usage: 7.02GB  Elapsed Time: 2:27:19\n",
      "Epoch: 06  Step 3000/3445  Trn Loss: 108.35  LR: 5.00e-04  GPU Usage: 7.02GB  Elapsed Time: 2:34:13\n",
      "Epoch: 06  Step 3445/3445  Trn Loss: 108.18  LR: 5.00e-04  GPU Usage: 7.02GB  Elapsed Time: 2:37:08\n",
      "\n",
      "Epoch: 06  Trn Loss: 108.18  Val Loss: 118.02  GPU Usage: 7.02GB  Elapsed Time: 2:39:40\n",
      "\n",
      "Epochs without improvement: 1\n",
      "\n",
      "Epoch: 07  Step 1000/3445  Trn Loss: 103.76  LR: 5.00e-04  GPU Usage: 7.02GB  Elapsed Time: 2:46:11\n",
      "Epoch: 07  Step 2000/3445  Trn Loss: 103.52  LR: 5.00e-04  GPU Usage: 7.02GB  Elapsed Time: 2:52:58\n",
      "Epoch: 07  Step 3000/3445  Trn Loss: 103.22  LR: 5.00e-04  GPU Usage: 7.02GB  Elapsed Time: 2:59:30\n",
      "Epoch: 07  Step 3445/3445  Trn Loss: 103.06  LR: 5.00e-04  GPU Usage: 7.02GB  Elapsed Time: 3:04:14\n",
      "\n",
      "Epoch: 07  Trn Loss: 103.06  Val Loss: 158.49  GPU Usage: 7.02GB  Elapsed Time: 3:08:52\n",
      "\n",
      "Epochs without improvement: 2\n",
      "\n",
      "Epoch: 08  Step 1000/3445  Trn Loss: 90.21  LR: 1.58e-04  GPU Usage: 7.02GB  Elapsed Time: 3:15:30\n",
      "Epoch: 08  Step 2000/3445  Trn Loss: 89.56  LR: 1.58e-04  GPU Usage: 7.02GB  Elapsed Time: 3:22:07\n",
      "Epoch: 08  Step 3000/3445  Trn Loss: 89.00  LR: 1.58e-04  GPU Usage: 7.02GB  Elapsed Time: 3:28:37\n",
      "Epoch: 08  Step 3445/3445  Trn Loss: 88.83  LR: 1.58e-04  GPU Usage: 7.02GB  Elapsed Time: 3:31:27\n",
      "\n",
      "Epoch: 08  Trn Loss: 88.83  Val Loss: 92.67  GPU Usage: 7.02GB  Elapsed Time: 3:34:14\n",
      "\n",
      "New best val_loss: 92.67\n",
      "\n",
      "Epoch: 09  Step 1000/3445  Trn Loss: 85.98  LR: 1.58e-04  GPU Usage: 7.02GB  Elapsed Time: 3:40:42\n",
      "Epoch: 09  Step 2000/3445  Trn Loss: 85.98  LR: 1.58e-04  GPU Usage: 7.02GB  Elapsed Time: 3:47:12\n",
      "Epoch: 09  Step 3000/3445  Trn Loss: 85.78  LR: 1.58e-04  GPU Usage: 7.02GB  Elapsed Time: 3:53:30\n",
      "Epoch: 09  Step 3445/3445  Trn Loss: 85.71  LR: 1.58e-04  GPU Usage: 7.02GB  Elapsed Time: 3:56:16\n",
      "\n",
      "Epoch: 09  Trn Loss: 85.71  Val Loss: 103.32  GPU Usage: 7.02GB  Elapsed Time: 3:58:52\n",
      "\n",
      "Epochs without improvement: 1\n",
      "\n",
      "Epoch: 10  Step 1000/3445  Trn Loss: 82.80  LR: 1.58e-04  GPU Usage: 7.02GB  Elapsed Time: 4:05:15\n",
      "Epoch: 10  Step 2000/3445  Trn Loss: 83.15  LR: 1.58e-04  GPU Usage: 7.02GB  Elapsed Time: 4:11:53\n",
      "Epoch: 10  Step 3000/3445  Trn Loss: 83.30  LR: 1.58e-04  GPU Usage: 7.02GB  Elapsed Time: 4:18:56\n",
      "Epoch: 10  Step 3445/3445  Trn Loss: 83.33  LR: 1.58e-04  GPU Usage: 7.02GB  Elapsed Time: 4:22:02\n",
      "\n",
      "Epoch: 10  Trn Loss: 83.33  Val Loss: 92.24  GPU Usage: 7.02GB  Elapsed Time: 4:24:35\n",
      "\n",
      "New best val_loss: 92.24\n",
      "\n",
      "Epoch: 11  Step 1000/3445  Trn Loss: 81.62  LR: 1.58e-04  GPU Usage: 7.02GB  Elapsed Time: 4:31:42\n",
      "Epoch: 11  Step 2000/3445  Trn Loss: 81.67  LR: 1.58e-04  GPU Usage: 7.02GB  Elapsed Time: 4:40:10\n",
      "Epoch: 11  Step 3000/3445  Trn Loss: 81.72  LR: 1.58e-04  GPU Usage: 7.02GB  Elapsed Time: 4:46:43\n",
      "Epoch: 11  Step 3445/3445  Trn Loss: 81.60  LR: 1.58e-04  GPU Usage: 7.02GB  Elapsed Time: 4:49:41\n",
      "\n",
      "Epoch: 11  Trn Loss: 81.60  Val Loss: 87.46  GPU Usage: 7.02GB  Elapsed Time: 4:52:31\n",
      "\n",
      "New best val_loss: 87.46\n",
      "\n",
      "Epoch: 12  Step 1000/3445  Trn Loss: 79.86  LR: 1.58e-04  GPU Usage: 7.02GB  Elapsed Time: 4:59:09\n",
      "Epoch: 12  Step 2000/3445  Trn Loss: 79.89  LR: 1.58e-04  GPU Usage: 7.02GB  Elapsed Time: 5:05:32\n",
      "Epoch: 12  Step 3000/3445  Trn Loss: 79.90  LR: 1.58e-04  GPU Usage: 7.02GB  Elapsed Time: 5:12:22\n",
      "Epoch: 12  Step 3445/3445  Trn Loss: 79.89  LR: 1.58e-04  GPU Usage: 7.02GB  Elapsed Time: 5:15:15\n",
      "\n",
      "Epoch: 12  Trn Loss: 79.89  Val Loss: 91.96  GPU Usage: 7.02GB  Elapsed Time: 5:17:46\n",
      "\n",
      "Epochs without improvement: 1\n",
      "\n",
      "Epoch: 13  Step 1000/3445  Trn Loss: 78.73  LR: 1.58e-04  GPU Usage: 7.02GB  Elapsed Time: 5:24:27\n",
      "Epoch: 13  Step 2000/3445  Trn Loss: 78.54  LR: 1.58e-04  GPU Usage: 7.02GB  Elapsed Time: 5:31:12\n",
      "Epoch: 13  Step 3000/3445  Trn Loss: 78.54  LR: 1.58e-04  GPU Usage: 7.02GB  Elapsed Time: 5:39:01\n",
      "Epoch: 13  Step 3445/3445  Trn Loss: 78.46  LR: 1.58e-04  GPU Usage: 7.02GB  Elapsed Time: 5:41:59\n",
      "\n",
      "Epoch: 13  Trn Loss: 78.46  Val Loss: 105.69  GPU Usage: 7.02GB  Elapsed Time: 5:44:43\n",
      "\n",
      "Epochs without improvement: 2\n",
      "\n",
      "Epoch: 14  Step 1000/3445  Trn Loss: 73.85  LR: 5.00e-05  GPU Usage: 7.02GB  Elapsed Time: 5:52:01\n",
      "Epoch: 14  Step 2000/3445  Trn Loss: 73.56  LR: 5.00e-05  GPU Usage: 7.02GB  Elapsed Time: 5:58:28\n",
      "Epoch: 14  Step 3000/3445  Trn Loss: 73.38  LR: 5.00e-05  GPU Usage: 7.02GB  Elapsed Time: 6:05:03\n",
      "Epoch: 14  Step 3445/3445  Trn Loss: 73.32  LR: 5.00e-05  GPU Usage: 7.02GB  Elapsed Time: 6:08:26\n",
      "\n",
      "Epoch: 14  Trn Loss: 73.32  Val Loss: 81.03  GPU Usage: 7.02GB  Elapsed Time: 6:10:52\n",
      "\n",
      "New best val_loss: 81.03\n",
      "\n",
      "Epoch: 15  Step 1000/3445  Trn Loss: 72.17  LR: 5.00e-05  GPU Usage: 7.02GB  Elapsed Time: 6:17:35\n",
      "Epoch: 15  Step 2000/3445  Trn Loss: 72.23  LR: 5.00e-05  GPU Usage: 7.02GB  Elapsed Time: 6:24:37\n",
      "Epoch: 15  Step 3000/3445  Trn Loss: 72.28  LR: 5.00e-05  GPU Usage: 7.02GB  Elapsed Time: 6:31:34\n",
      "Epoch: 15  Step 3445/3445  Trn Loss: 72.25  LR: 5.00e-05  GPU Usage: 7.02GB  Elapsed Time: 6:34:27\n",
      "\n",
      "Epoch: 15  Trn Loss: 72.25  Val Loss: 79.94  GPU Usage: 7.02GB  Elapsed Time: 6:36:58\n",
      "\n",
      "New best val_loss: 79.94\n",
      "\n",
      "Epoch: 16  Step 1000/3445  Trn Loss: 71.50  LR: 5.00e-05  GPU Usage: 7.02GB  Elapsed Time: 6:43:48\n",
      "Epoch: 16  Step 2000/3445  Trn Loss: 71.45  LR: 5.00e-05  GPU Usage: 7.02GB  Elapsed Time: 6:50:50\n",
      "Epoch: 16  Step 3000/3445  Trn Loss: 71.46  LR: 5.00e-05  GPU Usage: 7.02GB  Elapsed Time: 6:58:09\n",
      "Epoch: 16  Step 3445/3445  Trn Loss: 71.50  LR: 5.00e-05  GPU Usage: 7.02GB  Elapsed Time: 7:00:59\n",
      "\n",
      "Epoch: 16  Trn Loss: 71.50  Val Loss: 81.36  GPU Usage: 7.02GB  Elapsed Time: 7:04:11\n",
      "\n",
      "Epochs without improvement: 1\n",
      "\n",
      "Epoch: 17  Step 1000/3445  Trn Loss: 70.34  LR: 5.00e-05  GPU Usage: 7.02GB  Elapsed Time: 7:12:16\n",
      "Epoch: 17  Step 2000/3445  Trn Loss: 70.67  LR: 5.00e-05  GPU Usage: 7.02GB  Elapsed Time: 7:19:40\n",
      "Epoch: 17  Step 3000/3445  Trn Loss: 70.77  LR: 5.00e-05  GPU Usage: 7.02GB  Elapsed Time: 7:26:02\n",
      "Epoch: 17  Step 3445/3445  Trn Loss: 70.78  LR: 5.00e-05  GPU Usage: 7.02GB  Elapsed Time: 7:28:56\n",
      "\n",
      "Epoch: 17  Trn Loss: 70.78  Val Loss: 80.82  GPU Usage: 7.02GB  Elapsed Time: 7:32:05\n",
      "\n",
      "Epochs without improvement: 2\n",
      "\n",
      "Epoch: 18  Step 1000/3445  Trn Loss: 68.96  LR: 1.58e-05  GPU Usage: 7.02GB  Elapsed Time: 7:38:57\n",
      "Epoch: 18  Step 2000/3445  Trn Loss: 68.90  LR: 1.58e-05  GPU Usage: 7.02GB  Elapsed Time: 7:47:35\n",
      "Epoch: 18  Step 3000/3445  Trn Loss: 69.02  LR: 1.58e-05  GPU Usage: 7.02GB  Elapsed Time: 7:54:43\n",
      "Epoch: 18  Step 3445/3445  Trn Loss: 69.00  LR: 1.58e-05  GPU Usage: 7.02GB  Elapsed Time: 7:57:47\n",
      "\n",
      "Epoch: 18  Trn Loss: 69.00  Val Loss: 78.53  GPU Usage: 7.02GB  Elapsed Time: 8:00:48\n",
      "\n",
      "New best val_loss: 78.53\n",
      "\n",
      "Epoch: 19  Step 1000/3445  Trn Loss: 68.62  LR: 1.58e-05  GPU Usage: 7.02GB  Elapsed Time: 8:10:15\n",
      "Epoch: 19  Step 2000/3445  Trn Loss: 68.59  LR: 1.58e-05  GPU Usage: 7.02GB  Elapsed Time: 8:17:59\n",
      "Epoch: 19  Step 3000/3445  Trn Loss: 68.63  LR: 1.58e-05  GPU Usage: 7.02GB  Elapsed Time: 8:24:28\n",
      "Epoch: 19  Step 3445/3445  Trn Loss: 68.67  LR: 1.58e-05  GPU Usage: 7.02GB  Elapsed Time: 8:27:18\n",
      "\n",
      "Epoch: 19  Trn Loss: 68.67  Val Loss: 78.40  GPU Usage: 7.02GB  Elapsed Time: 8:29:59\n",
      "\n",
      "New best val_loss: 78.40\n",
      "\n",
      "Epoch: 20  Step 1000/3445  Trn Loss: 68.44  LR: 1.58e-05  GPU Usage: 7.02GB  Elapsed Time: 8:36:53\n",
      "Epoch: 20  Step 2000/3445  Trn Loss: 68.40  LR: 1.58e-05  GPU Usage: 7.02GB  Elapsed Time: 8:44:14\n",
      "Epoch: 20  Step 3000/3445  Trn Loss: 68.38  LR: 1.58e-05  GPU Usage: 7.02GB  Elapsed Time: 8:52:51\n",
      "Epoch: 20  Step 3445/3445  Trn Loss: 68.38  LR: 1.58e-05  GPU Usage: 7.02GB  Elapsed Time: 8:56:10\n",
      "\n",
      "Epoch: 20  Trn Loss: 68.38  Val Loss: 78.33  GPU Usage: 7.02GB  Elapsed Time: 9:00:49\n",
      "\n",
      "New best val_loss: 78.33\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Utils\n",
    "\n",
    "import datetime\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def format_time(elapsed):\n",
    "    \"\"\"Take a time in seconds and return a string hh:mm:ss.\"\"\"\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "def seed_everything(\n",
    "    seed_value: int\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Controlling a unified seed value for Python, NumPy, and PyTorch (CPU, GPU).\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    seed_value : int\n",
    "        The unified random seed value.\n",
    "    \"\"\"\n",
    "    random.seed(seed_value) # Python\n",
    "    np.random.seed(seed_value) # cpu vars\n",
    "    torch.manual_seed(seed_value) # cpu  vars    \n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value) # gpu vars\n",
    "    if torch.backends.cudnn.is_available:\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "# Preparation and training\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "from torch.utils.data import DataLoader\n",
    "from pprint import pprint\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "_, total = torch.cuda.mem_get_info(device=0)\n",
    "print(f\"GPU memory: {total / 1024**3:.2f}GB\")\n",
    "\n",
    "with open(\"config.yaml\", \"r\") as file_obj:\n",
    "    config = yaml.safe_load(file_obj)\n",
    "print()\n",
    "pprint(config)\n",
    "if config[\"data_path\"] is None:\n",
    "    config[\"data_path\"] = os.environ[\"TMPDIR\"]\n",
    "    print(\"data_path:\", config[\"data_path\"])\n",
    "print()\n",
    "\n",
    "seed_everything(config[\"seed\"])\n",
    "\n",
    "all_inputs, all_outputs = [], []\n",
    "for x in [\"/kaggle/input/open-wfi-1/openfwi_float16_1\", \"/kaggle/input/open-wfi-2/openfwi_float16_2\"]:\n",
    "    all_inputs1, all_outputs1 = get_train_files(x)\n",
    "    all_inputs.extend(all_inputs1)\n",
    "    all_outputs.extend(all_outputs1)\n",
    "print(\"Total number of input/output files:\", len(all_inputs))\n",
    "\n",
    "valid_inputs = [all_inputs[i] for i in range(0, len(all_inputs), config[\"valid_frac\"])]\n",
    "train_inputs = [f for f in all_inputs if not f in valid_inputs]\n",
    "if config[\"train_frac\"] > 1:\n",
    "    train_inputs = [train_inputs[i] for i in range(0, len(train_inputs), config[\"train_frac\"])]\n",
    "\n",
    "print(\"Number of train files:\", len(train_inputs))\n",
    "print(\"Number of valid files:\", len(valid_inputs))\n",
    "print()\n",
    "\n",
    "train_outputs = inputs_files_to_output_files(train_inputs)\n",
    "valid_outputs = inputs_files_to_output_files(valid_inputs)\n",
    "\n",
    "dstrain = SeismicDataset(train_inputs, train_outputs)\n",
    "dltrain = DataLoader(\n",
    "    dstrain,\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    pin_memory=False,\n",
    "    drop_last=True,\n",
    "    num_workers=4,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "\n",
    "dsvalid = SeismicDataset(valid_inputs, valid_outputs)\n",
    "dlvalid = DataLoader(\n",
    "    dsvalid,\n",
    "    batch_size=4*config[\"batch_size\"],\n",
    "    shuffle=False,\n",
    "    pin_memory=False,\n",
    "    drop_last=False,\n",
    "    num_workers=4,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = UNet(**config[\"model\"][\"unet_params\"]).to(device)\n",
    "\n",
    "if config[\"read_weights\"] is not None:\n",
    "    print(\"Reading weights from:\", config[\"read_weights\"])\n",
    "    model.load_state_dict(torch.load(config[\"read_weights\"], weights_only=True))\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), **config[\"optimizer\"])  # hparams\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', **config[\"scheduler\"][\"params\"])\n",
    "\n",
    "best_val_loss = 10000.0\n",
    "epochs_wo_improvement = 0\n",
    "t0 = time.time()  # Measure staring time\n",
    "\n",
    "for epoch in range(1, config[\"max_epochs\"] + 1):\n",
    "\n",
    "    # Train\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    for step, (inputs, targets) in enumerate(dltrain):\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.autocast(device_type=\"cuda\"):\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "        if step % config[\"print_freq\"] == config[\"print_freq\"] - 1 or step == len(dltrain) - 1:\n",
    "            trn_loss = np.mean(train_losses)\n",
    "            t1 = format_time(time.time() - t0)\n",
    "            free, total = torch.cuda.mem_get_info(device=0)\n",
    "            mem_used = (total - free) / 1024**3\n",
    "            lr = optimizer.param_groups[-1]['lr']\n",
    "            print(\n",
    "                f\"Epoch: {epoch:02d}  Step {step+1}/{len(dltrain)}  Trn Loss: {trn_loss:.2f}  LR: {lr:.2e}  GPU Usage: {mem_used:.2f}GB  Elapsed Time: {t1}\",\n",
    "                flush=True,\n",
    "            )\n",
    "\n",
    "    # Valid\n",
    "    model.eval()\n",
    "    valid_losses = []\n",
    "    for inputs, targets in dlvalid:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            with torch.autocast(device_type=\"cuda\"):\n",
    "                outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        valid_losses.append(loss.item())\n",
    "\n",
    "    t1 = format_time(time.time() - t0)\n",
    "    trn_loss = np.mean(train_losses)\n",
    "    val_loss = np.mean(valid_losses)\n",
    "\n",
    "    free, total = torch.cuda.mem_get_info(device=0)\n",
    "    mem_used = (total - free) / 1024**3\n",
    "\n",
    "    print(\n",
    "        f\"\\nEpoch: {epoch:02d}  Trn Loss: {trn_loss:.2f}  Val Loss: {val_loss:.2f}  GPU Usage: {mem_used:.2f}GB  Elapsed Time: {t1}\",\n",
    "        flush=True,\n",
    "    )\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_wo_improvement = 0\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        print(f\"\\nNew best val_loss: {val_loss:.2f}\\n\", flush=True)\n",
    "    else:\n",
    "        epochs_wo_improvement += 1\n",
    "        print(f\"\\nEpochs without improvement: {epochs_wo_improvement}\\n\", flush=True)\n",
    "\n",
    "    if epochs_wo_improvement == config[\"es_epochs\"]:\n",
    "        break\n",
    "\n",
    "    scheduler.step(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07a3c9a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T05:04:14.004461Z",
     "iopub.status.busy": "2025-05-06T05:04:14.002459Z",
     "iopub.status.idle": "2025-05-06T05:04:14.011140Z",
     "shell.execute_reply": "2025-05-06T05:04:14.010312Z"
    },
    "papermill": {
     "duration": 0.032173,
     "end_time": "2025-05-06T05:04:14.012464",
     "exception": false,
     "start_time": "2025-05-06T05:04:13.980291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Fine tuning Models ===============\n"
     ]
    }
   ],
   "source": [
    "print(\"==================== Fine tuning Models ===============\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ecb7f86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T05:04:14.029249Z",
     "iopub.status.busy": "2025-05-06T05:04:14.029014Z",
     "iopub.status.idle": "2025-05-06T05:09:19.294826Z",
     "shell.execute_reply": "2025-05-06T05:09:19.284632Z"
    },
    "papermill": {
     "duration": 305.288316,
     "end_time": "2025-05-06T05:09:19.308862",
     "exception": false,
     "start_time": "2025-05-06T05:04:14.020546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Time: 0:05:05\n"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "test_files = list(Path(\"/kaggle/input/open-wfi-test/test\").glob(\"*.npy\"))\n",
    "x_cols = [f\"x_{i}\" for i in range(1, 70, 2)]\n",
    "fieldnames = [\"oid_ypos\"] + x_cols\n",
    "ds = TestDataset(test_files)\n",
    "dl = DataLoader(ds, batch_size=4*config[\"batch_size\"], num_workers=4, pin_memory=False)\n",
    "\n",
    "model.load_state_dict(torch.load(\"best_model.pth\", weights_only=True))\n",
    "\n",
    "model.eval()\n",
    "with open(\"submission.csv\", \"wt\", newline=\"\") as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for inputs, oids_test in dl:\n",
    "        inputs = inputs.to(device)\n",
    "        with torch.inference_mode():\n",
    "            with torch.autocast(device_type=\"cuda\"):\n",
    "                outputs = model(inputs)\n",
    "\n",
    "        y_preds = outputs[:, 0].cpu().numpy()\n",
    "\n",
    "        for y_pred, oid_test in zip(y_preds, oids_test):\n",
    "            for y_pos in range(70):\n",
    "                row = dict(zip(x_cols, [y_pred[y_pos, x_pos] for x_pos in range(1, 70, 2)]))\n",
    "                row[\"oid_ypos\"] = f\"{oid_test}_y_{y_pos}\"\n",
    "\n",
    "                writer.writerow(row)\n",
    "\n",
    "t1 = format_time(time.time() - t0)\n",
    "print(f\"Inference Time: {t1}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11756775,
     "sourceId": 39763,
     "sourceType": "competition"
    },
    {
     "datasetId": 7253205,
     "sourceId": 11568812,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7253605,
     "sourceId": 11569667,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7253661,
     "sourceId": 11569755,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 32783.615918,
   "end_time": "2025-05-06T05:09:22.086367",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-05T20:02:58.470449",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
