{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/dalloliogm/vae-approach-to-beyond-visible?scriptVersionId=240668069\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"f0bdfcfb","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-05-19T17:31:09.750444Z","iopub.status.busy":"2025-05-19T17:31:09.750194Z","iopub.status.idle":"2025-05-19T17:31:14.434611Z","shell.execute_reply":"2025-05-19T17:31:14.433823Z"},"papermill":{"duration":4.690351,"end_time":"2025-05-19T17:31:14.435965","exception":false,"start_time":"2025-05-19T17:31:09.745614","status":"completed"},"tags":[]},"outputs":[],"source":["from torch.utils.data import Dataset\n","import numpy as np\n","import os\n","from glob import glob\n","import torch\n","\n","class HyperspectralDataset(Dataset):\n","    def __init__(self, root_dir, transform=None):\n","        self.samples = glob(os.path.join(root_dir, \"*\", \"*.npy\"))\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","    def __getitem__(self, idx):\n","        file_path = self.samples[idx]\n","        image = np.load(file_path).astype(np.float32)  # shape (H, W, C)\n","        image = image / (image.max() + 1e-8)\n","\n","        label_str = os.path.basename(os.path.dirname(file_path))\n","        label = int(label_str)\n","        image = np.transpose(image, (2, 0, 1))  # (C, H, W)\n","\n","        image = torch.from_numpy(image)\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image, torch.tensor(label, dtype=torch.long)\n"]},{"cell_type":"markdown","id":"c56303b6","metadata":{"papermill":{"duration":0.002996,"end_time":"2025-05-19T17:31:14.44239","exception":false,"start_time":"2025-05-19T17:31:14.439394","status":"completed"},"tags":[]},"source":["## CVAE model"]},{"cell_type":"code","execution_count":2,"id":"ebe855d8","metadata":{"execution":{"iopub.execute_input":"2025-05-19T17:31:14.449265Z","iopub.status.busy":"2025-05-19T17:31:14.448712Z","iopub.status.idle":"2025-05-19T17:31:14.461237Z","shell.execute_reply":"2025-05-19T17:31:14.460292Z"},"papermill":{"duration":0.017094,"end_time":"2025-05-19T17:31:14.462372","exception":false,"start_time":"2025-05-19T17:31:14.445278","status":"completed"},"tags":[]},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class CVAE(nn.Module):\n","    def __init__(self, img_channels=250, condition_dim=10, latent_dim=128, hidden_dims=None):\n","        super(CVAE, self).__init__()\n","        self.img_channels = img_channels\n","        self.latent_dim = latent_dim\n","        self.condition_dim = condition_dim\n","\n","        if hidden_dims is None:\n","            hidden_dims = [32, 64, 128, 256]\n","\n","        self.condition_embed = nn.Linear(condition_dim, 64)\n","\n","        # Encoder\n","        encoder_layers = []\n","        in_channels = img_channels + 1  # 1 for condition broadcast\n","        for h_dim in hidden_dims:\n","            encoder_layers.append(nn.Conv2d(in_channels, h_dim, kernel_size=3, stride=2, padding=1))\n","            encoder_layers.append(nn.ReLU())\n","            in_channels = h_dim\n","        self.encoder = nn.Sequential(*encoder_layers)\n","\n","        self.flatten = nn.Flatten()\n","        self.fc_mu = nn.Linear(hidden_dims[-1]*8*8, latent_dim)\n","        self.fc_logvar = nn.Linear(hidden_dims[-1]*8*8, latent_dim)\n","\n","\n","        # Decoder\n","        self.decoder_input = nn.Linear(latent_dim + 64, hidden_dims[-1] * 4 * 4)\n","\n","        hidden_dims.reverse()\n","        decoder_layers = []\n","        \n","        for i in range(len(hidden_dims) - 1):\n","            decoder_layers.append(nn.ConvTranspose2d(hidden_dims[i], hidden_dims[i + 1],\n","                                                     kernel_size=4, stride=2, padding=1))\n","            decoder_layers.append(nn.ReLU())\n","        \n","        # 32 → 16 → 125\n","        decoder_layers.append(nn.ConvTranspose2d(hidden_dims[-1], 64, kernel_size=4, stride=2, padding=1))\n","        decoder_layers.append(nn.ReLU())\n","        \n","        decoder_layers.append(nn.ConvTranspose2d(64, img_channels, kernel_size=4, stride=2, padding=1))\n","        decoder_layers.append(nn.Sigmoid())\n","        self.decoder = nn.Sequential(*decoder_layers)\n","\n","#\n","    def encode(self, x, c):\n","        B, _, H, W = x.shape\n","        c_broadcast = c.argmax(dim=1).view(B, 1, 1, 1).float().expand(-1, 1, H, W)\n","        x_cond = torch.cat([x, c_broadcast], dim=1)\n","        x_enc = self.encoder(x_cond)\n","        x_flat = self.flatten(x_enc)\n","        mu = self.fc_mu(x_flat)\n","        logvar = self.fc_logvar(x_flat)\n","        logvar = torch.clamp(logvar, min=-10, max=10)\n","\n","        return mu, logvar\n","\n","    def reparameterize(self, mu, logvar):\n","        std = torch.exp(0.5 * logvar)\n","        eps = torch.randn_like(std)\n","        return mu + eps * std\n","\n","    def decode(self, z, c):\n","        c_embed = self.condition_embed(c)\n","        zc = torch.cat([z, c_embed], dim=1)\n","        x = self.decoder_input(zc)\n","        x = x.view(x.size(0), -1, 4, 4)\n","        x = self.decoder(x)\n","        return x\n","\n","    def forward(self, x, c):\n","        mu, logvar = self.encode(x, c)\n","        z = self.reparameterize(mu, logvar)\n","        recon = self.decode(z, c)\n","        return recon, mu, logvar\n"]},{"cell_type":"markdown","id":"d54394aa","metadata":{"papermill":{"duration":0.00275,"end_time":"2025-05-19T17:31:14.468062","exception":false,"start_time":"2025-05-19T17:31:14.465312","status":"completed"},"tags":[]},"source":["## Loss Function"]},{"cell_type":"code","execution_count":3,"id":"30e7f810","metadata":{"execution":{"iopub.execute_input":"2025-05-19T17:31:14.474505Z","iopub.status.busy":"2025-05-19T17:31:14.474311Z","iopub.status.idle":"2025-05-19T17:31:14.477801Z","shell.execute_reply":"2025-05-19T17:31:14.477331Z"},"papermill":{"duration":0.007863,"end_time":"2025-05-19T17:31:14.478769","exception":false,"start_time":"2025-05-19T17:31:14.470906","status":"completed"},"tags":[]},"outputs":[],"source":["def vae_loss(recon_x, x, mu, logvar):\n","    recon_loss = F.mse_loss(recon_x, x, reduction='mean')\n","    kld_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) / x.size(0)\n","    return recon_loss + kld_loss\n"]},{"cell_type":"markdown","id":"37fecb30","metadata":{"papermill":{"duration":0.002734,"end_time":"2025-05-19T17:31:14.484414","exception":false,"start_time":"2025-05-19T17:31:14.48168","status":"completed"},"tags":[]},"source":["## Training Loop"]},{"cell_type":"code","execution_count":4,"id":"38bdd5b6","metadata":{"execution":{"iopub.execute_input":"2025-05-19T17:31:14.491283Z","iopub.status.busy":"2025-05-19T17:31:14.490795Z","iopub.status.idle":"2025-05-19T17:31:14.496301Z","shell.execute_reply":"2025-05-19T17:31:14.49575Z"},"papermill":{"duration":0.009911,"end_time":"2025-05-19T17:31:14.497282","exception":false,"start_time":"2025-05-19T17:31:14.487371","status":"completed"},"tags":[]},"outputs":[],"source":["from torch.utils.data import DataLoader\n","import torch.optim as optim\n","from tqdm import tqdm\n","\n","def train_cvae(model, dataloader, device, num_epochs=20, lr=1e-3):\n","    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n","    model.to(device)\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        running_loss = 0.0\n","        for x, labels in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n","            x = x.to(device)\n","            c = F.one_hot(labels, num_classes=10).float().to(device)\n","\n","            recon, mu, logvar = model(x, c)\n","            loss = vae_loss(recon, x, mu, logvar)\n","\n","            optimizer.zero_grad()\n","            loss.backward()\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","\n","            optimizer.step()\n","            running_loss += loss.item()\n","\n","        avg_loss = running_loss / len(dataloader)\n","        print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {avg_loss:.4f}\")\n","     "]},{"cell_type":"markdown","id":"5096efde","metadata":{"papermill":{"duration":0.002734,"end_time":"2025-05-19T17:31:14.50292","exception":false,"start_time":"2025-05-19T17:31:14.500186","status":"completed"},"tags":[]},"source":["## Usage"]},{"cell_type":"code","execution_count":5,"id":"d1388a16","metadata":{"execution":{"iopub.execute_input":"2025-05-19T17:31:14.509375Z","iopub.status.busy":"2025-05-19T17:31:14.509185Z","iopub.status.idle":"2025-05-19T17:36:34.504299Z","shell.execute_reply":"2025-05-19T17:36:34.503277Z"},"papermill":{"duration":319.99977,"end_time":"2025-05-19T17:36:34.505561","exception":false,"start_time":"2025-05-19T17:31:14.505791","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["Epoch 1/10: 100%|██████████| 131/131 [00:58<00:00,  2.22it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/10] - Loss: 0.0517\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2/10: 100%|██████████| 131/131 [00:28<00:00,  4.58it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [2/10] - Loss: 0.0364\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3/10: 100%|██████████| 131/131 [00:28<00:00,  4.62it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [3/10] - Loss: 0.0353\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4/10: 100%|██████████| 131/131 [00:28<00:00,  4.63it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [4/10] - Loss: 0.0349\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5/10: 100%|██████████| 131/131 [00:28<00:00,  4.60it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [5/10] - Loss: 0.0347\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 6/10: 100%|██████████| 131/131 [00:28<00:00,  4.63it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [6/10] - Loss: 0.0344\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 7/10: 100%|██████████| 131/131 [00:28<00:00,  4.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [7/10] - Loss: 0.0342\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 8/10: 100%|██████████| 131/131 [00:28<00:00,  4.61it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [8/10] - Loss: 0.0341\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 9/10: 100%|██████████| 131/131 [00:28<00:00,  4.64it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [9/10] - Loss: 0.0339\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 10/10: 100%|██████████| 131/131 [00:28<00:00,  4.59it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [10/10] - Loss: 0.0340\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# Setup\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","dataset = HyperspectralDataset(root_dir=\"/kaggle/input/beyond-visible-spectrum-ai-for-agriculture-2025p2/Train\")\n","dataloader = DataLoader(dataset, batch_size=16, shuffle=True, num_workers=2)\n","\n","model = CVAE(img_channels=125)\n","train_cvae(model, dataloader, device, num_epochs=10)\n"]},{"cell_type":"markdown","id":"30ab2c61","metadata":{"papermill":{"duration":0.052431,"end_time":"2025-05-19T17:36:34.612056","exception":false,"start_time":"2025-05-19T17:36:34.559625","status":"completed"},"tags":[]},"source":["## Generation"]},{"cell_type":"code","execution_count":6,"id":"1b927ee9","metadata":{"execution":{"iopub.execute_input":"2025-05-19T17:36:34.718534Z","iopub.status.busy":"2025-05-19T17:36:34.717938Z","iopub.status.idle":"2025-05-19T17:36:34.723475Z","shell.execute_reply":"2025-05-19T17:36:34.722915Z"},"papermill":{"duration":0.059864,"end_time":"2025-05-19T17:36:34.724515","exception":false,"start_time":"2025-05-19T17:36:34.664651","status":"completed"},"tags":[]},"outputs":[],"source":["def generate_samples(model, disease_level, num_samples=50, latent_dim=128, device='cpu'):\n","    model.eval()\n","    with torch.no_grad():\n","        z = torch.randn(num_samples, latent_dim).to(device)\n","        labels = torch.full((num_samples,), disease_level, dtype=torch.long).to(device)\n","        c = F.one_hot(labels, num_classes=10).float()\n","        samples = model.decode(z, c)\n","        return samples.cpu().numpy()  # (B, C, H, W)\n"]},{"cell_type":"markdown","id":"5e242cdf","metadata":{"papermill":{"duration":0.052643,"end_time":"2025-05-19T17:36:34.830172","exception":false,"start_time":"2025-05-19T17:36:34.777529","status":"completed"},"tags":[]},"source":["# Submission"]},{"cell_type":"markdown","id":"d7941109","metadata":{"papermill":{"duration":0.052953,"end_time":"2025-05-19T17:36:34.936192","exception":false,"start_time":"2025-05-19T17:36:34.883239","status":"completed"},"tags":[]},"source":[]},{"cell_type":"code","execution_count":7,"id":"aa097ff8","metadata":{"execution":{"iopub.execute_input":"2025-05-19T17:36:35.041808Z","iopub.status.busy":"2025-05-19T17:36:35.041536Z","iopub.status.idle":"2025-05-19T17:36:35.054367Z","shell.execute_reply":"2025-05-19T17:36:35.053859Z"},"papermill":{"duration":0.06745,"end_time":"2025-05-19T17:36:35.055486","exception":false,"start_time":"2025-05-19T17:36:34.988036","status":"completed"},"tags":[]},"outputs":[],"source":["import torch\n","\n","# Normalized SRFs for 125 bands\n","SRF_GREEN = torch.tensor([\n","    0.0000,0.0000,0.0000,0.0000,0.0001,0.0002,0.0005,0.0008,0.0014,0.0024,0.0041,\n","    0.0069,0.0113,0.0180,0.0279,0.0414,0.0583,0.0783,0.1008,0.1252,0.1507,0.1766,\n","    0.2023,0.2271,0.2505,0.2721,0.2913,0.3079,0.3216,0.3324,0.3404,0.3459,0.3495,\n","    0.3516,0.3528,0.3533,0.3535,0.3536,0.3538,0.3539,0.3541,0.3542,0.3542,0.3541,\n","    0.3535,0.3520,0.3491,0.3443,0.3373,0.3277,0.3152,0.2997,0.2811,0.2595,0.2349,\n","    0.2076,0.1778,0.1462,0.1140,0.0823,0.0524,0.0259,0.0037,0.0003,0.0000,0.0000,\n","    0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,\n","]).float()\n","SRF_RED = torch.tensor([\n","    0.0000,0.0000,0.0000,0.0000,0.0001,0.0002,0.0003,0.0006,0.0012,0.0024,0.0047,\n","    0.0087,0.0154,0.0255,0.0395,0.0575,0.0786,0.1020,0.1265,0.1505,0.1732,0.1940,\n","    0.2121,0.2269,0.2381,0.2454,0.2491,0.2494,0.2466,0.2409,0.2326,0.2219,0.2093,\n","    0.1952,0.1799,0.1639,0.1476,0.1314,0.1157,0.1008,0.0870,0.0744,0.0629,0.0525,\n","    0.0430,0.0344,0.0266,0.0195,0.0129,0.0070,0.0018,0.0003,0.0000,0.0000,0.0000,\n","    0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,\n","]).float()\n","SRF_NIR = torch.tensor([\n","    0.0000,0.0000,0.0000,0.0000,0.0000,0.0001,0.0002,0.0003,0.0006,0.0011,0.0022,\n","    0.0041,0.0073,0.0125,0.0204,0.0317,0.0470,0.0666,0.0905,0.1185,0.1500,0.1841,\n","    0.2196,0.2554,0.2900,0.3219,0.3495,0.3715,0.3870,0.3950,0.3950,0.3872,0.3721,\n","    0.3503,0.3228,0.2912,0.2573,0.2228,0.1888,0.1563,0.1261,0.0990,0.0755,0.0557,\n","    0.0395,0.0265,0.0162,0.0082,0.0023,0.0003,0.0000,0.0000,0.0000,0.0000,0.0000,\n","    0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,\n","]).float()\n","\n","# Normalize SRFs\n","SRF_TABLE = {\n","    'green': SRF_GREEN / SRF_GREEN.sum(),\n","    'red'  : SRF_RED / SRF_RED.sum(),\n","    'nir'  : SRF_NIR / SRF_NIR.sum(),\n","}\n","\n","\n","import torch.nn.functional as F\n","\n","def interpolate_srf(srf, target_len):\n","    srf = srf.view(1, 1, -1)  # (1, 1, original_len)\n","    srf = F.interpolate(srf, size=target_len, mode='linear', align_corners=False)\n","    return srf.view(-1)\n","\n","def hs_to_rgb(hs_img: torch.Tensor) -> torch.Tensor:\n","    \"\"\"\n","    Project a hyperspectral image (C, H, W) to RGB using interpolated SRFs.\n","    Returns an RGB image of shape (3, H, W)\n","    \"\"\"\n","    assert hs_img.dim() == 3, \"Expected (C, H, W)\"\n","    C, H, W = hs_img.shape\n","    device = hs_img.device\n","\n","    rgb = []\n","    for band, srf in zip(['green', 'red', 'nir'], [SRF_GREEN, SRF_RED, SRF_NIR]):\n","        w = interpolate_srf(srf, C).to(device)\n","        w = w / (w.sum() + 1e-8)  # normalize\n","        w = w.view(C, 1, 1)\n","        channel = (hs_img * w).sum(0)\n","        rgb.append(channel)\n","\n","    return torch.stack(rgb)\n"]},{"cell_type":"code","execution_count":8,"id":"c176f73f","metadata":{"execution":{"iopub.execute_input":"2025-05-19T17:36:35.160992Z","iopub.status.busy":"2025-05-19T17:36:35.160724Z","iopub.status.idle":"2025-05-19T17:36:35.754125Z","shell.execute_reply":"2025-05-19T17:36:35.753565Z"},"papermill":{"duration":0.648004,"end_time":"2025-05-19T17:36:35.755607","exception":false,"start_time":"2025-05-19T17:36:35.107603","status":"completed"},"tags":[]},"outputs":[],"source":["from torchvision.models import inception_v3, Inception_V3_Weights\n","import torch.nn as nn\n","\n","class InceptionPool3(nn.Module):\n","    def __init__(self, device):\n","        super().__init__()\n","        weights = Inception_V3_Weights.IMAGENET1K_V1\n","        net = inception_v3(weights=weights, aux_logits=True, transform_input=False).to(device)\n","        net.eval()\n","\n","        net.AuxLogits = nn.Identity()  # Remove aux\n","        self.stem_and_blocks = nn.Sequential(*list(net.children())[:-2])  # Cut off classifier\n","\n","    def forward(self, x):  # x: (B, 3, H, W)\n","        with torch.no_grad():\n","            x = F.interpolate(x, size=(299, 299), mode='bilinear', align_corners=False)\n","            x = self.stem_and_blocks(x)\n","            x = F.adaptive_avg_pool2d(x, output_size=1)\n","            return x.view(x.size(0), -1)\n"]},{"cell_type":"markdown","id":"c6f346b9","metadata":{"papermill":{"duration":0.051571,"end_time":"2025-05-19T17:36:35.860245","exception":false,"start_time":"2025-05-19T17:36:35.808674","status":"completed"},"tags":[]},"source":["## FID calculation"]},{"cell_type":"code","execution_count":9,"id":"882fdc07","metadata":{"execution":{"iopub.execute_input":"2025-05-19T17:36:35.966291Z","iopub.status.busy":"2025-05-19T17:36:35.965745Z","iopub.status.idle":"2025-05-19T17:36:36.495347Z","shell.execute_reply":"2025-05-19T17:36:36.494375Z"},"papermill":{"duration":0.585142,"end_time":"2025-05-19T17:36:36.497353","exception":false,"start_time":"2025-05-19T17:36:35.912211","status":"completed"},"tags":[]},"outputs":[],"source":["from scipy.linalg import sqrtm\n","import numpy as np\n","\n","def compute_fid(mu1, sigma1, mu2, sigma2, eps=1e-6):\n","    \"\"\"Compute Fréchet Inception Distance.\"\"\"\n","    diff = mu1 - mu2\n","    covmean, _ = sqrtm(sigma1 @ sigma2, disp=False)\n","    if not np.isfinite(covmean).all():\n","        covmean = sqrtm((sigma1 + eps * np.eye(sigma1.shape[0])) @ \n","                        (sigma2 + eps * np.eye(sigma2.shape[0])))\n","    if np.iscomplexobj(covmean):\n","        covmean = covmean.real\n","    return diff.dot(diff) + np.trace(sigma1 + sigma2 - 2.0 * covmean)\n"]},{"cell_type":"code","execution_count":10,"id":"6595fe7f","metadata":{"execution":{"iopub.execute_input":"2025-05-19T17:36:36.604062Z","iopub.status.busy":"2025-05-19T17:36:36.603751Z","iopub.status.idle":"2025-05-19T17:36:38.088352Z","shell.execute_reply":"2025-05-19T17:36:38.087542Z"},"papermill":{"duration":1.539189,"end_time":"2025-05-19T17:36:38.089811","exception":false,"start_time":"2025-05-19T17:36:36.550622","status":"completed"},"tags":[]},"outputs":[],"source":["import os\n","import pandas as pd\n","from tqdm import tqdm\n","\n","def generate_submission(model, fid_model, real_eval_dir, output_dir, device, num_levels=10, num_samples=50):\n","    model.eval()\n","    fid_model.eval()\n","    latent_dim = model.latent_dim\n","    fid_scores = []\n","\n","    os.makedirs(output_dir, exist_ok=True)\n","\n","    for level in tqdm(range(num_levels), desc=\"Generating submission\"):\n","        z = torch.randn(num_samples, latent_dim).to(device)\n","        labels = torch.full((num_samples,), level, dtype=torch.long).to(device)\n","        c = F.one_hot(labels, num_classes=num_levels).float().to(device)\n","        with torch.no_grad():\n","            fake_hsi = model.decode(z, c).cpu()\n","\n","        # Save optional .npy files\n","        for i in range(num_samples):\n","            out_path = os.path.join(output_dir, f\"gen_{level}_{i}.npy\")\n","            np.save(out_path, fake_hsi[i].numpy())\n","\n","        fake_rgb = torch.stack([hs_to_rgb(img) for img in fake_hsi]).to(device)\n","\n","        # Load real RGB images\n","        real_rgb = []\n","        real_folder = os.path.join(real_eval_dir, str(level))\n","        for f in sorted(os.listdir(real_folder))[:num_samples]:\n","            real = torch.tensor(np.load(os.path.join(real_folder, f))).float()\n","            real_rgb.append(hs_to_rgb(real))\n","        real_rgb = torch.stack(real_rgb).to(device)\n","\n","        # Compute Inception features\n","        f_fake = fid_model(fake_rgb).cpu().numpy()\n","        f_real = fid_model(real_rgb).cpu().numpy()\n","\n","        mu_fake, sigma_fake = f_fake.mean(0), np.cov(f_fake, rowvar=False)\n","        mu_real, sigma_real = f_real.mean(0), np.cov(f_real, rowvar=False)\n","        fid = compute_fid(mu_fake, sigma_fake, mu_real, sigma_real)\n","        fid_scores.append(fid)\n","\n","    # Write submission\n","    submission_df = pd.DataFrame({'ID': list(range(1, num_levels + 1)), 'Prediction': fid_scores})\n","    submission_df.to_csv(os.path.join(output_dir, \"submission.csv\"), index=False)\n","    return submission_df\n"]},{"cell_type":"markdown","id":"8f4e019f","metadata":{"papermill":{"duration":0.051818,"end_time":"2025-05-19T17:36:38.194922","exception":false,"start_time":"2025-05-19T17:36:38.143104","status":"completed"},"tags":[]},"source":[]},{"cell_type":"code","execution_count":11,"id":"e69a9167","metadata":{"execution":{"iopub.execute_input":"2025-05-19T17:36:38.300432Z","iopub.status.busy":"2025-05-19T17:36:38.299653Z","iopub.status.idle":"2025-05-19T17:36:38.450489Z","shell.execute_reply":"2025-05-19T17:36:38.449509Z"},"papermill":{"duration":0.204947,"end_time":"2025-05-19T17:36:38.45195","exception":false,"start_time":"2025-05-19T17:36:38.247003","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["0  1  2  3  4  5  6  7\t8  9\r\n"]}],"source":["!ls ../input/beyond-visible-spectrum-ai-for-agriculture-2025p2/evaluation\n"]},{"cell_type":"code","execution_count":12,"id":"3cc8e50e","metadata":{"execution":{"iopub.execute_input":"2025-05-19T17:36:38.561037Z","iopub.status.busy":"2025-05-19T17:36:38.560764Z","iopub.status.idle":"2025-05-19T17:38:16.973966Z","shell.execute_reply":"2025-05-19T17:38:16.973163Z"},"papermill":{"duration":98.46856,"end_time":"2025-05-19T17:38:16.975502","exception":false,"start_time":"2025-05-19T17:36:38.506942","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n","100%|██████████| 104M/104M [00:00<00:00, 188MB/s] \n","Generating submission: 100%|██████████| 10/10 [01:37<00:00,  9.73s/it]\n"]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","fid_model = InceptionPool3(device)\n","\n","submission = generate_submission(\n","    model=model,  \n","    fid_model=fid_model,\n","    real_eval_dir=\"../input/beyond-visible-spectrum-ai-for-agriculture-2025p2/evaluation\",  # replace with actual path\n","    output_dir=\"./generated_submission\",\n","    device=device\n",")\n"]},{"cell_type":"code","execution_count":13,"id":"d1d71579","metadata":{"execution":{"iopub.execute_input":"2025-05-19T17:38:17.113851Z","iopub.status.busy":"2025-05-19T17:38:17.113419Z","iopub.status.idle":"2025-05-19T17:38:17.268945Z","shell.execute_reply":"2025-05-19T17:38:17.267937Z"},"papermill":{"duration":0.234211,"end_time":"2025-05-19T17:38:17.270512","exception":false,"start_time":"2025-05-19T17:38:17.036301","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["gen_0_0.npy   gen_2_10.npy  gen_4_11.npy  gen_6_12.npy\tgen_8_13.npy\r\n","gen_0_10.npy  gen_2_11.npy  gen_4_12.npy  gen_6_13.npy\tgen_8_14.npy\r\n","gen_0_11.npy  gen_2_12.npy  gen_4_13.npy  gen_6_14.npy\tgen_8_15.npy\r\n","gen_0_12.npy  gen_2_13.npy  gen_4_14.npy  gen_6_15.npy\tgen_8_16.npy\r\n","gen_0_13.npy  gen_2_14.npy  gen_4_15.npy  gen_6_16.npy\tgen_8_17.npy\r\n","gen_0_14.npy  gen_2_15.npy  gen_4_16.npy  gen_6_17.npy\tgen_8_18.npy\r\n","gen_0_15.npy  gen_2_16.npy  gen_4_17.npy  gen_6_18.npy\tgen_8_19.npy\r\n","gen_0_16.npy  gen_2_17.npy  gen_4_18.npy  gen_6_19.npy\tgen_8_1.npy\r\n","gen_0_17.npy  gen_2_18.npy  gen_4_19.npy  gen_6_1.npy\tgen_8_20.npy\r\n","gen_0_18.npy  gen_2_19.npy  gen_4_1.npy   gen_6_20.npy\tgen_8_21.npy\r\n","gen_0_19.npy  gen_2_1.npy   gen_4_20.npy  gen_6_21.npy\tgen_8_22.npy\r\n","gen_0_1.npy   gen_2_20.npy  gen_4_21.npy  gen_6_22.npy\tgen_8_23.npy\r\n","gen_0_20.npy  gen_2_21.npy  gen_4_22.npy  gen_6_23.npy\tgen_8_24.npy\r\n","gen_0_21.npy  gen_2_22.npy  gen_4_23.npy  gen_6_24.npy\tgen_8_25.npy\r\n","gen_0_22.npy  gen_2_23.npy  gen_4_24.npy  gen_6_25.npy\tgen_8_26.npy\r\n","gen_0_23.npy  gen_2_24.npy  gen_4_25.npy  gen_6_26.npy\tgen_8_27.npy\r\n","gen_0_24.npy  gen_2_25.npy  gen_4_26.npy  gen_6_27.npy\tgen_8_28.npy\r\n","gen_0_25.npy  gen_2_26.npy  gen_4_27.npy  gen_6_28.npy\tgen_8_29.npy\r\n","gen_0_26.npy  gen_2_27.npy  gen_4_28.npy  gen_6_29.npy\tgen_8_2.npy\r\n","gen_0_27.npy  gen_2_28.npy  gen_4_29.npy  gen_6_2.npy\tgen_8_30.npy\r\n","gen_0_28.npy  gen_2_29.npy  gen_4_2.npy   gen_6_30.npy\tgen_8_31.npy\r\n","gen_0_29.npy  gen_2_2.npy   gen_4_30.npy  gen_6_31.npy\tgen_8_32.npy\r\n","gen_0_2.npy   gen_2_30.npy  gen_4_31.npy  gen_6_32.npy\tgen_8_33.npy\r\n","gen_0_30.npy  gen_2_31.npy  gen_4_32.npy  gen_6_33.npy\tgen_8_34.npy\r\n","gen_0_31.npy  gen_2_32.npy  gen_4_33.npy  gen_6_34.npy\tgen_8_35.npy\r\n","gen_0_32.npy  gen_2_33.npy  gen_4_34.npy  gen_6_35.npy\tgen_8_36.npy\r\n","gen_0_33.npy  gen_2_34.npy  gen_4_35.npy  gen_6_36.npy\tgen_8_37.npy\r\n","gen_0_34.npy  gen_2_35.npy  gen_4_36.npy  gen_6_37.npy\tgen_8_38.npy\r\n","gen_0_35.npy  gen_2_36.npy  gen_4_37.npy  gen_6_38.npy\tgen_8_39.npy\r\n","gen_0_36.npy  gen_2_37.npy  gen_4_38.npy  gen_6_39.npy\tgen_8_3.npy\r\n","gen_0_37.npy  gen_2_38.npy  gen_4_39.npy  gen_6_3.npy\tgen_8_40.npy\r\n","gen_0_38.npy  gen_2_39.npy  gen_4_3.npy   gen_6_40.npy\tgen_8_41.npy\r\n","gen_0_39.npy  gen_2_3.npy   gen_4_40.npy  gen_6_41.npy\tgen_8_42.npy\r\n","gen_0_3.npy   gen_2_40.npy  gen_4_41.npy  gen_6_42.npy\tgen_8_43.npy\r\n","gen_0_40.npy  gen_2_41.npy  gen_4_42.npy  gen_6_43.npy\tgen_8_44.npy\r\n","gen_0_41.npy  gen_2_42.npy  gen_4_43.npy  gen_6_44.npy\tgen_8_45.npy\r\n","gen_0_42.npy  gen_2_43.npy  gen_4_44.npy  gen_6_45.npy\tgen_8_46.npy\r\n","gen_0_43.npy  gen_2_44.npy  gen_4_45.npy  gen_6_46.npy\tgen_8_47.npy\r\n","gen_0_44.npy  gen_2_45.npy  gen_4_46.npy  gen_6_47.npy\tgen_8_48.npy\r\n","gen_0_45.npy  gen_2_46.npy  gen_4_47.npy  gen_6_48.npy\tgen_8_49.npy\r\n","gen_0_46.npy  gen_2_47.npy  gen_4_48.npy  gen_6_49.npy\tgen_8_4.npy\r\n","gen_0_47.npy  gen_2_48.npy  gen_4_49.npy  gen_6_4.npy\tgen_8_5.npy\r\n","gen_0_48.npy  gen_2_49.npy  gen_4_4.npy   gen_6_5.npy\tgen_8_6.npy\r\n","gen_0_49.npy  gen_2_4.npy   gen_4_5.npy   gen_6_6.npy\tgen_8_7.npy\r\n","gen_0_4.npy   gen_2_5.npy   gen_4_6.npy   gen_6_7.npy\tgen_8_8.npy\r\n","gen_0_5.npy   gen_2_6.npy   gen_4_7.npy   gen_6_8.npy\tgen_8_9.npy\r\n","gen_0_6.npy   gen_2_7.npy   gen_4_8.npy   gen_6_9.npy\tgen_9_0.npy\r\n","gen_0_7.npy   gen_2_8.npy   gen_4_9.npy   gen_7_0.npy\tgen_9_10.npy\r\n","gen_0_8.npy   gen_2_9.npy   gen_5_0.npy   gen_7_10.npy\tgen_9_11.npy\r\n","gen_0_9.npy   gen_3_0.npy   gen_5_10.npy  gen_7_11.npy\tgen_9_12.npy\r\n","gen_1_0.npy   gen_3_10.npy  gen_5_11.npy  gen_7_12.npy\tgen_9_13.npy\r\n","gen_1_10.npy  gen_3_11.npy  gen_5_12.npy  gen_7_13.npy\tgen_9_14.npy\r\n","gen_1_11.npy  gen_3_12.npy  gen_5_13.npy  gen_7_14.npy\tgen_9_15.npy\r\n","gen_1_12.npy  gen_3_13.npy  gen_5_14.npy  gen_7_15.npy\tgen_9_16.npy\r\n","gen_1_13.npy  gen_3_14.npy  gen_5_15.npy  gen_7_16.npy\tgen_9_17.npy\r\n","gen_1_14.npy  gen_3_15.npy  gen_5_16.npy  gen_7_17.npy\tgen_9_18.npy\r\n","gen_1_15.npy  gen_3_16.npy  gen_5_17.npy  gen_7_18.npy\tgen_9_19.npy\r\n","gen_1_16.npy  gen_3_17.npy  gen_5_18.npy  gen_7_19.npy\tgen_9_1.npy\r\n","gen_1_17.npy  gen_3_18.npy  gen_5_19.npy  gen_7_1.npy\tgen_9_20.npy\r\n","gen_1_18.npy  gen_3_19.npy  gen_5_1.npy   gen_7_20.npy\tgen_9_21.npy\r\n","gen_1_19.npy  gen_3_1.npy   gen_5_20.npy  gen_7_21.npy\tgen_9_22.npy\r\n","gen_1_1.npy   gen_3_20.npy  gen_5_21.npy  gen_7_22.npy\tgen_9_23.npy\r\n","gen_1_20.npy  gen_3_21.npy  gen_5_22.npy  gen_7_23.npy\tgen_9_24.npy\r\n","gen_1_21.npy  gen_3_22.npy  gen_5_23.npy  gen_7_24.npy\tgen_9_25.npy\r\n","gen_1_22.npy  gen_3_23.npy  gen_5_24.npy  gen_7_25.npy\tgen_9_26.npy\r\n","gen_1_23.npy  gen_3_24.npy  gen_5_25.npy  gen_7_26.npy\tgen_9_27.npy\r\n","gen_1_24.npy  gen_3_25.npy  gen_5_26.npy  gen_7_27.npy\tgen_9_28.npy\r\n","gen_1_25.npy  gen_3_26.npy  gen_5_27.npy  gen_7_28.npy\tgen_9_29.npy\r\n","gen_1_26.npy  gen_3_27.npy  gen_5_28.npy  gen_7_29.npy\tgen_9_2.npy\r\n","gen_1_27.npy  gen_3_28.npy  gen_5_29.npy  gen_7_2.npy\tgen_9_30.npy\r\n","gen_1_28.npy  gen_3_29.npy  gen_5_2.npy   gen_7_30.npy\tgen_9_31.npy\r\n","gen_1_29.npy  gen_3_2.npy   gen_5_30.npy  gen_7_31.npy\tgen_9_32.npy\r\n","gen_1_2.npy   gen_3_30.npy  gen_5_31.npy  gen_7_32.npy\tgen_9_33.npy\r\n","gen_1_30.npy  gen_3_31.npy  gen_5_32.npy  gen_7_33.npy\tgen_9_34.npy\r\n","gen_1_31.npy  gen_3_32.npy  gen_5_33.npy  gen_7_34.npy\tgen_9_35.npy\r\n","gen_1_32.npy  gen_3_33.npy  gen_5_34.npy  gen_7_35.npy\tgen_9_36.npy\r\n","gen_1_33.npy  gen_3_34.npy  gen_5_35.npy  gen_7_36.npy\tgen_9_37.npy\r\n","gen_1_34.npy  gen_3_35.npy  gen_5_36.npy  gen_7_37.npy\tgen_9_38.npy\r\n","gen_1_35.npy  gen_3_36.npy  gen_5_37.npy  gen_7_38.npy\tgen_9_39.npy\r\n","gen_1_36.npy  gen_3_37.npy  gen_5_38.npy  gen_7_39.npy\tgen_9_3.npy\r\n","gen_1_37.npy  gen_3_38.npy  gen_5_39.npy  gen_7_3.npy\tgen_9_40.npy\r\n","gen_1_38.npy  gen_3_39.npy  gen_5_3.npy   gen_7_40.npy\tgen_9_41.npy\r\n","gen_1_39.npy  gen_3_3.npy   gen_5_40.npy  gen_7_41.npy\tgen_9_42.npy\r\n","gen_1_3.npy   gen_3_40.npy  gen_5_41.npy  gen_7_42.npy\tgen_9_43.npy\r\n","gen_1_40.npy  gen_3_41.npy  gen_5_42.npy  gen_7_43.npy\tgen_9_44.npy\r\n","gen_1_41.npy  gen_3_42.npy  gen_5_43.npy  gen_7_44.npy\tgen_9_45.npy\r\n","gen_1_42.npy  gen_3_43.npy  gen_5_44.npy  gen_7_45.npy\tgen_9_46.npy\r\n","gen_1_43.npy  gen_3_44.npy  gen_5_45.npy  gen_7_46.npy\tgen_9_47.npy\r\n","gen_1_44.npy  gen_3_45.npy  gen_5_46.npy  gen_7_47.npy\tgen_9_48.npy\r\n","gen_1_45.npy  gen_3_46.npy  gen_5_47.npy  gen_7_48.npy\tgen_9_49.npy\r\n","gen_1_46.npy  gen_3_47.npy  gen_5_48.npy  gen_7_49.npy\tgen_9_4.npy\r\n","gen_1_47.npy  gen_3_48.npy  gen_5_49.npy  gen_7_4.npy\tgen_9_5.npy\r\n","gen_1_48.npy  gen_3_49.npy  gen_5_4.npy   gen_7_5.npy\tgen_9_6.npy\r\n","gen_1_49.npy  gen_3_4.npy   gen_5_5.npy   gen_7_6.npy\tgen_9_7.npy\r\n","gen_1_4.npy   gen_3_5.npy   gen_5_6.npy   gen_7_7.npy\tgen_9_8.npy\r\n","gen_1_5.npy   gen_3_6.npy   gen_5_7.npy   gen_7_8.npy\tgen_9_9.npy\r\n","gen_1_6.npy   gen_3_7.npy   gen_5_8.npy   gen_7_9.npy\tsubmission.csv\r\n","gen_1_7.npy   gen_3_8.npy   gen_5_9.npy   gen_8_0.npy\r\n","gen_1_8.npy   gen_3_9.npy   gen_6_0.npy   gen_8_10.npy\r\n","gen_1_9.npy   gen_4_0.npy   gen_6_10.npy  gen_8_11.npy\r\n","gen_2_0.npy   gen_4_10.npy  gen_6_11.npy  gen_8_12.npy\r\n"]}],"source":["!ls generated_submission"]},{"cell_type":"code","execution_count":14,"id":"77a1c7fb","metadata":{"execution":{"iopub.execute_input":"2025-05-19T17:38:17.411123Z","iopub.status.busy":"2025-05-19T17:38:17.410823Z","iopub.status.idle":"2025-05-19T17:38:18.358544Z","shell.execute_reply":"2025-05-19T17:38:18.357549Z"},"papermill":{"duration":1.006762,"end_time":"2025-05-19T17:38:18.359868","exception":false,"start_time":"2025-05-19T17:38:17.353106","status":"completed"},"tags":[]},"outputs":[],"source":["!rm generated_submission/*npy"]},{"cell_type":"code","execution_count":15,"id":"fe13bed6","metadata":{"execution":{"iopub.execute_input":"2025-05-19T17:38:18.467966Z","iopub.status.busy":"2025-05-19T17:38:18.467694Z","iopub.status.idle":"2025-05-19T17:38:18.618264Z","shell.execute_reply":"2025-05-19T17:38:18.617519Z"},"papermill":{"duration":0.205549,"end_time":"2025-05-19T17:38:18.61961","exception":false,"start_time":"2025-05-19T17:38:18.414061","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["ID,Prediction\r\n","1,14397712.89194936\r\n","2,11435704.678536616\r\n","3,14679595.898587903\r\n","4,12684752.026057094\r\n","5,13448411.392849056\r\n","6,10758936.901352173\r\n","7,12190513.780222293\r\n","8,12358015.4095991\r\n","9,9989942.804649405\r\n"]}],"source":["!head generated_submission/submission.csv"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":12076007,"sourceId":100385,"sourceType":"competition"}],"dockerImageVersionId":31040,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"papermill":{"default_parameters":{},"duration":436.623987,"end_time":"2025-05-19T17:38:22.026461","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-05-19T17:31:05.402474","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}