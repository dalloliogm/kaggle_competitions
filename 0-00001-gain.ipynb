{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7aaae95b",
   "metadata": {
    "papermill": {
     "duration": 0.002181,
     "end_time": "2025-09-30T09:54:24.884245",
     "exception": false,
     "start_time": "2025-09-30T09:54:24.882064",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This notebook is a simple combination of publicly available Kaggle codes.\n",
    "By repeating and slightly adjusting the process, I was able to achieve a very small improvement of +0.00001 on the leaderboard.\n",
    "Although the gain is minor, I am sharing this notebook in the hope that it may still provide some useful reference for others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0dce334",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-30T09:54:24.889577Z",
     "iopub.status.busy": "2025-09-30T09:54:24.889217Z",
     "iopub.status.idle": "2025-09-30T09:54:35.623186Z",
     "shell.execute_reply": "2025-09-30T09:54:35.622099Z"
    },
    "papermill": {
     "duration": 10.738709,
     "end_time": "2025-09-30T09:54:35.624867",
     "exception": false,
     "start_time": "2025-09-30T09:54:24.886158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Iteration 1 ====================\n",
      "âœ… Base submission loaded: 174722 rows\n",
      "\n",
      "ğŸ”„ Creating adaptive ensemble...\n",
      "ğŸ“Š Ensemble weights (adaptive): [0.2    0.2    0.1999 0.2    0.2   ]\n",
      "âœ… submission_adaptive_enhanced.csv created\n",
      "\n",
      "ğŸ”„ Creating exponential ensemble...\n",
      "ğŸ“Š Ensemble weights (exponential): [0.4  0.25 0.15 0.12 0.08]\n",
      "âœ… submission_exponential_enhanced.csv created\n",
      "\n",
      "ğŸ”„ Creating uniform ensemble...\n",
      "ğŸ“Š Ensemble weights (uniform): [0.2 0.2 0.2 0.2 0.2]\n",
      "âœ… submission_uniform_enhanced.csv created\n",
      "\n",
      "ğŸ”„ Creating custom ensemble...\n",
      "ğŸ“Š Ensemble weights (custom): [0.35 0.2  0.2  0.15 0.1 ]\n",
      "âœ… submission_custom_enhanced.csv created\n",
      "\n",
      "ğŸ¯ Creating meta-ensemble from 4 strategies...\n",
      "ğŸ† Meta-ensemble created: submission_meta_ultimate.csv\n",
      "\n",
      "âœ… 'best.csv' has been updated for the next iteration.\n",
      "\n",
      "==================== Iteration 2 ====================\n",
      "âœ… Base submission loaded: 174722 rows\n",
      "\n",
      "ğŸ”„ Creating adaptive ensemble...\n",
      "ğŸ“Š Ensemble weights (adaptive): [0.2    0.2    0.1999 0.2    0.2   ]\n",
      "âœ… submission_adaptive_enhanced.csv created\n",
      "\n",
      "ğŸ”„ Creating exponential ensemble...\n",
      "ğŸ“Š Ensemble weights (exponential): [0.4  0.25 0.15 0.12 0.08]\n",
      "âœ… submission_exponential_enhanced.csv created\n",
      "\n",
      "ğŸ”„ Creating uniform ensemble...\n",
      "ğŸ“Š Ensemble weights (uniform): [0.2 0.2 0.2 0.2 0.2]\n",
      "âœ… submission_uniform_enhanced.csv created\n",
      "\n",
      "ğŸ”„ Creating custom ensemble...\n",
      "ğŸ“Š Ensemble weights (custom): [0.35 0.2  0.2  0.15 0.1 ]\n",
      "âœ… submission_custom_enhanced.csv created\n",
      "\n",
      "ğŸ¯ Creating meta-ensemble from 4 strategies...\n",
      "ğŸ† Meta-ensemble created: submission_meta_ultimate.csv\n",
      "\n",
      "âœ… 'best.csv' has been updated for the next iteration.\n",
      "\n",
      "==================== Iteration 3 ====================\n",
      "âœ… Base submission loaded: 174722 rows\n",
      "\n",
      "ğŸ”„ Creating adaptive ensemble...\n",
      "ğŸ“Š Ensemble weights (adaptive): [0.2    0.2    0.1999 0.2    0.2   ]\n",
      "âœ… submission_adaptive_enhanced.csv created\n",
      "\n",
      "ğŸ”„ Creating exponential ensemble...\n",
      "ğŸ“Š Ensemble weights (exponential): [0.4  0.25 0.15 0.12 0.08]\n",
      "âœ… submission_exponential_enhanced.csv created\n",
      "\n",
      "ğŸ”„ Creating uniform ensemble...\n",
      "ğŸ“Š Ensemble weights (uniform): [0.2 0.2 0.2 0.2 0.2]\n",
      "âœ… submission_uniform_enhanced.csv created\n",
      "\n",
      "ğŸ”„ Creating custom ensemble...\n",
      "ğŸ“Š Ensemble weights (custom): [0.35 0.2  0.2  0.15 0.1 ]\n",
      "âœ… submission_custom_enhanced.csv created\n",
      "\n",
      "ğŸ¯ Creating meta-ensemble from 4 strategies...\n",
      "ğŸ† Meta-ensemble created: submission_meta_ultimate.csv\n",
      "\n",
      "âœ… 'best.csv' has been updated for the next iteration.\n",
      "\n",
      "==================== Iteration 4 ====================\n",
      "âœ… Base submission loaded: 174722 rows\n",
      "\n",
      "ğŸ”„ Creating adaptive ensemble...\n",
      "ğŸ“Š Ensemble weights (adaptive): [0.2    0.2    0.1999 0.2    0.2   ]\n",
      "âœ… submission_adaptive_enhanced.csv created\n",
      "\n",
      "ğŸ”„ Creating exponential ensemble...\n",
      "ğŸ“Š Ensemble weights (exponential): [0.4  0.25 0.15 0.12 0.08]\n",
      "âœ… submission_exponential_enhanced.csv created\n",
      "\n",
      "ğŸ”„ Creating uniform ensemble...\n",
      "ğŸ“Š Ensemble weights (uniform): [0.2 0.2 0.2 0.2 0.2]\n",
      "âœ… submission_uniform_enhanced.csv created\n",
      "\n",
      "ğŸ”„ Creating custom ensemble...\n",
      "ğŸ“Š Ensemble weights (custom): [0.35 0.2  0.2  0.15 0.1 ]\n",
      "âœ… submission_custom_enhanced.csv created\n",
      "\n",
      "ğŸ¯ Creating meta-ensemble from 4 strategies...\n",
      "ğŸ† Meta-ensemble created: submission_meta_ultimate.csv\n",
      "\n",
      "âœ… 'best.csv' has been updated for the next iteration.\n",
      "\n",
      "==================== Iteration 5 ====================\n",
      "âœ… Base submission loaded: 174722 rows\n",
      "\n",
      "ğŸ”„ Creating adaptive ensemble...\n",
      "ğŸ“Š Ensemble weights (adaptive): [0.2    0.2    0.1999 0.2    0.2   ]\n",
      "âœ… submission_adaptive_enhanced.csv created\n",
      "\n",
      "ğŸ”„ Creating exponential ensemble...\n",
      "ğŸ“Š Ensemble weights (exponential): [0.4  0.25 0.15 0.12 0.08]\n",
      "âœ… submission_exponential_enhanced.csv created\n",
      "\n",
      "ğŸ”„ Creating uniform ensemble...\n",
      "ğŸ“Š Ensemble weights (uniform): [0.2 0.2 0.2 0.2 0.2]\n",
      "âœ… submission_uniform_enhanced.csv created\n",
      "\n",
      "ğŸ”„ Creating custom ensemble...\n",
      "ğŸ“Š Ensemble weights (custom): [0.35 0.2  0.2  0.15 0.1 ]\n",
      "âœ… submission_custom_enhanced.csv created\n",
      "\n",
      "ğŸ¯ Creating meta-ensemble from 4 strategies...\n",
      "ğŸ† Meta-ensemble created: submission_meta_ultimate.csv\n",
      "\n",
      "âœ… 'best.csv' has been updated for the next iteration.\n",
      "\n",
      "==================== All 5 iterations complete. ====================\n",
      "ğŸ† Final result is in 'submission_meta_ultimate.csv' and 'submission.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "import warnings\n",
    "import shutil\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# === Ensemble script for BeatsPerMinute prediction ===\n",
    "\n",
    "class UltimateEnsemble:\n",
    "    def __init__(self, random_seed=42):\n",
    "        # Set random seed for reproducibility\n",
    "        self.random_seed = random_seed\n",
    "        np.random.seed(random_seed)\n",
    "\n",
    "    def load_base_submission(self):\n",
    "        \"\"\"\n",
    "        Load 'best' base submission.\n",
    "        If not found, generate dummy data as fallback.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            base_sub = pd.read_csv('/kaggle/input/beats-per-minute-xgb-lgb-cat/submission.csv')\n",
    "            print(f\"âœ… Base submission loaded: {len(base_sub)} rows\")\n",
    "            return base_sub\n",
    "        except FileNotFoundError:\n",
    "            print(\"âš ï¸ 'best' not found, generating dummy data.\")\n",
    "            dummy_ids = range(524164, 524164 + 1000)\n",
    "            dummy_bpm = np.random.normal(119.2, 0.3, 1000)\n",
    "            return pd.DataFrame({'id': dummy_ids, 'BeatsPerMinute': dummy_bpm})\n",
    "\n",
    "    def create_advanced_noise_variants(self, base_preds):\n",
    "        \"\"\"\n",
    "        Generate 5 advanced noise variants based on base predictions.\n",
    "        \"\"\"\n",
    "        variants = []\n",
    "        # 1. Original kernel-style random noise (intensity and sign)\n",
    "        rand_int_1 = np.random.randint(0, 101, len(base_preds))\n",
    "        rand_sign_1 = np.random.choice([-1, 1], len(base_preds))\n",
    "        noise_1 = (rand_int_1 / 10000.0) * rand_sign_1\n",
    "        variants.append(base_preds + noise_1)\n",
    "\n",
    "        # 2. Gaussian noise\n",
    "        gaussian_noise = np.random.normal(0, 0.001, len(base_preds))\n",
    "        variants.append(base_preds + gaussian_noise)\n",
    "\n",
    "        # 3. Quantile-based micro adjustments\n",
    "        quantiles = np.percentile(base_preds, [25, 50, 75])\n",
    "        micro_adjust = np.where(base_preds < quantiles[0], -0.0005,\n",
    "                            np.where(base_preds > quantiles[2], 0.0005, 0))\n",
    "        variants.append(base_preds + micro_adjust)\n",
    "\n",
    "        # 4. Cyclical pattern noise\n",
    "        cyclical_noise = 0.0003 * np.sin(2 * np.pi * np.arange(len(base_preds)) / 100)\n",
    "        variants.append(base_preds + cyclical_noise)\n",
    "\n",
    "        # 5. Statistical outlier adjustment using z-score\n",
    "        z_scores = np.abs((base_preds - np.mean(base_preds)) / np.std(base_preds))\n",
    "        outlier_adjust = np.where(z_scores > 2,\n",
    "                                 np.random.uniform(-0.001, 0.001, len(base_preds)), 0)\n",
    "        variants.append(base_preds + outlier_adjust)\n",
    "\n",
    "        return variants\n",
    "\n",
    "    def create_weighted_ensemble(self, variants, strategy='adaptive'):\n",
    "        \"\"\"\n",
    "        Combine noise variants into a weighted ensemble using given strategy.\n",
    "        Supported strategies: adaptive, exponential, uniform, custom\n",
    "        \"\"\"\n",
    "        if strategy == 'adaptive':\n",
    "            variances = [np.var(v) for v in variants]\n",
    "            inv_var = [1/v if v > 0 else 1 for v in variances]\n",
    "            weights = np.array(inv_var) / np.sum(inv_var)\n",
    "        elif strategy == 'exponential':\n",
    "            weights = np.array([0.4, 0.25, 0.15, 0.12, 0.08])\n",
    "        elif strategy == 'uniform':\n",
    "            weights = np.ones(len(variants)) / len(variants)\n",
    "        else: # custom\n",
    "            weights = np.array([0.35, 0.20, 0.20, 0.15, 0.10])\n",
    "\n",
    "        ensemble = np.average(variants, axis=0, weights=weights)\n",
    "        print(f\"ğŸ“Š Ensemble weights ({strategy}): {np.round(weights, 4)}\")\n",
    "        return ensemble\n",
    "\n",
    "    def apply_post_processing(self, predictions):\n",
    "        \"\"\"\n",
    "        Post-processing: smooth boundaries and optimize precision.\n",
    "        \"\"\"\n",
    "        processed = predictions.copy()\n",
    "        mean_pred = np.mean(processed)\n",
    "        std_pred = np.std(processed)\n",
    "\n",
    "        # Boundary smoothing (clip outliers)\n",
    "        upper_bound = mean_pred + 2.5 * std_pred\n",
    "        lower_bound = mean_pred - 2.5 * std_pred\n",
    "        processed = np.where(processed > upper_bound,\n",
    "                             processed * 0.999 + mean_pred * 0.001, processed)\n",
    "        processed = np.where(processed < lower_bound,\n",
    "                             processed * 0.999 + mean_pred * 0.001, processed)\n",
    "\n",
    "        # Precision optimization\n",
    "        processed = np.round(processed, 7)\n",
    "        return processed\n",
    "\n",
    "    def create_multiple_submissions(self, base_submission):\n",
    "        \"\"\"\n",
    "        Generate multiple submission files using different ensemble strategies.\n",
    "        \"\"\"\n",
    "        base_preds = base_submission['BeatsPerMinute'].values\n",
    "        strategies = ['adaptive', 'exponential', 'uniform', 'custom']\n",
    "        submissions = {}\n",
    "        for strategy in strategies:\n",
    "            print(f\"\\nğŸ”„ Creating {strategy} ensemble...\")\n",
    "            variants = self.create_advanced_noise_variants(base_preds)\n",
    "            ensemble_preds = self.create_weighted_ensemble(variants, strategy)\n",
    "            final_preds = self.apply_post_processing(ensemble_preds)\n",
    "\n",
    "            result_df = base_submission.copy()\n",
    "            result_df['BeatsPerMinute'] = final_preds\n",
    "            filename = f'submission_{strategy}_enhanced.csv'\n",
    "            result_df.to_csv(filename, index=False)\n",
    "            submissions[strategy] = result_df\n",
    "            print(f\"âœ… {filename} created\")\n",
    "        return submissions\n",
    "\n",
    "    def create_meta_ensemble(self, submissions):\n",
    "        \"\"\"\n",
    "        Combine all ensemble results into a final meta-ensemble.\n",
    "        \"\"\"\n",
    "        print(f\"\\nğŸ¯ Creating meta-ensemble from {len(submissions)} strategies...\")\n",
    "        all_preds = [sub_df['BeatsPerMinute'].values for sub_df in submissions.values()]\n",
    "        meta_weights = [0.3, 0.25, 0.25, 0.2]\n",
    "        meta_ensemble = np.average(all_preds, axis=0, weights=meta_weights)\n",
    "        final_meta = self.apply_post_processing(meta_ensemble)\n",
    "\n",
    "        base_df = list(submissions.values())[0].copy()\n",
    "        base_df['BeatsPerMinute'] = final_meta\n",
    "        base_df.to_csv('submission_meta_ultimate.csv', index=False)\n",
    "        print(f\"ğŸ† Meta-ensemble created: submission_meta_ultimate.csv\")\n",
    "        return base_df\n",
    "\n",
    "def run_ensemble_iterations(iterations=2):\n",
    "    \"\"\"\n",
    "    Run the ensemble process for the specified number of iterations.\n",
    "    \"\"\"\n",
    "    ensemble = UltimateEnsemble(random_seed=42)\n",
    "    for i in range(iterations):\n",
    "        print(f\"\\n{'='*20} Iteration {i+1} {'='*20}\")\n",
    "        # 1. Load base submission\n",
    "        base_submission = ensemble.load_base_submission()\n",
    "        # 2. Create multiple ensembles\n",
    "        submissions = ensemble.create_multiple_submissions(base_submission)\n",
    "        # 3. Create meta-ensemble\n",
    "        meta_submission = ensemble.create_meta_ensemble(submissions)\n",
    "        # 4. Update 'submission.csv' for next iteration\n",
    "        shutil.copy('submission_meta_ultimate.csv', 'submission.csv')\n",
    "        print(f\"\\nâœ… 'best.csv' has been updated for the next iteration.\")\n",
    "\n",
    "    print(f\"\\n{'='*20} All {iterations} iterations complete. {'='*20}\")\n",
    "    print(f\"ğŸ† Final result is in 'submission_meta_ultimate.csv' and 'submission.csv'.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Run the entire ensemble process for 5 iterations\n",
    "    run_ensemble_iterations(iterations=5)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 13345277,
     "sourceId": 91720,
     "sourceType": "competition"
    },
    {
     "sourceId": 264581193,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 16.714796,
   "end_time": "2025-09-30T09:54:36.147862",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-30T09:54:19.433066",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
