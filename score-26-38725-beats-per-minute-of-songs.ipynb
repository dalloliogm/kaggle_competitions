{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a235c1f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-10T20:59:11.690118Z",
     "iopub.status.busy": "2025-09-10T20:59:11.689895Z",
     "iopub.status.idle": "2025-09-10T21:05:08.457715Z",
     "shell.execute_reply": "2025-09-10T21:05:08.456793Z"
    },
    "papermill": {
     "duration": 356.772025,
     "end_time": "2025-09-10T21:05:08.459144",
     "exception": false,
     "start_time": "2025-09-10T20:59:11.687119",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 RMSE: 26.463422803149086\n",
      "Fold 2 RMSE: 26.541648201871084\n",
      "Fold 3 RMSE: 26.380426314116118\n",
      "Fold 4 RMSE: 26.449916055920802\n",
      "Fold 5 RMSE: 26.528234838400365\n",
      "Fold 6 RMSE: 26.49852329669373\n",
      "Fold 7 RMSE: 26.544993736639746\n",
      "Fold 8 RMSE: 26.43562855517827\n",
      "Fold 9 RMSE: 26.317323191461874\n",
      "Fold 10 RMSE: 26.44996439822229\n",
      "\n",
      "Optimized Weights: [0.77692201 0.         0.22307799]\n",
      "Optimized RMSE: 26.46076204537075\n",
      "Optimized submission file created!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "from scipy.stats import skew\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Load the competition data\n",
    "train = pd.read_csv('/kaggle/input/playground-series-s5e9/train.csv')\n",
    "test = pd.read_csv('/kaggle/input/playground-series-s5e9/test.csv')\n",
    "submission = pd.read_csv('/kaggle/input/playground-series-s5e9/sample_submission.csv')\n",
    "\n",
    "# Load and concatenate original data\n",
    "original = pd.read_csv('/kaggle/input/bpm-prediction-challenge/Train.csv')\n",
    "train = pd.concat([train, original], ignore_index=True)\n",
    "\n",
    "# Feature engineering\n",
    "def create_features(df):\n",
    "    # Handle missing values\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
    "    \n",
    "    # Interaction features\n",
    "    df['Rhythm_Audio_Interaction'] = df['RhythmScore'] * df['AudioLoudness']\n",
    "    df['Vocal_Acoustic_Ratio'] = df['VocalContent'] / (df['AcousticQuality'] + 1e-6)\n",
    "    df['Energy_Mood_Product'] = df['Energy'] * df['MoodScore']\n",
    "    df['Instrumental_Live_Interaction'] = df['InstrumentalScore'] * df['LivePerformanceLikelihood']\n",
    "    \n",
    "    # Polynomial features\n",
    "    poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "    poly_features = poly.fit_transform(df[['RhythmScore', 'AudioLoudness', 'Energy']])\n",
    "    poly_cols = [f'poly_{i}' for i in range(poly_features.shape[1])]\n",
    "    df[poly_cols] = poly_features\n",
    "    \n",
    "    # Log transformation for skewed features\n",
    "    for col in ['TrackDurationMs', 'AudioLoudness', 'VocalContent']:\n",
    "        if col in df.columns and skew(df[col].dropna()) > 0.5:\n",
    "            if df[col].min() < 0:\n",
    "                shift = abs(df[col].min()) + 1\n",
    "                df[f'log_{col}'] = np.log1p(df[col] + shift)\n",
    "            else:\n",
    "                df[f'log_{col}'] = np.log1p(df[col].clip(lower=0))\n",
    "    \n",
    "    # Binning features\n",
    "    df['Duration_Bin'] = pd.qcut(df['TrackDurationMs'], q=10, labels=False, duplicates='drop')\n",
    "    df['Energy_Bin'] = pd.qcut(df['Energy'], q=5, labels=False, duplicates='drop')\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply feature engineering\n",
    "train = create_features(train)\n",
    "test = create_features(test)\n",
    "\n",
    "# Features list, excluding target and constant features\n",
    "features = [col for col in train.columns if col not in ['id', 'BeatsPerMinute'] and train[col].nunique() > 1]\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(train[features])\n",
    "X_test = scaler.transform(test[features])\n",
    "y = train['BeatsPerMinute']\n",
    "\n",
    "# Model parameters\n",
    "lgb_params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'learning_rate': 0.015,  # Slightly reduced for better generalization\n",
    "    'num_leaves': 40,\n",
    "    'max_depth': 7,\n",
    "    'min_data_in_leaf': 50,\n",
    "    'feature_fraction': 0.65,\n",
    "    'bagging_fraction': 0.75,\n",
    "    'bagging_freq': 5,\n",
    "    'lambda_l1': 0.3,  # Increased regularization\n",
    "    'lambda_l2': 0.3,  # Increased regularization\n",
    "    'verbose': -1,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "xgb_params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse',\n",
    "    'learning_rate': 0.015,  # Slightly reduced\n",
    "    'max_depth': 5,\n",
    "    'min_child_weight': 2,\n",
    "    'subsample': 0.75,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'reg_alpha': 0.3,  # Increased regularization\n",
    "    'reg_lambda': 1.8,  # Increased regularization\n",
    "    'seed': 42,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "cat_params = {\n",
    "    'loss_function': 'RMSE',\n",
    "    'learning_rate': 0.02,  # Slightly reduced\n",
    "    'depth': 6,\n",
    "    'min_data_in_leaf': 50,\n",
    "    'l2_leaf_reg': 3.5,  # Increased regularization\n",
    "    'iterations': 2000,  # Increased iterations\n",
    "    'random_seed': 42,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# K-Fold for training\n",
    "n_splits = 10\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "lgb_preds = np.zeros(len(test))\n",
    "xgb_preds = np.zeros(len(test))\n",
    "cat_preds = np.zeros(len(test))\n",
    "\n",
    "lgb_oof = np.zeros(len(X))\n",
    "xgb_oof = np.zeros(len(X))\n",
    "cat_oof = np.zeros(len(X))\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X, y)):\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    # LightGBM\n",
    "    lgb_train = lgb.Dataset(X_train, y_train)\n",
    "    lgb_val = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
    "    lgb_model = lgb.train(\n",
    "        lgb_params,\n",
    "        lgb_train,\n",
    "        num_boost_round=2000,\n",
    "        valid_sets=[lgb_train, lgb_val],\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=100, verbose=False)]\n",
    "    )\n",
    "    lgb_oof[val_idx] = lgb_model.predict(X_val)\n",
    "    lgb_preds += lgb_model.predict(X_test) / n_splits\n",
    "    \n",
    "    # XGBoost\n",
    "    xgb_train = xgb.DMatrix(X_train, y_train)\n",
    "    xgb_val = xgb.DMatrix(X_val, y_val)\n",
    "    xgb_model = xgb.train(\n",
    "        xgb_params,\n",
    "        xgb_train,\n",
    "        num_boost_round=2000,\n",
    "        evals=[(xgb_val, 'val')],\n",
    "        early_stopping_rounds=100,\n",
    "        verbose_eval=False\n",
    "    )\n",
    "    xgb_oof[val_idx] = xgb_model.predict(xgb_val)\n",
    "    xgb_preds += xgb_model.predict(xgb.DMatrix(X_test)) / n_splits\n",
    "    \n",
    "    # CatBoost\n",
    "    cat_train = cb.Pool(X_train, y_train)\n",
    "    cat_val = cb.Pool(X_val, y_val)\n",
    "    cat_model = cb.CatBoostRegressor(**cat_params)\n",
    "    cat_model.fit(cat_train, eval_set=cat_val, early_stopping_rounds=100, verbose=False)\n",
    "    cat_oof[val_idx] = cat_model.predict(X_val)\n",
    "    cat_preds += cat_model.predict(X_test) / n_splits\n",
    "    \n",
    "    # Print fold RMSE for blend\n",
    "    blend_val_pred = 0.5 * lgb_oof[val_idx] + 0.3 * xgb_oof[val_idx] + 0.2 * cat_oof[val_idx]\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, blend_val_pred))\n",
    "    print(f'Fold {fold+1} RMSE: {rmse}')\n",
    "\n",
    "# Optimize blending weights using OOF predictions\n",
    "def rmse_func(weights):\n",
    "    blend_oof = weights[0] * lgb_oof + weights[1] * xgb_oof + weights[2] * cat_oof\n",
    "    return np.sqrt(mean_squared_error(y, blend_oof))\n",
    "\n",
    "cons = ({'type': 'eq', 'fun': lambda w: 1 - sum(w)})\n",
    "bnds = [(0, 1)] * 3\n",
    "init_guess = [0.5, 0.3, 0.2]\n",
    "\n",
    "opt_res = minimize(rmse_func, init_guess, bounds=bnds, constraints=cons, method='SLSQP')\n",
    "print(f'\\nOptimized Weights: {opt_res.x}')\n",
    "print(f'Optimized RMSE: {opt_res.fun}')\n",
    "\n",
    "# Final blended predictions with optimized weights\n",
    "final_preds = opt_res.x[0] * lgb_preds + opt_res.x[1] * xgb_preds + opt_res.x[2] * cat_preds\n",
    "\n",
    "# Clip predictions to reasonable BPM range (e.g., 40-200 BPM)\n",
    "final_preds = np.clip(final_preds, 40, 200)\n",
    "\n",
    "# Create submission\n",
    "submission['BeatsPerMinute'] = final_preds\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print('Optimized submission file created!')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 13345277,
     "sourceId": 91720,
     "sourceType": "competition"
    },
    {
     "datasetId": 8025996,
     "sourceId": 12699678,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 361.699092,
   "end_time": "2025-09-10T21:05:09.279172",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-10T20:59:07.580080",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
