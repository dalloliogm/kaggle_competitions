{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61673e61",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-28T14:45:51.706399Z",
     "iopub.status.busy": "2025-03-28T14:45:51.706069Z",
     "iopub.status.idle": "2025-03-28T14:45:52.595653Z",
     "shell.execute_reply": "2025-03-28T14:45:52.594482Z"
    },
    "papermill": {
     "duration": 0.895334,
     "end_time": "2025-03-28T14:45:52.597557",
     "exception": false,
     "start_time": "2025-03-28T14:45:51.702223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/el-hackathon-2025/elucidata_ai_challenge_data.h5\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b6fcba",
   "metadata": {
    "papermill": {
     "duration": 0.001942,
     "end_time": "2025-03-28T14:45:52.602341",
     "exception": false,
     "start_time": "2025-03-28T14:45:52.600399",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Elucidata competition\n",
    "\n",
    "This is my main notebook for the Elucidata Competition.\n",
    "\n",
    "Other notebooks:\n",
    "- [EDA Plotting Cell Type Distribution by Slice](http://https://www.kaggle.com/code/dalloliogm/eda-plotting-cell-distribution-by-slice/notebook)\n",
    "- [EDA Exploring Cell Type Abundance](https://www.kaggle.com/code/dalloliogm/eda-exploring-cell-type-abundance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7080051f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T14:45:52.608036Z",
     "iopub.status.busy": "2025-03-28T14:45:52.607563Z",
     "iopub.status.idle": "2025-03-28T14:45:54.283272Z",
     "shell.execute_reply": "2025-03-28T14:45:54.282311Z"
    },
    "papermill": {
     "duration": 1.680664,
     "end_time": "2025-03-28T14:45:54.285116",
     "exception": false,
     "start_time": "2025-03-28T14:45:52.604452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from scipy.spatial import KDTree\n",
    "from scipy.stats import spearmanr\n",
    "from tqdm import tqdm\n",
    "\n",
    "class ElucidataPipeline:\n",
    "    def __init__(self, h5_file_path, test_slide='S_7', submission_path='submission.csv', test_size=0.02, random_state=2024):\n",
    "        self.h5_file_path = h5_file_path\n",
    "        self.test_slide = test_slide\n",
    "        self.submission_path = submission_path\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "\n",
    "        # Data holders\n",
    "        self.train_df = None\n",
    "        self.test_df = None\n",
    "        self.smoothed_ranks = None\n",
    "\n",
    "        # Model I/O\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.X_train = None\n",
    "        self.X_valid = None\n",
    "        self.y_train = None\n",
    "        self.y_valid = None\n",
    "        self.models = {}\n",
    "        self.predictions = None\n",
    "\n",
    "    def load_train_data(self):\n",
    "        print(\"Loading training data...\")\n",
    "        with h5py.File(self.h5_file_path, \"r\") as f:\n",
    "            train_spots = f[\"spots/Train\"]\n",
    "            train_spot_tables = {\n",
    "                slide_name: pd.DataFrame(np.array(train_spots[slide_name]))\n",
    "                for slide_name in train_spots.keys()\n",
    "            }\n",
    "        self.train_df = pd.concat(train_spot_tables.values(), ignore_index=True)\n",
    "        print(f\"Training data loaded. Shape: {self.train_df.shape}\")\n",
    "\n",
    "    def prepare_data(self):\n",
    "        print(\"Preparing training data...\")\n",
    "        self.X = self.train_df[['x', 'y']]\n",
    "        self.y = self.train_df.iloc[:, 2:]  # C1 to C35\n",
    "        self.X_train, self.X_valid, self.y_train, self.y_valid = train_test_split(\n",
    "            self.X, self.y, test_size=self.test_size, random_state=self.random_state\n",
    "        )\n",
    "        print(\"Data split into training and validation sets.\")\n",
    "\n",
    "    def define_models(self):\n",
    "        print(\"Defining models...\")\n",
    "        self.models = {\n",
    "            \"RANSACRegressor\": RANSACRegressor()\n",
    "        }\n",
    "        print(\"Models defined:\", list(self.models.keys()))\n",
    "\n",
    "    def train_models(self):\n",
    "        print(\"Training models...\")\n",
    "        for name, model in self.models.items():\n",
    "            print(f\"Training {name}...\")\n",
    "            model.fit(self.X_train, self.y_train)\n",
    "        print(\"Model training complete.\")\n",
    "\n",
    "    def validate_models(self):\n",
    "        print(\"Validating models on the validation set...\")\n",
    "        preds_valid = {}\n",
    "        for name, model in self.models.items():\n",
    "            print(f\"Predicting with {name} on validation data...\")\n",
    "            preds_valid[name] = model.predict(self.X_valid)\n",
    "        return preds_valid\n",
    "\n",
    "    def load_test_data(self):\n",
    "        print(\"Loading test data...\")\n",
    "        with h5py.File(self.h5_file_path, \"r\") as f:\n",
    "            test_spots = f[\"spots/Test\"]\n",
    "            self.test_df = pd.DataFrame(np.array(test_spots[self.test_slide]))\n",
    "        print(f\"Test data loaded. Shape: {self.test_df.shape}\")\n",
    "\n",
    "    def predict_test(self):\n",
    "        print(\"Predicting on test data...\")\n",
    "        X_test = self.test_df[['x', 'y']]\n",
    "        test_preds = np.zeros((X_test.shape[0], self.y.shape[1]))\n",
    "        for name, model in self.models.items():\n",
    "            print(f\"Predicting with {name}...\")\n",
    "            test_preds += model.predict(X_test)\n",
    "        test_preds /= len(self.models)\n",
    "        self.predictions = test_preds\n",
    "        print(\"Test predictions complete.\")\n",
    "\n",
    "    def create_submission(self):\n",
    "        print(\"Creating submission file...\")\n",
    "        submission_df = pd.DataFrame(self.predictions, columns=self.y.columns)\n",
    "        submission_df.insert(0, 'ID', self.test_df.index)\n",
    "        submission_df.to_csv(self.submission_path, index=False)\n",
    "        print(f\"Submission file '{self.submission_path}' created!\")\n",
    "\n",
    "    def compute_smoothed_ranks(self, radius=100):\n",
    "        print(\"Computing smoothed ranks from training data...\")\n",
    "        df = self.train_df.copy()\n",
    "        cell_types = [f\"C{i+1}\" for i in range(35)]\n",
    "        df.columns.values[2:] = cell_types  # Rename columns to C1–C35\n",
    "        long_df = df.melt(id_vars=[\"x\", \"y\"], var_name=\"cell_type\", value_name=\"abundance\")\n",
    "        long_df[\"rank\"] = long_df.groupby([\"x\", \"y\"])[\"abundance\"].rank(method=\"dense\", ascending=False)\n",
    "\n",
    "        coords = long_df[[\"x\", \"y\"]].drop_duplicates().values\n",
    "        tree = KDTree(coords)\n",
    "\n",
    "        smoothed = []\n",
    "        for i, (x, y) in enumerate(tqdm(coords, desc=\"Smoothing ranks\")):\n",
    "            idx = tree.query_ball_point([x, y], r=radius)\n",
    "            spot_neighbors = long_df.set_index([\"x\", \"y\"]).loc[[tuple(coords[j]) for j in idx]]\n",
    "            avg_ranks = spot_neighbors.groupby(\"cell_type\")[\"rank\"].mean()\n",
    "            smoothed.append(avg_ranks)\n",
    "\n",
    "        smoothed_df = pd.DataFrame(smoothed).reset_index(drop=True)\n",
    "        smoothed_df[\"x\"] = coords[:, 0]\n",
    "        smoothed_df[\"y\"] = coords[:, 1]\n",
    "        self.smoothed_ranks = smoothed_df\n",
    "        print(\"Smoothed ranks computed.\")\n",
    "\n",
    "    def score_submission_feasibility(self, radius=100, alpha=0.7):\n",
    "        print(\"Scoring submission for biological/spatial plausibility...\")\n",
    "        test_coords = self.test_df[['x', 'y']].to_numpy()\n",
    "        train_coords = self.smoothed_ranks[[\"x\", \"y\"]].to_numpy()\n",
    "        tree = KDTree(train_coords)\n",
    "\n",
    "        cell_cols = [f\"C{i+1}\" for i in range(35)]\n",
    "        avg_global_rank = self.smoothed_ranks[cell_cols].mean().to_numpy()\n",
    "\n",
    "        submission_df = pd.DataFrame(self.predictions, columns=cell_cols)\n",
    "        scores = []\n",
    "\n",
    "        for i, (x, y) in enumerate(test_coords):\n",
    "            pred = submission_df.iloc[i].to_numpy()\n",
    "            neighbor_idx = tree.query_ball_point([x, y], r=radius)\n",
    "            local_sim = None\n",
    "            if neighbor_idx:\n",
    "                neighbors = self.smoothed_ranks.iloc[neighbor_idx][cell_cols].mean().to_numpy()\n",
    "                local_sim, _ = spearmanr(pred, neighbors)\n",
    "            global_sim, _ = spearmanr(pred, avg_global_rank)\n",
    "\n",
    "            if local_sim is not None:\n",
    "                score = alpha * local_sim + (1 - alpha) * global_sim\n",
    "            else:\n",
    "                score = global_sim\n",
    "            scores.append(score)\n",
    "\n",
    "        final_score = np.nanmean(scores)\n",
    "        print(f\"Feasibility Score: {final_score:.4f}\")\n",
    "        return final_score\n",
    "\n",
    "    def run_pipeline(self):\n",
    "        self.load_train_data()\n",
    "        self.prepare_data()\n",
    "        self.define_models()\n",
    "        self.train_models()\n",
    "        _ = self.validate_models()\n",
    "        self.load_test_data()\n",
    "        self.predict_test()\n",
    "        self.create_submission()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd2e4642",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T14:45:54.291266Z",
     "iopub.status.busy": "2025-03-28T14:45:54.290726Z",
     "iopub.status.idle": "2025-03-28T14:55:19.755252Z",
     "shell.execute_reply": "2025-03-28T14:55:19.754053Z"
    },
    "papermill": {
     "duration": 565.469247,
     "end_time": "2025-03-28T14:55:19.756879",
     "exception": false,
     "start_time": "2025-03-28T14:45:54.287632",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Training data loaded. Shape: (8349, 37)\n",
      "Preparing training data...\n",
      "Data split into training and validation sets.\n",
      "Defining models...\n",
      "Models defined: ['RANSACRegressor']\n",
      "Training models...\n",
      "Training RANSACRegressor...\n",
      "Model training complete.\n",
      "Validating models on the validation set...\n",
      "Predicting with RANSACRegressor on validation data...\n",
      "Loading test data...\n",
      "Test data loaded. Shape: (2088, 3)\n",
      "Predicting on test data...\n",
      "Predicting with RANSACRegressor...\n",
      "Test predictions complete.\n",
      "Creating submission file...\n",
      "Submission file 'submission.csv' created!\n",
      "Computing smoothed ranks from training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Smoothing ranks: 100%|██████████| 8341/8341 [09:14<00:00, 15.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoothed ranks computed.\n",
      "Scoring submission for biological/spatial plausibility...\n",
      "Feasibility Score: -0.2239\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.22391028778107622"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = ElucidataPipeline(\"/kaggle/input/el-hackathon-2025/elucidata_ai_challenge_data.h5\")\n",
    "pipeline.run_pipeline()\n",
    "\n",
    "# Optional: compute and score submission\n",
    "pipeline.compute_smoothed_ranks(radius=100)\n",
    "pipeline.score_submission_feasibility()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11390004,
     "sourceId": 94147,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 572.419718,
   "end_time": "2025-03-28T14:55:20.623261",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-28T14:45:48.203543",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
