{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3ffb48a",
   "metadata": {
    "papermill": {
     "duration": 0.002524,
     "end_time": "2025-05-03T09:09:09.454830",
     "exception": false,
     "start_time": "2025-05-03T09:09:09.452306",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**UpVote if you find helpful**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cfb5354",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T09:09:09.460289Z",
     "iopub.status.busy": "2025-05-03T09:09:09.459915Z",
     "iopub.status.idle": "2025-05-03T09:11:28.139066Z",
     "shell.execute_reply": "2025-05-03T09:11:28.137385Z"
    },
    "papermill": {
     "duration": 138.684257,
     "end_time": "2025-05-03T09:11:28.141294",
     "exception": false,
     "start_time": "2025-05-03T09:09:09.457037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.7/222.7 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.5/454.5 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m382.4/382.4 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.2/181.2 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.8/275.8 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.0/819.0 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.9/125.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m354.4/354.4 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.3/135.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "category-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.6.1 which is incompatible.\r\n",
      "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\r\n",
      "bigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\r\n",
      "ibis-framework 9.2.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25e40039",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-03T09:11:28.200415Z",
     "iopub.status.busy": "2025-05-03T09:11:28.200052Z",
     "iopub.status.idle": "2025-05-03T11:33:44.411556Z",
     "shell.execute_reply": "2025-05-03T11:33:44.410340Z"
    },
    "papermill": {
     "duration": 8536.244184,
     "end_time": "2025-05-03T11:33:44.414089",
     "exception": false,
     "start_time": "2025-05-03T09:11:28.169905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.11.11\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP PREEMPT_DYNAMIC Sun Nov 10 10:07:59 UTC 2024\n",
      "CPU Count:          4\n",
      "Memory Avail:       29.83 GB / 31.35 GB (95.1%)\n",
      "Disk Space Avail:   19.50 GB / 19.52 GB (99.9%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=5, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 1800s of the 7200s of remaining time (25%).\n",
      "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
      "2025-05-03 09:11:41,843\tINFO worker.py:1843 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\t\tContext path: \"/kaggle/working/autogluon_model/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m Running DyStack sub-fit ...\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m Beginning AutoGluon training ... Time limit = 1792s\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m AutoGluon will save models to \"/kaggle/working/autogluon_model/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m Train Data Rows:    666666\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m Train Data Columns: 22\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m Label Column:       log_Calories\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m Problem Type:       regression\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m Preprocessing data ...\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m Using Feature Generators to preprocess the data ...\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \tAvailable Memory:                    29704.59 MB\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \tTrain Data (Original)  Memory Usage: 146.23 MB (0.5% of available memory)\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \tStage 1 Generators:\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \tStage 2 Generators:\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \tStage 3 Generators:\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \tStage 4 Generators:\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \tStage 5 Generators:\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \t\t('float', [])  : 20 | ['Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp', ...]\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \t\t('int', [])    :  1 | ['Age']\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \t\t('object', []) :  1 | ['Sex']\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \t\t('float', [])     : 20 | ['Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp', ...]\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \t\t('int', [])       :  1 | ['Age']\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \t\t('int', ['bool']) :  1 | ['Sex']\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \t2.2s = Fit runtime\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \t22 features in original data used to generate 22 features in processed data.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \tTrain Data (Processed) Memory Usage: 107.45 MB (0.4% of available memory)\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m Data preprocessing and feature engineering runtime = 2.46s ...\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m User-specified model hyperparameters to be fit:\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m {\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m }\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 1192.67s of the 1789.44s of remaining time.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \t-0.0909\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \t1.92s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \t310.72s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 874.00s of the 1470.77s of remaining time.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \t-0.0896\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \t1.02s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \t311.62s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 559.84s of the 1156.61s of remaining time.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=2.46%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=727)\u001b[0m [1000]\tvalid_set's rmse: 0.0615723\n",
      "\u001b[36m(_ray_fit pid=727)\u001b[0m [2000]\tvalid_set's rmse: 0.0611432\u001b[32m [repeated 4x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=726)\u001b[0m \tRan out of time, early stopping on iteration 1994. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=726)\u001b[0m \t[1992]\tvalid_set's rmse: 0.0604478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=916)\u001b[0m [1000]\tvalid_set's rmse: 0.0627939\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=916)\u001b[0m [2000]\tvalid_set's rmse: 0.0622754\n",
      "\u001b[36m(_ray_fit pid=916)\u001b[0m [3000]\tvalid_set's rmse: 0.0621232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=916)\u001b[0m \tRan out of time, early stopping on iteration 3851. Best iteration is:\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=916)\u001b[0m \t[3845]\tvalid_set's rmse: 0.0620573\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \t-0.0607\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \t525.28s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \t311.18s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 555.96s of remaining time.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.95, 'KNeighborsDist_BAG_L1': 0.05}\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \t-0.0606\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \t0.61s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 555.28s of the 555.18s of remaining time.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=2.65%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1113)\u001b[0m [1000]\tvalid_set's rmse: 0.0627265\n",
      "\u001b[36m(_ray_fit pid=1114)\u001b[0m [1000]\tvalid_set's rmse: 0.0609608\n",
      "\u001b[36m(_ray_fit pid=1111)\u001b[0m [1000]\tvalid_set's rmse: 0.0602214\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1114)\u001b[0m \tRan out of time, early stopping on iteration 1536. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=1114)\u001b[0m \t[1532]\tvalid_set's rmse: 0.060649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1302)\u001b[0m [1000]\tvalid_set's rmse: 0.0620647\n",
      "\u001b[36m(_ray_fit pid=1302)\u001b[0m [2000]\tvalid_set's rmse: 0.0615058\n",
      "\u001b[36m(_ray_fit pid=1302)\u001b[0m [3000]\tvalid_set's rmse: 0.0613061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1302)\u001b[0m \tRan out of time, early stopping on iteration 3037. Best iteration is:\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1302)\u001b[0m \t[3008]\tvalid_set's rmse: 0.061303\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \t-0.0609\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \t514.74s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \t303.8s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the -18.40s of remaining time.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.545, 'LightGBMXT_BAG_L2': 0.455}\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \t-0.0602\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \t0.67s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m \t0.02s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m AutoGluon training complete, total runtime = 1811.29s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 180.3 rows/s (133334 batch size)\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/kaggle/working/autogluon_model/ds_sub_fit/sub_fit_ho\")\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=280)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                   model  score_holdout  score_val              eval_metric  pred_time_test  pred_time_val     fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0    WeightedEnsemble_L3      -0.060092  -0.060185  root_mean_squared_error      185.054146    1237.340143  1043.639589                 0.005662                0.017007           0.667726            3       True          6\n",
      "1    WeightedEnsemble_L2      -0.060198  -0.060610  root_mean_squared_error      100.403278     622.820886   526.916197                 0.005352                0.014059           0.609385            2       True          4\n",
      "2      LightGBMXT_BAG_L1      -0.060201  -0.060703  root_mean_squared_error       61.431305     311.183863   525.283115                61.431305              311.183863         525.283115            1       True          3\n",
      "3      LightGBMXT_BAG_L2      -0.060435  -0.060925  root_mean_squared_error      185.048484    1237.323136  1042.971863                45.985286              303.797012         514.742221            2       True          5\n",
      "4  KNeighborsDist_BAG_L1      -0.090319  -0.089597  root_mean_squared_error       38.966622     311.622964     1.023696                38.966622              311.622964           1.023696            1       True          2\n",
      "5  KNeighborsUnif_BAG_L1      -0.091359  -0.090880  root_mean_squared_error       38.665272     310.719297     1.922831                38.665272              310.719297           1.922831            1       True          1\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t2008s\t = DyStack   runtime |\t5192s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 5192s\n",
      "AutoGluon will save models to \"/kaggle/working/autogluon_model\"\n",
      "Train Data Rows:    750000\n",
      "Train Data Columns: 22\n",
      "Label Column:       log_Calories\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    29257.25 MB\n",
      "\tTrain Data (Original)  Memory Usage: 164.51 MB (0.6% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 20 | ['Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp', ...]\n",
      "\t\t('int', [])    :  1 | ['Age']\n",
      "\t\t('object', []) :  1 | ['Sex']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 20 | ['Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp', ...]\n",
      "\t\t('int', [])       :  1 | ['Age']\n",
      "\t\t('int', ['bool']) :  1 | ['Sex']\n",
      "\t3.4s = Fit runtime\n",
      "\t22 features in original data used to generate 22 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 120.88 MB (0.4% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 3.87s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 3458.12s of the 5188.46s of remaining time.\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "\t-0.09\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.46s\t = Training   runtime\n",
      "\t387.91s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 3062.91s of the 4793.25s of remaining time.\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "\t-0.0888\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.08s\t = Training   runtime\n",
      "\t382.04s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 2678.34s of the 4408.68s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=2.60%)\n",
      "\t-0.0603\t = Validation score   (-root_mean_squared_error)\n",
      "\t1385.38s\t = Training   runtime\n",
      "\t1184.66s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1041.47s of the 2771.81s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=2.63%)\n",
      "\t-0.0603\t = Validation score   (-root_mean_squared_error)\n",
      "\t323.6s\t = Training   runtime\n",
      "\t130.6s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 687.93s of the 2418.27s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 149 due to low time. Expected time usage reduced from 1382.1s -> 687.4s...\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t-0.0621\t = Validation score   (-root_mean_squared_error)\n",
      "\t699.96s\t = Training   runtime\n",
      "\t18.5s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 1697.20s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.385, 'LightGBM_BAG_L1': 0.385, 'RandomForestMSE_BAG_L1': 0.231}\n",
      "\t-0.0596\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.81s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 1696.30s of the 1696.18s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=2.95%)\n",
      "\t-0.0605\t = Validation score   (-root_mean_squared_error)\n",
      "\t1056.76s\t = Training   runtime\n",
      "\t728.38s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 480.33s of the 480.20s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=2.94%)\n",
      "\t-0.0599\t = Validation score   (-root_mean_squared_error)\n",
      "\t93.39s\t = Training   runtime\n",
      "\t9.98s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 378.16s of the 378.03s of remaining time.\n",
      "\tWarning: Model is expected to require 3604.8s to train, which exceeds the maximum time limit of 376.9s, skipping model...\n",
      "\tTime limit exceeded... Skipping RandomForestMSE_BAG_L2.\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 328.38s of the 328.25s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=4.33%)\n",
      "\t-0.0606\t = Validation score   (-root_mean_squared_error)\n",
      "\t264.94s\t = Training   runtime\n",
      "\t0.93s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 57.49s of the 57.37s of remaining time.\n",
      "\tWarning: Model is expected to require 528.4s to train, which exceeds the maximum time limit of 56.5s, skipping model...\n",
      "\tTime limit exceeded... Skipping ExtraTreesMSE_BAG_L2.\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 49.06s of the 48.93s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=5.16%)\n",
      "\tTime limit exceeded... Skipping NeuralNetFastAI_BAG_L2.\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 25.46s of the 25.33s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=4.09%)\n",
      "2025-05-03 11:11:15,915\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=4003, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 349, in _fit\n",
      "    raise TimeLimitExceeded\n",
      "autogluon.core.utils.exceptions.TimeLimitExceeded\n",
      "2025-05-03 11:11:15,928\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-05-03 11:11:15,952\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=4016, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 349, in _fit\n",
      "    raise TimeLimitExceeded\n",
      "autogluon.core.utils.exceptions.TimeLimitExceeded\n",
      "\t-0.7863\t = Validation score   (-root_mean_squared_error)\n",
      "\t26.77s\t = Training   runtime\n",
      "\t3.74s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the -14.37s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.278, 'LightGBM_BAG_L1': 0.278, 'RandomForestMSE_BAG_L1': 0.167, 'LightGBMXT_BAG_L2': 0.167, 'LightGBM_BAG_L2': 0.056, 'CatBoost_BAG_L2': 0.056}\n",
      "\t-0.0595\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.57s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5208.73s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 67.8 rows/s (150000 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/kaggle/working/autogluon_model\")\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import Library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "\n",
    "def add_feature_cross_terms(df, numerical_features):\n",
    "    df_new = df.copy()\n",
    "    for i in range(len(numerical_features)):\n",
    "        for j in range(i + 1, len(numerical_features)):  \n",
    "            feature1 = numerical_features[i]\n",
    "            feature2 = numerical_features[j]\n",
    "            cross_term_name = f\"{feature1}_x_{feature2}\"\n",
    "            df_new[cross_term_name] = df_new[feature1] * df_new[feature2]\n",
    "    return df_new\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv(\"/kaggle/input/playground-series-s5e5/train.csv\")\n",
    "test = pd.read_csv(\"/kaggle/input/playground-series-s5e5/test.csv\")\n",
    "submission = pd.read_csv(\"/kaggle/input/playground-series-s5e5/sample_submission.csv\")\n",
    "\n",
    "\n",
    "\n",
    "# Define numerical features\n",
    "numerical_features = [\"Age\", \"Height\", \"Weight\", \"Duration\", \"Heart_Rate\", \"Body_Temp\"]\n",
    "\n",
    "\n",
    "\n",
    "# Add cross terms to capture feature interactions\n",
    "train = add_feature_cross_terms(train, numerical_features)\n",
    "test = add_feature_cross_terms(test, numerical_features)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Prepare training data with log-transformed target\n",
    "train_data = train.copy()\n",
    "train_data['log_Calories'] = np.log1p(train_data['Calories'])\n",
    "train_data = train_data.drop(columns=['id', 'Calories'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Prepare test data, keeping 'id' for submission\n",
    "test_data = test.copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initialize AutoGluon TabularPredictor\n",
    "predictor = TabularPredictor(\n",
    "    label='log_Calories',\n",
    "    problem_type='regression',\n",
    "    eval_metric='root_mean_squared_error',\n",
    "    path='autogluon_model'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Fit the model with bagging for robustness\n",
    "predictor.fit(\n",
    "    train_data,\n",
    "    presets='best_quality',\n",
    "    num_bag_folds=5,\n",
    "    time_limit=7200  # Increase Time for better output\n",
    ")\n",
    "\n",
    "# Generate predictions on test data\n",
    "log_preds = predictor.predict(test_data)\n",
    "\n",
    "# Transform predictions back to original scale and clip\n",
    "preds = np.expm1(log_preds)\n",
    "preds = np.clip(preds, 1, 314)\n",
    "\n",
    "# Submission file\n",
    "submission['Calories'] = preds\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7639e2",
   "metadata": {
    "papermill": {
     "duration": 0.038795,
     "end_time": "2025-05-03T11:33:44.493865",
     "exception": false,
     "start_time": "2025-05-03T11:33:44.455070",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Thank You !**"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11893428,
     "sourceId": 91716,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8685.976417,
   "end_time": "2025-05-03T11:33:49.766131",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-03T09:09:03.789714",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
