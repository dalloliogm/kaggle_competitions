{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fcfb24d",
   "metadata": {
    "papermill": {
     "duration": 0.002979,
     "end_time": "2025-05-31T09:17:16.613112",
     "exception": false,
     "start_time": "2025-05-31T09:17:16.610133",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**UpVote if you find helpful**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9304f1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T09:17:16.619283Z",
     "iopub.status.busy": "2025-05-31T09:17:16.618763Z",
     "iopub.status.idle": "2025-05-31T09:20:41.127184Z",
     "shell.execute_reply": "2025-05-31T09:20:41.124879Z"
    },
    "papermill": {
     "duration": 204.516143,
     "end_time": "2025-05-31T09:20:41.131517",
     "exception": false,
     "start_time": "2025-05-31T09:17:16.615374",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m922.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.7/222.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.5/454.5 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m382.4/382.4 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.8/275.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.0/819.0 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.9/125.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m354.4/354.4 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m968.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.3/135.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "category-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.6.1 which is incompatible.\r\n",
      "preprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.8.1 which is incompatible.\r\n",
      "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\r\n",
      "bigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\r\n",
      "textblob 0.19.0 requires nltk>=3.9, but you have nltk 3.8.1 which is incompatible.\r\n",
      "ibis-framework 9.2.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cd37317",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-31T09:20:41.233717Z",
     "iopub.status.busy": "2025-05-31T09:20:41.233200Z",
     "iopub.status.idle": "2025-05-31T14:53:05.676633Z",
     "shell.execute_reply": "2025-05-31T14:53:05.674281Z"
    },
    "papermill": {
     "duration": 19944.503593,
     "end_time": "2025-05-31T14:53:05.684199",
     "exception": false,
     "start_time": "2025-05-31T09:20:41.180606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.11.11\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP PREEMPT_DYNAMIC Sun Nov 10 10:07:59 UTC 2024\n",
      "CPU Count:          4\n",
      "Memory Avail:       29.80 GB / 31.35 GB (95.1%)\n",
      "Disk Space Avail:   19.50 GB / 19.52 GB (99.9%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=10, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 4300s of the 17200s of remaining time (25%).\n",
      "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
      "2025-05-31 09:21:00,967\tINFO worker.py:1843 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\t\tContext path: \"/kaggle/working/autogluon_model/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m Running DyStack sub-fit ...\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m Beginning AutoGluon training ... Time limit = 4289s\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m AutoGluon will save models to \"/kaggle/working/autogluon_model/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m Train Data Rows:    666666\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m Train Data Columns: 22\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m Label Column:       log_Calories\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m Problem Type:       regression\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m Preprocessing data ...\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m Using Feature Generators to preprocess the data ...\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \tAvailable Memory:                    29686.52 MB\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \tTrain Data (Original)  Memory Usage: 146.23 MB (0.5% of available memory)\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \tStage 1 Generators:\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \tStage 2 Generators:\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \tStage 3 Generators:\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \tStage 4 Generators:\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \tStage 5 Generators:\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \t\t('float', [])  : 20 | ['Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp', ...]\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \t\t('int', [])    :  1 | ['Age']\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \t\t('object', []) :  1 | ['Sex']\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \t\t('float', [])     : 20 | ['Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp', ...]\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \t\t('int', [])       :  1 | ['Age']\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \t\t('int', ['bool']) :  1 | ['Sex']\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \t2.6s = Fit runtime\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \t22 features in original data used to generate 22 features in processed data.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \tTrain Data (Processed) Memory Usage: 107.45 MB (0.4% of available memory)\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m Data preprocessing and feature engineering runtime = 2.9s ...\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m User-specified model hyperparameters to be fit:\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m {\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m }\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 2856.56s of the 4285.91s of remaining time.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \t-0.0909\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \t2.39s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \t385.57s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 2460.46s of the 3889.80s of remaining time.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \t-0.0896\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \t1.1s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \t392.42s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 2065.44s of the 3494.78s of remaining time.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=2.46%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=760)\u001b[0m [1000]\tvalid_set's rmse: 0.0627012\n",
      "\u001b[36m(_ray_fit pid=761)\u001b[0m [2000]\tvalid_set's rmse: 0.0589532\u001b[32m [repeated 4x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=762)\u001b[0m [2000]\tvalid_set's rmse: 0.057757\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=761)\u001b[0m [3000]\tvalid_set's rmse: 0.0587181\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=759)\u001b[0m [3000]\tvalid_set's rmse: 0.0592981\n",
      "\u001b[36m(_ray_fit pid=762)\u001b[0m [3000]\tvalid_set's rmse: 0.0575848\n",
      "\u001b[36m(_ray_fit pid=761)\u001b[0m [4000]\tvalid_set's rmse: 0.0586156\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=762)\u001b[0m [4000]\tvalid_set's rmse: 0.0575027\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=760)\u001b[0m \tRan out of time, early stopping on iteration 4640. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=760)\u001b[0m \t[4596]\tvalid_set's rmse: 0.0616363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1020)\u001b[0m [1000]\tvalid_set's rmse: 0.0626315\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1051)\u001b[0m [1000]\tvalid_set's rmse: 0.0603104\n",
      "\u001b[36m(_ray_fit pid=1084)\u001b[0m [1000]\tvalid_set's rmse: 0.0619564\n",
      "\u001b[36m(_ray_fit pid=1020)\u001b[0m [2000]\tvalid_set's rmse: 0.0620239\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1051)\u001b[0m [2000]\tvalid_set's rmse: 0.0598285\n",
      "\u001b[36m(_ray_fit pid=1085)\u001b[0m [2000]\tvalid_set's rmse: 0.0601858\n",
      "\u001b[36m(_ray_fit pid=1020)\u001b[0m [3000]\tvalid_set's rmse: 0.061818\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1051)\u001b[0m [3000]\tvalid_set's rmse: 0.0596861\n",
      "\u001b[36m(_ray_fit pid=1085)\u001b[0m [3000]\tvalid_set's rmse: 0.0599617\n",
      "\u001b[36m(_ray_fit pid=1020)\u001b[0m [4000]\tvalid_set's rmse: 0.0617565\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1051)\u001b[0m [4000]\tvalid_set's rmse: 0.0596282\n",
      "\u001b[36m(_ray_fit pid=1085)\u001b[0m [4000]\tvalid_set's rmse: 0.0598454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1020)\u001b[0m \tRan out of time, early stopping on iteration 4700. Best iteration is:\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1020)\u001b[0m \t[4284]\tvalid_set's rmse: 0.0617387\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1084)\u001b[0m \tRan out of time, early stopping on iteration 4563. Best iteration is:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1084)\u001b[0m \t[4240]\tvalid_set's rmse: 0.0612341\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1285)\u001b[0m [1000]\tvalid_set's rmse: 0.0647836\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1285)\u001b[0m [2000]\tvalid_set's rmse: 0.0641368\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1285)\u001b[0m [3000]\tvalid_set's rmse: 0.0638829\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1286)\u001b[0m [4000]\tvalid_set's rmse: 0.0601553\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1286)\u001b[0m [5000]\tvalid_set's rmse: 0.0601597\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1285)\u001b[0m [6000]\tvalid_set's rmse: 0.0636792\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1285)\u001b[0m [7000]\tvalid_set's rmse: 0.0636992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=283)\u001b[0m \t-0.0603\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \t1796.55s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \t655.37s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 201.60s of the 1630.94s of remaining time.\n",
      "\u001b[36m(_ray_fit pid=1085)\u001b[0m \tRan out of time, early stopping on iteration 4625. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=1085)\u001b[0m \t[4515]\tvalid_set's rmse: 0.0598108\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=2.50%)\n",
      "\u001b[36m(_ray_fit pid=1570)\u001b[0m \tRan out of time, early stopping on iteration 305. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=1570)\u001b[0m \t[305]\tvalid_set's rmse: 0.0626482\n",
      "\u001b[36m(_ray_fit pid=1718)\u001b[0m \tRan out of time, early stopping on iteration 289. Best iteration is:\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1718)\u001b[0m \t[289]\tvalid_set's rmse: 0.0618275\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1866)\u001b[0m \tRan out of time, early stopping on iteration 577. Best iteration is:\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1866)\u001b[0m \t[577]\tvalid_set's rmse: 0.0640553\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \t-0.0609\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \t190.48s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \t27.48s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 1.68s of the 1431.02s of remaining time.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \tWarning: Model is expected to require 1456.3s to train, which exceeds the maximum time limit of 0.8s, skipping model...\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \tTime limit exceeded... Skipping RandomForestMSE_BAG_L1.\n",
      "\u001b[36m(_ray_fit pid=1867)\u001b[0m \tRan out of time, early stopping on iteration 579. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=1867)\u001b[0m \t[578]\tvalid_set's rmse: 0.0601964\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 1409.99s of remaining time.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.56, 'LightGBM_BAG_L1': 0.4, 'KNeighborsDist_BAG_L1': 0.04}\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \t-0.0598\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \t0.56s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 1409.36s of the 1409.26s of remaining time.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=2.72%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2059)\u001b[0m [1000]\tvalid_set's rmse: 0.0628213\n",
      "\u001b[36m(_ray_fit pid=2059)\u001b[0m [2000]\tvalid_set's rmse: 0.0625616\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2062)\u001b[0m [2000]\tvalid_set's rmse: 0.0597113\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2059)\u001b[0m \tRan out of time, early stopping on iteration 2627. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=2059)\u001b[0m \t[2624]\tvalid_set's rmse: 0.0625169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2311)\u001b[0m [1000]\tvalid_set's rmse: 0.0599981\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2310)\u001b[0m [1000]\tvalid_set's rmse: 0.0598752\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2311)\u001b[0m [2000]\tvalid_set's rmse: 0.0596073\n",
      "\u001b[36m(_ray_fit pid=2280)\u001b[0m [2000]\tvalid_set's rmse: 0.0599623\n",
      "\u001b[36m(_ray_fit pid=2310)\u001b[0m [2000]\tvalid_set's rmse: 0.0594981\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2280)\u001b[0m \tRan out of time, early stopping on iteration 2588. Best iteration is:\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2280)\u001b[0m \t[2562]\tvalid_set's rmse: 0.0598405\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2499)\u001b[0m [1000]\tvalid_set's rmse: 0.0617226\n",
      "\u001b[36m(_ray_fit pid=2531)\u001b[0m [1000]\tvalid_set's rmse: 0.0614183\n",
      "\u001b[36m(_ray_fit pid=2499)\u001b[0m [2000]\tvalid_set's rmse: 0.0614506\n",
      "\u001b[36m(_ray_fit pid=2531)\u001b[0m [2000]\tvalid_set's rmse: 0.0609654\n",
      "\u001b[36m(_ray_fit pid=2499)\u001b[0m [3000]\tvalid_set's rmse: 0.0613537\n",
      "\u001b[36m(_ray_fit pid=2531)\u001b[0m [3000]\tvalid_set's rmse: 0.0607985\n",
      "\u001b[36m(_ray_fit pid=2499)\u001b[0m [4000]\tvalid_set's rmse: 0.0613273\n",
      "\u001b[36m(_ray_fit pid=2531)\u001b[0m [4000]\tvalid_set's rmse: 0.0607268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2499)\u001b[0m \tRan out of time, early stopping on iteration 4377. Best iteration is:\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2499)\u001b[0m \t[4334]\tvalid_set's rmse: 0.0613072\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \t-0.0606\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \t1229.5s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \t378.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 129.78s of the 129.68s of remaining time.\n",
      "\u001b[36m(_ray_fit pid=2531)\u001b[0m \tRan out of time, early stopping on iteration 4298. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=2531)\u001b[0m \t[4112]\tvalid_set's rmse: 0.0607116\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=2.75%)\n",
      "\u001b[36m(_ray_fit pid=2756)\u001b[0m \tRan out of time, early stopping on iteration 118. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=2756)\u001b[0m \t[118]\tvalid_set's rmse: 0.0612018\n",
      "\u001b[36m(_ray_fit pid=2900)\u001b[0m \tRan out of time, early stopping on iteration 123. Best iteration is:\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2900)\u001b[0m \t[121]\tvalid_set's rmse: 0.0597677\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \t-0.0603\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \t123.77s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \t7.39s\t = Validation runtime\n",
      "\u001b[36m(_ray_fit pid=2901)\u001b[0m \tRan out of time, early stopping on iteration 118. Best iteration is:\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2901)\u001b[0m \t[118]\tvalid_set's rmse: 0.0593929\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the -1.66s of remaining time.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.391, 'LightGBM_BAG_L1': 0.304, 'LightGBMXT_BAG_L2': 0.261, 'LightGBM_BAG_L2': 0.043}\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \t-0.0598\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \t0.84s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m AutoGluon training complete, total runtime = 4291.68s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 58.2 rows/s (66667 batch size)\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/kaggle/working/autogluon_model/ds_sub_fit/sub_fit_ho\")\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=283)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                   model  score_holdout  score_val              eval_metric  pred_time_test  pred_time_val     fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0    WeightedEnsemble_L3      -0.059909  -0.059751  root_mean_squared_error      481.548656    1846.341357  3344.637283                 0.008472                0.012972           0.842737            3       True          8\n",
      "1    WeightedEnsemble_L2      -0.059996  -0.059844  root_mean_squared_error      287.370519    1075.281391  1988.698561                 0.007100                0.012625           0.564407            2       True          5\n",
      "2      LightGBMXT_BAG_L1      -0.060043  -0.060327  root_mean_squared_error      223.115635     655.368287  1796.553804               223.115635              655.368287        1796.553804            1       True          3\n",
      "3      LightGBMXT_BAG_L2      -0.060069  -0.060567  root_mean_squared_error      478.082448    1838.936938  3220.024061               142.029767              378.102151        1229.502397            2       True          6\n",
      "4        LightGBM_BAG_L2      -0.060290  -0.060265  root_mean_squared_error      339.510416    1468.226235  2114.292149                 3.457736                7.391448         123.770485            2       True          7\n",
      "5        LightGBM_BAG_L1      -0.060859  -0.060882  root_mean_squared_error       15.465935      27.477087   190.482174                15.465935               27.477087         190.482174            1       True          4\n",
      "6  KNeighborsDist_BAG_L1      -0.090319  -0.089597  root_mean_squared_error       48.781849     392.423392     1.098177                48.781849              392.423392           1.098177            1       True          2\n",
      "7  KNeighborsUnif_BAG_L1      -0.091359  -0.090880  root_mean_squared_error       48.689261     385.566020     2.387510                48.689261              385.566020           2.387510            1       True          1\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t4789s\t = DyStack   runtime |\t12411s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 12411s\n",
      "AutoGluon will save models to \"/kaggle/working/autogluon_model\"\n",
      "Train Data Rows:    750000\n",
      "Train Data Columns: 22\n",
      "Label Column:       log_Calories\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    29226.31 MB\n",
      "\tTrain Data (Original)  Memory Usage: 164.51 MB (0.6% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 20 | ['Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp', ...]\n",
      "\t\t('int', [])    :  1 | ['Age']\n",
      "\t\t('object', []) :  1 | ['Sex']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 20 | ['Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp', ...]\n",
      "\t\t('int', [])       :  1 | ['Age']\n",
      "\t\t('int', ['bool']) :  1 | ['Sex']\n",
      "\t3.2s = Fit runtime\n",
      "\t22 features in original data used to generate 22 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 120.88 MB (0.4% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 3.97s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 8269.39s of the 12407.17s of remaining time.\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "\t-0.09\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.81s\t = Training   runtime\n",
      "\t503.5s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 7757.99s of the 11895.77s of remaining time.\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "\t-0.0888\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.33s\t = Training   runtime\n",
      "\t495.8s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 7259.23s of the 11397.01s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=2.61%)\n",
      "\t-0.0601\t = Validation score   (-root_mean_squared_error)\n",
      "\t3360.37s\t = Training   runtime\n",
      "\t1396.14s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 3819.48s of the 7957.26s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=2.65%)\n",
      "\t-0.0602\t = Validation score   (-root_mean_squared_error)\n",
      "\t639.54s\t = Training   runtime\n",
      "\t139.2s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 3164.96s of the 7302.74s of remaining time.\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t-0.062\t = Validation score   (-root_mean_squared_error)\n",
      "\t1648.73s\t = Training   runtime\n",
      "\t45.59s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1466.32s of the 5604.09s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=3.99%)\n",
      "\t-0.0598\t = Validation score   (-root_mean_squared_error)\n",
      "\t1185.67s\t = Training   runtime\n",
      "\t4.42s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 274.00s of the 4411.78s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 167 due to low time. Expected time usage reduced from 488.2s -> 273.1s...\n",
      "\tNot enough time to generate out-of-fold predictions for model. Estimated time required was 187.71s compared to 88.21s of available time.\n",
      "\tTime limit exceeded... Skipping ExtraTreesMSE_BAG_L1.\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 5.57s of the 4143.35s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=4.65%)\n",
      "\tTime limit exceeded... Skipping NeuralNetFastAI_BAG_L1.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 826.94s of the 4118.02s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.368, 'LightGBMXT_BAG_L1': 0.263, 'LightGBM_BAG_L1': 0.211, 'RandomForestMSE_BAG_L1': 0.158}\n",
      "\t-0.0592\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.21s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 4116.69s of the 4116.54s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=3.24%)\n",
      "2025-05-31 12:58:59,037\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=6376, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 349, in _fit\n",
      "    raise TimeLimitExceeded\n",
      "autogluon.core.utils.exceptions.TimeLimitExceeded\n",
      "2025-05-31 12:58:59,050\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=6362, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 349, in _fit\n",
      "    raise TimeLimitExceeded\n",
      "autogluon.core.utils.exceptions.TimeLimitExceeded\n",
      "2025-05-31 12:58:59,063\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=6369, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 349, in _fit\n",
      "    raise TimeLimitExceeded\n",
      "autogluon.core.utils.exceptions.TimeLimitExceeded\n",
      "\t-0.0603\t = Validation score   (-root_mean_squared_error)\n",
      "\t2273.43s\t = Training   runtime\n",
      "\t599.38s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 1750.39s of the 1750.24s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=3.09%)\n",
      "\t-0.0595\t = Validation score   (-root_mean_squared_error)\n",
      "\t169.3s\t = Training   runtime\n",
      "\t9.46s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 1572.87s of the 1572.73s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 123 due to low time. Expected time usage reduced from 3809.8s -> 1571.6s...\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t-0.0603\t = Validation score   (-root_mean_squared_error)\n",
      "\t1594.05s\t = Training   runtime\n",
      "\t19.36s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 411.67s of the -43.21s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.3, 'LightGBMXT_BAG_L1': 0.15, 'LightGBM_BAG_L1': 0.15, 'RandomForestMSE_BAG_L2': 0.15, 'RandomForestMSE_BAG_L1': 0.1, 'LightGBM_BAG_L2': 0.1, 'LightGBMXT_BAG_L2': 0.05}\n",
      "\t-0.0592\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 12455.89s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 33.3 rows/s (75000 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/kaggle/working/autogluon_model\")\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import Library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "\n",
    "def add_feature_cross_terms(df, numerical_features):\n",
    "    df_new = df.copy()\n",
    "    for i in range(len(numerical_features)):\n",
    "        for j in range(i + 1, len(numerical_features)):  \n",
    "            feature1 = numerical_features[i]\n",
    "            feature2 = numerical_features[j]\n",
    "            cross_term_name = f\"{feature1}_x_{feature2}\"\n",
    "            df_new[cross_term_name] = df_new[feature1] * df_new[feature2]\n",
    "    return df_new\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv(\"/kaggle/input/playground-series-s5e5/train.csv\")\n",
    "test = pd.read_csv(\"/kaggle/input/playground-series-s5e5/test.csv\")\n",
    "submission = pd.read_csv(\"/kaggle/input/playground-series-s5e5/sample_submission.csv\")\n",
    "\n",
    "\n",
    "\n",
    "# Define numerical features\n",
    "numerical_features = [\"Age\", \"Height\", \"Weight\", \"Duration\", \"Heart_Rate\", \"Body_Temp\"]\n",
    "\n",
    "\n",
    "\n",
    "# Add cross terms to capture feature interactions\n",
    "train = add_feature_cross_terms(train, numerical_features)\n",
    "test = add_feature_cross_terms(test, numerical_features)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Prepare training data with log-transformed target\n",
    "train_data = train.copy()\n",
    "train_data['log_Calories'] = np.log1p(train_data['Calories'])\n",
    "train_data = train_data.drop(columns=['id', 'Calories'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Prepare test data, keeping 'id' for submission\n",
    "test_data = test.copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initialize AutoGluon TabularPredictor\n",
    "predictor = TabularPredictor(\n",
    "    label='log_Calories',\n",
    "    problem_type='regression',\n",
    "    eval_metric='root_mean_squared_error',\n",
    "    path='autogluon_model'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Fit the model with bagging for robustness\n",
    "predictor.fit(\n",
    "    train_data,\n",
    "    presets='best_quality',\n",
    "    num_bag_folds=10,\n",
    "    time_limit=17200  # Increase Time for better output\n",
    ")\n",
    "\n",
    "# Generate predictions on test data\n",
    "log_preds = predictor.predict(test_data)\n",
    "\n",
    "# Transform predictions back to original scale and clip\n",
    "preds = np.expm1(log_preds)\n",
    "preds = np.clip(preds, 1, 314)\n",
    "\n",
    "# Submission file\n",
    "submission['Calories'] = preds\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8063839e",
   "metadata": {
    "papermill": {
     "duration": 0.642879,
     "end_time": "2025-05-31T14:53:06.397973",
     "exception": false,
     "start_time": "2025-05-31T14:53:05.755094",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Thank You !**"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11893428,
     "sourceId": 91716,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 20164.120023,
   "end_time": "2025-05-31T14:53:11.821525",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-31T09:17:07.701502",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
