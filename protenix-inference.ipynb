{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f95980dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T17:32:04.035366Z",
     "iopub.status.busy": "2025-05-06T17:32:04.034980Z",
     "iopub.status.idle": "2025-05-06T17:35:00.357268Z",
     "shell.execute_reply": "2025-05-06T17:35:00.356278Z"
    },
    "papermill": {
     "duration": 176.329937,
     "end_time": "2025-05-06T17:35:00.359263",
     "exception": false,
     "start_time": "2025-05-06T17:32:04.029326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "google-cloud-bigtable 2.27.0 requires google-api-core[grpc]<3.0.0dev,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "langchain 0.3.12 requires async-timeout<5.0.0,>=4.0.0; python_version < \"3.11\", but you have async-timeout 5.0.1 which is incompatible.\r\n",
      "mkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 1.26.3 which is incompatible.\r\n",
      "mkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 1.26.3 which is incompatible.\r\n",
      "mkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 1.26.3 which is incompatible.\r\n",
      "mlxtend 0.23.3 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\r\n",
      "pandas-gbq 0.25.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "pylibcugraph-cu12 24.10.0 requires pylibraft-cu12==24.10.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 24.10.0 requires rmm-cu12==24.10.*, but you have rmm-cu12 25.2.0 which is incompatible.\r\n",
      "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.20.2 which is incompatible.\r\n",
      "tensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, but you have tensorflow 2.17.1 which is incompatible.\r\n",
      "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.20.2 which is incompatible.\r\n",
      "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.3.1 which is incompatible.\r\n",
      "torchvision 0.20.1+cu121 requires torch==2.5.1, but you have torch 2.3.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Assuming you've mounted your dataset containing the wheels and Protenix code\n",
    "DATASET_PATH = '/kaggle/input/required-presets'\n",
    "\n",
    "# Install dependencies from wheels\n",
    "wheel_path = os.path.join(DATASET_PATH, 'wheels')\n",
    "!pip install -qqq --no-index --find-links {wheel_path} torch numpy pandas scipy rdkit protenix\n",
    "\n",
    "# Add Protenix to Python path\n",
    "protenix_path = os.path.join(DATASET_PATH, 'Protenix')\n",
    "sys.path.append(protenix_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14ff057e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T17:35:00.369100Z",
     "iopub.status.busy": "2025-05-06T17:35:00.368810Z",
     "iopub.status.idle": "2025-05-06T17:35:01.265132Z",
     "shell.execute_reply": "2025-05-06T17:35:01.264449Z"
    },
    "papermill": {
     "duration": 0.902252,
     "end_time": "2025-05-06T17:35:01.266660",
     "exception": false,
     "start_time": "2025-05-06T17:35:00.364408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "validation_sequence = pd.read_csv('/kaggle/input/stanford-rna-3d-folding/validation_sequences.csv')\n",
    "validation_labels = pd.read_csv('/kaggle/input/stanford-rna-3d-folding/validation_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44c11cb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T17:35:01.275189Z",
     "iopub.status.busy": "2025-05-06T17:35:01.274930Z",
     "iopub.status.idle": "2025-05-06T17:35:01.351595Z",
     "shell.execute_reply": "2025-05-06T17:35:01.350757Z"
    },
    "papermill": {
     "duration": 0.082307,
     "end_time": "2025-05-06T17:35:01.352994",
     "exception": false,
     "start_time": "2025-05-06T17:35:01.270687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>temporal_cutoff</th>\n",
       "      <th>description</th>\n",
       "      <th>all_sequences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1SCL_A</td>\n",
       "      <td>GGGUGCUCAGUACGAGAGGAACCGCACCC</td>\n",
       "      <td>1995-01-26</td>\n",
       "      <td>THE SARCIN-RICIN LOOP, A MODULAR RNA</td>\n",
       "      <td>&gt;1SCL_1|Chain A|RNA SARCIN-RICIN LOOP|Rattus n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1RNK_A</td>\n",
       "      <td>GGCGCAGUGGGCUAGCGCCACUCAAAAGGCCCAU</td>\n",
       "      <td>1995-02-27</td>\n",
       "      <td>THE STRUCTURE OF AN RNA PSEUDOKNOT THAT CAUSES...</td>\n",
       "      <td>&gt;1RNK_1|Chain A|RNA PSEUDOKNOT|null\\nGGCGCAGUG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1RHT_A</td>\n",
       "      <td>GGGACUGACGAUCACGCAGUCUAU</td>\n",
       "      <td>1995-06-03</td>\n",
       "      <td>24-MER RNA HAIRPIN COAT PROTEIN BINDING SITE F...</td>\n",
       "      <td>&gt;1RHT_1|Chain A|RNA (5'-R(P*GP*GP*GP*AP*CP*UP*...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1HLX_A</td>\n",
       "      <td>GGGAUAACUUCGGUUGUCCC</td>\n",
       "      <td>1995-09-15</td>\n",
       "      <td>P1 HELIX NUCLEIC ACIDS (DNA/RNA) RIBONUCLEIC ACID</td>\n",
       "      <td>&gt;1HLX_1|Chain A|RNA (5'-R(*GP*GP*GP*AP*UP*AP*A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1HMH_E</td>\n",
       "      <td>GGCGACCCUGAUGAGGCCGAAAGGCCGAAACCGU</td>\n",
       "      <td>1995-12-07</td>\n",
       "      <td>THREE-DIMENSIONAL STRUCTURE OF A HAMMERHEAD RI...</td>\n",
       "      <td>&gt;1HMH_1|Chains A, C, E|HAMMERHEAD RIBOZYME-RNA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target_id                            sequence temporal_cutoff  \\\n",
       "0    1SCL_A       GGGUGCUCAGUACGAGAGGAACCGCACCC      1995-01-26   \n",
       "1    1RNK_A  GGCGCAGUGGGCUAGCGCCACUCAAAAGGCCCAU      1995-02-27   \n",
       "2    1RHT_A            GGGACUGACGAUCACGCAGUCUAU      1995-06-03   \n",
       "3    1HLX_A                GGGAUAACUUCGGUUGUCCC      1995-09-15   \n",
       "4    1HMH_E  GGCGACCCUGAUGAGGCCGAAAGGCCGAAACCGU      1995-12-07   \n",
       "\n",
       "                                         description  \\\n",
       "0               THE SARCIN-RICIN LOOP, A MODULAR RNA   \n",
       "1  THE STRUCTURE OF AN RNA PSEUDOKNOT THAT CAUSES...   \n",
       "2  24-MER RNA HAIRPIN COAT PROTEIN BINDING SITE F...   \n",
       "3  P1 HELIX NUCLEIC ACIDS (DNA/RNA) RIBONUCLEIC ACID   \n",
       "4  THREE-DIMENSIONAL STRUCTURE OF A HAMMERHEAD RI...   \n",
       "\n",
       "                                       all_sequences  \n",
       "0  >1SCL_1|Chain A|RNA SARCIN-RICIN LOOP|Rattus n...  \n",
       "1  >1RNK_1|Chain A|RNA PSEUDOKNOT|null\\nGGCGCAGUG...  \n",
       "2  >1RHT_1|Chain A|RNA (5'-R(P*GP*GP*GP*AP*CP*UP*...  \n",
       "3  >1HLX_1|Chain A|RNA (5'-R(*GP*GP*GP*AP*UP*AP*A...  \n",
       "4  >1HMH_1|Chains A, C, E|HAMMERHEAD RIBOZYME-RNA...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sequences = pd.read_csv('/kaggle/input/stanford-rna-3d-folding/train_sequences.csv') \n",
    "test_sequences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "901a551a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T17:35:01.361495Z",
     "iopub.status.busy": "2025-05-06T17:35:01.361267Z",
     "iopub.status.idle": "2025-05-06T17:35:01.376349Z",
     "shell.execute_reply": "2025-05-06T17:35:01.375533Z"
    },
    "papermill": {
     "duration": 0.020725,
     "end_time": "2025-05-06T17:35:01.377703",
     "exception": false,
     "start_time": "2025-05-06T17:35:01.356978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('/kaggle/input/stanford-rna-3d-folding/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d66d513b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T17:35:01.386289Z",
     "iopub.status.busy": "2025-05-06T17:35:01.386068Z",
     "iopub.status.idle": "2025-05-06T17:35:01.403695Z",
     "shell.execute_reply": "2025-05-06T17:35:01.403084Z"
    },
    "papermill": {
     "duration": 0.023072,
     "end_time": "2025-05-06T17:35:01.404855",
     "exception": false,
     "start_time": "2025-05-06T17:35:01.381783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>resname</th>\n",
       "      <th>resid</th>\n",
       "      <th>x_1</th>\n",
       "      <th>y_1</th>\n",
       "      <th>z_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>y_2</th>\n",
       "      <th>z_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>y_3</th>\n",
       "      <th>z_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>y_4</th>\n",
       "      <th>z_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>y_5</th>\n",
       "      <th>z_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R1107_1</td>\n",
       "      <td>G</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R1107_2</td>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R1107_3</td>\n",
       "      <td>G</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R1107_4</td>\n",
       "      <td>G</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R1107_5</td>\n",
       "      <td>G</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID resname  resid  x_1  y_1  z_1  x_2  y_2  z_2  x_3  y_3  z_3  x_4  \\\n",
       "0  R1107_1       G      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1  R1107_2       G      2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2  R1107_3       G      3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3  R1107_4       G      4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4  R1107_5       G      5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   y_4  z_4  x_5  y_5  z_5  \n",
       "0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1821cc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T17:35:01.413401Z",
     "iopub.status.busy": "2025-05-06T17:35:01.413192Z",
     "iopub.status.idle": "2025-05-06T17:35:01.417367Z",
     "shell.execute_reply": "2025-05-06T17:35:01.416583Z"
    },
    "papermill": {
     "duration": 0.009647,
     "end_time": "2025-05-06T17:35:01.418483",
     "exception": false,
     "start_time": "2025-05-06T17:35:01.408836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2515"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0824db9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T17:35:01.427348Z",
     "iopub.status.busy": "2025-05-06T17:35:01.427115Z",
     "iopub.status.idle": "2025-05-06T17:42:53.288847Z",
     "shell.execute_reply": "2025-05-06T17:42:53.287601Z"
    },
    "papermill": {
     "duration": 471.867914,
     "end_time": "2025-05-06T17:42:53.290428",
     "exception": false,
     "start_time": "2025-05-06T17:35:01.422514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 12 test sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing R1107: GGGGGCCACAGCAGAAGCGUUCACGUCGCAGCCCCUGUCAGCCAUUGCACUCCGGCUGCGAAUUCUGCU\n",
      "Running inference for R1107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 1/12 [00:44<08:10, 44.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error running inference for R1107: Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 1348, in do_open\n",
      "    h.request(req.get_method(), req.selector, req.data, headers,\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1283, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1329, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1278, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1038, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 976, in send\n",
      "    self.connect()\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1448, in connect\n",
      "    super().connect()\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 942, in connect\n",
      "    self.sock = self._create_connection(\n",
      "  File \"/usr/lib/python3.10/socket.py\", line 824, in create_connection\n",
      "    for res in getaddrinfo(host, port, 0, SOCK_STREAM):\n",
      "  File \"/usr/lib/python3.10/socket.py\", line 955, in getaddrinfo\n",
      "    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\n",
      "socket.gaierror: [Errno -3] Temporary failure in name resolution\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/kaggle/input/required-presets/Protenix/runner/inference.py\", line 305, in <module>\n",
      "    run()\n",
      "  File \"/kaggle/input/required-presets/Protenix/runner/inference.py\", line 300, in run\n",
      "    download_infercence_cache(configs, model_version=\"v0.2.0\")\n",
      "  File \"/kaggle/input/required-presets/Protenix/runner/inference.py\", line 179, in download_infercence_cache\n",
      "    urllib.request.urlretrieve(tos_url, cur_cache_fpath)\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 241, in urlretrieve\n",
      "    with contextlib.closing(urlopen(url, data)) as fp:\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 216, in urlopen\n",
      "    return opener.open(url, data, timeout)\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 519, in open\n",
      "    response = self._open(req, data)\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 536, in _open\n",
      "    result = self._call_chain(self.handle_open, protocol, protocol +\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 496, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 1391, in https_open\n",
      "    return self.do_open(http.client.HTTPSConnection, req,\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 1351, in do_open\n",
      "    raise URLError(err)\n",
      "urllib.error.URLError: <urlopen error [Errno -3] Temporary failure in name resolution>\n",
      "\n",
      "Inference failed for R1107\n",
      "Processing R1108: GGGGGCCACAGCAGAAGCGUUCACGUCGCGGCCCCUGUCAGCCAUUGCACUCCGGCUGCGAAUUCUGCU\n",
      "Running inference for R1108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 2/12 [01:23<06:51, 41.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error running inference for R1108: Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 1348, in do_open\n",
      "    h.request(req.get_method(), req.selector, req.data, headers,\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1283, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1329, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1278, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1038, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 976, in send\n",
      "    self.connect()\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1448, in connect\n",
      "    super().connect()\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 942, in connect\n",
      "    self.sock = self._create_connection(\n",
      "  File \"/usr/lib/python3.10/socket.py\", line 824, in create_connection\n",
      "    for res in getaddrinfo(host, port, 0, SOCK_STREAM):\n",
      "  File \"/usr/lib/python3.10/socket.py\", line 955, in getaddrinfo\n",
      "    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\n",
      "socket.gaierror: [Errno -3] Temporary failure in name resolution\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/kaggle/input/required-presets/Protenix/runner/inference.py\", line 305, in <module>\n",
      "    run()\n",
      "  File \"/kaggle/input/required-presets/Protenix/runner/inference.py\", line 300, in run\n",
      "    download_infercence_cache(configs, model_version=\"v0.2.0\")\n",
      "  File \"/kaggle/input/required-presets/Protenix/runner/inference.py\", line 179, in download_infercence_cache\n",
      "    urllib.request.urlretrieve(tos_url, cur_cache_fpath)\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 241, in urlretrieve\n",
      "    with contextlib.closing(urlopen(url, data)) as fp:\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 216, in urlopen\n",
      "    return opener.open(url, data, timeout)\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 519, in open\n",
      "    response = self._open(req, data)\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 536, in _open\n",
      "    result = self._call_chain(self.handle_open, protocol, protocol +\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 496, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 1391, in https_open\n",
      "    return self.do_open(http.client.HTTPSConnection, req,\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 1351, in do_open\n",
      "    raise URLError(err)\n",
      "urllib.error.URLError: <urlopen error [Errno -3] Temporary failure in name resolution>\n",
      "\n",
      "Inference failed for R1108\n",
      "Processing R1116: CGCCCGGAUAGCUCAGUCGGUAGAGCAGCGGCUAAAACAGCUCUGGGGUUGUACCCACCCCAGAGGCCCACGUGGCGGCUAGUACUCCGGUAUUGCGGUACCCUUGUACGCCUGUUUUAGCCGCGGGUCCAGGGUUCAAGUCCCUGUUCGGGCGCCA\n",
      "Running inference for R1116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 3/12 [02:02<06:00, 40.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error running inference for R1116: Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 1348, in do_open\n",
      "    h.request(req.get_method(), req.selector, req.data, headers,\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1283, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1329, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1278, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1038, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 976, in send\n",
      "    self.connect()\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1448, in connect\n",
      "    super().connect()\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 942, in connect\n",
      "    self.sock = self._create_connection(\n",
      "  File \"/usr/lib/python3.10/socket.py\", line 824, in create_connection\n",
      "    for res in getaddrinfo(host, port, 0, SOCK_STREAM):\n",
      "  File \"/usr/lib/python3.10/socket.py\", line 955, in getaddrinfo\n",
      "    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\n",
      "socket.gaierror: [Errno -3] Temporary failure in name resolution\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/kaggle/input/required-presets/Protenix/runner/inference.py\", line 305, in <module>\n",
      "    run()\n",
      "  File \"/kaggle/input/required-presets/Protenix/runner/inference.py\", line 300, in run\n",
      "    download_infercence_cache(configs, model_version=\"v0.2.0\")\n",
      "  File \"/kaggle/input/required-presets/Protenix/runner/inference.py\", line 179, in download_infercence_cache\n",
      "    urllib.request.urlretrieve(tos_url, cur_cache_fpath)\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 241, in urlretrieve\n",
      "    with contextlib.closing(urlopen(url, data)) as fp:\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 216, in urlopen\n",
      "    return opener.open(url, data, timeout)\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 519, in open\n",
      "    response = self._open(req, data)\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 536, in _open\n",
      "    result = self._call_chain(self.handle_open, protocol, protocol +\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 496, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 1391, in https_open\n",
      "    return self.do_open(http.client.HTTPSConnection, req,\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 1351, in do_open\n",
      "    raise URLError(err)\n",
      "urllib.error.URLError: <urlopen error [Errno -3] Temporary failure in name resolution>\n",
      "\n",
      "Inference failed for R1116\n",
      "Processing R1117v2: UUGGGUUCCCUCACCCCAAUCAUAAAAAGG\n",
      "Running inference for R1117v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 4/12 [02:40<05:16, 39.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error running inference for R1117v2: Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 1348, in do_open\n",
      "    h.request(req.get_method(), req.selector, req.data, headers,\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1283, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1329, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1278, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1038, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 976, in send\n",
      "    self.connect()\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1448, in connect\n",
      "    super().connect()\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 942, in connect\n",
      "    self.sock = self._create_connection(\n",
      "  File \"/usr/lib/python3.10/socket.py\", line 824, in create_connection\n",
      "    for res in getaddrinfo(host, port, 0, SOCK_STREAM):\n",
      "  File \"/usr/lib/python3.10/socket.py\", line 955, in getaddrinfo\n",
      "    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\n",
      "socket.gaierror: [Errno -3] Temporary failure in name resolution\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/kaggle/input/required-presets/Protenix/runner/inference.py\", line 305, in <module>\n",
      "    run()\n",
      "  File \"/kaggle/input/required-presets/Protenix/runner/inference.py\", line 300, in run\n",
      "    download_infercence_cache(configs, model_version=\"v0.2.0\")\n",
      "  File \"/kaggle/input/required-presets/Protenix/runner/inference.py\", line 179, in download_infercence_cache\n",
      "    urllib.request.urlretrieve(tos_url, cur_cache_fpath)\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 241, in urlretrieve\n",
      "    with contextlib.closing(urlopen(url, data)) as fp:\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 216, in urlopen\n",
      "    return opener.open(url, data, timeout)\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 519, in open\n",
      "    response = self._open(req, data)\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 536, in _open\n",
      "    result = self._call_chain(self.handle_open, protocol, protocol +\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 496, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 1391, in https_open\n",
      "    return self.do_open(http.client.HTTPSConnection, req,\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 1351, in do_open\n",
      "    raise URLError(err)\n",
      "urllib.error.URLError: <urlopen error [Errno -3] Temporary failure in name resolution>\n",
      "\n",
      "Inference failed for R1117v2\n",
      "Processing R1126: GGAAUCUCGCCCGAUGUUCGCAUCGGGAUUUGCAGGUCCAUGGAUUACACCAUGCAACGCAGACCUGUAGAUGCCACGCUAGCCGUGGUGAGGGUCGGGUCCAGAUGUCAUUCGACUUUAACGCGCCUAAGCGUUGAAGGCGUGUUAGAGCAGAUAGUUCGCUAUCUGGGGAGCCUGUUCGCAGGCUCAGGAGCCUUCGGGCUCCUAGCGCUAUUACCCCGGACACCACCGGGCAGACAAGUAAUGGUGCUCCUCGAAUGACUUCUGUUGAGUAGAGUGUGGGCUCCGCGGCUAGUGUGCACCUUAGCGGUGAAUGUCUGACACCGUUAAGGUGGUUACUCUUCGGAGUAACGCCGAGAUUCC\n",
      "Running inference for R1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 5/12 [03:19<04:34, 39.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error running inference for R1126: Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 1348, in do_open\n",
      "    h.request(req.get_method(), req.selector, req.data, headers,\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1283, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1329, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1278, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1038, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 976, in send\n",
      "    self.connect()\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1448, in connect\n",
      "    super().connect()\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 942, in connect\n",
      "    self.sock = self._create_connection(\n",
      "  File \"/usr/lib/python3.10/socket.py\", line 824, in create_connection\n",
      "    for res in getaddrinfo(host, port, 0, SOCK_STREAM):\n",
      "  File \"/usr/lib/python3.10/socket.py\", line 955, in getaddrinfo\n",
      "    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\n",
      "socket.gaierror: [Errno -3] Temporary failure in name resolution\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/kaggle/input/required-presets/Protenix/runner/inference.py\", line 305, in <module>\n",
      "    run()\n",
      "  File \"/kaggle/input/required-presets/Protenix/runner/inference.py\", line 300, in run\n",
      "    download_infercence_cache(configs, model_version=\"v0.2.0\")\n",
      "  File \"/kaggle/input/required-presets/Protenix/runner/inference.py\", line 179, in download_infercence_cache\n",
      "    urllib.request.urlretrieve(tos_url, cur_cache_fpath)\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 241, in urlretrieve\n",
      "    with contextlib.closing(urlopen(url, data)) as fp:\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 216, in urlopen\n",
      "    return opener.open(url, data, timeout)\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 519, in open\n",
      "    response = self._open(req, data)\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 536, in _open\n",
      "    result = self._call_chain(self.handle_open, protocol, protocol +\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 496, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 1391, in https_open\n",
      "    return self.do_open(http.client.HTTPSConnection, req,\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 1351, in do_open\n",
      "    raise URLError(err)\n",
      "urllib.error.URLError: <urlopen error [Errno -3] Temporary failure in name resolution>\n",
      "\n",
      "Inference failed for R1126\n",
      "Processing R1128: GGAAUAUCGUCAUGGUGAUUCGUCACCAUGAGGCUAGAUCUCAUAUCUAGCGCUUUCGAGCGCUAGAGUCCUUAUCUAGCCGGUUUAUACUUUCGAGUGUGAACCCGAUAUUCCGCGGAUCACUAUGAGUCGUUCGCGGCUCAUAGUCCGGCUCAAAGGACAUCAUGGCCUGUUCGCAGGUUGUGAUUAUGAGUGAGCCGGGUAAGGCAUACCGUUCGCGGUAUGUCUUACGAUCCGC\n",
      "Running inference for R1128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 6/12 [03:58<03:54, 39.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error running inference for R1128: Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 1348, in do_open\n",
      "    h.request(req.get_method(), req.selector, req.data, headers,\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1283, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1329, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1278, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1038, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 976, in send\n",
      "    self.connect()\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1448, in connect\n",
      "    super().connect()\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 942, in connect\n",
      "    self.sock = self._create_connection(\n",
      "  File \"/usr/lib/python3.10/socket.py\", line 824, in create_connection\n",
      "    for res in getaddrinfo(host, port, 0, SOCK_STREAM):\n",
      "  File \"/usr/lib/python3.10/socket.py\", line 955, in getaddrinfo\n",
      "    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\n",
      "socket.gaierror: [Errno -3] Temporary failure in name resolution\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/kaggle/input/required-presets/Protenix/runner/inference.py\", line 305, in <module>\n",
      "    run()\n",
      "  File \"/kaggle/input/required-presets/Protenix/runner/inference.py\", line 300, in run\n",
      "    download_infercence_cache(configs, model_version=\"v0.2.0\")\n",
      "  File \"/kaggle/input/required-presets/Protenix/runner/inference.py\", line 179, in download_infercence_cache\n",
      "    urllib.request.urlretrieve(tos_url, cur_cache_fpath)\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 241, in urlretrieve\n",
      "    with contextlib.closing(urlopen(url, data)) as fp:\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 216, in urlopen\n",
      "    return opener.open(url, data, timeout)\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 519, in open\n",
      "    response = self._open(req, data)\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 536, in _open\n",
      "    result = self._call_chain(self.handle_open, protocol, protocol +\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 496, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 1391, in https_open\n",
      "    return self.do_open(http.client.HTTPSConnection, req,\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 1351, in do_open\n",
      "    raise URLError(err)\n",
      "urllib.error.URLError: <urlopen error [Errno -3] Temporary failure in name resolution>\n",
      "\n",
      "Inference failed for R1128\n",
      "Processing R1136: GGAUACGUCUACGCUCAGUGACGGACUCUCUUCGGAGAGUCUGACAUCCGAACCAUACACGGAUGUGCCUCGCCGAACAGUCUACGGCGAGCUUAAGCGCUGGGGACGCCCAACGCAUCACAAAGACUGAGUGAUGAACCAGAAGUAUGGACUGGUUGCGUUGGUGGAGACGGUCGGGUCCAGUUCGCUGUCGAGUAGAGUGUGGGCUCCAUCGACGCCGCUUUAAGGUCCCCAAUCGUGGCGUGUCGGCCUGCUUCGGCAGGCACUGGCGCCGGGACCUUGAAGAGAUGAGAUUUCGAUCUCAUCUUUGGGUGUCUCUGGUGCUUGAGGGCCCUGUGUUCGCACAGGGCCGCUCACUGGGUGUGGACGUAUCC\n",
      "Running inference for R1136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 7/12 [04:37<03:14, 39.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error running inference for R1136: Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 1348, in do_open\n",
      "    h.request(req.get_method(), req.selector, req.data, headers,\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1283, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1329, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1278, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1038, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 976, in send\n",
      "    self.connect()\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1448, in connect\n",
      "    super().connect()\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 942, in connect\n",
      "    self.sock = self._create_connection(\n",
      "  File \"/usr/lib/python3.10/socket.py\", line 824, in create_connection\n",
      "    for res in getaddrinfo(host, port, 0, SOCK_STREAM):\n",
      "  File \"/usr/lib/python3.10/socket.py\", line 955, in getaddrinfo\n",
      "    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\n",
      "socket.gaierror: [Errno -3] Temporary failure in name resolution\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/kaggle/input/required-presets/Protenix/runner/inference.py\", line 305, in <module>\n",
      "    run()\n",
      "  File \"/kaggle/input/required-presets/Protenix/runner/inference.py\", line 300, in run\n",
      "    download_infercence_cache(configs, model_version=\"v0.2.0\")\n",
      "  File \"/kaggle/input/required-presets/Protenix/runner/inference.py\", line 179, in download_infercence_cache\n",
      "    urllib.request.urlretrieve(tos_url, cur_cache_fpath)\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 241, in urlretrieve\n",
      "    with contextlib.closing(urlopen(url, data)) as fp:\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 216, in urlopen\n",
      "    return opener.open(url, data, timeout)\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 519, in open\n",
      "    response = self._open(req, data)\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 536, in _open\n",
      "    result = self._call_chain(self.handle_open, protocol, protocol +\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 496, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 1391, in https_open\n",
      "    return self.do_open(http.client.HTTPSConnection, req,\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 1351, in do_open\n",
      "    raise URLError(err)\n",
      "urllib.error.URLError: <urlopen error [Errno -3] Temporary failure in name resolution>\n",
      "\n",
      "Inference failed for R1136\n",
      "Processing R1138: GGGAGAGUACUAUUCAGAUGCAGACCGCAAGUUCAGAGCGGUUUGCAUCUAGGGUACGUUUUCGAACGUAUCCUCCGACUAAGUGUAUUCGUAUACUUAGUGCCUUGUGCCUGCUUCGGCAGGCAUGACCCAAAUGUGCCUUUCGGGGCACAUUUCCGGUCAUCCAAGUUCGCUUGGGUGAUGCGGGCGUAUAGGUUCGUCUAUACGUCCGCGUUUUCCGAGAAGAGGUAACUCGGGAAACCGGUCCACGUGACAAAGGUAGAGUUACGUGGAGGGAGCAGCUGCAAAGGGAUAAUGCAGUUGCUGGCUGGAUGCCAGAACUCACGACUGGCAUCUACGGGGAUGGUGCUCUCCCAAUUCUCCAUUUACCGCCGAAUCGACCCCAACGUGAGAGGGGUCGGUUCCCCGAGCAUAGACCAAUAUCCCAGGUUUAUGCUCCCCAACGCUGGACGAACUACCUACGUCUAGCGUUCCGGCAAAUGAGUCAAUACCUCAGACUUAUUUGCGGUGCCUGAGCCUAAACUGAACAUGGGUUCAGGCAUCUUGGCUCCAGUUCGCUGGAGCCGACGGUAGCGCUGCGUUCGCGCAGUGCUAGGGAGCAUCCGUUUUCGAGCGGAUGCUGGGCGGUUGCCUGUUCGCAGGCAAUCGGGCCUACUCAUGAUUCGUCAUGAGUGGUGACAGCGUGAUGUUCGCAUUACGCUGUCGGGUAGAUGGAGAAUU\n",
      "Running inference for R1138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 8/12 [05:15<02:35, 38.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error running inference for R1138: Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 1348, in do_open\n",
      "    h.request(req.get_method(), req.selector, req.data, headers,\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1283, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1329, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1278, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1038, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 976, in send\n",
      "    self.connect()\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1448, in connect\n",
      "    super().connect()\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 942, in connect\n",
      "    self.sock = self._create_connection(\n",
      "  File \"/usr/lib/python3.10/socket.py\", line 824, in create_connection\n",
      "    for res in getaddrinfo(host, port, 0, SOCK_STREAM):\n",
      "  File \"/usr/lib/python3.10/socket.py\", line 955, in getaddrinfo\n",
      "    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\n",
      "socket.gaierror: [Errno -3] Temporary failure in name resolution\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/kaggle/input/required-presets/Protenix/runner/inference.py\", line 305, in <module>\n",
      "    run()\n",
      "  File \"/kaggle/input/required-presets/Protenix/runner/inference.py\", line 300, in run\n",
      "    download_infercence_cache(configs, model_version=\"v0.2.0\")\n",
      "  File \"/kaggle/input/required-presets/Protenix/runner/inference.py\", line 179, in download_infercence_cache\n",
      "    urllib.request.urlretrieve(tos_url, cur_cache_fpath)\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 241, in urlretrieve\n",
      "    with contextlib.closing(urlopen(url, data)) as fp:\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 216, in urlopen\n",
      "    return opener.open(url, data, timeout)\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 519, in open\n",
      "    response = self._open(req, data)\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 536, in _open\n",
      "    result = self._call_chain(self.handle_open, protocol, protocol +\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 496, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 1391, in https_open\n",
      "    return self.do_open(http.client.HTTPSConnection, req,\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 1351, in do_open\n",
      "    raise URLError(err)\n",
      "urllib.error.URLError: <urlopen error [Errno -3] Temporary failure in name resolution>\n",
      "\n",
      "Inference failed for R1138\n",
      "Processing R1149: GGACACGAGUAACUCGUCUAUCUUCUGCAGGCUGCUUACGGUUUCGUCCGUGUUGCAGCCGAUCAUCAGCACAUCUAGGUUUCGUCCGGGUGUGACCGAAAGGUAAGAUGGAGAGCCUUGUCCC\n",
      "Running inference for R1149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 9/12 [05:54<01:56, 38.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error running inference for R1149: Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 1348, in do_open\n",
      "    h.request(req.get_method(), req.selector, req.data, headers,\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1283, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1329, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1278, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1038, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 976, in send\n",
      "    self.connect()\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1448, in connect\n",
      "    super().connect()\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 942, in connect\n",
      "    self.sock = self._create_connection(\n",
      "  File \"/usr/lib/python3.10/socket.py\", line 824, in create_connection\n",
      "    for res in getaddrinfo(host, port, 0, SOCK_STREAM):\n",
      "  File \"/usr/lib/python3.10/socket.py\", line 955, in getaddrinfo\n",
      "    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\n",
      "socket.gaierror: [Errno -3] Temporary failure in name resolution\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/kaggle/input/required-presets/Protenix/runner/inference.py\", line 305, in <module>\n",
      "    run()\n",
      "  File \"/kaggle/input/required-presets/Protenix/runner/inference.py\", line 300, in run\n",
      "    download_infercence_cache(configs, model_version=\"v0.2.0\")\n",
      "  File \"/kaggle/input/required-presets/Protenix/runner/inference.py\", line 179, in download_infercence_cache\n",
      "    urllib.request.urlretrieve(tos_url, cur_cache_fpath)\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 241, in urlretrieve\n",
      "    with contextlib.closing(urlopen(url, data)) as fp:\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 216, in urlopen\n",
      "    return opener.open(url, data, timeout)\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 519, in open\n",
      "    response = self._open(req, data)\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 536, in _open\n",
      "    result = self._call_chain(self.handle_open, protocol, protocol +\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 496, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 1391, in https_open\n",
      "    return self.do_open(http.client.HTTPSConnection, req,\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 1351, in do_open\n",
      "    raise URLError(err)\n",
      "urllib.error.URLError: <urlopen error [Errno -3] Temporary failure in name resolution>\n",
      "\n",
      "Inference failed for R1149\n",
      "Processing R1156: GGAGCAUCGUGUCUCAAGUGCUUCACGGUCACAAUAUACCGUUUCGUCGGGUGCGUGGCAAUUCGGUGCACAUCAUGUCUUUCGUGGCUGGUGUGGCUCCUCAAGGUGCGAGGGGCAAGUAUAGAGCAGAGCUCC\n",
      "Running inference for R1156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 10/12 [06:33<01:17, 38.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error running inference for R1156: Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 1348, in do_open\n",
      "    h.request(req.get_method(), req.selector, req.data, headers,\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1283, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1329, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1278, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1038, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 976, in send\n",
      "    self.connect()\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1448, in connect\n",
      "    super().connect()\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 942, in connect\n",
      "    self.sock = self._create_connection(\n",
      "  File \"/usr/lib/python3.10/socket.py\", line 824, in create_connection\n",
      "    for res in getaddrinfo(host, port, 0, SOCK_STREAM):\n",
      "  File \"/usr/lib/python3.10/socket.py\", line 955, in getaddrinfo\n",
      "    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\n",
      "socket.gaierror: [Errno -3] Temporary failure in name resolution\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/kaggle/input/required-presets/Protenix/runner/inference.py\", line 305, in <module>\n",
      "    run()\n",
      "  File \"/kaggle/input/required-presets/Protenix/runner/inference.py\", line 300, in run\n",
      "    download_infercence_cache(configs, model_version=\"v0.2.0\")\n",
      "  File \"/kaggle/input/required-presets/Protenix/runner/inference.py\", line 179, in download_infercence_cache\n",
      "    urllib.request.urlretrieve(tos_url, cur_cache_fpath)\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 241, in urlretrieve\n",
      "    with contextlib.closing(urlopen(url, data)) as fp:\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 216, in urlopen\n",
      "    return opener.open(url, data, timeout)\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 519, in open\n",
      "    response = self._open(req, data)\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 536, in _open\n",
      "    result = self._call_chain(self.handle_open, protocol, protocol +\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 496, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 1391, in https_open\n",
      "    return self.do_open(http.client.HTTPSConnection, req,\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 1351, in do_open\n",
      "    raise URLError(err)\n",
      "urllib.error.URLError: <urlopen error [Errno -3] Temporary failure in name resolution>\n",
      "\n",
      "Inference failed for R1156\n",
      "Processing R1189: GCGUACAGGGAACACGCAACCCCGAAGGAUCGGGGAAGGGACGUCGCCAGGGAGGCGAUUCCAUCAGGAUGAUGACGAGGGACUGAAGAGUGGGCGGGGUAAUACCCCGCCCCUUUUU\n",
      "Running inference for R1189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 11/12 [07:12<00:38, 38.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error running inference for R1189: Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 1348, in do_open\n",
      "    h.request(req.get_method(), req.selector, req.data, headers,\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1283, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1329, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1278, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1038, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 976, in send\n",
      "    self.connect()\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1448, in connect\n",
      "    super().connect()\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 942, in connect\n",
      "    self.sock = self._create_connection(\n",
      "  File \"/usr/lib/python3.10/socket.py\", line 824, in create_connection\n",
      "    for res in getaddrinfo(host, port, 0, SOCK_STREAM):\n",
      "  File \"/usr/lib/python3.10/socket.py\", line 955, in getaddrinfo\n",
      "    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\n",
      "socket.gaierror: [Errno -3] Temporary failure in name resolution\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/kaggle/input/required-presets/Protenix/runner/inference.py\", line 305, in <module>\n",
      "    run()\n",
      "  File \"/kaggle/input/required-presets/Protenix/runner/inference.py\", line 300, in run\n",
      "    download_infercence_cache(configs, model_version=\"v0.2.0\")\n",
      "  File \"/kaggle/input/required-presets/Protenix/runner/inference.py\", line 179, in download_infercence_cache\n",
      "    urllib.request.urlretrieve(tos_url, cur_cache_fpath)\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 241, in urlretrieve\n",
      "    with contextlib.closing(urlopen(url, data)) as fp:\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 216, in urlopen\n",
      "    return opener.open(url, data, timeout)\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 519, in open\n",
      "    response = self._open(req, data)\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 536, in _open\n",
      "    result = self._call_chain(self.handle_open, protocol, protocol +\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 496, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 1391, in https_open\n",
      "    return self.do_open(http.client.HTTPSConnection, req,\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 1351, in do_open\n",
      "    raise URLError(err)\n",
      "urllib.error.URLError: <urlopen error [Errno -3] Temporary failure in name resolution>\n",
      "\n",
      "Inference failed for R1189\n",
      "Processing R1190: GCGUACAGGGAACACGCAACCCCGAAGGAUCGGGGAAGGGACGUCGCCAGGGAGGCGAUUCCAUCAGGAUGAUGACGAGGGACUGAAGAGUGGGCGGGGUAAUACCCCGCCCCUUUUU\n",
      "Running inference for R1190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [07:50<00:00, 39.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error running inference for R1190: Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 1348, in do_open\n",
      "    h.request(req.get_method(), req.selector, req.data, headers,\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1283, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1329, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1278, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1038, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 976, in send\n",
      "    self.connect()\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1448, in connect\n",
      "    super().connect()\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 942, in connect\n",
      "    self.sock = self._create_connection(\n",
      "  File \"/usr/lib/python3.10/socket.py\", line 824, in create_connection\n",
      "    for res in getaddrinfo(host, port, 0, SOCK_STREAM):\n",
      "  File \"/usr/lib/python3.10/socket.py\", line 955, in getaddrinfo\n",
      "    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\n",
      "socket.gaierror: [Errno -3] Temporary failure in name resolution\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/kaggle/input/required-presets/Protenix/runner/inference.py\", line 305, in <module>\n",
      "    run()\n",
      "  File \"/kaggle/input/required-presets/Protenix/runner/inference.py\", line 300, in run\n",
      "    download_infercence_cache(configs, model_version=\"v0.2.0\")\n",
      "  File \"/kaggle/input/required-presets/Protenix/runner/inference.py\", line 179, in download_infercence_cache\n",
      "    urllib.request.urlretrieve(tos_url, cur_cache_fpath)\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 241, in urlretrieve\n",
      "    with contextlib.closing(urlopen(url, data)) as fp:\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 216, in urlopen\n",
      "    return opener.open(url, data, timeout)\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 519, in open\n",
      "    response = self._open(req, data)\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 536, in _open\n",
      "    result = self._call_chain(self.handle_open, protocol, protocol +\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 496, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 1391, in https_open\n",
      "    return self.do_open(http.client.HTTPSConnection, req,\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 1351, in do_open\n",
      "    raise URLError(err)\n",
      "urllib.error.URLError: <urlopen error [Errno -3] Temporary failure in name resolution>\n",
      "\n",
      "Inference failed for R1190\n",
      "No prediction found for R1107, using zeros\n",
      "No prediction found for R1108, using zeros\n",
      "No prediction found for R1116, using zeros\n",
      "No prediction found for R1117v2, using zeros\n",
      "No prediction found for R1126, using zeros\n",
      "No prediction found for R1128, using zeros\n",
      "No prediction found for R1136, using zeros\n",
      "No prediction found for R1138, using zeros\n",
      "No prediction found for R1149, using zeros\n",
      "No prediction found for R1156, using zeros\n",
      "No prediction found for R1189, using zeros\n",
      "No prediction found for R1190, using zeros\n",
      "Created submission file: submission.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "RNA 3D Structure Prediction and Submission Generator for Kaggle Environment\n",
    "\n",
    "This script:\n",
    "1. Reads RNA sequences from test_sequences.csv\n",
    "2. Creates input JSONs for each sequence\n",
    "3. Runs the Protenix model to predict 3D structures\n",
    "4. Extracts C1' atom coordinates from the output CIF files\n",
    "5. Creates a submission.csv file in the format required\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from biotite.structure.io import pdbx\n",
    "\n",
    "def create_input_json(sequence, target_id):\n",
    "    \"\"\"\n",
    "    Create the input JSON for a single RNA sequence\n",
    "    \"\"\"\n",
    "    input_json = [{\n",
    "        \"sequences\": [\n",
    "            {\n",
    "                \"rnaSequence\": {\n",
    "                    \"sequence\": sequence,\n",
    "                    \"count\": 1,\n",
    "                    \"modifications\": []\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        \"name\": target_id,\n",
    "        \"covalent_bonds\": []\n",
    "    }]\n",
    "    return input_json\n",
    "\n",
    "def run_inference(input_json_path, output_dir, target_id):\n",
    "    \"\"\"\n",
    "    Run inference using the Protenix model with kaggle-specific paths\n",
    "    \"\"\"\n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Define command with kaggle-specific paths\n",
    "    cmd = [\n",
    "        \"python\", \"/kaggle/input/required-presets/Protenix/runner/inference.py\",\n",
    "        \"--seeds\", \"42\",\n",
    "        \"--dump_dir\", output_dir,\n",
    "        \"--input_json_path\", input_json_path,\n",
    "        \"--model.N_cycle\", \"10\",\n",
    "        \"--sample_diffusion.N_sample\", \"5\",\n",
    "        \"--sample_diffusion.N_step\", \"200\",\n",
    "        \"--load_checkpoint_path\", \"/kaggle/input/required-presets/Protenix/release_data/checkpoint/model_v0.2.0.pt\",\n",
    "        \"--use_deepspeed_evo_attention\", \"false\"\n",
    "    ]\n",
    "    \n",
    "    print(f\"Running inference for {target_id}\")\n",
    "    try:\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "        if result.returncode != 0:\n",
    "            print(f\"Error running inference for {target_id}: {result.stderr}\")\n",
    "            return False\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Exception running inference for {target_id}: {e}\")\n",
    "        return False\n",
    "\n",
    "def extract_c1_coordinates(cif_file_path):\n",
    "    \"\"\"\n",
    "    Extract C1' atom coordinates from a CIF file using biotite\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the CIF file using the correct biotite method\n",
    "        with open(cif_file_path, 'r') as f:\n",
    "            cif_data = pdbx.CIFFile.read(f)\n",
    "        \n",
    "        # Get structure from CIF data\n",
    "        atom_array = pdbx.get_structure(cif_data, model=1)\n",
    "        \n",
    "        # Clean atom names and find C1' atoms\n",
    "        atom_names_clean = np.char.strip(atom_array.atom_name.astype(str))\n",
    "        mask_c1 = atom_names_clean == \"C1'\"\n",
    "        c1_atoms = atom_array[mask_c1]\n",
    "        \n",
    "        if len(c1_atoms) == 0:\n",
    "            print(f\"Warning: No C1' atoms found in {cif_file_path}\")\n",
    "            return None\n",
    "        \n",
    "        # Sort by residue ID and return coordinates\n",
    "        sort_indices = np.argsort(c1_atoms.res_id)\n",
    "        c1_atoms_sorted = c1_atoms[sort_indices]\n",
    "        c1_coords = c1_atoms_sorted.coord\n",
    "        \n",
    "        return c1_coords\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting C1' coordinates from {cif_file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def process_sequence(sequence, target_id, temp_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Process a single RNA sequence and return C1' coordinates\n",
    "    \"\"\"\n",
    "    print(f\"Processing {target_id}: {sequence}\")\n",
    "    \n",
    "    # Create input JSON\n",
    "    input_json = create_input_json(sequence, target_id)\n",
    "    \n",
    "    # Save JSON to temporary file\n",
    "    os.makedirs(temp_dir, exist_ok=True)\n",
    "    input_json_path = os.path.join(temp_dir, f\"{target_id}_input.json\")\n",
    "    with open(input_json_path, \"w\") as f:\n",
    "        json.dump(input_json, f, indent=4)\n",
    "    \n",
    "    # Run inference\n",
    "    success = run_inference(input_json_path, output_dir, target_id)\n",
    "    \n",
    "    if not success:\n",
    "        print(f\"Inference failed for {target_id}\")\n",
    "        return None\n",
    "    \n",
    "    # Find the CIF files for this target\n",
    "    target_prediction_dir = os.path.join(output_dir, target_id, \"seed_42\", \"predictions\")\n",
    "    if not os.path.exists(target_prediction_dir):\n",
    "        print(f\"Prediction directory not found for {target_id}\")\n",
    "        return None\n",
    "    \n",
    "    # Look for CIF files with the pattern {target_id}_seed_42_sample_*.cif\n",
    "    cif_files = sorted(glob.glob(os.path.join(target_prediction_dir, f\"{target_id}_seed_42_sample_*.cif\")))\n",
    "    \n",
    "    # If no CIF files found, return None\n",
    "    if not cif_files:\n",
    "        print(f\"No CIF files found for {target_id}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Found {len(cif_files)} CIF files for {target_id}\")\n",
    "    \n",
    "    # Extract C1' coordinates from each CIF file\n",
    "    all_coords = []\n",
    "    for cif_file in cif_files:\n",
    "        coords = extract_c1_coordinates(cif_file)\n",
    "        if coords is not None:\n",
    "            all_coords.append(coords)\n",
    "    \n",
    "    if not all_coords:\n",
    "        print(f\"No valid C1' coordinates found for {target_id}\")\n",
    "        return None\n",
    "    \n",
    "    # Ensure we have 5 models (if we have fewer, duplicate the last one)\n",
    "    while len(all_coords) < 5:\n",
    "        print(f\"Only {len(all_coords)} models found for {target_id}, duplicating last model\")\n",
    "        all_coords.append(all_coords[-1])\n",
    "    \n",
    "    return all_coords[:5]  # Ensure we only have 5 models\n",
    "\n",
    "def create_submission(test_sequences_df, c1_coords_dict, output_file):\n",
    "    \"\"\"\n",
    "    Create the submission CSV file with C1' coordinates\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    \n",
    "    # Process each sequence\n",
    "    for _, row in test_sequences_df.iterrows():\n",
    "        target_id = row['target_id']\n",
    "        sequence = row['sequence']\n",
    "        \n",
    "        if target_id not in c1_coords_dict or c1_coords_dict[target_id] is None:\n",
    "            print(f\"No prediction found for {target_id}, using zeros\")\n",
    "            # Create empty predictions (all zeros)\n",
    "            for i, residue in enumerate(sequence):\n",
    "                row_data = {\n",
    "                    'ID': f\"{target_id}_{i+1}\",\n",
    "                    'resname': residue,\n",
    "                    'resid': i+1\n",
    "                }\n",
    "                for model in range(1, 6):\n",
    "                    row_data[f'x_{model}'] = 0.0\n",
    "                    row_data[f'y_{model}'] = 0.0\n",
    "                    row_data[f'z_{model}'] = 0.0\n",
    "                rows.append(row_data)\n",
    "        else:\n",
    "            # Get the 5 models for this target\n",
    "            models = c1_coords_dict[target_id]\n",
    "            \n",
    "            # Create a row for each residue\n",
    "            for i, residue in enumerate(sequence):\n",
    "                row_data = {\n",
    "                    'ID': f\"{target_id}_{i+1}\",\n",
    "                    'resname': residue,\n",
    "                    'resid': i+1\n",
    "                }\n",
    "                \n",
    "                # Add coordinates for each model\n",
    "                for model_idx in range(5):\n",
    "                    if model_idx < len(models) and i < len(models[model_idx]):\n",
    "                        row_data[f'x_{model_idx+1}'] = models[model_idx][i][0]\n",
    "                        row_data[f'y_{model_idx+1}'] = models[model_idx][i][1]\n",
    "                        row_data[f'z_{model_idx+1}'] = models[model_idx][i][2]\n",
    "                    else:\n",
    "                        # If coordinates are not available, use zeros\n",
    "                        row_data[f'x_{model_idx+1}'] = 0.0\n",
    "                        row_data[f'y_{model_idx+1}'] = 0.0\n",
    "                        row_data[f'z_{model_idx+1}'] = 0.0\n",
    "                \n",
    "                rows.append(row_data)\n",
    "    \n",
    "    # Create DataFrame and save to CSV\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Created submission file: {output_file}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function\n",
    "    \"\"\"\n",
    "    # Set up required symlinks for CCD cache as in kaggle_inference.py\n",
    "    os.makedirs(\"/usr/local/lib/python3.10/dist-packages/release_data/ccd_cache\", exist_ok=True)\n",
    "    \n",
    "    source_ccd_file = \"/kaggle/input/required-presets/Protenix/release_data/ccd_cache/components.v20240608.cif\"\n",
    "    target_ccd_file = \"/usr/local/lib/python3.10/dist-packages/release_data/ccd_cache/components.v20240608.cif\"\n",
    "    \n",
    "    source_rdkit_file = \"/kaggle/input/required-presets/Protenix/release_data/ccd_cache/components.v20240608.cif.rdkit_mol.pkl\"\n",
    "    target_rdkit_file = \"/usr/local/lib/python3.10/dist-packages/release_data/ccd_cache/components.v20240608.cif.rdkit_mol.pkl\"\n",
    "    \n",
    "    # Create the symlinks if the source files exist\n",
    "    if os.path.exists(source_ccd_file) and not os.path.exists(target_ccd_file):\n",
    "        try:\n",
    "            os.symlink(source_ccd_file, target_ccd_file)\n",
    "            print(f\"Created symlink for CCD file\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating symlink for CCD file: {e}\")\n",
    "    \n",
    "    if os.path.exists(source_rdkit_file) and not os.path.exists(target_rdkit_file):\n",
    "        try:\n",
    "            os.symlink(source_rdkit_file, target_rdkit_file)\n",
    "            print(f\"Created symlink for RDKIT file\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating symlink for RDKIT file: {e}\")\n",
    "    \n",
    "    # Create directories\n",
    "    temp_dir = \"./input\"  # Same as in kaggle_inference.py\n",
    "    output_dir = \"./output\"  # Same as in kaggle_inference.py\n",
    "    os.makedirs(temp_dir, exist_ok=True)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Read test sequences\n",
    "    test_sequences_df = pd.read_csv(\"/kaggle/input/stanford-rna-3d-folding/test_sequences.csv\")\n",
    "    print(f\"Loaded {len(test_sequences_df)} test sequences\")\n",
    "    \n",
    "    # Process each sequence\n",
    "    c1_coords_dict = {}\n",
    "    for _, row in tqdm(test_sequences_df.iterrows(), total=len(test_sequences_df)):\n",
    "        target_id = row['target_id']\n",
    "        sequence = row['sequence']\n",
    "        \n",
    "        # Check if we already have predictions for this target\n",
    "        target_prediction_dir = os.path.join(output_dir, target_id, \"seed_42\", \"predictions\")\n",
    "        if os.path.exists(target_prediction_dir):\n",
    "            print(f\"Found existing prediction for {target_id}, loading coordinates\")\n",
    "            # Extract coordinates from existing predictions\n",
    "            cif_files = sorted(glob.glob(os.path.join(target_prediction_dir, f\"{target_id}_seed_42_sample_*.cif\")))\n",
    "            \n",
    "            all_coords = []\n",
    "            for cif_file in cif_files:\n",
    "                coords = extract_c1_coordinates(cif_file)\n",
    "                if coords is not None:\n",
    "                    all_coords.append(coords)\n",
    "            \n",
    "            if all_coords:\n",
    "                # Ensure we have 5 models\n",
    "                while len(all_coords) < 5:\n",
    "                    all_coords.append(all_coords[-1])\n",
    "                c1_coords_dict[target_id] = all_coords[:5]\n",
    "                continue\n",
    "        \n",
    "        # Process the sequence if no existing prediction was found or was invalid\n",
    "        c1_coords = process_sequence(sequence, target_id, temp_dir, output_dir)\n",
    "        c1_coords_dict[target_id] = c1_coords\n",
    "    \n",
    "    # Create submission file\n",
    "    create_submission(test_sequences_df, c1_coords_dict, \"submission.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cc3a90e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T17:42:53.304104Z",
     "iopub.status.busy": "2025-05-06T17:42:53.303798Z",
     "iopub.status.idle": "2025-05-06T17:42:53.338457Z",
     "shell.execute_reply": "2025-05-06T17:42:53.337652Z"
    },
    "papermill": {
     "duration": 0.04279,
     "end_time": "2025-05-06T17:42:53.339709",
     "exception": false,
     "start_time": "2025-05-06T17:42:53.296919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>resname</th>\n",
       "      <th>resid</th>\n",
       "      <th>x_1</th>\n",
       "      <th>y_1</th>\n",
       "      <th>z_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>y_2</th>\n",
       "      <th>z_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>y_3</th>\n",
       "      <th>z_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>y_4</th>\n",
       "      <th>z_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>y_5</th>\n",
       "      <th>z_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R1107_1</td>\n",
       "      <td>G</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R1107_2</td>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R1107_3</td>\n",
       "      <td>G</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R1107_4</td>\n",
       "      <td>G</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R1107_5</td>\n",
       "      <td>G</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2510</th>\n",
       "      <td>R1190_114</td>\n",
       "      <td>U</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2511</th>\n",
       "      <td>R1190_115</td>\n",
       "      <td>U</td>\n",
       "      <td>115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2512</th>\n",
       "      <td>R1190_116</td>\n",
       "      <td>U</td>\n",
       "      <td>116</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2513</th>\n",
       "      <td>R1190_117</td>\n",
       "      <td>U</td>\n",
       "      <td>117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2514</th>\n",
       "      <td>R1190_118</td>\n",
       "      <td>U</td>\n",
       "      <td>118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2515 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID resname  resid  x_1  y_1  z_1  x_2  y_2  z_2  x_3  y_3  z_3  \\\n",
       "0       R1107_1       G      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1       R1107_2       G      2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2       R1107_3       G      3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3       R1107_4       G      4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4       R1107_5       G      5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "...         ...     ...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "2510  R1190_114       U    114  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2511  R1190_115       U    115  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2512  R1190_116       U    116  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2513  R1190_117       U    117  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2514  R1190_118       U    118  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "      x_4  y_4  z_4  x_5  y_5  z_5  \n",
       "0     0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1     0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2     0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3     0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4     0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "...   ...  ...  ...  ...  ...  ...  \n",
       "2510  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2511  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2512  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2513  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2514  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[2515 rows x 18 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52f50b3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T17:42:53.353778Z",
     "iopub.status.busy": "2025-05-06T17:42:53.353490Z",
     "iopub.status.idle": "2025-05-06T17:42:53.356580Z",
     "shell.execute_reply": "2025-05-06T17:42:53.355955Z"
    },
    "papermill": {
     "duration": 0.011634,
     "end_time": "2025-05-06T17:42:53.357928",
     "exception": false,
     "start_time": "2025-05-06T17:42:53.346294",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# # Check if the components.cif file exists\n",
    "# ccd_file = \"/kaggle/input/required-presets/Protenix/release_data/ccd_cache/components.v20240608.cif\"\n",
    "# rdkit_file = \"/kaggle/input/required-presets/Protenix/release_data/ccd_cache/components.v20240608.cif.rdkit_mol.pkl\"\n",
    "\n",
    "# print(f\"CCD file exists: {os.path.exists(ccd_file)}\")\n",
    "# print(f\"RDKIT file exists: {os.path.exists(rdkit_file)}\")\n",
    "\n",
    "# # If they don't exist, let's look for them\n",
    "# if not (os.path.exists(ccd_file) and os.path.exists(rdkit_file)):\n",
    "#     print(\"Searching for CCD files in /kaggle/input/required-presets/Protenix/release_data/...\")\n",
    "#     for root, dirs, files in os.walk(\"/kaggle/input/required-presets/Protenix/release_data/\"):\n",
    "#         for file in files:\n",
    "#             if \"components\" in file and (\"cif\" in file or \"rdkit\" in file):\n",
    "#                 print(f\"Found: {os.path.join(root, file)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d5e33e",
   "metadata": {
    "papermill": {
     "duration": 0.005989,
     "end_time": "2025-05-06T17:42:53.370417",
     "exception": false,
     "start_time": "2025-05-06T17:42:53.364428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bc860ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T17:42:53.384043Z",
     "iopub.status.busy": "2025-05-06T17:42:53.383700Z",
     "iopub.status.idle": "2025-05-06T17:42:53.387480Z",
     "shell.execute_reply": "2025-05-06T17:42:53.386843Z"
    },
    "papermill": {
     "duration": 0.011968,
     "end_time": "2025-05-06T17:42:53.388589",
     "exception": false,
     "start_time": "2025-05-06T17:42:53.376621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import json\n",
    "# import subprocess\n",
    "\n",
    "# # Create the directory structure needed\n",
    "# os.makedirs(\"/usr/local/lib/python3.10/dist-packages/release_data/ccd_cache\", exist_ok=True)\n",
    "\n",
    "# # Create symlinks to the actual files\n",
    "# source_ccd_file = \"/kaggle/input/required-presets/Protenix/release_data/ccd_cache/components.v20240608.cif\"\n",
    "# target_ccd_file = \"/usr/local/lib/python3.10/dist-packages/release_data/ccd_cache/components.v20240608.cif\"\n",
    "\n",
    "# source_rdkit_file = \"/kaggle/input/required-presets/Protenix/release_data/ccd_cache/components.v20240608.cif.rdkit_mol.pkl\"\n",
    "# target_rdkit_file = \"/usr/local/lib/python3.10/dist-packages/release_data/ccd_cache/components.v20240608.cif.rdkit_mol.pkl\"\n",
    "\n",
    "# # Check if the source files exist\n",
    "# print(f\"Source CCD file exists: {os.path.exists(source_ccd_file)}\")\n",
    "# print(f\"Source RDKIT file exists: {os.path.exists(source_rdkit_file)}\")\n",
    "\n",
    "# # Create the symlinks if the source files exist\n",
    "# if os.path.exists(source_ccd_file):\n",
    "#     try:\n",
    "#         os.symlink(source_ccd_file, target_ccd_file)\n",
    "#         print(f\"Created symlink for CCD file\")\n",
    "#     except FileExistsError:\n",
    "#         print(f\"Symlink for CCD file already exists\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error creating symlink for CCD file: {e}\")\n",
    "# else:\n",
    "#     print(f\"Cannot create symlink, source CCD file doesn't exist\")\n",
    "\n",
    "# if os.path.exists(source_rdkit_file):\n",
    "#     try:\n",
    "#         os.symlink(source_rdkit_file, target_rdkit_file)\n",
    "#         print(f\"Created symlink for RDKIT file\")\n",
    "#     except FileExistsError:\n",
    "#         print(f\"Symlink for RDKIT file already exists\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error creating symlink for RDKIT file: {e}\")\n",
    "# else:\n",
    "#     print(f\"Cannot create symlink, source RDKIT file doesn't exist\")\n",
    "\n",
    "# # Create RNA input JSON\n",
    "# input_json = [{\n",
    "#     \"sequences\": [\n",
    "#         {\n",
    "#             \"rnaSequence\": {\n",
    "#                 \"sequence\": \"GGGUGCUCAGUACGAGAGGAACCGCACCC\",\n",
    "#                 \"count\": 1,\n",
    "#                 \"modifications\": []\n",
    "#             }\n",
    "#         }\n",
    "#     ],\n",
    "#     \"name\": \"rna_prediction\",\n",
    "#     \"covalent_bonds\": []\n",
    "# }]\n",
    "\n",
    "# # Save input JSON\n",
    "# os.makedirs(\"./input\", exist_ok=True)\n",
    "# with open(\"./input/rna_input.json\", \"w\") as f:\n",
    "#     json.dump(input_json, f, indent=4)\n",
    "\n",
    "# # Run inference using subprocess\n",
    "# cmd = [\n",
    "#     \"python\", \"/kaggle/input/required-presets/Protenix/runner/inference.py\",\n",
    "#     \"--seeds\", \"42\",\n",
    "#     \"--dump_dir\", \"./output\",\n",
    "#     \"--input_json_path\", \"./input/rna_input.json\",\n",
    "#     \"--model.N_cycle\", \"10\",\n",
    "#     \"--sample_diffusion.N_sample\", \"5\",\n",
    "#     \"--sample_diffusion.N_step\", \"200\",\n",
    "#     \"--load_checkpoint_path\", \"/kaggle/input/required-presets/Protenix/release_data/checkpoint/model_v0.2.0.pt\",\n",
    "#     \"--use_deepspeed_evo_attention\", \"false\"\n",
    "# ]\n",
    "\n",
    "# # Run the command\n",
    "# result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "# print(\"STDOUT:\", result.stdout)\n",
    "# print(\"STDERR:\", result.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfb5120f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T17:42:53.401933Z",
     "iopub.status.busy": "2025-05-06T17:42:53.401686Z",
     "iopub.status.idle": "2025-05-06T17:42:53.404535Z",
     "shell.execute_reply": "2025-05-06T17:42:53.403930Z"
    },
    "papermill": {
     "duration": 0.010787,
     "end_time": "2025-05-06T17:42:53.405627",
     "exception": false,
     "start_time": "2025-05-06T17:42:53.394840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Check for error files\n",
    "# if os.path.exists(\"./output/ERR\"):\n",
    "#     print(\"Error directory exists!\")\n",
    "#     print(\"Contents:\")\n",
    "#     for item in os.listdir(\"./output/ERR\"):\n",
    "#         print(f\" - {item}\")\n",
    "    \n",
    "#     # If there are error files, show their contents\n",
    "#     error_files = os.listdir(\"./output/ERR\")\n",
    "#     if error_files:\n",
    "#         with open(os.path.join(\"./output/ERR\", error_files[0]), \"r\") as f:\n",
    "#             print(f\"Contents of {error_files[0]}:\")\n",
    "#             print(f.read())\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3496e53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T17:42:53.418802Z",
     "iopub.status.busy": "2025-05-06T17:42:53.418595Z",
     "iopub.status.idle": "2025-05-06T17:42:53.422529Z",
     "shell.execute_reply": "2025-05-06T17:42:53.421929Z"
    },
    "papermill": {
     "duration": 0.011953,
     "end_time": "2025-05-06T17:42:53.423721",
     "exception": false,
     "start_time": "2025-05-06T17:42:53.411768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import json\n",
    "# import pandas as pd\n",
    "# import biotite.structure.io.pdbx as pdbx\n",
    "# import matplotlib.pyplot as plt\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "# import numpy as np\n",
    "\n",
    "# # List all the prediction files\n",
    "# output_dir = \"/kaggle/working/output/rna_prediction/seed_42/predictions/\"\n",
    "# cif_files = [f for f in os.listdir(output_dir) if f.endswith(\".cif\")]\n",
    "# print(f\"Found {len(cif_files)} prediction files:\")\n",
    "# for file in cif_files:\n",
    "#     print(f\" - {file}\")\n",
    "\n",
    "# # Read and analyze the first prediction file\n",
    "# if cif_files:\n",
    "#     # Read CIF file\n",
    "#     cif_file = os.path.join(output_dir, cif_files[0])\n",
    "#     with open(cif_file, 'r') as f:\n",
    "#         cif_data = pdbx.CIFFile.read(f)\n",
    "\n",
    "#     atom_array = pdbx.get_structure(cif_data, model=1)\n",
    "    \n",
    "#     print(f\"\\nStructure information for {cif_files[0]}:\")\n",
    "#     print(f\"Number of atoms: {len(atom_array)}\")\n",
    "#     print(f\"Residue count: {len(np.unique(atom_array.res_id))}\")\n",
    "\n",
    "#     # Clean and extract C1' atoms\n",
    "#     atom_names_clean = np.char.strip(atom_array.atom_name.astype(str))\n",
    "#     mask_c1 = atom_names_clean == \"C1'\"\n",
    "#     c1_atoms = atom_array[mask_c1]\n",
    "#     c1_coords = c1_atoms.coord\n",
    "\n",
    "#     print(f\"\\nFound {len(c1_atoms)} C1' atoms\")\n",
    "\n",
    "#     # Create DataFrame\n",
    "#     df = pd.DataFrame({\n",
    "#         \"res_name\": c1_atoms.res_name,\n",
    "#         \"res_id\": c1_atoms.res_id,\n",
    "#         \"chain_id\": c1_atoms.chain_id,\n",
    "#         \"x\": c1_coords[:, 0],\n",
    "#         \"y\": c1_coords[:, 1],\n",
    "#         \"z\": c1_coords[:, 2]\n",
    "#     })\n",
    "\n",
    "#     print(\"\\nFirst few C1' atoms:\")\n",
    "#     print(df.head())\n",
    "\n",
    "#     # Save to CSV and JSON\n",
    "#     df.to_csv(\"c1_prime_coordinates.csv\", index=False)\n",
    "#     df.to_json(\"c1_prime_coordinates.json\", orient=\"records\", indent=2)\n",
    "#     print(\"Saved C1' coordinates to CSV and JSON.\")\n",
    "\n",
    "#     # Plot C1' atoms with backbone\n",
    "#     fig = plt.figure(figsize=(10, 8))\n",
    "#     ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "#     chain_ids = np.unique(c1_atoms.chain_id)\n",
    "#     colors = plt.cm.rainbow(np.linspace(0, 1, len(chain_ids)))\n",
    "\n",
    "#     for i, chain_id in enumerate(chain_ids):\n",
    "#         chain_mask = c1_atoms.chain_id == chain_id\n",
    "#         chain_df = df[df[\"chain_id\"] == chain_id]\n",
    "#         chain_df_sorted = chain_df.sort_values(\"res_id\")\n",
    "\n",
    "#         ax.scatter(\n",
    "#             chain_df_sorted[\"x\"],\n",
    "#             chain_df_sorted[\"y\"],\n",
    "#             chain_df_sorted[\"z\"],\n",
    "#             c=[colors[i]],\n",
    "#             label=f\"Chain {chain_id}\",\n",
    "#             alpha=0.9,\n",
    "#             s=30\n",
    "#         )\n",
    "\n",
    "#         ax.plot(\n",
    "#             chain_df_sorted[\"x\"],\n",
    "#             chain_df_sorted[\"y\"],\n",
    "#             chain_df_sorted[\"z\"],\n",
    "#             color=colors[i],\n",
    "#             alpha=0.6,\n",
    "#             linewidth=2\n",
    "#         )\n",
    "\n",
    "#     ax.set_xlabel(\"X (Å)\")\n",
    "#     ax.set_ylabel(\"Y (Å)\")\n",
    "#     ax.set_zlabel(\"Z (Å)\")\n",
    "#     ax.set_title(f\"C1' atom backbone - {cif_files[0]}\")\n",
    "#     ax.legend()\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "#     # --- NEW: Plot all atoms in another image ---\n",
    "#     print(\"\\nGenerating full atom visualization...\")\n",
    "\n",
    "#     all_coords = atom_array.coord\n",
    "#     all_chain_ids = np.unique(atom_array.chain_id)\n",
    "#     colors_all = plt.cm.rainbow(np.linspace(0, 1, len(all_chain_ids)))\n",
    "\n",
    "#     fig_all = plt.figure(figsize=(10, 8))\n",
    "#     ax_all = fig_all.add_subplot(111, projection='3d')\n",
    "\n",
    "#     for i, chain_id in enumerate(all_chain_ids):\n",
    "#         chain_mask = atom_array.chain_id == chain_id\n",
    "#         ax_all.scatter(\n",
    "#             all_coords[chain_mask, 0],\n",
    "#             all_coords[chain_mask, 1],\n",
    "#             all_coords[chain_mask, 2],\n",
    "#             c=[colors_all[i]],\n",
    "#             label=f\"Chain {chain_id}\",\n",
    "#             alpha=0.6,\n",
    "#             s=5  # smaller for all atoms\n",
    "#         )\n",
    "\n",
    "#     ax_all.set_xlabel(\"X (Å)\")\n",
    "#     ax_all.set_ylabel(\"Y (Å)\")\n",
    "#     ax_all.set_zlabel(\"Z (Å)\")\n",
    "#     ax_all.set_title(f\"All atoms - {cif_files[0]}\")\n",
    "#     ax_all.legend()\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85005cdd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T17:42:53.437082Z",
     "iopub.status.busy": "2025-05-06T17:42:53.436797Z",
     "iopub.status.idle": "2025-05-06T17:42:53.439634Z",
     "shell.execute_reply": "2025-05-06T17:42:53.439033Z"
    },
    "papermill": {
     "duration": 0.010789,
     "end_time": "2025-05-06T17:42:53.440698",
     "exception": false,
     "start_time": "2025-05-06T17:42:53.429909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install nglview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "379b5ca6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T17:42:53.454243Z",
     "iopub.status.busy": "2025-05-06T17:42:53.454025Z",
     "iopub.status.idle": "2025-05-06T17:42:53.457620Z",
     "shell.execute_reply": "2025-05-06T17:42:53.456842Z"
    },
    "papermill": {
     "duration": 0.011707,
     "end_time": "2025-05-06T17:42:53.458780",
     "exception": false,
     "start_time": "2025-05-06T17:42:53.447073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import json\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# # Path to the summary confidence JSON file\n",
    "# confidence_file = \"/kaggle/working/output/rna_prediction/seed_42/predictions/rna_prediction_seed_42_summary_confidence_sample_0.json\"\n",
    "\n",
    "# # Read and display the file contents\n",
    "# with open(confidence_file, 'r') as f:\n",
    "#     confidence_data = json.load(f)\n",
    "\n",
    "# # Show the keys in the JSON file\n",
    "# print(\"Keys in the confidence file:\")\n",
    "# for key in confidence_data.keys():\n",
    "#     print(f\" - {key}\")\n",
    "\n",
    "# # Function to display and visualize specific metrics\n",
    "# def analyze_metric(data, metric_name):\n",
    "#     if metric_name in data:\n",
    "#         print(f\"\\n{metric_name} data:\")\n",
    "        \n",
    "#         # Handle different data types\n",
    "#         if isinstance(data[metric_name], (int, float)):\n",
    "#             print(f\"{metric_name}: {data[metric_name]}\")\n",
    "        \n",
    "#         elif isinstance(data[metric_name], list):\n",
    "#             print(f\"{metric_name} (first 5 values): {data[metric_name][:5]}\")\n",
    "            \n",
    "#             # Plot if it's a list of numbers\n",
    "#             if data[metric_name] and isinstance(data[metric_name][0], (int, float)):\n",
    "#                 plt.figure(figsize=(10, 6))\n",
    "#                 plt.plot(data[metric_name])\n",
    "#                 plt.title(f\"{metric_name} across residues\")\n",
    "#                 plt.xlabel(\"Residue index\")\n",
    "#                 plt.ylabel(metric_name)\n",
    "#                 plt.grid(True, alpha=0.3)\n",
    "#                 plt.savefig(f\"{metric_name}_plot.png\")\n",
    "#                 plt.close()\n",
    "#                 print(f\"Saved visualization to '{metric_name}_plot.png'\")\n",
    "        \n",
    "#         elif isinstance(data[metric_name], dict):\n",
    "#             # For dictionaries, show keys and sample values\n",
    "#             print(f\"{metric_name} contains {len(data[metric_name])} keys:\")\n",
    "#             for k in list(data[metric_name].keys())[:5]:\n",
    "#                 print(f\"  - {k}: {data[metric_name][k]}\")\n",
    "#     else:\n",
    "#         print(f\"\\n{metric_name} not found in the data\")\n",
    "\n",
    "# # Analyze common confidence metrics\n",
    "# analyze_metric(confidence_data, \"plddt\")  # Per-residue confidence scores\n",
    "# analyze_metric(confidence_data, \"ranking_score\")  # Overall ranking score of the model\n",
    "# analyze_metric(confidence_data, \"gpde\")  # Global predicted distance error\n",
    "\n",
    "# # If there's PAE (Predicted Aligned Error) matrix, visualize it\n",
    "# if \"pae\" in confidence_data and isinstance(confidence_data[\"pae\"], list):\n",
    "#     pae_data = np.array(confidence_data[\"pae\"])\n",
    "    \n",
    "#     if len(pae_data.shape) == 2:\n",
    "#         plt.figure(figsize=(10, 8))\n",
    "#         im = plt.imshow(pae_data, cmap='viridis_r')\n",
    "#         plt.colorbar(im, label=\"Predicted Aligned Error (Å)\")\n",
    "#         plt.title(\"PAE Matrix\")\n",
    "#         plt.xlabel(\"Residue\")\n",
    "#         plt.ylabel(\"Residue\")\n",
    "#         plt.savefig(\"pae_matrix.png\")\n",
    "#         plt.close()\n",
    "#         print(\"\\nSaved PAE matrix visualization to 'pae_matrix.png'\")\n",
    "\n",
    "# # Display the structure's overall quality assessment\n",
    "# print(\"\\nOverall structure quality assessment:\")\n",
    "# quality_metrics = [\"ranking_score\", \"gpde\", \"plddt_avg\", \"pae_avg\"]\n",
    "# for metric in quality_metrics:\n",
    "#     if metric in confidence_data:\n",
    "#         print(f\" - {metric}: {confidence_data[metric]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5770e462",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T17:42:53.472303Z",
     "iopub.status.busy": "2025-05-06T17:42:53.472047Z",
     "iopub.status.idle": "2025-05-06T17:42:53.475066Z",
     "shell.execute_reply": "2025-05-06T17:42:53.474278Z"
    },
    "papermill": {
     "duration": 0.011236,
     "end_time": "2025-05-06T17:42:53.476294",
     "exception": false,
     "start_time": "2025-05-06T17:42:53.465058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import json\n",
    "# import pprint\n",
    "\n",
    "# # Path to the summary confidence JSON file\n",
    "# confidence_file = \"/kaggle/working/output/rna_prediction/seed_42/predictions/rna_prediction_seed_42_summary_confidence_sample_0.json\"\n",
    "\n",
    "# # Read and display the complete file contents\n",
    "# with open(confidence_file, 'r') as f:\n",
    "#     confidence_data = json.load(f)\n",
    "\n",
    "# # Use pretty print to display formatted JSON\n",
    "# print(\"Complete JSON content:\")\n",
    "# pp = pprint.PrettyPrinter(indent=2)\n",
    "# pp.pprint(confidence_data)\n",
    "\n",
    "# # Or alternatively, print it with json.dumps for more control over formatting\n",
    "# print(\"\\nAlternative JSON formatting:\")\n",
    "# print(json.dumps(confidence_data, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8742132f",
   "metadata": {
    "papermill": {
     "duration": 0.005966,
     "end_time": "2025-05-06T17:42:53.488556",
     "exception": false,
     "start_time": "2025-05-06T17:42:53.482590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11553390,
     "sourceId": 87793,
     "sourceType": "competition"
    },
    {
     "datasetId": 6896780,
     "sourceId": 11068753,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 652.846667,
   "end_time": "2025-05-06T17:42:54.013352",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-06T17:32:01.166685",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
