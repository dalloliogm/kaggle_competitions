{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b559142",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T16:06:30.387774Z",
     "iopub.status.busy": "2025-09-14T16:06:30.387470Z",
     "iopub.status.idle": "2025-09-14T16:06:32.413704Z",
     "shell.execute_reply": "2025-09-14T16:06:32.412648Z"
    },
    "papermill": {
     "duration": 2.035048,
     "end_time": "2025-09-14T16:06:32.416300",
     "exception": false,
     "start_time": "2025-09-14T16:06:30.381252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/smiles-extra-data/data_dnst1.xlsx\n",
      "/kaggle/input/smiles-extra-data/data_tg3.xlsx\n",
      "/kaggle/input/smiles-extra-data/JCIM_sup_bigsmiles.csv\n",
      "/kaggle/input/open-polymer-challenge/sample_submission.csv\n",
      "/kaggle/input/open-polymer-challenge/train.csv\n",
      "/kaggle/input/open-polymer-challenge/test.csv\n",
      "/kaggle/input/open-polymer-challenge/train_supplement/dataset2.csv\n",
      "/kaggle/input/open-polymer-challenge/train_supplement/dataset4.csv\n",
      "/kaggle/input/open-polymer-challenge/train_supplement/dataset1.csv\n",
      "/kaggle/input/open-polymer-challenge/train_supplement/dataset3.csv\n",
      "/kaggle/input/rdkit-2025-3-3-cp311/rdkit-2025.3.3-cp311-cp311-manylinux_2_28_x86_64.whl\n",
      "/kaggle/input/c/transformers/default/1/ChemBERTa-77M-MLM/config.json\n",
      "/kaggle/input/c/transformers/default/1/ChemBERTa-77M-MLM/merges.txt\n",
      "/kaggle/input/c/transformers/default/1/ChemBERTa-77M-MLM/tokenizer.json\n",
      "/kaggle/input/c/transformers/default/1/ChemBERTa-77M-MLM/vocab.json\n",
      "/kaggle/input/c/transformers/default/1/ChemBERTa-77M-MLM/tokenizer_config.json\n",
      "/kaggle/input/c/transformers/default/1/ChemBERTa-77M-MLM/model.safetensors\n",
      "/kaggle/input/c/transformers/default/1/ChemBERTa-77M-MLM/special_tokens_map.json\n",
      "/kaggle/input/c/transformers/default/1/ChemBERTa-77M-MLM/added_tokens.json\n",
      "/kaggle/input/tc-smiles/Tc_SMILES.csv\n",
      "/kaggle/input/autogluon-package/spacy_loggers-1.0.5-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/aiohttp-3.12.13-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/autogluon-package/fasttransform-0.0.2-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/charset_normalizer-3.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/autogluon-package/lightgbm-4.6.0-py3-none-manylinux_2_28_x86_64.whl\n",
      "/kaggle/input/autogluon-package/contourpy-1.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/autogluon-package/shellingham-1.5.4-py2.py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/fonttools-4.58.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl\n",
      "/kaggle/input/autogluon-package/plum_dispatch-2.5.7-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/autogluon-package/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl\n",
      "/kaggle/input/autogluon-package/pyasn1-0.6.1-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/msgpack-1.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/autogluon-package/catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl\n",
      "/kaggle/input/autogluon-package/joblib-1.5.1-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/cachetools-5.5.2-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/click-8.2.1-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/grpcio-1.73.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/autogluon-package/google_auth-2.40.3-py2.py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/tensorboardx-2.6.4-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl\n",
      "/kaggle/input/autogluon-package/triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/autogluon-package/fastai-2.8.2-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/filelock-3.18.0-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/jsonschema_specifications-2025.4.1-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/autogluon-package/jmespath-1.0.1-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/scipy-1.15.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/autogluon-package/wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/autogluon-package/future-1.0.0-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl\n",
      "/kaggle/input/autogluon-package/autogluon.core-1.3.1-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl\n",
      "/kaggle/input/autogluon-package/srsly-2.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/autogluon-package/opencensus-0.11.4-py2.py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/beartype-0.21.0-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/googleapis_common_protos-1.70.0-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/langcodes-3.5.0-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/pillow-11.2.1-cp311-cp311-manylinux_2_28_x86_64.whl\n",
      "/kaggle/input/autogluon-package/requests-2.32.4-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl\n",
      "/kaggle/input/autogluon-package/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl\n",
      "/kaggle/input/autogluon-package/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl\n",
      "/kaggle/input/autogluon-package/tqdm-4.67.1-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/aiosignal-1.3.2-py2.py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/fastcore-1.8.4-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/py4j-0.10.9.9-py2.py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/thinc-8.3.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/autogluon-package/rpds_py-0.25.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/autogluon-package/kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/autogluon-package/autogluon.features-1.3.1-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/platformdirs-4.3.8-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/blis-1.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/autogluon-package/cloudpathlib-0.21.1-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/autogluon-package/__results__.html\n",
      "/kaggle/input/autogluon-package/networkx-3.5-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/marisa_trie-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/autogluon-package/fastdownload-0.0.7-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/autogluon-package/fsspec-2025.5.1-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/annotated_types-0.7.0-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/pytz-2025.2-py2.py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/cycler-0.12.1-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/weasel-0.4.1-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/autogluon.tabular-1.3.1-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl\n",
      "/kaggle/input/autogluon-package/idna-3.10-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/urllib3-2.5.0-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/mpmath-1.3.0-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/aiohappyeyeballs-2.6.1-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/jinja2-3.1.6-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/botocore-1.38.45-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl\n",
      "/kaggle/input/autogluon-package/google_api_core-2.25.1-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/graphviz-0.21-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/preshed-3.0.10-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/autogluon-package/ray-2.44.1-cp311-cp311-manylinux2014_x86_64.whl\n",
      "/kaggle/input/autogluon-package/cymem-2.0.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/autogluon-package/pyasn1_modules-0.4.2-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/six-1.17.0-py2.py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/typing_inspection-0.4.1-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/autogluon-package/referencing-0.36.2-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/hyperopt-0.2.7-py2.py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/py_spy-0.4.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl\n",
      "/kaggle/input/autogluon-package/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl\n",
      "/kaggle/input/autogluon-package/language_data-1.3.0-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/autogluon.common-1.3.1-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/threadpoolctl-3.6.0-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/yarl-1.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/autogluon-package/narwhals-1.44.0-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/pip-25.1.1-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/multidict-6.6.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl\n",
      "/kaggle/input/autogluon-package/torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl\n",
      "/kaggle/input/autogluon-package/pyparsing-3.2.3-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/python_dateutil-2.9.0.post0-py2.py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/rich-14.0.0-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/certifi-2025.6.15-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/jsonschema-4.24.0-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/pygments-2.19.2-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/spacy-3.8.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/autogluon-package/pydantic-2.11.7-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/attrs-25.3.0-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/xgboost-3.0.2-py3-none-manylinux_2_28_x86_64.whl\n",
      "/kaggle/input/autogluon-package/matplotlib-3.10.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/autogluon-package/nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl\n",
      "/kaggle/input/autogluon-package/cloudpickle-3.1.1-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/autogluon-package/plotly-6.2.0-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/autogluon-package/__notebook__.ipynb\n",
      "/kaggle/input/autogluon-package/proto_plus-1.26.1-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/typing_extensions-4.14.0-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/s3transfer-0.13.0-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl\n",
      "/kaggle/input/autogluon-package/catalogue-2.0.10-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl\n",
      "/kaggle/input/autogluon-package/prometheus_client-0.22.1-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/packaging-25.0-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/rsa-4.9.1-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl\n",
      "/kaggle/input/autogluon-package/murmurhash-1.0.13-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/autogluon-package/__output__.json\n",
      "/kaggle/input/autogluon-package/spacy_legacy-3.0.12-py2.py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/setuptools-80.9.0-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/boto3-1.38.45-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/typer-0.16.0-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/huggingface_hub-0.33.1-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/sympy-1.13.1-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/mdurl-0.1.2-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/smart_open-7.1.0-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/colorful-0.5.6-py2.py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/autogluon-package/opencensus_context-0.1.3-py2.py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/wasabi-1.1.3-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/fastprogress-1.0.3-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/autogluon-package/aiohttp_cors-0.8.1-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/tzdata-2025.2-py2.py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/pyarrow-20.0.0-cp311-cp311-manylinux_2_28_x86_64.whl\n",
      "/kaggle/input/autogluon-package/distlib-0.3.9-py2.py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/propcache-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/autogluon-package/virtualenv-20.31.2-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl\n",
      "/kaggle/input/autogluon-package/confection-0.1.5-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/frozenlist-1.7.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/autogluon-package/einops-0.8.1-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/markdown_it_py-3.0.0-py3-none-any.whl\n",
      "/kaggle/input/autogluon-package/custom.css\n",
      "/kaggle/input/scikit-package/joblib-1.5.1-py3-none-any.whl\n",
      "/kaggle/input/scikit-package/numpy-2.3.1-cp311-cp311-manylinux_2_28_x86_64.whl\n",
      "/kaggle/input/scikit-package/scipy-1.16.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl\n",
      "/kaggle/input/scikit-package/__results__.html\n",
      "/kaggle/input/scikit-package/scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/scikit-package/threadpoolctl-3.6.0-py3-none-any.whl\n",
      "/kaggle/input/scikit-package/__notebook__.ipynb\n",
      "/kaggle/input/scikit-package/__output__.json\n",
      "/kaggle/input/scikit-package/custom.css\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "daa6e6fb",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-09-14T16:06:32.427165Z",
     "iopub.status.busy": "2025-09-14T16:06:32.426683Z",
     "iopub.status.idle": "2025-09-14T16:07:24.437189Z",
     "shell.execute_reply": "2025-09-14T16:07:24.435357Z"
    },
    "papermill": {
     "duration": 52.018546,
     "end_time": "2025-09-14T16:07:24.439889",
     "exception": false,
     "start_time": "2025-09-14T16:06:32.421343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: --quiet, /kaggle/input/autogluon-package\r\n",
      "Processing ./autogluon.tabular-1.3.1-py3-none-any.whl\r\n",
      "Requirement already satisfied: numpy<2.3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular==1.3.1) (1.26.4)\r\n",
      "Requirement already satisfied: scipy<1.16,>=1.5.4 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular==1.3.1) (1.15.2)\r\n",
      "Requirement already satisfied: pandas<2.3.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular==1.3.1) (2.2.3)\r\n",
      "\u001b[33mWARNING: Location '--quiet' is ignored: it is either a non-existing path or lacks a specific scheme.\u001b[0m\u001b[33m\r\n",
      "\u001b[0mProcessing /kaggle/input/autogluon-package/scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from autogluon.tabular==1.3.1)\r\n",
      "Requirement already satisfied: networkx<4,>=3.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular==1.3.1) (3.4.2)\r\n",
      "\u001b[33mWARNING: Location '--quiet' is ignored: it is either a non-existing path or lacks a specific scheme.\u001b[0m\u001b[33m\r\n",
      "\u001b[0mProcessing /kaggle/input/autogluon-package/autogluon.core-1.3.1-py3-none-any.whl (from autogluon.tabular==1.3.1)\r\n",
      "\u001b[33mWARNING: Location '--quiet' is ignored: it is either a non-existing path or lacks a specific scheme.\u001b[0m\u001b[33m\r\n",
      "\u001b[0mProcessing /kaggle/input/autogluon-package/autogluon.features-1.3.1-py3-none-any.whl (from autogluon.tabular==1.3.1)\r\n",
      "Requirement already satisfied: tqdm<5,>=4.38 in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.3.1->autogluon.tabular==1.3.1) (4.67.1)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.3.1->autogluon.tabular==1.3.1) (2.32.3)\r\n",
      "Requirement already satisfied: matplotlib<3.11,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.3.1->autogluon.tabular==1.3.1) (3.7.2)\r\n",
      "Requirement already satisfied: boto3<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.3.1->autogluon.tabular==1.3.1) (1.38.11)\r\n",
      "\u001b[33mWARNING: Location '--quiet' is ignored: it is either a non-existing path or lacks a specific scheme.\u001b[0m\u001b[33m\r\n",
      "\u001b[0mProcessing /kaggle/input/autogluon-package/autogluon.common-1.3.1-py3-none-any.whl (from autogluon.core==1.3.1->autogluon.tabular==1.3.1)\r\n",
      "Requirement already satisfied: psutil<7.1.0,>=5.7.3 in /usr/local/lib/python3.11/dist-packages (from autogluon.common==1.3.1->autogluon.core==1.3.1->autogluon.tabular==1.3.1) (7.0.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.3.0,>=1.25.0->autogluon.tabular==1.3.1) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.3.0,>=1.25.0->autogluon.tabular==1.3.1) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.3.0,>=1.25.0->autogluon.tabular==1.3.1) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.3.0,>=1.25.0->autogluon.tabular==1.3.1) (2025.1.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.3.0,>=1.25.0->autogluon.tabular==1.3.1) (2022.1.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.3.0,>=1.25.0->autogluon.tabular==1.3.1) (2.4.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.tabular==1.3.1) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.tabular==1.3.1) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.tabular==1.3.1) (2025.2)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<1.7.0,>=1.4.0->autogluon.tabular==1.3.1) (1.5.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<1.7.0,>=1.4.0->autogluon.tabular==1.3.1) (3.6.0)\r\n",
      "Requirement already satisfied: botocore<1.39.0,>=1.38.11 in /usr/local/lib/python3.11/dist-packages (from boto3<2,>=1.10->autogluon.core==1.3.1->autogluon.tabular==1.3.1) (1.38.11)\r\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from boto3<2,>=1.10->autogluon.core==1.3.1->autogluon.tabular==1.3.1) (1.0.1)\r\n",
      "Requirement already satisfied: s3transfer<0.13.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from boto3<2,>=1.10->autogluon.core==1.3.1->autogluon.tabular==1.3.1) (0.12.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.3.1->autogluon.tabular==1.3.1) (1.3.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.3.1->autogluon.tabular==1.3.1) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.3.1->autogluon.tabular==1.3.1) (4.57.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.3.1->autogluon.tabular==1.3.1) (1.4.8)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.3.1->autogluon.tabular==1.3.1) (25.0)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.3.1->autogluon.tabular==1.3.1) (11.1.0)\r\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.3.1->autogluon.tabular==1.3.1) (3.0.9)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<2.3.0,>=2.0.0->autogluon.tabular==1.3.1) (1.17.0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.3.0,>=1.25.0->autogluon.tabular==1.3.1) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.3.0,>=1.25.0->autogluon.tabular==1.3.1) (2022.1.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.3.0,>=1.25.0->autogluon.tabular==1.3.1) (1.3.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.3.0,>=1.25.0->autogluon.tabular==1.3.1) (2024.2.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->autogluon.core==1.3.1->autogluon.tabular==1.3.1) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->autogluon.core==1.3.1->autogluon.tabular==1.3.1) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->autogluon.core==1.3.1->autogluon.tabular==1.3.1) (2.4.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->autogluon.core==1.3.1->autogluon.tabular==1.3.1) (2025.4.26)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.3.0,>=1.25.0->autogluon.tabular==1.3.1) (2024.2.0)\r\n",
      "Installing collected packages: scikit-learn, autogluon.common, autogluon.features, autogluon.core, autogluon.tabular\r\n",
      "  Attempting uninstall: scikit-learn\r\n",
      "    Found existing installation: scikit-learn 1.2.2\r\n",
      "    Uninstalling scikit-learn-1.2.2:\r\n",
      "      Successfully uninstalled scikit-learn-1.2.2\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "category-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.6.1 which is incompatible.\r\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed autogluon.common-1.3.1 autogluon.core-1.3.1 autogluon.features-1.3.1 autogluon.tabular-1.3.1 scikit-learn-1.6.1\r\n"
     ]
    }
   ],
   "source": [
    "!cp -r /kaggle/input/autogluon-package/* /kaggle/working/\n",
    "!pip install -f --quiet --no-index --find-links='/kaggle/input/autogluon-package' 'autogluon.tabular-1.3.1-py3-none-any.whl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0480ce10",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-09-14T16:07:24.454317Z",
     "iopub.status.busy": "2025-09-14T16:07:24.453857Z",
     "iopub.status.idle": "2025-09-14T16:07:32.880748Z",
     "shell.execute_reply": "2025-09-14T16:07:32.879455Z"
    },
    "papermill": {
     "duration": 8.436975,
     "end_time": "2025-09-14T16:07:32.883017",
     "exception": false,
     "start_time": "2025-09-14T16:07:24.446042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: --quiet, /kaggle/input/scikit-package\r\n",
      "Processing ./scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (1.15.2)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (1.5.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (3.6.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn==1.5.2) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn==1.5.2) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn==1.5.2) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn==1.5.2) (2025.1.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn==1.5.2) (2022.1.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn==1.5.2) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.5->scikit-learn==1.5.2) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.5->scikit-learn==1.5.2) (2022.1.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.5->scikit-learn==1.5.2) (1.3.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.19.5->scikit-learn==1.5.2) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.19.5->scikit-learn==1.5.2) (2024.2.0)\r\n",
      "Installing collected packages: scikit-learn\r\n",
      "  Attempting uninstall: scikit-learn\r\n",
      "    Found existing installation: scikit-learn 1.6.1\r\n",
      "    Uninstalling scikit-learn-1.6.1:\r\n",
      "      Successfully uninstalled scikit-learn-1.6.1\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed scikit-learn-1.5.2\r\n"
     ]
    }
   ],
   "source": [
    "!cp -r /kaggle/input/scikit-package/* /kaggle/working/\n",
    "!pip install -f --quiet --no-index --find-links='/kaggle/input/scikit-package' 'scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d62f0cab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T16:07:32.896735Z",
     "iopub.status.busy": "2025-09-14T16:07:32.896365Z",
     "iopub.status.idle": "2025-09-14T16:07:35.853579Z",
     "shell.execute_reply": "2025-09-14T16:07:35.852613Z"
    },
    "papermill": {
     "duration": 2.966322,
     "end_time": "2025-09-14T16:07:35.855357",
     "exception": false,
     "start_time": "2025-09-14T16:07:32.889035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96cebc27",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-09-14T16:07:35.868459Z",
     "iopub.status.busy": "2025-09-14T16:07:35.867907Z",
     "iopub.status.idle": "2025-09-14T16:07:42.544461Z",
     "shell.execute_reply": "2025-09-14T16:07:42.543312Z"
    },
    "papermill": {
     "duration": 6.685276,
     "end_time": "2025-09-14T16:07:42.546264",
     "exception": false,
     "start_time": "2025-09-14T16:07:35.860988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/rdkit-2025-3-3-cp311/rdkit-2025.3.3-cp311-cp311-manylinux_2_28_x86_64.whl\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rdkit==2025.3.3) (1.26.4)\r\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rdkit==2025.3.3) (11.1.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit==2025.3.3) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit==2025.3.3) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit==2025.3.3) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit==2025.3.3) (2025.1.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit==2025.3.3) (2022.1.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit==2025.3.3) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rdkit==2025.3.3) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rdkit==2025.3.3) (2022.1.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->rdkit==2025.3.3) (1.3.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->rdkit==2025.3.3) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->rdkit==2025.3.3) (2024.2.0)\r\n",
      "Installing collected packages: rdkit\r\n",
      "Successfully installed rdkit-2025.3.3\r\n"
     ]
    }
   ],
   "source": [
    "!pip install /kaggle/input/rdkit-2025-3-3-cp311/rdkit-2025.3.3-cp311-cp311-manylinux_2_28_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81958927",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T16:07:42.559241Z",
     "iopub.status.busy": "2025-09-14T16:07:42.558875Z",
     "iopub.status.idle": "2025-09-14T16:07:42.623963Z",
     "shell.execute_reply": "2025-09-14T16:07:42.622942Z"
    },
    "papermill": {
     "duration": 0.073838,
     "end_time": "2025-09-14T16:07:42.625879",
     "exception": false,
     "start_time": "2025-09-14T16:07:42.552041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "csv_path = '/kaggle/input/open-polymer-challenge/train.csv'\n",
    "train_df = pd.read_csv(csv_path)\n",
    "csv2_path = '/kaggle/input/open-polymer-challenge/test.csv'\n",
    "test_df = pd.read_csv(csv2_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f51f23e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T16:07:42.639028Z",
     "iopub.status.busy": "2025-09-14T16:07:42.638690Z",
     "iopub.status.idle": "2025-09-14T16:07:43.571087Z",
     "shell.execute_reply": "2025-09-14T16:07:43.570151Z"
    },
    "papermill": {
     "duration": 0.941149,
     "end_time": "2025-09-14T16:07:43.572876",
     "exception": false,
     "start_time": "2025-09-14T16:07:42.631727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 外部データ読み込み\n",
    "\n",
    "# https://www.kaggle.com/datasets/minatoyukinaxlisa/tc-smiles\n",
    "data_tc = pd.read_csv('/kaggle/input/tc-smiles/Tc_SMILES.csv')\n",
    "data_tc = data_tc.rename(columns={'TC_mean': 'Tc'})\n",
    "\n",
    "# https://springernature.figshare.com/articles/dataset/dataset_with_glass_transition_temperature/24219958?file=42507037\n",
    "data_tg2 = pd.read_csv('/kaggle/input/smiles-extra-data/JCIM_sup_bigsmiles.csv', usecols=['SMILES', 'Tg (C)'])\n",
    "data_tg2 = data_tg2.rename(columns={'Tg (C)': 'Tg'})\n",
    "\n",
    "# https://www.sciencedirect.com/science/article/pii/S2590159123000377#ec0005\n",
    "data_tg3 = pd.read_excel('/kaggle/input/smiles-extra-data/data_tg3.xlsx')\n",
    "data_tg3 = data_tg3.rename(columns={'Tg [K]': 'Tg'})\n",
    "data_tg3['Tg'] = data_tg3['Tg'] - 273.15\n",
    "\n",
    "# https://github.com/Duke-MatSci/ChemProps\n",
    "data_dnst = pd.read_excel('/kaggle/input/smiles-extra-data/data_dnst1.xlsx')\n",
    "data_dnst = data_dnst.rename(columns={'density(g/cm3)': 'Density'})[['SMILES', 'Density']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96a0ef13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T16:07:43.585970Z",
     "iopub.status.busy": "2025-09-14T16:07:43.585470Z",
     "iopub.status.idle": "2025-09-14T16:07:43.595233Z",
     "shell.execute_reply": "2025-09-14T16:07:43.594257Z"
    },
    "papermill": {
     "duration": 0.018194,
     "end_time": "2025-09-14T16:07:43.596919",
     "exception": false,
     "start_time": "2025-09-14T16:07:43.578725",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 列が足りない場合には NaN を追加して結合します\n",
    "combined_df = pd.concat([train_df, data_tc, data_tg2, data_tg3, data_dnst], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bdbd3e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T16:07:43.611690Z",
     "iopub.status.busy": "2025-09-14T16:07:43.611398Z",
     "iopub.status.idle": "2025-09-14T16:07:43.617435Z",
     "shell.execute_reply": "2025-09-14T16:07:43.616548Z"
    },
    "papermill": {
     "duration": 0.016111,
     "end_time": "2025-09-14T16:07:43.619049",
     "exception": false,
     "start_time": "2025-09-14T16:07:43.602938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = combined_df\n",
    "train_df['Density'] = pd.to_numeric(train_df['Density'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e60eb3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T16:07:43.632617Z",
     "iopub.status.busy": "2025-09-14T16:07:43.631744Z",
     "iopub.status.idle": "2025-09-14T16:11:45.600553Z",
     "shell.execute_reply": "2025-09-14T16:11:45.598771Z"
    },
    "papermill": {
     "duration": 241.978129,
     "end_time": "2025-09-14T16:11:45.603020",
     "exception": false,
     "start_time": "2025-09-14T16:07:43.624891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "記述子＋グラフ特徴量計算: 100%|█████████▉| 10754/10797 [04:00<00:00, 97.04it/s] [16:11:44] SMILES Parse Error: syntax error while parsing: *O[Si](*)([R])[R]\n",
      "[16:11:44] SMILES Parse Error: check for mistakes around position 12:\n",
      "[16:11:44] *O[Si](*)([R])[R]\n",
      "[16:11:44] ~~~~~~~~~~~^\n",
      "[16:11:44] SMILES Parse Error: Failed parsing SMILES '*O[Si](*)([R])[R]' for input: '*O[Si](*)([R])[R]'\n",
      "[16:11:44] SMILES Parse Error: syntax error while parsing: *O[Si](*)([R])[R]\n",
      "[16:11:44] SMILES Parse Error: check for mistakes around position 12:\n",
      "[16:11:44] *O[Si](*)([R])[R]\n",
      "[16:11:44] ~~~~~~~~~~~^\n",
      "[16:11:44] SMILES Parse Error: Failed parsing SMILES '*O[Si](*)([R])[R]' for input: '*O[Si](*)([R])[R]'\n",
      "[16:11:44] SMILES Parse Error: syntax error while parsing: *NC(=O)c4ccc3c(=O)n(c2ccc([R]c1ccc(*)cc1)cc2)c(=O)c3c4\n",
      "[16:11:44] SMILES Parse Error: check for mistakes around position 28:\n",
      "[16:11:44] c4ccc3c(=O)n(c2ccc([R]c1ccc(*)cc1)cc2)c(=\n",
      "[16:11:44] ~~~~~~~~~~~~~~~~~~~~^\n",
      "[16:11:44] SMILES Parse Error: Failed parsing SMILES '*NC(=O)c4ccc3c(=O)n(c2ccc([R]c1ccc(*)cc1)cc2)c(=O)c3c4' for input: '*NC(=O)c4ccc3c(=O)n(c2ccc([R]c1ccc(*)cc1)cc2)c(=O)c3c4'\n",
      "[16:11:44] SMILES Parse Error: syntax error while parsing: *NC(=O)c4ccc3c(=O)n(c2ccc([R]c1ccc(*)cc1)cc2)c(=O)c3c4\n",
      "[16:11:44] SMILES Parse Error: check for mistakes around position 28:\n",
      "[16:11:44] c4ccc3c(=O)n(c2ccc([R]c1ccc(*)cc1)cc2)c(=\n",
      "[16:11:44] ~~~~~~~~~~~~~~~~~~~~^\n",
      "[16:11:44] SMILES Parse Error: Failed parsing SMILES '*NC(=O)c4ccc3c(=O)n(c2ccc([R]c1ccc(*)cc1)cc2)c(=O)c3c4' for input: '*NC(=O)c4ccc3c(=O)n(c2ccc([R]c1ccc(*)cc1)cc2)c(=O)c3c4'\n",
      "記述子＋グラフ特徴量計算: 100%|█████████▉| 10765/10797 [04:00<00:00, 97.63it/s][16:11:44] SMILES Parse Error: syntax error while parsing: O=C=N[R1]N=C=O.O[R2]O.O[R3]O\n",
      "[16:11:44] SMILES Parse Error: check for mistakes around position 7:\n",
      "[16:11:44] O=C=N[R1]N=C=O.O[R2]O.O[R3]O\n",
      "[16:11:44] ~~~~~~^\n",
      "[16:11:44] SMILES Parse Error: Failed parsing SMILES 'O=C=N[R1]N=C=O.O[R2]O.O[R3]O' for input: 'O=C=N[R1]N=C=O.O[R2]O.O[R3]O'\n",
      "[16:11:44] SMILES Parse Error: syntax error while parsing: O=C=N[R1]N=C=O.O[R2]O.O[R3]O\n",
      "[16:11:44] SMILES Parse Error: check for mistakes around position 7:\n",
      "[16:11:44] O=C=N[R1]N=C=O.O[R2]O.O[R3]O\n",
      "[16:11:44] ~~~~~~^\n",
      "[16:11:44] SMILES Parse Error: Failed parsing SMILES 'O=C=N[R1]N=C=O.O[R2]O.O[R3]O' for input: 'O=C=N[R1]N=C=O.O[R2]O.O[R3]O'\n",
      "記述子＋グラフ特徴量計算: 100%|█████████▉| 10785/10797 [04:00<00:00, 87.03it/s][16:11:44] SMILES Parse Error: syntax error while parsing: *CN([R'])Cc2cc([R]c1cc(*)c(O)c(CN([R'])C*)c1)cc(*)c2O\n",
      "[16:11:44] SMILES Parse Error: check for mistakes around position 6:\n",
      "[16:11:44] *CN([R'])Cc2cc([R]c1cc(*)c(O)c(CN([R'])C*\n",
      "[16:11:44] ~~~~~^\n",
      "[16:11:44] SMILES Parse Error: Failed parsing SMILES '*CN([R'])Cc2cc([R]c1cc(*)c(O)c(CN([R'])C*)c1)cc(*)c2O' for input: '*CN([R'])Cc2cc([R]c1cc(*)c(O)c(CN([R'])C*)c1)cc(*)c2O'\n",
      "[16:11:44] SMILES Parse Error: syntax error while parsing: *CN([R'])Cc2cc([R]c1cc(*)c(O)c(CN([R'])C*)c1)cc(*)c2O\n",
      "[16:11:44] SMILES Parse Error: check for mistakes around position 6:\n",
      "[16:11:44] *CN([R'])Cc2cc([R]c1cc(*)c(O)c(CN([R'])C*\n",
      "[16:11:44] ~~~~~^\n",
      "[16:11:44] SMILES Parse Error: Failed parsing SMILES '*CN([R'])Cc2cc([R]c1cc(*)c(O)c(CN([R'])C*)c1)cc(*)c2O' for input: '*CN([R'])Cc2cc([R]c1cc(*)c(O)c(CN([R'])C*)c1)cc(*)c2O'\n",
      "[16:11:44] SMILES Parse Error: syntax error while parsing: *C(F)(F)CC(F)([R])C(*)(F)F\n",
      "[16:11:44] SMILES Parse Error: check for mistakes around position 16:\n",
      "[16:11:44] *C(F)(F)CC(F)([R])C(*)(F)F\n",
      "[16:11:44] ~~~~~~~~~~~~~~~^\n",
      "[16:11:44] SMILES Parse Error: Failed parsing SMILES '*C(F)(F)CC(F)([R])C(*)(F)F' for input: '*C(F)(F)CC(F)([R])C(*)(F)F'\n",
      "[16:11:44] SMILES Parse Error: syntax error while parsing: *C(F)(F)CC(F)([R])C(*)(F)F\n",
      "[16:11:44] SMILES Parse Error: check for mistakes around position 16:\n",
      "[16:11:44] *C(F)(F)CC(F)([R])C(*)(F)F\n",
      "[16:11:44] ~~~~~~~~~~~~~~~^\n",
      "[16:11:44] SMILES Parse Error: Failed parsing SMILES '*C(F)(F)CC(F)([R])C(*)(F)F' for input: '*C(F)(F)CC(F)([R])C(*)(F)F'\n",
      "[16:11:44] SMILES Parse Error: syntax error while parsing: *OC2OC(CO[R])C(OC1OC(CO[R])C(*)C(O[R])C1O[R])C(O[R])C2O[R]\n",
      "[16:11:44] SMILES Parse Error: check for mistakes around position 11:\n",
      "[16:11:44] *OC2OC(CO[R])C(OC1OC(CO[R])C(*)C(O[R])C1O\n",
      "[16:11:44] ~~~~~~~~~~^\n",
      "[16:11:44] SMILES Parse Error: Failed parsing SMILES '*OC2OC(CO[R])C(OC1OC(CO[R])C(*)C(O[R])C1O[R])C(O[R])C2O[R]' for input: '*OC2OC(CO[R])C(OC1OC(CO[R])C(*)C(O[R])C1O[R])C(O[R])C2O[R]'\n",
      "[16:11:44] SMILES Parse Error: syntax error while parsing: *OC2OC(CO[R])C(OC1OC(CO[R])C(*)C(O[R])C1O[R])C(O[R])C2O[R]\n",
      "[16:11:44] SMILES Parse Error: check for mistakes around position 11:\n",
      "[16:11:44] *OC2OC(CO[R])C(OC1OC(CO[R])C(*)C(O[R])C1O\n",
      "[16:11:44] ~~~~~~~~~~^\n",
      "[16:11:44] SMILES Parse Error: Failed parsing SMILES '*OC2OC(CO[R])C(OC1OC(CO[R])C(*)C(O[R])C1O[R])C(O[R])C2O[R]' for input: '*OC2OC(CO[R])C(OC1OC(CO[R])C(*)C(O[R])C1O[R])C(O[R])C2O[R]'\n",
      "記述子＋グラフ特徴量計算: 100%|██████████| 10797/10797 [04:00<00:00, 44.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 欠損確認 (train_df_with_desc)\n",
      "Rg               10183\n",
      "BCUT2D_MRHI       9984\n",
      "BCUT2D_LOGPHI     9984\n",
      "BCUT2D_MWHI       9984\n",
      "BCUT2D_MWLOW      9984\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.ML.Descriptors import MoleculeDescriptors\n",
    "from rdkit.Chem import Descriptors, rdmolops\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# === 1. 208個のdescriptor名を取得 ===\n",
    "descriptor_names = [desc[0] for desc in Descriptors._descList]\n",
    "\n",
    "# === 2. descriptor計算器を準備 ===\n",
    "calc = MoleculeDescriptors.MolecularDescriptorCalculator(descriptor_names)\n",
    "\n",
    "# === 3. 記述子計算関数（例外をnp.nanで吸収） ===\n",
    "def compute_descriptors(smiles):\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            return [np.nan] * len(descriptor_names)\n",
    "        return calc.CalcDescriptors(mol)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ SMILES: {smiles} -> 記述子計算エラー: {e}\")\n",
    "        return [np.nan] * len(descriptor_names)\n",
    "\n",
    "# === 4. グラフ特徴量計算関数（安全処理あり） ===\n",
    "def compute_graph_features(smiles):\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            return [np.nan, np.nan, np.nan]\n",
    "        adj = rdmolops.GetAdjacencyMatrix(mol)\n",
    "        G = nx.from_numpy_array(adj)\n",
    "        diameter = nx.diameter(G) if nx.is_connected(G) else 0\n",
    "        avg_shortest = nx.average_shortest_path_length(G) if nx.is_connected(G) else 0\n",
    "        num_cycles = len(list(nx.cycle_basis(G)))\n",
    "        return [diameter, avg_shortest, num_cycles]\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ SMILES: {smiles} -> グラフ特徴量計算エラー: {e}\")\n",
    "        return [np.nan, np.nan, np.nan]\n",
    "\n",
    "# === 5. SMILES列から 208記述子 + グラフ特徴量 を計算 ===\n",
    "descriptors_list = []\n",
    "graph_feats_list = []\n",
    "\n",
    "for smi in tqdm(train_df['SMILES'], desc=\"記述子＋グラフ特徴量計算\"):\n",
    "    descriptors_list.append(compute_descriptors(smi))\n",
    "    graph_feats_list.append(compute_graph_features(smi))\n",
    "\n",
    "# === 6. DataFrame化 ===\n",
    "descriptor_df = pd.DataFrame(descriptors_list, columns=descriptor_names)\n",
    "graph_feats_df = pd.DataFrame(graph_feats_list, columns=['graph_diameter', 'avg_shortest_path', 'num_cycles'])\n",
    "\n",
    "# === 7. 結合（元のtrain_dfと） ===\n",
    "train_df_with_desc = pd.concat([train_df.reset_index(drop=True), descriptor_df, graph_feats_df], axis=1)\n",
    "\n",
    "# === 8. 欠損確認 ===\n",
    "print(\"✅ 欠損確認 (train_df_with_desc)\")\n",
    "print(train_df_with_desc.isnull().sum().sort_values(ascending=False).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26a5bd7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T16:11:45.786177Z",
     "iopub.status.busy": "2025-09-14T16:11:45.785352Z",
     "iopub.status.idle": "2025-09-14T16:11:45.990720Z",
     "shell.execute_reply": "2025-09-14T16:11:45.989523Z"
    },
    "papermill": {
     "duration": 0.29911,
     "end_time": "2025-09-14T16:11:45.992343",
     "exception": false,
     "start_time": "2025-09-14T16:11:45.693233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test 記述子＋グラフ特徴量計算: 100%|██████████| 3/3 [00:00<00:00, 32.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "定数または全欠損列の数: 0\n",
      "例: []\n",
      "BCUT2D_MRLOW     3\n",
      "BCUT2D_CHGHI     3\n",
      "BCUT2D_MWHI      3\n",
      "BCUT2D_CHGLO     3\n",
      "BCUT2D_LOGPHI    3\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# === test の記述子計算＋グラフ特徴量計算 ===\n",
    "test_descriptors_list = []\n",
    "test_graph_feats_list = []\n",
    "\n",
    "for smi in tqdm(test_df['SMILES'], desc=\"test 記述子＋グラフ特徴量計算\"):\n",
    "    test_descriptors_list.append(compute_descriptors(smi))\n",
    "    test_graph_feats_list.append(compute_graph_features(smi))\n",
    "\n",
    "# === DataFrame化 ===\n",
    "test_descriptor_df = pd.DataFrame(test_descriptors_list, columns=descriptor_names)\n",
    "test_graph_feats_df = pd.DataFrame(test_graph_feats_list, columns=['graph_diameter', 'avg_shortest_path', 'num_cycles'])\n",
    "\n",
    "# === test_dfと連結 ===\n",
    "test_df_with_desc = pd.concat([test_df.reset_index(drop=True), test_descriptor_df, test_graph_feats_df], axis=1)\n",
    "\n",
    "# === train で定数列（全て同じ値 or 全欠損）を検出 ===\n",
    "constant_columns = []\n",
    "for col in train_df_with_desc.columns:\n",
    "    try:\n",
    "        nunique = train_df_with_desc[col].nunique(dropna=False)\n",
    "        all_null = train_df_with_desc[col].isnull().all()\n",
    "        if nunique == 1 or all_null:\n",
    "            constant_columns.append(col)\n",
    "    except Exception as e:\n",
    "        print(f\"列 {col} の処理でエラー: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"定数または全欠損列の数: {len(constant_columns)}\")\n",
    "print(\"例:\", constant_columns[:10])\n",
    "\n",
    "# === train, test から削除 ===\n",
    "train_df_with_desc = train_df_with_desc.drop(columns=constant_columns, errors='ignore')\n",
    "test_df_with_desc = test_df_with_desc.drop(columns=constant_columns, errors='ignore')\n",
    "\n",
    "# === 欠損確認 ===\n",
    "print(test_df_with_desc.isnull().sum().sort_values(ascending=False).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e2ff1c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T16:11:46.177079Z",
     "iopub.status.busy": "2025-09-14T16:11:46.176745Z",
     "iopub.status.idle": "2025-09-14T16:11:46.286821Z",
     "shell.execute_reply": "2025-09-14T16:11:46.285882Z"
    },
    "papermill": {
     "duration": 0.204235,
     "end_time": "2025-09-14T16:11:46.288565",
     "exception": false,
     "start_time": "2025-09-14T16:11:46.084330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "欠損率20%以上の列を除外: 12 列\n",
      "定数列の数: 0\n",
      "最終的に使用する記述子数: 205\n"
     ]
    }
   ],
   "source": [
    "# 1. 欠損率が高い列を除去（例: 20%以上のNaN）\n",
    "nan_threshold = 0.2  # 20%を閾値に設定\n",
    "\n",
    "# train側の記述子だけで欠損率計算\n",
    "desc_df = train_df_with_desc.loc[:, descriptor_names]  # 記述子のみ抽出\n",
    "nan_frac = desc_df.isnull().mean()\n",
    "\n",
    "# 欠損率20%以上の列は除外\n",
    "cols_to_keep = nan_frac[nan_frac < nan_threshold].index.tolist()\n",
    "\n",
    "print(f\"欠損率20%以上の列を除外: {len(desc_df.columns) - len(cols_to_keep)} 列\")\n",
    "\n",
    "# 2. 定数列（全て同じ値の列）を除去（trainとtest両方で）\n",
    "\n",
    "constant_columns = []\n",
    "for col in cols_to_keep:\n",
    "    if train_df_with_desc[col].nunique(dropna=False) == 1:\n",
    "        constant_columns.append(col)\n",
    "\n",
    "print(f\"定数列の数: {len(constant_columns)}\")\n",
    "\n",
    "# 除去対象の列\n",
    "cols_filtered = [col for col in cols_to_keep if col not in constant_columns]\n",
    "\n",
    "# train/test 両方から該当列を除去\n",
    "train_df_with_desc = train_df_with_desc.drop(columns=[col for col in desc_df.columns if col not in cols_filtered], errors='ignore')\n",
    "test_df_with_desc = test_df_with_desc.drop(columns=[col for col in desc_df.columns if col not in cols_filtered], errors='ignore')\n",
    "\n",
    "print(f\"最終的に使用する記述子数: {len(cols_filtered)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "898d3f60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T16:11:46.465064Z",
     "iopub.status.busy": "2025-09-14T16:11:46.464741Z",
     "iopub.status.idle": "2025-09-14T16:11:46.485845Z",
     "shell.execute_reply": "2025-09-14T16:11:46.484703Z"
    },
    "papermill": {
     "duration": 0.111797,
     "end_time": "2025-09-14T16:11:46.487920",
     "exception": false,
     "start_time": "2025-09-14T16:11:46.376123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用する記述子数: 205 / 217\n"
     ]
    }
   ],
   "source": [
    "# 1. train_df_with_desc に実際に存在する descriptor のみ使用し、80%以上 NaN の列を除外\n",
    "existing_descriptor_names = [name for name in descriptor_names if name in train_df_with_desc.columns]\n",
    "desc_df = train_df_with_desc[existing_descriptor_names]\n",
    "valid_descriptor_mask = desc_df.isnull().mean() < 0.2\n",
    "filtered_descriptor_names = desc_df.columns[valid_descriptor_mask].tolist()\n",
    "print(f\"使用する記述子数: {len(filtered_descriptor_names)} / {len(descriptor_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50948ecd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T16:11:46.667833Z",
     "iopub.status.busy": "2025-09-14T16:11:46.667523Z",
     "iopub.status.idle": "2025-09-14T16:11:51.632102Z",
     "shell.execute_reply": "2025-09-14T16:11:51.631275Z"
    },
    "papermill": {
     "duration": 5.057587,
     "end_time": "2025-09-14T16:11:51.633897",
     "exception": false,
     "start_time": "2025-09-14T16:11:46.576310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/2572210559.py:10: RuntimeWarning: invalid value encountered in less\n",
      "  lambda x: np.nan if isinstance(x, (int, float)) and abs(x) > max_float32 else x\n"
     ]
    }
   ],
   "source": [
    "# filtered_descriptor_namesに対してinfをNaNに置換し、NaNは中央値補完\n",
    "for col in filtered_descriptor_names:\n",
    "    # infをNaNに置換\n",
    "    train_df_with_desc[col] = train_df_with_desc[col].replace([np.inf, -np.inf], np.nan)\n",
    "    test_df_with_desc[col] = test_df_with_desc[col].replace([np.inf, -np.inf], np.nan)\n",
    "    \n",
    "    # 極端に大きな値もNaNに\n",
    "    max_float32 = np.finfo(np.float32).max\n",
    "    train_df_with_desc[col] = train_df_with_desc[col].apply(\n",
    "        lambda x: np.nan if isinstance(x, (int, float)) and abs(x) > max_float32 else x\n",
    "    )\n",
    "    test_df_with_desc[col] = test_df_with_desc[col].apply(\n",
    "        lambda x: np.nan if isinstance(x, (int, float)) and abs(x) > max_float32 else x\n",
    "    )\n",
    "\n",
    "# 中央値でNaN補完（学習時のみに）\n",
    "median_values = train_df_with_desc[filtered_descriptor_names].median()\n",
    "train_df_with_desc[filtered_descriptor_names] = train_df_with_desc[filtered_descriptor_names].fillna(median_values)\n",
    "test_df_with_desc[filtered_descriptor_names] = test_df_with_desc[filtered_descriptor_names].fillna(median_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "787dcb19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T16:11:51.813782Z",
     "iopub.status.busy": "2025-09-14T16:11:51.813116Z",
     "iopub.status.idle": "2025-09-14T16:11:51.823468Z",
     "shell.execute_reply": "2025-09-14T16:11:51.822398Z"
    },
    "papermill": {
     "duration": 0.101994,
     "end_time": "2025-09-14T16:11:51.825100",
     "exception": false,
     "start_time": "2025-09-14T16:11:51.723106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "models = {}\n",
    "\n",
    "def predict_test_autogluon(df, predictor, target_col, feature_cols):\n",
    "    # AutoGluonのpredictorで予測し、dfに代入する関数\n",
    "    # feature_colsがdfに必須なので事前に確認してください\n",
    "    y_pred = predictor.predict(df[feature_cols])\n",
    "    df.loc[df.index, target_col] = y_pred\n",
    "    return df\n",
    "\n",
    "def fill_with_autogluon(df, target, descriptors, time_limit=3600):\n",
    "    import numpy as np\n",
    "    from autogluon.tabular import TabularPredictor\n",
    "\n",
    "    target_series = df[target]\n",
    "    non_null_mask = target_series.notnull()\n",
    "\n",
    "    train_data = df.loc[non_null_mask, descriptors + [target]].copy()\n",
    "    # infをnanに変換\n",
    "    train_data = train_data.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    # 欠損値があれば中央値で補完\n",
    "    if train_data.isnull().any().any():\n",
    "        median_values = train_data.median()\n",
    "        train_data = train_data.fillna(median_values)\n",
    "\n",
    "    # ここで再度train_dataにnanがあるかチェック\n",
    "    if train_data.isnull().any().any():\n",
    "        print(f\"[{target}] 補完後もNaNあり。スキップ。\")\n",
    "        return df, None\n",
    "\n",
    "    pred_data = df.loc[~non_null_mask, descriptors].copy()\n",
    "    pred_data = pred_data.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    # 予測用データも同様に欠損補完（中央値）\n",
    "    if pred_data.isnull().any().any():\n",
    "        median_values = pred_data.median()\n",
    "        pred_data = pred_data.fillna(median_values)\n",
    "\n",
    "    if train_data.empty or pred_data.empty:\n",
    "        print(f\"[{target}] 有効な学習/予測データなし。スキップ。\")\n",
    "        return df, None\n",
    "\n",
    "    predictor = TabularPredictor(label=target, problem_type='regression').fit(\n",
    "    train_data=train_data,\n",
    "    time_limit=time_limit,\n",
    "    presets='best_quality',\n",
    "    excluded_model_types=['KNN'],  # 不要であれば\n",
    "    verbosity=2\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        y_pred = predictor.predict(pred_data)\n",
    "        df.loc[pred_data.index, target] = y_pred\n",
    "        print(f\"[{target}] 欠損 {len(y_pred)} 件を AutoGluon で補完\")\n",
    "    except ValueError as e:\n",
    "        print(f\"[{target}] ❌予測失敗: {e}\")\n",
    "\n",
    "    return df, predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87f2344f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T16:11:52.005126Z",
     "iopub.status.busy": "2025-09-14T16:11:52.004818Z",
     "iopub.status.idle": "2025-09-14T20:17:54.863702Z",
     "shell.execute_reply": "2025-09-14T20:17:54.862369Z"
    },
    "papermill": {
     "duration": 14763.25389,
     "end_time": "2025-09-14T20:17:55.168332",
     "exception": false,
     "start_time": "2025-09-14T16:11:51.914442",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250914_161152\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.11.11\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP PREEMPT_DYNAMIC Sun Nov 10 10:07:59 UTC 2024\n",
      "CPU Count:          4\n",
      "Memory Avail:       30.09 GB / 31.35 GB (96.0%)\n",
      "Disk Space Avail:   15.94 GB / 19.52 GB (81.7%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 30s of the 120s of remaining time (25%).\n",
      "/usr/local/lib/python3.11/dist-packages/autogluon/tabular/predictor/predictor.py:1382: UserWarning: Failed to use ray for memory safe fits. Falling back to normal fit. Error: ValueError('ray==2.46.0 detected. 2.10.0 <= ray < 2.45.0 is required. You can use pip to install certain version of ray `pip install \"ray>=2.10.0,<2.45.0\"`')\n",
      "  stacked_overfitting = self._sub_fit_memory_save_wrapper(\n",
      "\t\tContext path: \"/kaggle/working/AutogluonModels/ag-20250914_161152/ds_sub_fit/sub_fit_ho\"\n",
      "Running DyStack sub-fit ...\n",
      "Beginning AutoGluon training ... Time limit = 28s\n",
      "AutoGluon will save models to \"/kaggle/working/AutogluonModels/ag-20250914_161152/ds_sub_fit/sub_fit_ho\"\n",
      "Train Data Rows:    6248\n",
      "Train Data Columns: 205\n",
      "Label Column:       FFV\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    30784.21 MB\n",
      "\tTrain Data (Original)  Memory Usage: 9.77 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 10 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 15): ['NumRadicalElectrons', 'SMR_VSA8', 'SlogP_VSA9', 'fr_HOCCN', 'fr_azide', 'fr_barbitur', 'fr_benzodiazepine', 'fr_diazo', 'fr_dihydropyridine', 'fr_epoxide', 'fr_isothiocyan', 'fr_lactam', 'fr_nitroso', 'fr_prisulfonamd', 'fr_thiocyan']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 9): ['MaxEStateIndex', 'fr_COO2', 'fr_Nhpyrrole', 'fr_amide', 'fr_benzene', 'fr_nitro_arom', 'fr_phenol', 'fr_phenol_noOrthoHbond', 'fr_phos_ester']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 9 | ['MaxEStateIndex', 'fr_COO2', 'fr_Nhpyrrole', 'fr_amide', 'fr_benzene', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 181 | ['MaxAbsEStateIndex', 'MinAbsEStateIndex', 'MinEStateIndex', 'qed', 'SPS', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 172 | ['MaxAbsEStateIndex', 'MinAbsEStateIndex', 'MinEStateIndex', 'qed', 'SPS', ...]\n",
      "\t\t('int', ['bool']) :   9 | ['fr_SH', 'fr_isocyan', 'fr_morpholine', 'fr_phos_acid', 'fr_piperzine', ...]\n",
      "\t3.0s = Fit runtime\n",
      "\t181 features in original data used to generate 181 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 8.25 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 3.08s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
      "Fitting 106 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 16.83s of the 25.24s of remaining time.\n",
      "Will use sequential fold fitting strategy because import of ray failed. Reason: ray==2.46.0 detected. 2.10.0 <= ray < 2.45.0 is required. You can use pip to install certain version of ray `pip install \"ray>=2.10.0,<2.45.0\"`\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 92. Best iteration is:\n",
      "\t[92]\tvalid_set's rmse: 0.0124229\n",
      "\tTime limit exceeded... Skipping LightGBMXT_BAG_L1.\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 3.93s of the 12.34s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 1. Best iteration is:\n",
      "\t[1]\tvalid_set's rmse: 0.0276458\n",
      "\tRan out of time, early stopping on iteration 1. Best iteration is:\n",
      "\t[1]\tvalid_set's rmse: 0.0304346\n",
      "\tRan out of time, early stopping on iteration 2. Best iteration is:\n",
      "\t[2]\tvalid_set's rmse: 0.0289225\n",
      "\tRan out of time, early stopping on iteration 3. Best iteration is:\n",
      "\t[3]\tvalid_set's rmse: 0.0251379\n",
      "\tRan out of time, early stopping on iteration 5. Best iteration is:\n",
      "\t[5]\tvalid_set's rmse: 0.0243759\n",
      "\tRan out of time, early stopping on iteration 8. Best iteration is:\n",
      "\t[8]\tvalid_set's rmse: 0.0226176\n",
      "\tRan out of time, early stopping on iteration 11. Best iteration is:\n",
      "\t[11]\tvalid_set's rmse: 0.0229993\n",
      "\tRan out of time, early stopping on iteration 21. Best iteration is:\n",
      "\t[21]\tvalid_set's rmse: 0.0189932\n",
      "\t-0.0254\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.69s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 0.11s of the 8.52s of remaining time.\n",
      "\t-0.0134\t = Validation score   (-root_mean_squared_error)\n",
      "\t60.41s\t = Training   runtime\n",
      "\t0.76s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 25.26s of the -53.67s of remaining time.\n",
      "\tEnsemble Weights: {'RandomForestMSE_BAG_L1': 1.0}\n",
      "\t-0.0134\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 25.26s of the -53.77s of remaining time.\n",
      "\tEnsemble Weights: {'RandomForestMSE_BAG_L1': 1.0}\n",
      "\t-0.0134\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 82.16s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 8175.2 rows/s (6248 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/kaggle/working/AutogluonModels/ag-20250914_161152/ds_sub_fit/sub_fit_ho\")\n",
      "Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                    model  score_holdout  score_val              eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  RandomForestMSE_BAG_L1      -0.018021  -0.013377  root_mean_squared_error        0.497678       0.763694  60.411850                 0.497678                0.763694          60.411850            1       True          2\n",
      "1     WeightedEnsemble_L3      -0.018021  -0.013377  root_mean_squared_error        0.499177       0.764292  60.419755                 0.001498                0.000598           0.007905            3       True          4\n",
      "2     WeightedEnsemble_L2      -0.018021  -0.013377  root_mean_squared_error        0.499580       0.764263  60.421536                 0.001901                0.000570           0.009686            2       True          3\n",
      "3         LightGBM_BAG_L1      -0.031787  -0.025383  root_mean_squared_error        0.025310       0.019353   3.685613                 0.025310                0.019353           3.685613            1       True          1\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t84s\t = DyStack   runtime |\t36s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 36s\n",
      "AutoGluon will save models to \"/kaggle/working/AutogluonModels/ag-20250914_161152\"\n",
      "Train Data Rows:    7030\n",
      "Train Data Columns: 205\n",
      "Label Column:       FFV\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    30137.82 MB\n",
      "\tTrain Data (Original)  Memory Usage: 11.00 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 11 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 14): ['NumRadicalElectrons', 'SMR_VSA8', 'SlogP_VSA9', 'fr_azide', 'fr_barbitur', 'fr_benzodiazepine', 'fr_diazo', 'fr_dihydropyridine', 'fr_epoxide', 'fr_isothiocyan', 'fr_lactam', 'fr_nitroso', 'fr_prisulfonamd', 'fr_thiocyan']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 11): ['fr_COO2', 'fr_Nhpyrrole', 'fr_aldehyde', 'fr_amide', 'fr_benzene', 'fr_hdrzone', 'fr_morpholine', 'fr_nitro_arom', 'fr_phenol', 'fr_phenol_noOrthoHbond', 'fr_phos_ester']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 11 | ['fr_COO2', 'fr_Nhpyrrole', 'fr_aldehyde', 'fr_amide', 'fr_benzene', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 180 | ['MaxAbsEStateIndex', 'MaxEStateIndex', 'MinAbsEStateIndex', 'MinEStateIndex', 'qed', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 171 | ['MaxAbsEStateIndex', 'MaxEStateIndex', 'MinAbsEStateIndex', 'MinEStateIndex', 'qed', ...]\n",
      "\t\t('int', ['bool']) :   9 | ['fr_HOCCN', 'fr_SH', 'fr_isocyan', 'fr_phos_acid', 'fr_piperzine', ...]\n",
      "\t3.3s = Fit runtime\n",
      "\t180 features in original data used to generate 180 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 9.23 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 3.31s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
      "Fitting 106 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 21.47s of the 32.21s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 374. Best iteration is:\n",
      "\t[374]\tvalid_set's rmse: 0.00985722\n",
      "\tRan out of time, early stopping on iteration 380. Best iteration is:\n",
      "\t[380]\tvalid_set's rmse: 0.0173837\n",
      "\tRan out of time, early stopping on iteration 395. Best iteration is:\n",
      "\t[395]\tvalid_set's rmse: 0.0117251\n",
      "\tRan out of time, early stopping on iteration 400. Best iteration is:\n",
      "\t[399]\tvalid_set's rmse: 0.0115198\n",
      "\tRan out of time, early stopping on iteration 434. Best iteration is:\n",
      "\t[430]\tvalid_set's rmse: 0.0173726\n",
      "\tRan out of time, early stopping on iteration 473. Best iteration is:\n",
      "\t[453]\tvalid_set's rmse: 0.0113199\n",
      "\tRan out of time, early stopping on iteration 555. Best iteration is:\n",
      "\t[554]\tvalid_set's rmse: 0.0179839\n",
      "\tRan out of time, early stopping on iteration 664. Best iteration is:\n",
      "\t[664]\tvalid_set's rmse: 0.0106975\n",
      "\t-0.0139\t = Validation score   (-root_mean_squared_error)\n",
      "\t20.27s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 0.65s of the 11.38s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 1. Best iteration is:\n",
      "\t[1]\tvalid_set's rmse: 0.0261496\n",
      "\tTime limit exceeded... Skipping LightGBM_BAG_L1.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 32.22s of the 10.59s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
      "\t-0.0139\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 10.58s of the 10.55s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 164. Best iteration is:\n",
      "\t[116]\tvalid_set's rmse: 0.0129447\n",
      "\tRan out of time, early stopping on iteration 170. Best iteration is:\n",
      "\t[56]\tvalid_set's rmse: 0.0189401\n",
      "\tRan out of time, early stopping on iteration 175. Best iteration is:\n",
      "\t[161]\tvalid_set's rmse: 0.0155043\n",
      "\tRan out of time, early stopping on iteration 189. Best iteration is:\n",
      "\t[188]\tvalid_set's rmse: 0.0137467\n",
      "\tRan out of time, early stopping on iteration 199. Best iteration is:\n",
      "\t[96]\tvalid_set's rmse: 0.011425\n",
      "\tRan out of time, early stopping on iteration 223. Best iteration is:\n",
      "\t[135]\tvalid_set's rmse: 0.0134824\n",
      "\tRan out of time, early stopping on iteration 220. Best iteration is:\n",
      "\t[220]\tvalid_set's rmse: 0.0155559\n",
      "\tRan out of time, early stopping on iteration 249. Best iteration is:\n",
      "\t[246]\tvalid_set's rmse: 0.0104277\n",
      "\t-0.0142\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.99s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 0.34s of the 0.32s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Model has no time left to train, skipping model... (Time Left = -0.0s)\n",
      "\tTime limit exceeded... Skipping LightGBM_BAG_L2.\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 32.22s of the -0.10s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
      "\t-0.0139\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 35.67s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 4336.6 rows/s (879 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/kaggle/working/AutogluonModels/ag-20250914_161152\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250914_161353\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.11.11\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP PREEMPT_DYNAMIC Sun Nov 10 10:07:59 UTC 2024\n",
      "CPU Count:          4\n",
      "Memory Avail:       29.42 GB / 31.35 GB (93.8%)\n",
      "Disk Space Avail:   15.92 GB / 19.52 GB (81.5%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
      "/usr/local/lib/python3.11/dist-packages/autogluon/tabular/predictor/predictor.py:1382: UserWarning: Failed to use ray for memory safe fits. Falling back to normal fit. Error: ValueError('ray==2.46.0 detected. 2.10.0 <= ray < 2.45.0 is required. You can use pip to install certain version of ray `pip install \"ray>=2.10.0,<2.45.0\"`')\n",
      "  stacked_overfitting = self._sub_fit_memory_save_wrapper(\n",
      "\t\tContext path: \"/kaggle/working/AutogluonModels/ag-20250914_161353/ds_sub_fit/sub_fit_ho\"\n",
      "Running DyStack sub-fit ...\n",
      "Beginning AutoGluon training ... Time limit = 900s\n",
      "AutoGluon will save models to \"/kaggle/working/AutogluonModels/ag-20250914_161353/ds_sub_fit/sub_fit_ho\"\n",
      "Train Data Rows:    1488\n",
      "Train Data Columns: 206\n",
      "Label Column:       Tg\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    30130.30 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.34 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FFV] 欠損 3767 件を AutoGluon で補完\n",
      "                 model  score_val              eval_metric  pred_time_val  \\\n",
      "0    LightGBMXT_BAG_L1  -0.013862  root_mean_squared_error       0.202630   \n",
      "1  WeightedEnsemble_L2  -0.013862  root_mean_squared_error       0.203134   \n",
      "2  WeightedEnsemble_L3  -0.013862  root_mean_squared_error       0.203200   \n",
      "3    LightGBMXT_BAG_L2  -0.014225  root_mean_squared_error       0.276971   \n",
      "\n",
      "    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
      "0  20.266397                0.202630          20.266397            1   \n",
      "1  20.269587                0.000504           0.003190            2   \n",
      "2  20.275077                0.000569           0.008681            3   \n",
      "3  30.261060                0.074341           9.994664            2   \n",
      "\n",
      "   can_infer  fit_order  \n",
      "0       True          1  \n",
      "1       True          2  \n",
      "2       True          4  \n",
      "3       True          3  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 18 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 8): ['SMR_VSA8', 'SlogP_VSA9', 'fr_isocyan', 'fr_isothiocyan', 'fr_nitroso', 'fr_prisulfonamd', 'fr_tetrazole', 'fr_thiocyan']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 7): ['MaxEStateIndex', 'fr_COO2', 'fr_Nhpyrrole', 'fr_amide', 'fr_diazo', 'fr_phenol', 'fr_phos_ester']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 7 | ['MaxEStateIndex', 'fr_COO2', 'fr_Nhpyrrole', 'fr_amide', 'fr_diazo', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 191 | ['MaxAbsEStateIndex', 'MinAbsEStateIndex', 'MinEStateIndex', 'qed', 'SPS', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 174 | ['MaxAbsEStateIndex', 'MinAbsEStateIndex', 'MinEStateIndex', 'qed', 'SPS', ...]\n",
      "\t\t('int', ['bool']) :  17 | ['NumRadicalElectrons', 'NumBridgeheadAtoms', 'NumSpiroAtoms', 'fr_HOCCN', 'fr_N_O', ...]\n",
      "\t1.9s = Fit runtime\n",
      "\t191 features in original data used to generate 191 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 2.00 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.95s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
      "Fitting 106 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 598.54s of the 898.03s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 33.4509\n",
      "[2000]\tvalid_set's rmse: 33.047\n",
      "[3000]\tvalid_set's rmse: 33.0122\n",
      "[4000]\tvalid_set's rmse: 32.9911\n",
      "[5000]\tvalid_set's rmse: 32.9865\n",
      "[6000]\tvalid_set's rmse: 32.9834\n",
      "[7000]\tvalid_set's rmse: 32.9823\n",
      "[8000]\tvalid_set's rmse: 32.9824\n",
      "[9000]\tvalid_set's rmse: 32.9823\n",
      "[1000]\tvalid_set's rmse: 35.8124\n",
      "[2000]\tvalid_set's rmse: 35.651\n",
      "[3000]\tvalid_set's rmse: 35.6416\n",
      "[1000]\tvalid_set's rmse: 39.9453\n",
      "[2000]\tvalid_set's rmse: 39.7677\n",
      "[1000]\tvalid_set's rmse: 33.5928\n",
      "[1000]\tvalid_set's rmse: 30.7804\n",
      "[1000]\tvalid_set's rmse: 39.0459\n",
      "[2000]\tvalid_set's rmse: 38.6394\n",
      "[3000]\tvalid_set's rmse: 38.5989\n",
      "[1000]\tvalid_set's rmse: 41.9016\n",
      "[2000]\tvalid_set's rmse: 41.4092\n",
      "[3000]\tvalid_set's rmse: 41.3295\n",
      "[4000]\tvalid_set's rmse: 41.3058\n",
      "[5000]\tvalid_set's rmse: 41.2966\n",
      "[6000]\tvalid_set's rmse: 41.2893\n",
      "[7000]\tvalid_set's rmse: 41.2868\n",
      "[8000]\tvalid_set's rmse: 41.2853\n",
      "[9000]\tvalid_set's rmse: 41.2839\n",
      "[10000]\tvalid_set's rmse: 41.2832\n",
      "[1000]\tvalid_set's rmse: 39.8521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-36.7134\t = Validation score   (-root_mean_squared_error)\n",
      "\t90.5s\t = Training   runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 505.51s of the 804.99s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 35.2217\n",
      "[1000]\tvalid_set's rmse: 39.4987\n",
      "[2000]\tvalid_set's rmse: 39.4779\n",
      "[1000]\tvalid_set's rmse: 41.4827\n",
      "[2000]\tvalid_set's rmse: 41.2535\n",
      "[3000]\tvalid_set's rmse: 41.2132\n",
      "[4000]\tvalid_set's rmse: 41.1995\n",
      "[5000]\tvalid_set's rmse: 41.1984\n",
      "[6000]\tvalid_set's rmse: 41.198\n",
      "[7000]\tvalid_set's rmse: 41.1978\n",
      "[8000]\tvalid_set's rmse: 41.1975\n",
      "[9000]\tvalid_set's rmse: 41.1973\n",
      "[10000]\tvalid_set's rmse: 41.1972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-36.3396\t = Validation score   (-root_mean_squared_error)\n",
      "\t97.73s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 406.26s of the 705.75s of remaining time.\n",
      "\t-37.3616\t = Validation score   (-root_mean_squared_error)\n",
      "\t10.87s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 395.05s of the 694.54s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 2632.\n",
      "\tRan out of time, early stopping on iteration 2944.\n",
      "\tRan out of time, early stopping on iteration 3000.\n",
      "\tRan out of time, early stopping on iteration 3664.\n",
      "\t-36.3875\t = Validation score   (-root_mean_squared_error)\n",
      "\t347.44s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 47.32s of the 346.81s of remaining time.\n",
      "\t-36.7179\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.56s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 43.40s of the 342.89s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 2: early stopping\n",
      "\t-52.5259\t = Validation score   (-root_mean_squared_error)\n",
      "\t19.77s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 23.37s of the 322.85s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-39.0131\t = Validation score   (-root_mean_squared_error)\n",
      "\t22.31s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 0.89s of the 300.37s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_BAG_L1.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 292.56s of remaining time.\n",
      "\tEnsemble Weights: {'ExtraTreesMSE_BAG_L1': 0.435, 'LightGBM_BAG_L1': 0.304, 'LightGBMXT_BAG_L1': 0.13, 'CatBoost_BAG_L1': 0.13}\n",
      "\t-33.921\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 292.54s of the 292.51s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 27.0514\n",
      "[2000]\tvalid_set's rmse: 26.9499\n",
      "[3000]\tvalid_set's rmse: 26.9005\n",
      "[4000]\tvalid_set's rmse: 26.8761\n",
      "[5000]\tvalid_set's rmse: 26.8545\n",
      "[6000]\tvalid_set's rmse: 26.8457\n",
      "[7000]\tvalid_set's rmse: 26.8362\n",
      "[8000]\tvalid_set's rmse: 26.8335\n",
      "[9000]\tvalid_set's rmse: 26.8293\n",
      "[10000]\tvalid_set's rmse: 26.8275\n",
      "[1000]\tvalid_set's rmse: 27.2346\n",
      "[2000]\tvalid_set's rmse: 27.1445\n",
      "[1000]\tvalid_set's rmse: 29.4839\n",
      "[2000]\tvalid_set's rmse: 29.4187\n",
      "[3000]\tvalid_set's rmse: 29.3962\n",
      "[4000]\tvalid_set's rmse: 29.388\n",
      "[5000]\tvalid_set's rmse: 29.3805\n",
      "[6000]\tvalid_set's rmse: 29.3765\n",
      "[7000]\tvalid_set's rmse: 29.372\n",
      "[8000]\tvalid_set's rmse: 29.3687\n",
      "[9000]\tvalid_set's rmse: 29.3649\n",
      "[10000]\tvalid_set's rmse: 29.3678\n",
      "[1000]\tvalid_set's rmse: 31.5616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-32.5513\t = Validation score   (-root_mean_squared_error)\n",
      "\t65.74s\t = Training   runtime\n",
      "\t0.51s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 224.58s of the 224.55s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 26.1128\n",
      "[2000]\tvalid_set's rmse: 26.0787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-32.1507\t = Validation score   (-root_mean_squared_error)\n",
      "\t35.91s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 188.32s of the 188.29s of remaining time.\n",
      "\t-31.3908\t = Validation score   (-root_mean_squared_error)\n",
      "\t12.45s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 175.55s of the 175.52s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 1382.\n",
      "\tRan out of time, early stopping on iteration 2028.\n",
      "\t-32.7379\t = Validation score   (-root_mean_squared_error)\n",
      "\t126.48s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 48.88s of the 48.85s of remaining time.\n",
      "\t-30.9965\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.89s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 44.65s of the 44.62s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 9: early stopping\n",
      "\t-35.4133\t = Validation score   (-root_mean_squared_error)\n",
      "\t19.11s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 25.29s of the 25.26s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-32.3481\t = Validation score   (-root_mean_squared_error)\n",
      "\t24.16s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 0.87s of remaining time.\n",
      "\tEnsemble Weights: {'ExtraTreesMSE_BAG_L2': 0.556, 'RandomForestMSE_BAG_L2': 0.222, 'NeuralNetFastAI_BAG_L2': 0.111, 'LightGBMXT_BAG_L2': 0.056, 'LightGBM_BAG_L2': 0.056}\n",
      "\t-30.8297\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 899.17s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 96.7 rows/s (186 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/kaggle/working/AutogluonModels/ag-20250914_161353/ds_sub_fit/sub_fit_ho\")\n",
      "Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                     model  score_holdout  score_val              eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0          LightGBM_BAG_L2     -29.427473 -32.150728  root_mean_squared_error        2.417619       1.619596  628.095295                 0.122388                0.059693          35.908786            2       True         10\n",
      "1          CatBoost_BAG_L2     -29.500896 -32.737910  root_mean_squared_error        2.389450       1.636083  718.663237                 0.094219                0.076180         126.476728            2       True         12\n",
      "2          CatBoost_BAG_L1     -29.512687 -36.387501  root_mean_squared_error        0.153555       0.090724  347.436717                 0.153555                0.090724         347.436717            1       True          4\n",
      "3        LightGBMXT_BAG_L2     -29.862838 -32.551338  root_mean_squared_error        3.207775       2.068665  657.925351                 0.912544                0.508761          65.738843            2       True          9\n",
      "4        LightGBMXT_BAG_L1     -29.904075 -36.713351  root_mean_squared_error        1.047709       0.565127   90.499456                 1.047709                0.565127          90.499456            1       True          1\n",
      "5      WeightedEnsemble_L3     -30.025760 -30.829683  root_mean_squared_error        3.696011       2.586367  729.297115                 0.003227                0.000440           0.018201            3       True         16\n",
      "6          LightGBM_BAG_L1     -30.179420 -36.339590  root_mean_squared_error        0.612130       0.370321   97.728650                 0.612130                0.370321          97.728650            1       True          2\n",
      "7           XGBoost_BAG_L1     -30.234544 -39.013134  root_mean_squared_error        0.110366       0.054378   22.312921                 0.110366                0.054378          22.312921            1       True          7\n",
      "8     ExtraTreesMSE_BAG_L2     -30.507316 -30.996513  root_mean_squared_error        2.407679       1.745121  596.072219                 0.112448                0.185218           3.885710            2       True         13\n",
      "9      WeightedEnsemble_L2     -30.660769 -33.921036  root_mean_squared_error        1.941669       1.218272  539.241569                 0.002913                0.000482           0.014163            2       True          8\n",
      "10          XGBoost_BAG_L2     -31.328454 -32.348093  root_mean_squared_error        2.401067       1.602724  616.350229                 0.105836                0.042821          24.163720            2       True         15\n",
      "11  RandomForestMSE_BAG_L2     -31.519464 -31.390774  root_mean_squared_error        2.418996       1.749538  604.635006                 0.123766                0.189635          12.448497            2       True         11\n",
      "12  NeuralNetFastAI_BAG_L2     -31.555423 -35.413257  root_mean_squared_error        2.421637       1.642620  611.297077                 0.126406                0.082717          19.110569            2       True         14\n",
      "13    ExtraTreesMSE_BAG_L1     -34.572414 -36.717855  root_mean_squared_error        0.125361       0.191619    3.562582                 0.125361                0.191619           3.562582            1       True          5\n",
      "14  RandomForestMSE_BAG_L1     -35.803957 -37.361589  root_mean_squared_error        0.124286       0.191368   10.872572                 0.124286                0.191368          10.872572            1       True          3\n",
      "15  NeuralNetFastAI_BAG_L1     -44.516661 -52.525919  root_mean_squared_error        0.121822       0.096367   19.773611                 0.121822                0.096367          19.773611            1       True          6\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t903s\t = DyStack   runtime |\t2697s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 2697s\n",
      "AutoGluon will save models to \"/kaggle/working/AutogluonModels/ag-20250914_161353\"\n",
      "Train Data Rows:    1674\n",
      "Train Data Columns: 206\n",
      "Label Column:       Tg\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    29984.01 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.63 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 18 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 8): ['SMR_VSA8', 'SlogP_VSA9', 'fr_isocyan', 'fr_isothiocyan', 'fr_nitroso', 'fr_prisulfonamd', 'fr_tetrazole', 'fr_thiocyan']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 6): ['MaxEStateIndex', 'fr_COO2', 'fr_Nhpyrrole', 'fr_amide', 'fr_diazo', 'fr_phos_ester']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 6 | ['MaxEStateIndex', 'fr_COO2', 'fr_Nhpyrrole', 'fr_amide', 'fr_diazo', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 192 | ['MaxAbsEStateIndex', 'MinAbsEStateIndex', 'MinEStateIndex', 'qed', 'SPS', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 175 | ['MaxAbsEStateIndex', 'MinAbsEStateIndex', 'MinEStateIndex', 'qed', 'SPS', ...]\n",
      "\t\t('int', ['bool']) :  17 | ['NumRadicalElectrons', 'NumBridgeheadAtoms', 'NumSpiroAtoms', 'fr_HOCCN', 'fr_N_O', ...]\n",
      "\t2.0s = Fit runtime\n",
      "\t192 features in original data used to generate 192 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 2.26 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.04s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
      "Fitting 106 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1796.05s of the 2694.73s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 33.3607\n",
      "[2000]\tvalid_set's rmse: 32.724\n",
      "[3000]\tvalid_set's rmse: 32.676\n",
      "[4000]\tvalid_set's rmse: 32.6707\n",
      "[1000]\tvalid_set's rmse: 31.3003\n",
      "[2000]\tvalid_set's rmse: 30.849\n",
      "[3000]\tvalid_set's rmse: 30.8305\n",
      "[1000]\tvalid_set's rmse: 25.2785\n",
      "[2000]\tvalid_set's rmse: 24.8048\n",
      "[3000]\tvalid_set's rmse: 24.7502\n",
      "[4000]\tvalid_set's rmse: 24.7436\n",
      "[5000]\tvalid_set's rmse: 24.7411\n",
      "[6000]\tvalid_set's rmse: 24.7376\n",
      "[7000]\tvalid_set's rmse: 24.7377\n",
      "[1000]\tvalid_set's rmse: 27.9374\n",
      "[2000]\tvalid_set's rmse: 27.3648\n",
      "[3000]\tvalid_set's rmse: 27.3314\n",
      "[1000]\tvalid_set's rmse: 38.6484\n",
      "[2000]\tvalid_set's rmse: 38.0317\n",
      "[3000]\tvalid_set's rmse: 37.9736\n",
      "[4000]\tvalid_set's rmse: 37.9547\n",
      "[5000]\tvalid_set's rmse: 37.9424\n",
      "[6000]\tvalid_set's rmse: 37.9355\n",
      "[7000]\tvalid_set's rmse: 37.9303\n",
      "[8000]\tvalid_set's rmse: 37.9271\n",
      "[9000]\tvalid_set's rmse: 37.9247\n",
      "[10000]\tvalid_set's rmse: 37.9226\n",
      "[1000]\tvalid_set's rmse: 37.0924\n",
      "[2000]\tvalid_set's rmse: 36.4223\n",
      "[3000]\tvalid_set's rmse: 36.3877\n",
      "[4000]\tvalid_set's rmse: 36.3804\n",
      "[5000]\tvalid_set's rmse: 36.3829\n",
      "[1000]\tvalid_set's rmse: 32.8235\n",
      "[2000]\tvalid_set's rmse: 32.3168\n",
      "[3000]\tvalid_set's rmse: 32.2942\n",
      "[1000]\tvalid_set's rmse: 28.358\n",
      "[2000]\tvalid_set's rmse: 28.0197\n",
      "[3000]\tvalid_set's rmse: 27.9979\n",
      "[4000]\tvalid_set's rmse: 27.9913\n",
      "[5000]\tvalid_set's rmse: 27.9857\n",
      "[6000]\tvalid_set's rmse: 27.9819\n",
      "[7000]\tvalid_set's rmse: 27.9823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-31.5498\t = Validation score   (-root_mean_squared_error)\n",
      "\t112.55s\t = Training   runtime\n",
      "\t0.79s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1680.08s of the 2578.76s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 31.7389\n",
      "[2000]\tvalid_set's rmse: 31.6414\n",
      "[3000]\tvalid_set's rmse: 31.6326\n",
      "[4000]\tvalid_set's rmse: 31.6329\n",
      "[1000]\tvalid_set's rmse: 30.7562\n",
      "[2000]\tvalid_set's rmse: 30.6675\n",
      "[3000]\tvalid_set's rmse: 30.6569\n",
      "[4000]\tvalid_set's rmse: 30.6572\n",
      "[1000]\tvalid_set's rmse: 25.0663\n",
      "[2000]\tvalid_set's rmse: 25.0064\n",
      "[3000]\tvalid_set's rmse: 24.9998\n",
      "[1000]\tvalid_set's rmse: 27.5573\n",
      "[2000]\tvalid_set's rmse: 27.54\n",
      "[1000]\tvalid_set's rmse: 38.1821\n",
      "[2000]\tvalid_set's rmse: 38.0757\n",
      "[3000]\tvalid_set's rmse: 38.0473\n",
      "[4000]\tvalid_set's rmse: 38.0431\n",
      "[5000]\tvalid_set's rmse: 38.0427\n",
      "[1000]\tvalid_set's rmse: 31.869\n",
      "[2000]\tvalid_set's rmse: 31.839\n",
      "[3000]\tvalid_set's rmse: 31.8342\n",
      "[4000]\tvalid_set's rmse: 31.8333\n",
      "[5000]\tvalid_set's rmse: 31.8331\n",
      "[6000]\tvalid_set's rmse: 31.8331\n",
      "[1000]\tvalid_set's rmse: 34.2725\n",
      "[1000]\tvalid_set's rmse: 28.0561\n",
      "[2000]\tvalid_set's rmse: 28.04\n",
      "[3000]\tvalid_set's rmse: 28.0251\n",
      "[4000]\tvalid_set's rmse: 28.0201\n",
      "[5000]\tvalid_set's rmse: 28.018\n",
      "[6000]\tvalid_set's rmse: 28.0169\n",
      "[7000]\tvalid_set's rmse: 28.0165\n",
      "[8000]\tvalid_set's rmse: 28.0165\n",
      "[9000]\tvalid_set's rmse: 28.0164\n",
      "[10000]\tvalid_set's rmse: 28.0164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-31.1121\t = Validation score   (-root_mean_squared_error)\n",
      "\t175.4s\t = Training   runtime\n",
      "\t0.75s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 1501.73s of the 2400.41s of remaining time.\n",
      "\t-32.6938\t = Validation score   (-root_mean_squared_error)\n",
      "\t11.89s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1489.56s of the 2388.25s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 7774.\n",
      "\tRan out of time, early stopping on iteration 9242.\n",
      "\t-31.2305\t = Validation score   (-root_mean_squared_error)\n",
      "\t1050.65s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 438.52s of the 1337.20s of remaining time.\n",
      "\t-31.8347\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.86s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 434.27s of the 1332.96s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-46.7576\t = Validation score   (-root_mean_squared_error)\n",
      "\t15.11s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 418.92s of the 1317.60s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-33.0525\t = Validation score   (-root_mean_squared_error)\n",
      "\t88.11s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 330.50s of the 1229.19s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 425)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 438)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 441)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 459)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 481)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 765)\n",
      "\t-37.3845\t = Validation score   (-root_mean_squared_error)\n",
      "\t306.81s\t = Training   runtime\n",
      "\t0.71s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 22.86s of the 921.54s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 108. Best iteration is:\n",
      "\t[108]\tvalid_set's rmse: 36.4787\n",
      "\tRan out of time, early stopping on iteration 85. Best iteration is:\n",
      "\t[85]\tvalid_set's rmse: 31.8526\n",
      "\tRan out of time, early stopping on iteration 116. Best iteration is:\n",
      "\t[116]\tvalid_set's rmse: 27.1069\n",
      "\tRan out of time, early stopping on iteration 119. Best iteration is:\n",
      "\t[119]\tvalid_set's rmse: 29.5892\n",
      "\tRan out of time, early stopping on iteration 125. Best iteration is:\n",
      "\t[125]\tvalid_set's rmse: 45.2828\n",
      "\tRan out of time, early stopping on iteration 131. Best iteration is:\n",
      "\t[131]\tvalid_set's rmse: 34.6704\n",
      "\tRan out of time, early stopping on iteration 130. Best iteration is:\n",
      "\t[130]\tvalid_set's rmse: 31.1653\n",
      "\tRan out of time, early stopping on iteration 180. Best iteration is:\n",
      "\t[180]\tvalid_set's rmse: 29.7351\n",
      "\t-33.66\t = Validation score   (-root_mean_squared_error)\n",
      "\t21.77s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 0.75s of the 899.44s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 1.\n",
      "\tTime limit exceeded... Skipping CatBoost_r177_BAG_L1.\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 0.31s of the 898.99s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_r79_BAG_L1.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 897.71s of remaining time.\n",
      "\tEnsemble Weights: {'ExtraTreesMSE_BAG_L1': 0.421, 'LightGBM_BAG_L1': 0.316, 'CatBoost_BAG_L1': 0.158, 'LightGBMXT_BAG_L1': 0.105}\n",
      "\t-28.6242\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 897.68s of the 897.65s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 23.8312\n",
      "[2000]\tvalid_set's rmse: 23.7487\n",
      "[1000]\tvalid_set's rmse: 24.0049\n",
      "[2000]\tvalid_set's rmse: 23.8715\n",
      "[3000]\tvalid_set's rmse: 23.8204\n",
      "[4000]\tvalid_set's rmse: 23.798\n",
      "[5000]\tvalid_set's rmse: 23.7811\n",
      "[6000]\tvalid_set's rmse: 23.7709\n",
      "[7000]\tvalid_set's rmse: 23.7662\n",
      "[8000]\tvalid_set's rmse: 23.7618\n",
      "[9000]\tvalid_set's rmse: 23.7577\n",
      "[10000]\tvalid_set's rmse: 23.7569\n",
      "[1000]\tvalid_set's rmse: 23.5124\n",
      "[2000]\tvalid_set's rmse: 23.4261\n",
      "[3000]\tvalid_set's rmse: 23.417\n",
      "[4000]\tvalid_set's rmse: 23.4007\n",
      "[5000]\tvalid_set's rmse: 23.3915\n",
      "[6000]\tvalid_set's rmse: 23.382\n",
      "[7000]\tvalid_set's rmse: 23.3762\n",
      "[8000]\tvalid_set's rmse: 23.3745\n",
      "[9000]\tvalid_set's rmse: 23.3739\n",
      "[10000]\tvalid_set's rmse: 23.3727\n",
      "[1000]\tvalid_set's rmse: 24.1969\n",
      "[1000]\tvalid_set's rmse: 23.9285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-25.6245\t = Validation score   (-root_mean_squared_error)\n",
      "\t79.43s\t = Training   runtime\n",
      "\t0.68s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 815.72s of the 815.69s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-25.7916\t = Validation score   (-root_mean_squared_error)\n",
      "\t32.58s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 782.87s of the 782.84s of remaining time.\n",
      "\t-25.1269\t = Validation score   (-root_mean_squared_error)\n",
      "\t13.93s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 768.55s of the 768.52s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 4520.\n",
      "\tRan out of time, early stopping on iteration 9313.\n",
      "\t-25.3476\t = Validation score   (-root_mean_squared_error)\n",
      "\t653.16s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 115.07s of the 115.04s of remaining time.\n",
      "\t-24.6571\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.46s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 110.24s of the 110.21s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-30.8998\t = Validation score   (-root_mean_squared_error)\n",
      "\t15.6s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 94.37s of the 94.34s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-25.7088\t = Validation score   (-root_mean_squared_error)\n",
      "\t67.61s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 26.51s of the 26.48s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 21)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 23)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 24)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 24)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 26)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 33)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 41)\n",
      "\t-30.1598\t = Validation score   (-root_mean_squared_error)\n",
      "\t24.65s\t = Training   runtime\n",
      "\t0.72s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 0.89s of remaining time.\n",
      "\tEnsemble Weights: {'ExtraTreesMSE_BAG_L2': 0.6, 'LightGBMXT_BAG_L2': 0.15, 'CatBoost_BAG_L2': 0.15, 'XGBoost_BAG_L2': 0.1}\n",
      "\t-24.429\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2695.95s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 61.3 rows/s (210 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/kaggle/working/AutogluonModels/ag-20250914_161353\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250914_171539\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.11.11\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP PREEMPT_DYNAMIC Sun Nov 10 10:07:59 UTC 2024\n",
      "CPU Count:          4\n",
      "Memory Avail:       29.25 GB / 31.35 GB (93.3%)\n",
      "Disk Space Avail:   15.36 GB / 19.52 GB (78.7%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
      "/usr/local/lib/python3.11/dist-packages/autogluon/tabular/predictor/predictor.py:1382: UserWarning: Failed to use ray for memory safe fits. Falling back to normal fit. Error: ValueError('ray==2.46.0 detected. 2.10.0 <= ray < 2.45.0 is required. You can use pip to install certain version of ray `pip install \"ray>=2.10.0,<2.45.0\"`')\n",
      "  stacked_overfitting = self._sub_fit_memory_save_wrapper(\n",
      "\t\tContext path: \"/kaggle/working/AutogluonModels/ag-20250914_171539/ds_sub_fit/sub_fit_ho\"\n",
      "Running DyStack sub-fit ...\n",
      "Beginning AutoGluon training ... Time limit = 900s\n",
      "AutoGluon will save models to \"/kaggle/working/AutogluonModels/ag-20250914_171539/ds_sub_fit/sub_fit_ho\"\n",
      "Train Data Rows:    1432\n",
      "Train Data Columns: 206\n",
      "Label Column:       Tc\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    29953.87 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.25 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tg] 欠損 9123 件を AutoGluon で補完\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 26 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 28): ['NumRadicalElectrons', 'PEOE_VSA5', 'SMR_VSA8', 'SlogP_VSA9', 'NumSpiroAtoms', 'fr_ArN', 'fr_C_S', 'fr_HOCCN', 'fr_SH', 'fr_azide', 'fr_barbitur', 'fr_benzodiazepine', 'fr_diazo', 'fr_dihydropyridine', 'fr_guanido', 'fr_hdrzine', 'fr_hdrzone', 'fr_isocyan', 'fr_isothiocyan', 'fr_lactam', 'fr_nitroso', 'fr_oxime', 'fr_phos_acid', 'fr_phos_ester', 'fr_prisulfonamd', 'fr_term_acetylene', 'fr_tetrazole', 'fr_thiocyan']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 10): ['MaxEStateIndex', 'NumUnspecifiedAtomStereoCenters', 'fr_COO2', 'fr_Nhpyrrole', 'fr_amide', 'fr_benzene', 'fr_nitro_arom_nonortho', 'fr_phenol', 'fr_phenol_noOrthoHbond', 'fr_priamide']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 10 | ['MaxEStateIndex', 'NumUnspecifiedAtomStereoCenters', 'fr_COO2', 'fr_Nhpyrrole', 'fr_amide', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 168 | ['MaxAbsEStateIndex', 'MinAbsEStateIndex', 'MinEStateIndex', 'qed', 'SPS', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 146 | ['MaxAbsEStateIndex', 'MinAbsEStateIndex', 'MinEStateIndex', 'qed', 'SPS', ...]\n",
      "\t\t('int', ['bool']) :  22 | ['fr_Al_COO', 'fr_Al_OH', 'fr_Al_OH_noTert', 'fr_Ar_COO', 'fr_Ar_OH', ...]\n",
      "\t1.5s = Fit runtime\n",
      "\t168 features in original data used to generate 168 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.63 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.55s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
      "Fitting 106 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 598.81s of the 898.43s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.0259994\n",
      "[2000]\tvalid_set's rmse: 0.0242189\n",
      "[3000]\tvalid_set's rmse: 0.0237398\n",
      "[4000]\tvalid_set's rmse: 0.023549\n",
      "[5000]\tvalid_set's rmse: 0.0234556\n",
      "[6000]\tvalid_set's rmse: 0.0234007\n",
      "[7000]\tvalid_set's rmse: 0.0233563\n",
      "[8000]\tvalid_set's rmse: 0.0233397\n",
      "[9000]\tvalid_set's rmse: 0.0233313\n",
      "[10000]\tvalid_set's rmse: 0.0233235\n",
      "[1000]\tvalid_set's rmse: 0.0289731\n",
      "[2000]\tvalid_set's rmse: 0.0280695\n",
      "[3000]\tvalid_set's rmse: 0.0278966\n",
      "[4000]\tvalid_set's rmse: 0.0277046\n",
      "[5000]\tvalid_set's rmse: 0.0276257\n",
      "[6000]\tvalid_set's rmse: 0.02761\n",
      "[7000]\tvalid_set's rmse: 0.0276056\n",
      "[8000]\tvalid_set's rmse: 0.0275995\n",
      "[9000]\tvalid_set's rmse: 0.0275959\n",
      "[10000]\tvalid_set's rmse: 0.0275918\n",
      "[1000]\tvalid_set's rmse: 0.0236384\n",
      "[2000]\tvalid_set's rmse: 0.022521\n",
      "[3000]\tvalid_set's rmse: 0.0219912\n",
      "[4000]\tvalid_set's rmse: 0.0218595\n",
      "[5000]\tvalid_set's rmse: 0.0218398\n",
      "[6000]\tvalid_set's rmse: 0.0218279\n",
      "[7000]\tvalid_set's rmse: 0.0218216\n",
      "[8000]\tvalid_set's rmse: 0.0218101\n",
      "[9000]\tvalid_set's rmse: 0.0218061\n",
      "[10000]\tvalid_set's rmse: 0.0218008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.0453\t = Validation score   (-root_mean_squared_error)\n",
      "\t65.65s\t = Training   runtime\n",
      "\t0.72s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 530.32s of the 829.93s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.0229527\n",
      "[2000]\tvalid_set's rmse: 0.0227203\n",
      "[1000]\tvalid_set's rmse: 0.021599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.0454\t = Validation score   (-root_mean_squared_error)\n",
      "\t30.08s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 499.85s of the 799.47s of remaining time.\n",
      "\t-0.0507\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.96s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 491.56s of the 791.18s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 4197.\n",
      "\tRan out of time, early stopping on iteration 4299.\n",
      "\tRan out of time, early stopping on iteration 4421.\n",
      "\tRan out of time, early stopping on iteration 4621.\n",
      "\t-0.0471\t = Validation score   (-root_mean_squared_error)\n",
      "\t381.07s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 110.23s of the 409.84s of remaining time.\n",
      "\t-0.0504\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.74s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 107.17s of the 406.79s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 4: early stopping\n",
      "\t-0.0504\t = Validation score   (-root_mean_squared_error)\n",
      "\t15.46s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 91.48s of the 391.09s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.0485\t = Validation score   (-root_mean_squared_error)\n",
      "\t27.0s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 64.26s of the 363.88s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 177)\n",
      "\t-0.0537\t = Validation score   (-root_mean_squared_error)\n",
      "\t37.96s\t = Training   runtime\n",
      "\t0.53s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 25.68s of the 325.30s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 121. Best iteration is:\n",
      "\t[40]\tvalid_set's rmse: 0.048108\n",
      "\tRan out of time, early stopping on iteration 123. Best iteration is:\n",
      "\t[123]\tvalid_set's rmse: 0.0360821\n",
      "\tRan out of time, early stopping on iteration 173. Best iteration is:\n",
      "\t[94]\tvalid_set's rmse: 0.0332113\n",
      "\tRan out of time, early stopping on iteration 137. Best iteration is:\n",
      "\t[133]\tvalid_set's rmse: 0.0216428\n",
      "\tRan out of time, early stopping on iteration 190. Best iteration is:\n",
      "\t[107]\tvalid_set's rmse: 0.0242146\n",
      "\tRan out of time, early stopping on iteration 151. Best iteration is:\n",
      "\t[100]\tvalid_set's rmse: 0.0974871\n",
      "\tRan out of time, early stopping on iteration 168. Best iteration is:\n",
      "\t[102]\tvalid_set's rmse: 0.028266\n",
      "\tRan out of time, early stopping on iteration 203. Best iteration is:\n",
      "\t[79]\tvalid_set's rmse: 0.054274\n",
      "\t-0.0488\t = Validation score   (-root_mean_squared_error)\n",
      "\t24.47s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 0.92s of the 300.54s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 1.\n",
      "\tTime limit exceeded... Skipping CatBoost_r177_BAG_L1.\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 0.46s of the 300.07s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_r79_BAG_L1.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 299.08s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.333, 'LightGBMXT_BAG_L1': 0.208, 'LightGBM_BAG_L1': 0.208, 'NeuralNetFastAI_BAG_L1': 0.125, 'NeuralNetTorch_BAG_L1': 0.125}\n",
      "\t-0.044\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 299.05s of the 299.02s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.0451\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.56s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 289.37s of the 289.34s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.0254478\n",
      "[1000]\tvalid_set's rmse: 0.0249134\n",
      "[1000]\tvalid_set's rmse: 0.0984902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.0433\t = Validation score   (-root_mean_squared_error)\n",
      "\t29.97s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 259.06s of the 259.03s of remaining time.\n",
      "\t-0.0436\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.72s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 249.02s of the 248.99s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 2840.\n",
      "\tRan out of time, early stopping on iteration 2923.\n",
      "\t-0.0442\t = Validation score   (-root_mean_squared_error)\n",
      "\t135.73s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 113.07s of the 113.04s of remaining time.\n",
      "\t-0.0433\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.21s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 109.57s of the 109.54s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 6: early stopping\n",
      "\t-0.0477\t = Validation score   (-root_mean_squared_error)\n",
      "\t15.72s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 93.60s of the 93.57s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.0442\t = Validation score   (-root_mean_squared_error)\n",
      "\t25.55s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 67.87s of the 67.84s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.0467\t = Validation score   (-root_mean_squared_error)\n",
      "\t32.56s\t = Training   runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 34.63s of the 34.60s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 149. Best iteration is:\n",
      "\t[110]\tvalid_set's rmse: 0.0216888\n",
      "\tRan out of time, early stopping on iteration 151. Best iteration is:\n",
      "\t[151]\tvalid_set's rmse: 0.0300135\n",
      "\tRan out of time, early stopping on iteration 156. Best iteration is:\n",
      "\t[111]\tvalid_set's rmse: 0.0397088\n",
      "\tRan out of time, early stopping on iteration 160. Best iteration is:\n",
      "\t[158]\tvalid_set's rmse: 0.0218754\n",
      "\tRan out of time, early stopping on iteration 197. Best iteration is:\n",
      "\t[128]\tvalid_set's rmse: 0.02663\n",
      "\tRan out of time, early stopping on iteration 211. Best iteration is:\n",
      "\t[129]\tvalid_set's rmse: 0.0265623\n",
      "\tRan out of time, early stopping on iteration 202. Best iteration is:\n",
      "\t[93]\tvalid_set's rmse: 0.0325173\n",
      "\tRan out of time, early stopping on iteration 245. Best iteration is:\n",
      "\t[245]\tvalid_set's rmse: 0.09388\n",
      "\t-0.0429\t = Validation score   (-root_mean_squared_error)\n",
      "\t33.11s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 0.95s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMLarge_BAG_L2': 0.44, 'LightGBM_BAG_L2': 0.16, 'CatBoost_BAG_L1': 0.12, 'NeuralNetTorch_BAG_L1': 0.08, 'ExtraTreesMSE_BAG_L2': 0.08, 'NeuralNetFastAI_BAG_L1': 0.04, 'RandomForestMSE_BAG_L2': 0.04, 'NeuralNetTorch_BAG_L2': 0.04}\n",
      "\t-0.0422\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 899.1s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 78.3 rows/s (179 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/kaggle/working/AutogluonModels/ag-20250914_171539/ds_sub_fit/sub_fit_ho\")\n",
      "Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                     model  score_holdout  score_val              eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0   NeuralNetFastAI_BAG_L2      -0.034443  -0.047684  root_mean_squared_error        2.897649       1.975540  583.640387                 0.127732                0.088654          15.723299            2       True         16\n",
      "1          CatBoost_BAG_L2      -0.034656  -0.044169  root_mean_squared_error        2.863309       1.970502  703.646539                 0.093392                0.083616         135.729450            2       True         14\n",
      "2          LightGBM_BAG_L1      -0.034668  -0.045412  root_mean_squared_error        0.147320       0.069473   30.080772                 0.147320                0.069473          30.080772            1       True          2\n",
      "3      WeightedEnsemble_L3      -0.034716  -0.042166  root_mean_squared_error        3.826123       2.926654  676.517278                 0.004324                0.000520           0.021997            3       True         20\n",
      "4     LightGBMLarge_BAG_L2      -0.035367  -0.042884  root_mean_squared_error        2.885144       1.923887  601.027942                 0.115227                0.037002          33.110854            2       True         19\n",
      "5   RandomForestMSE_BAG_L2      -0.036586  -0.043552  root_mean_squared_error        2.893336       2.071434  577.637892                 0.123419                0.184548           9.720803            2       True         13\n",
      "6          LightGBM_BAG_L2      -0.037075  -0.043268  root_mean_squared_error        2.894201       1.950546  597.890687                 0.124284                0.063660          29.973598            2       True         12\n",
      "7      WeightedEnsemble_L2      -0.037197  -0.043999  root_mean_squared_error        2.325850       1.474813  530.228977                 0.003448                0.000463           0.013530            2       True         10\n",
      "8          CatBoost_BAG_L1      -0.037624  -0.047056  root_mean_squared_error        0.161474       0.076188  381.065711                 0.161474                0.076188         381.065711            1       True          4\n",
      "9        LightGBMXT_BAG_L2      -0.038423  -0.045120  root_mean_squared_error        2.811245       1.911288  577.473064                 0.041328                0.024402           9.555975            2       True         11\n",
      "10       LightGBMXT_BAG_L1      -0.039544  -0.045288  root_mean_squared_error        1.338672       0.716243   65.651700                 1.338672                0.716243          65.651700            1       True          1\n",
      "11  NeuralNetFastAI_BAG_L1      -0.039705  -0.050413  root_mean_squared_error        0.130708       0.081737   15.459084                 0.130708                0.081737          15.459084            1       True          6\n",
      "12          XGBoost_BAG_L1      -0.039843  -0.048459  root_mean_squared_error        0.188640       0.049860   27.001217                 0.188640                0.049860          27.001217            1       True          7\n",
      "13    ExtraTreesMSE_BAG_L2      -0.040952  -0.043254  root_mean_squared_error        2.892224       2.069878  571.131651                 0.122307                0.182992           3.214563            2       True         15\n",
      "14   NeuralNetTorch_BAG_L2      -0.041331  -0.046705  root_mean_squared_error        3.336561       2.457931  600.475463                 0.566644                0.571045          32.558374            2       True         18\n",
      "15    ExtraTreesMSE_BAG_L1      -0.042651  -0.050383  root_mean_squared_error        0.127587       0.180956    2.739852                 0.127587                0.180956           2.739852            1       True          5\n",
      "16   NeuralNetTorch_BAG_L1      -0.048438  -0.053745  root_mean_squared_error        0.544229       0.530709   37.958180                 0.544229                0.530709          37.958180            1       True          8\n",
      "17  RandomForestMSE_BAG_L1      -0.053224  -0.050704  root_mean_squared_error        0.131287       0.181721    7.960572                 0.131287                0.181721           7.960572            1       True          3\n",
      "18          XGBoost_BAG_L2      -0.053394  -0.044160  root_mean_squared_error        2.913314       1.930091  593.469805                 0.143397                0.043205          25.552716            2       True         17\n",
      "19    LightGBMLarge_BAG_L1      -0.054181  -0.048763  root_mean_squared_error        0.083474       0.022216   24.468088                 0.083474                0.022216          24.468088            1       True          9\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t904s\t = DyStack   runtime |\t2696s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 2696s\n",
      "AutoGluon will save models to \"/kaggle/working/AutogluonModels/ag-20250914_171539\"\n",
      "Train Data Rows:    1611\n",
      "Train Data Columns: 206\n",
      "Label Column:       Tc\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    29993.86 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.53 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 23 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 27): ['NumRadicalElectrons', 'PEOE_VSA5', 'SMR_VSA8', 'SlogP_VSA9', 'NumSpiroAtoms', 'fr_ArN', 'fr_C_S', 'fr_HOCCN', 'fr_SH', 'fr_azide', 'fr_barbitur', 'fr_benzodiazepine', 'fr_diazo', 'fr_dihydropyridine', 'fr_guanido', 'fr_hdrzine', 'fr_hdrzone', 'fr_isocyan', 'fr_isothiocyan', 'fr_lactam', 'fr_nitroso', 'fr_oxime', 'fr_phos_acid', 'fr_phos_ester', 'fr_prisulfonamd', 'fr_tetrazole', 'fr_thiocyan']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 10): ['MaxEStateIndex', 'NumUnspecifiedAtomStereoCenters', 'fr_COO2', 'fr_Nhpyrrole', 'fr_amide', 'fr_benzene', 'fr_nitro_arom_nonortho', 'fr_phenol', 'fr_phenol_noOrthoHbond', 'fr_priamide']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 10 | ['MaxEStateIndex', 'NumUnspecifiedAtomStereoCenters', 'fr_COO2', 'fr_Nhpyrrole', 'fr_amide', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 169 | ['MaxAbsEStateIndex', 'MinAbsEStateIndex', 'MinEStateIndex', 'qed', 'SPS', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 148 | ['MaxAbsEStateIndex', 'MinAbsEStateIndex', 'MinEStateIndex', 'qed', 'SPS', ...]\n",
      "\t\t('int', ['bool']) :  21 | ['fr_Al_COO', 'fr_Al_OH', 'fr_Al_OH_noTert', 'fr_Ar_COO', 'fr_NH2', ...]\n",
      "\t2.3s = Fit runtime\n",
      "\t169 features in original data used to generate 169 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.85 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.31s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
      "Fitting 106 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1795.63s of the 2694.10s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.0338853\n",
      "[2000]\tvalid_set's rmse: 0.0330585\n",
      "[3000]\tvalid_set's rmse: 0.0329005\n",
      "[4000]\tvalid_set's rmse: 0.0328875\n",
      "[1000]\tvalid_set's rmse: 0.0152477\n",
      "[2000]\tvalid_set's rmse: 0.0143665\n",
      "[3000]\tvalid_set's rmse: 0.0142066\n",
      "[4000]\tvalid_set's rmse: 0.0141786\n",
      "[5000]\tvalid_set's rmse: 0.0141829\n",
      "[1000]\tvalid_set's rmse: 0.0162239\n",
      "[2000]\tvalid_set's rmse: 0.0145248\n",
      "[3000]\tvalid_set's rmse: 0.0141635\n",
      "[4000]\tvalid_set's rmse: 0.0140425\n",
      "[5000]\tvalid_set's rmse: 0.0140158\n",
      "[6000]\tvalid_set's rmse: 0.0140181\n",
      "[1000]\tvalid_set's rmse: 0.0935354\n",
      "[2000]\tvalid_set's rmse: 0.0932391\n",
      "[1000]\tvalid_set's rmse: 0.021482\n",
      "[2000]\tvalid_set's rmse: 0.0208032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.0437\t = Validation score   (-root_mean_squared_error)\n",
      "\t45.87s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1748.24s of the 2646.71s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.0139781\n",
      "[2000]\tvalid_set's rmse: 0.0138014\n",
      "[3000]\tvalid_set's rmse: 0.01378\n",
      "[4000]\tvalid_set's rmse: 0.0137689\n",
      "[5000]\tvalid_set's rmse: 0.0137669\n",
      "[1000]\tvalid_set's rmse: 0.0178396\n",
      "[1000]\tvalid_set's rmse: 0.0944671\n",
      "[2000]\tvalid_set's rmse: 0.0937592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.0435\t = Validation score   (-root_mean_squared_error)\n",
      "\t47.07s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 1700.33s of the 2598.80s of remaining time.\n",
      "\t-0.0472\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.92s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1691.15s of the 2589.63s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 9979.\n",
      "\t-0.0435\t = Validation score   (-root_mean_squared_error)\n",
      "\t936.45s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 754.38s of the 1652.86s of remaining time.\n",
      "\t-0.0471\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.02s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 751.03s of the 1649.50s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 5: early stopping\n",
      "No improvement since epoch 3: early stopping\n",
      "\t-0.0521\t = Validation score   (-root_mean_squared_error)\n",
      "\t14.12s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 736.68s of the 1635.15s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.0479\t = Validation score   (-root_mean_squared_error)\n",
      "\t28.69s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 707.77s of the 1606.25s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.0564\t = Validation score   (-root_mean_squared_error)\n",
      "\t32.32s\t = Training   runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 674.83s of the 1573.30s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.0944855\n",
      "[2000]\tvalid_set's rmse: 0.0944822\n",
      "[3000]\tvalid_set's rmse: 0.0944821\n",
      "[4000]\tvalid_set's rmse: 0.0944821\n",
      "[5000]\tvalid_set's rmse: 0.0944821\n",
      "[6000]\tvalid_set's rmse: 0.0944821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.0465\t = Validation score   (-root_mean_squared_error)\n",
      "\t128.19s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 544.68s of the 1443.16s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 4448.\n",
      "\tRan out of time, early stopping on iteration 4619.\n",
      "\tRan out of time, early stopping on iteration 5501.\n",
      "\tRan out of time, early stopping on iteration 5751.\n",
      "\t-0.0444\t = Validation score   (-root_mean_squared_error)\n",
      "\t487.06s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 57.36s of the 955.84s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 47)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 51)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 50)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 58)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 63)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 107)\n",
      "\t-0.051\t = Validation score   (-root_mean_squared_error)\n",
      "\t53.77s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 2.92s of the 901.40s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 1. Best iteration is:\n",
      "\t[1]\tvalid_set's rmse: 0.087332\n",
      "\tTime limit exceeded... Skipping LightGBM_r131_BAG_L1.\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 2.18s of the 900.65s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTime limit exceeded... Skipping NeuralNetFastAI_r191_BAG_L1.\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 1.68s of the 900.16s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 1.\n",
      "\tRan out of time, early stopping on iteration 1.\n",
      "\tRan out of time, early stopping on iteration 1.\n",
      "\tRan out of time, early stopping on iteration 1.\n",
      "\tRan out of time, early stopping on iteration 1.\n",
      "\tRan out of time, early stopping on iteration 2.\n",
      "\tRan out of time, early stopping on iteration 2.\n",
      "\tRan out of time, early stopping on iteration 5.\n",
      "\t-0.0932\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.36s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 0.19s of the 898.67s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Model has no time left to train, skipping model... (Time Left = -0.0s)\n",
      "\tTime limit exceeded... Skipping LightGBM_r96_BAG_L1.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 898.23s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.4, 'ExtraTreesMSE_BAG_L1': 0.2, 'LightGBMXT_BAG_L1': 0.133, 'LightGBM_BAG_L1': 0.133, 'NeuralNetTorch_r79_BAG_L1': 0.133}\n",
      "\t-0.0421\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 898.20s of the 898.16s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.0203856\n",
      "[1000]\tvalid_set's rmse: 0.0177555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.0395\t = Validation score   (-root_mean_squared_error)\n",
      "\t14.22s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 883.67s of the 883.64s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.0178182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.0395\t = Validation score   (-root_mean_squared_error)\n",
      "\t23.7s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 859.73s of the 859.69s of remaining time.\n",
      "\t-0.04\t = Validation score   (-root_mean_squared_error)\n",
      "\t10.73s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 848.73s of the 848.70s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 6448.\n",
      "\t-0.0395\t = Validation score   (-root_mean_squared_error)\n",
      "\t693.22s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 155.24s of the 155.21s of remaining time.\n",
      "\t-0.0401\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.51s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 151.40s of the 151.37s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 3: early stopping\n",
      "\t-0.0433\t = Validation score   (-root_mean_squared_error)\n",
      "\t15.12s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 136.02s of the 135.99s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.0418\t = Validation score   (-root_mean_squared_error)\n",
      "\t25.31s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 110.52s of the 110.48s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.0439\t = Validation score   (-root_mean_squared_error)\n",
      "\t36.66s\t = Training   runtime\n",
      "\t0.56s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 73.16s of the 73.13s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 572. Best iteration is:\n",
      "\t[572]\tvalid_set's rmse: 0.0183459\n",
      "\tRan out of time, early stopping on iteration 780. Best iteration is:\n",
      "\t[586]\tvalid_set's rmse: 0.090519\n",
      "\t-0.0434\t = Validation score   (-root_mean_squared_error)\n",
      "\t69.46s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 2.93s of remaining time.\n",
      "\tEnsemble Weights: {'RandomForestMSE_BAG_L2': 0.333, 'LightGBMXT_BAG_L2': 0.286, 'LightGBM_BAG_L2': 0.19, 'NeuralNetTorch_BAG_L2': 0.143, 'CatBoost_BAG_L2': 0.048}\n",
      "\t-0.0385\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2693.54s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 77.2 rows/s (202 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/kaggle/working/AutogluonModels/ag-20250914_171539\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250914_181610\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.11.11\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP PREEMPT_DYNAMIC Sun Nov 10 10:07:59 UTC 2024\n",
      "CPU Count:          4\n",
      "Memory Avail:       29.26 GB / 31.35 GB (93.3%)\n",
      "Disk Space Avail:   14.90 GB / 19.52 GB (76.3%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
      "/usr/local/lib/python3.11/dist-packages/autogluon/tabular/predictor/predictor.py:1382: UserWarning: Failed to use ray for memory safe fits. Falling back to normal fit. Error: ValueError('ray==2.46.0 detected. 2.10.0 <= ray < 2.45.0 is required. You can use pip to install certain version of ray `pip install \"ray>=2.10.0,<2.45.0\"`')\n",
      "  stacked_overfitting = self._sub_fit_memory_save_wrapper(\n",
      "\t\tContext path: \"/kaggle/working/AutogluonModels/ag-20250914_181610/ds_sub_fit/sub_fit_ho\"\n",
      "Running DyStack sub-fit ...\n",
      "Beginning AutoGluon training ... Time limit = 900s\n",
      "AutoGluon will save models to \"/kaggle/working/AutogluonModels/ag-20250914_181610/ds_sub_fit/sub_fit_ho\"\n",
      "Train Data Rows:    1243\n",
      "Train Data Columns: 206\n",
      "Label Column:       Density\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    29961.57 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.95 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tc] 欠損 9186 件を AutoGluon で補完\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 31 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 20): ['SMR_VSA8', 'SlogP_VSA9', 'fr_azide', 'fr_barbitur', 'fr_benzodiazepine', 'fr_diazo', 'fr_dihydropyridine', 'fr_guanido', 'fr_hdrzone', 'fr_isocyan', 'fr_isothiocyan', 'fr_lactam', 'fr_lactone', 'fr_oxime', 'fr_phos_acid', 'fr_phos_ester', 'fr_prisulfonamd', 'fr_term_acetylene', 'fr_tetrazole', 'fr_thiazole']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 7): ['MaxEStateIndex', 'NumUnspecifiedAtomStereoCenters', 'fr_Nhpyrrole', 'fr_amide', 'fr_benzene', 'fr_nitro_arom_nonortho', 'fr_phenol_noOrthoHbond']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 7 | ['MaxEStateIndex', 'NumUnspecifiedAtomStereoCenters', 'fr_Nhpyrrole', 'fr_amide', 'fr_benzene', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 179 | ['MaxAbsEStateIndex', 'MinAbsEStateIndex', 'MinEStateIndex', 'qed', 'SPS', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 149 | ['MaxAbsEStateIndex', 'MinAbsEStateIndex', 'MinEStateIndex', 'qed', 'SPS', ...]\n",
      "\t\t('int', ['bool']) :  30 | ['NumRadicalElectrons', 'EState_VSA11', 'NumSpiroAtoms', 'fr_Al_COO', 'fr_ArN', ...]\n",
      "\t2.1s = Fit runtime\n",
      "\t179 features in original data used to generate 179 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.45 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.09s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
      "Fitting 106 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 598.46s of the 897.90s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.0815\t = Validation score   (-root_mean_squared_error)\n",
      "\t11.07s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 587.22s of the 886.66s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.0866\t = Validation score   (-root_mean_squared_error)\n",
      "\t18.98s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 568.10s of the 867.54s of remaining time.\n",
      "\t-0.0879\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.8s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 560.06s of the 859.50s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.0822\t = Validation score   (-root_mean_squared_error)\n",
      "\t56.7s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 503.20s of the 802.65s of remaining time.\n",
      "\t-0.0858\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.8s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 500.09s of the 799.53s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.0909\t = Validation score   (-root_mean_squared_error)\n",
      "\t15.63s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 484.22s of the 783.66s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.0891\t = Validation score   (-root_mean_squared_error)\n",
      "\t31.86s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 452.18s of the 751.62s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.0794\t = Validation score   (-root_mean_squared_error)\n",
      "\t65.67s\t = Training   runtime\n",
      "\t0.58s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 385.82s of the 685.26s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.0943\t = Validation score   (-root_mean_squared_error)\n",
      "\t60.8s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 324.65s of the 624.10s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.082\t = Validation score   (-root_mean_squared_error)\n",
      "\t45.05s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 279.46s of the 578.90s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.0838\t = Validation score   (-root_mean_squared_error)\n",
      "\t90.66s\t = Training   runtime\n",
      "\t0.6s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 188.08s of the 487.52s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.0796843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.0867\t = Validation score   (-root_mean_squared_error)\n",
      "\t33.65s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 153.91s of the 453.35s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 9: early stopping\n",
      "\t-0.0851\t = Validation score   (-root_mean_squared_error)\n",
      "\t33.79s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 119.85s of the 419.29s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 163.\n",
      "\tRan out of time, early stopping on iteration 168.\n",
      "\tRan out of time, early stopping on iteration 178.\n",
      "\tRan out of time, early stopping on iteration 179.\n",
      "\tRan out of time, early stopping on iteration 189.\n",
      "\tRan out of time, early stopping on iteration 203.\n",
      "\tRan out of time, early stopping on iteration 241.\n",
      "\tRan out of time, early stopping on iteration 299.\n",
      "\t-0.0829\t = Validation score   (-root_mean_squared_error)\n",
      "\t114.74s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 4.93s of the 304.38s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 77. Best iteration is:\n",
      "\t[77]\tvalid_set's rmse: 0.149308\n",
      "\tRan out of time, early stopping on iteration 181. Best iteration is:\n",
      "\t[181]\tvalid_set's rmse: 0.108041\n",
      "\tRan out of time, early stopping on iteration 204. Best iteration is:\n",
      "\t[204]\tvalid_set's rmse: 0.110875\n",
      "\tRan out of time, early stopping on iteration 207. Best iteration is:\n",
      "\t[207]\tvalid_set's rmse: 0.0984513\n",
      "\tRan out of time, early stopping on iteration 186. Best iteration is:\n",
      "\t[186]\tvalid_set's rmse: 0.108741\n",
      "\tRan out of time, early stopping on iteration 255. Best iteration is:\n",
      "\t[254]\tvalid_set's rmse: 0.0759196\n",
      "\tRan out of time, early stopping on iteration 332. Best iteration is:\n",
      "\t[332]\tvalid_set's rmse: 0.0997246\n",
      "\tRan out of time, early stopping on iteration 445. Best iteration is:\n",
      "\t[445]\tvalid_set's rmse: 0.100104\n",
      "\t-0.1082\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.66s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 0.14s of the 299.58s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Model has no time left to train, skipping model... (Time Left = -0.0s)\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_r22_BAG_L1.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 299.14s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetTorch_BAG_L1': 0.368, 'NeuralNetFastAI_r191_BAG_L1': 0.211, 'CatBoost_r177_BAG_L1': 0.158, 'NeuralNetTorch_r79_BAG_L1': 0.158, 'LightGBMXT_BAG_L1': 0.105}\n",
      "\t-0.0752\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 299.10s of the 299.07s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.0763967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.0798\t = Validation score   (-root_mean_squared_error)\n",
      "\t12.28s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 286.58s of the 286.54s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.0758289\n",
      "[2000]\tvalid_set's rmse: 0.0756074\n",
      "[1000]\tvalid_set's rmse: 0.0636816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.0793\t = Validation score   (-root_mean_squared_error)\n",
      "\t34.79s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 251.34s of the 251.30s of remaining time.\n",
      "\t-0.0788\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.48s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 241.51s of the 241.47s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.0792\t = Validation score   (-root_mean_squared_error)\n",
      "\t43.48s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 197.88s of the 197.84s of remaining time.\n",
      "\t-0.0766\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.11s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 194.50s of the 194.46s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.084\t = Validation score   (-root_mean_squared_error)\n",
      "\t16.01s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 178.24s of the 178.20s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.0788\t = Validation score   (-root_mean_squared_error)\n",
      "\t39.03s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 138.99s of the 138.95s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.0809\t = Validation score   (-root_mean_squared_error)\n",
      "\t30.76s\t = Training   runtime\n",
      "\t0.6s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 107.53s of the 107.49s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 742. Best iteration is:\n",
      "\t[742]\tvalid_set's rmse: 0.0796257\n",
      "\t-0.0821\t = Validation score   (-root_mean_squared_error)\n",
      "\t70.37s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 36.57s of the 36.53s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 307.\n",
      "\tRan out of time, early stopping on iteration 310.\n",
      "\tRan out of time, early stopping on iteration 321.\n",
      "\tRan out of time, early stopping on iteration 335.\n",
      "\tRan out of time, early stopping on iteration 349.\n",
      "\tRan out of time, early stopping on iteration 369.\n",
      "\t-0.0793\t = Validation score   (-root_mean_squared_error)\n",
      "\t33.1s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 3.18s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetTorch_BAG_L1': 0.32, 'ExtraTreesMSE_BAG_L2': 0.32, 'NeuralNetFastAI_r191_BAG_L1': 0.16, 'XGBoost_BAG_L2': 0.12, 'LightGBM_BAG_L2': 0.08}\n",
      "\t-0.0747\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 896.87s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 87.6 rows/s (156 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/kaggle/working/AutogluonModels/ag-20250914_181610/ds_sub_fit/sub_fit_ho\")\n",
      "Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                          model  score_holdout  score_val              eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0               LightGBM_BAG_L2      -0.078937  -0.079277  root_mean_squared_error        2.318089       2.004979  414.797545                 0.145839                0.074825          34.791236            2       True         18\n",
      "1          LightGBMLarge_BAG_L2      -0.079691  -0.082138  root_mean_squared_error        2.340900       1.985943  450.372674                 0.168650                0.055789          70.366364            2       True         25\n",
      "2                XGBoost_BAG_L2      -0.080235  -0.078848  root_mean_squared_error        2.340256       1.982781  419.040550                 0.168006                0.052626          39.034240            2       True         23\n",
      "3          ExtraTreesMSE_BAG_L2      -0.081042  -0.076626  root_mean_squared_error        2.291354       2.117045  383.115503                 0.119104                0.186891           3.109194            2       True         21\n",
      "4        RandomForestMSE_BAG_L2      -0.081724  -0.078846  root_mean_squared_error        2.294786       2.136870  389.485282                 0.122536                0.206716           9.478973            2       True         19\n",
      "5               CatBoost_BAG_L2      -0.081854  -0.079208  root_mean_squared_error        2.261577       2.010185  423.483952                 0.089327                0.080030          43.477643            2       True         20\n",
      "6          CatBoost_r177_BAG_L2      -0.082000  -0.079255  root_mean_squared_error        2.260394       2.009014  413.108237                 0.088145                0.078859          33.101928            2       True         26\n",
      "7             LightGBMXT_BAG_L2      -0.082245  -0.079810  root_mean_squared_error        2.247372       1.970712  392.290148                 0.075122                0.040557          12.283839            2       True         17\n",
      "8           WeightedEnsemble_L3      -0.082876  -0.074692  root_mean_squared_error        2.608379       2.245014  456.961999                 0.003180                0.000518           0.021020            3       True         27\n",
      "9         NeuralNetTorch_BAG_L2      -0.084736  -0.080895  root_mean_squared_error        2.768730       2.532130  410.762985                 0.596480                0.601976          30.756675            2       True         24\n",
      "10               XGBoost_BAG_L1      -0.086856  -0.089081  root_mean_squared_error        0.139457       0.038331   31.859560                 0.139457                0.038331          31.859560            1       True          7\n",
      "11       NeuralNetFastAI_BAG_L2      -0.087066  -0.084001  root_mean_squared_error        2.292860       2.018501  396.013764                 0.120610                0.088346          16.007455            2       True         22\n",
      "12          WeightedEnsemble_L2      -0.087646  -0.075211  root_mean_squared_error        1.523227       1.372616  246.258031                 0.003628                0.000475           0.018590            2       True         16\n",
      "13              LightGBM_BAG_L1      -0.087979  -0.086647  root_mean_squared_error        0.057653       0.027665   18.975135                 0.057653                0.027665          18.975135            1       True          2\n",
      "14        NeuralNetTorch_BAG_L1      -0.089042  -0.079376  root_mean_squared_error        0.603496       0.584110   65.671591                 0.603496                0.584110          65.671591            1       True          8\n",
      "15              CatBoost_BAG_L1      -0.089170  -0.082244  root_mean_squared_error        0.089494       0.068327   56.696721                 0.089494                0.068327          56.696721            1       True          4\n",
      "16           CatBoost_r9_BAG_L1      -0.089266  -0.082880  root_mean_squared_error        0.110421       0.079673  114.736930                 0.110421                0.079673         114.736930            1       True         14\n",
      "17         LightGBM_r131_BAG_L1      -0.089992  -0.086711  root_mean_squared_error        0.164739       0.054965   33.648003                 0.164739                0.054965          33.648003            1       True         12\n",
      "18         CatBoost_r177_BAG_L1      -0.090928  -0.081954  root_mean_squared_error        0.090986       0.068255   45.045666                 0.090986                0.068255          45.045666            1       True         10\n",
      "19       RandomForestMSE_BAG_L1      -0.092037  -0.087885  root_mean_squared_error        0.122992       0.169619    7.798214                 0.122992                0.169619           7.798214            1       True          3\n",
      "20            LightGBMXT_BAG_L1      -0.092049  -0.081471  root_mean_squared_error        0.072734       0.029271   11.074847                 0.072734                0.029271          11.074847            1       True          1\n",
      "21         LightGBMLarge_BAG_L1      -0.092346  -0.094298  root_mean_squared_error        0.137499       0.026414   60.800977                 0.137499                0.026414          60.800977            1       True          9\n",
      "22       NeuralNetFastAI_BAG_L1      -0.093102  -0.090877  root_mean_squared_error        0.124604       0.080720   15.634759                 0.124604                0.080720          15.634759            1       True          6\n",
      "23         ExtraTreesMSE_BAG_L1      -0.093912  -0.085824  root_mean_squared_error        0.118450       0.173352    2.802479                 0.118450                0.173352           2.802479            1       True          5\n",
      "24  NeuralNetFastAI_r191_BAG_L1      -0.094134  -0.085057  root_mean_squared_error        0.131762       0.094314   33.791504                 0.131762                0.094314          33.791504            1       True         13\n",
      "25    NeuralNetTorch_r79_BAG_L1      -0.101291  -0.083776  root_mean_squared_error        0.620621       0.596190   90.655833                 0.620621                0.596190          90.655833            1       True         11\n",
      "26          LightGBM_r96_BAG_L1      -0.105636  -0.108154  root_mean_squared_error        0.054413       0.025460    4.658560                 0.054413                0.025460           4.658560            1       True         15\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t901s\t = DyStack   runtime |\t2699s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 2699s\n",
      "AutoGluon will save models to \"/kaggle/working/AutogluonModels/ag-20250914_181610\"\n",
      "Train Data Rows:    1399\n",
      "Train Data Columns: 206\n",
      "Label Column:       Density\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    29970.75 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.20 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 31 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 18): ['SMR_VSA8', 'SlogP_VSA9', 'fr_azide', 'fr_barbitur', 'fr_benzodiazepine', 'fr_diazo', 'fr_dihydropyridine', 'fr_guanido', 'fr_hdrzone', 'fr_isocyan', 'fr_isothiocyan', 'fr_lactam', 'fr_oxime', 'fr_phos_acid', 'fr_phos_ester', 'fr_prisulfonamd', 'fr_term_acetylene', 'fr_tetrazole']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 7): ['MaxEStateIndex', 'NumUnspecifiedAtomStereoCenters', 'fr_Nhpyrrole', 'fr_amide', 'fr_benzene', 'fr_nitro_arom_nonortho', 'fr_phenol_noOrthoHbond']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 7 | ['MaxEStateIndex', 'NumUnspecifiedAtomStereoCenters', 'fr_Nhpyrrole', 'fr_amide', 'fr_benzene', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 181 | ['MaxAbsEStateIndex', 'MinAbsEStateIndex', 'MinEStateIndex', 'qed', 'SPS', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 151 | ['MaxAbsEStateIndex', 'MinAbsEStateIndex', 'MinEStateIndex', 'qed', 'SPS', ...]\n",
      "\t\t('int', ['bool']) :  30 | ['NumRadicalElectrons', 'EState_VSA11', 'NumSpiroAtoms', 'fr_Al_COO', 'fr_ArN', ...]\n",
      "\t2.0s = Fit runtime\n",
      "\t181 features in original data used to generate 181 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.65 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.08s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
      "Fitting 106 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1797.25s of the 2696.54s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.0831\t = Validation score   (-root_mean_squared_error)\n",
      "\t13.27s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1783.77s of the 2683.06s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.0864\t = Validation score   (-root_mean_squared_error)\n",
      "\t19.25s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 1764.35s of the 2663.64s of remaining time.\n",
      "\t-0.0882\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.86s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1755.13s of the 2654.42s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.0809\t = Validation score   (-root_mean_squared_error)\n",
      "\t69.82s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 1685.13s of the 2584.42s of remaining time.\n",
      "\t-0.0863\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.14s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1681.65s of the 2580.94s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 8: early stopping\n",
      "No improvement since epoch 0: early stopping\n",
      "\t-0.1165\t = Validation score   (-root_mean_squared_error)\n",
      "\t12.15s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 1669.25s of the 2568.54s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.0862\t = Validation score   (-root_mean_squared_error)\n",
      "\t32.52s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 1636.55s of the 2535.84s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.0819\t = Validation score   (-root_mean_squared_error)\n",
      "\t62.45s\t = Training   runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 1573.41s of the 2472.70s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.0906\t = Validation score   (-root_mean_squared_error)\n",
      "\t57.02s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 1516.08s of the 2415.37s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.0811\t = Validation score   (-root_mean_squared_error)\n",
      "\t53.25s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 1462.66s of the 2361.95s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.0869\t = Validation score   (-root_mean_squared_error)\n",
      "\t62.87s\t = Training   runtime\n",
      "\t0.58s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 1399.10s of the 2298.39s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.0856\t = Validation score   (-root_mean_squared_error)\n",
      "\t30.68s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 1367.97s of the 2267.26s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 0: early stopping\n",
      "\t-0.1127\t = Validation score   (-root_mean_squared_error)\n",
      "\t28.44s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 1339.26s of the 2238.55s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.0813\t = Validation score   (-root_mean_squared_error)\n",
      "\t317.95s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 1021.10s of the 1920.39s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.0816893\n",
      "[2000]\tvalid_set's rmse: 0.0787532\n",
      "[1000]\tvalid_set's rmse: 0.116501\n",
      "[2000]\tvalid_set's rmse: 0.113549\n",
      "[3000]\tvalid_set's rmse: 0.11257\n",
      "[4000]\tvalid_set's rmse: 0.112142\n",
      "[5000]\tvalid_set's rmse: 0.112066\n",
      "[6000]\tvalid_set's rmse: 0.112144\n",
      "[1000]\tvalid_set's rmse: 0.0854924\n",
      "[1000]\tvalid_set's rmse: 0.0764844\n",
      "[2000]\tvalid_set's rmse: 0.0736356\n",
      "[3000]\tvalid_set's rmse: 0.0731501\n",
      "[1000]\tvalid_set's rmse: 0.0799174\n",
      "[2000]\tvalid_set's rmse: 0.0767792\n",
      "[3000]\tvalid_set's rmse: 0.0765111\n",
      "[1000]\tvalid_set's rmse: 0.0756937\n",
      "[2000]\tvalid_set's rmse: 0.0725444\n",
      "[3000]\tvalid_set's rmse: 0.0721535\n",
      "[1000]\tvalid_set's rmse: 0.094591\n",
      "[2000]\tvalid_set's rmse: 0.0937812\n",
      "[1000]\tvalid_set's rmse: 0.0747314\n",
      "[2000]\tvalid_set's rmse: 0.0735373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.0841\t = Validation score   (-root_mean_squared_error)\n",
      "\t26.97s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 993.07s of the 1892.36s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.0814\t = Validation score   (-root_mean_squared_error)\n",
      "\t71.89s\t = Training   runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 920.48s of the 1819.77s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.0907\t = Validation score   (-root_mean_squared_error)\n",
      "\t143.48s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L1 ... Training model for up to 776.62s of the 1675.91s of remaining time.\n",
      "\t-0.0851\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.45s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 773.81s of the 1673.10s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.0831\t = Validation score   (-root_mean_squared_error)\n",
      "\t51.5s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L1 ... Training model for up to 722.16s of the 1621.45s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 2: early stopping\n",
      "\t-0.1029\t = Validation score   (-root_mean_squared_error)\n",
      "\t75.49s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: CatBoost_r13_BAG_L1 ... Training model for up to 646.27s of the 1545.56s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 2129.\n",
      "\t-0.0823\t = Validation score   (-root_mean_squared_error)\n",
      "\t321.89s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: RandomForest_r195_BAG_L1 ... Training model for up to 324.14s of the 1223.43s of remaining time.\n",
      "\t-0.0878\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.05s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: LightGBM_r188_BAG_L1 ... Training model for up to 316.83s of the 1216.11s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.0842\t = Validation score   (-root_mean_squared_error)\n",
      "\t22.04s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r145_BAG_L1 ... Training model for up to 294.37s of the 1193.66s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.0938\t = Validation score   (-root_mean_squared_error)\n",
      "\t29.57s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: XGBoost_r89_BAG_L1 ... Training model for up to 264.51s of the 1163.80s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.0823\t = Validation score   (-root_mean_squared_error)\n",
      "\t17.18s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r30_BAG_L1 ... Training model for up to 247.14s of the 1146.43s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.089\t = Validation score   (-root_mean_squared_error)\n",
      "\t90.4s\t = Training   runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Fitting model: LightGBM_r130_BAG_L1 ... Training model for up to 156.02s of the 1055.30s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.0872\t = Validation score   (-root_mean_squared_error)\n",
      "\t12.31s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r86_BAG_L1 ... Training model for up to 143.51s of the 1042.80s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 133)\n",
      "\t-0.0791\t = Validation score   (-root_mean_squared_error)\n",
      "\t110.98s\t = Training   runtime\n",
      "\t0.6s\t = Validation runtime\n",
      "Fitting model: CatBoost_r50_BAG_L1 ... Training model for up to 31.82s of the 931.11s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 343.\n",
      "\tRan out of time, early stopping on iteration 352.\n",
      "\tRan out of time, early stopping on iteration 372.\n",
      "\tRan out of time, early stopping on iteration 393.\n",
      "\tRan out of time, early stopping on iteration 417.\n",
      "\tRan out of time, early stopping on iteration 433.\n",
      "\tRan out of time, early stopping on iteration 581.\n",
      "\t-0.0822\t = Validation score   (-root_mean_squared_error)\n",
      "\t30.37s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r11_BAG_L1 ... Training model for up to 1.29s of the 900.58s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTime limit exceeded... Skipping NeuralNetFastAI_r11_BAG_L1.\n",
      "Fitting model: XGBoost_r194_BAG_L1 ... Training model for up to 0.78s of the 900.07s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTime limit exceeded... Skipping XGBoost_r194_BAG_L1.\n",
      "Fitting model: ExtraTrees_r172_BAG_L1 ... Training model for up to 0.31s of the 899.59s of remaining time.\n",
      "\t-0.0855\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.37s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 897.94s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetTorch_r86_BAG_L1': 0.391, 'CatBoost_r177_BAG_L1': 0.174, 'NeuralNetTorch_r22_BAG_L1': 0.174, 'CatBoost_BAG_L1': 0.087, 'NeuralNetFastAI_r145_BAG_L1': 0.087, 'XGBoost_r89_BAG_L1': 0.087}\n",
      "\t-0.0756\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 897.91s of the 897.85s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.079869\n",
      "[2000]\tvalid_set's rmse: 0.0789388\n",
      "[3000]\tvalid_set's rmse: 0.0787622\n",
      "[4000]\tvalid_set's rmse: 0.0787195\n",
      "[5000]\tvalid_set's rmse: 0.078692\n",
      "[6000]\tvalid_set's rmse: 0.0786791\n",
      "[7000]\tvalid_set's rmse: 0.0786785\n",
      "[8000]\tvalid_set's rmse: 0.0786761\n",
      "[9000]\tvalid_set's rmse: 0.0786753\n",
      "[10000]\tvalid_set's rmse: 0.0786749\n",
      "[1000]\tvalid_set's rmse: 0.0698949\n",
      "[2000]\tvalid_set's rmse: 0.0681845\n",
      "[3000]\tvalid_set's rmse: 0.0677697\n",
      "[4000]\tvalid_set's rmse: 0.067623\n",
      "[5000]\tvalid_set's rmse: 0.0675638\n",
      "[6000]\tvalid_set's rmse: 0.0675321\n",
      "[7000]\tvalid_set's rmse: 0.067517\n",
      "[8000]\tvalid_set's rmse: 0.0675086\n",
      "[9000]\tvalid_set's rmse: 0.0675035\n",
      "[10000]\tvalid_set's rmse: 0.0675002\n",
      "[1000]\tvalid_set's rmse: 0.0954097\n",
      "[2000]\tvalid_set's rmse: 0.0946784\n",
      "[3000]\tvalid_set's rmse: 0.0944243\n",
      "[4000]\tvalid_set's rmse: 0.0943458\n",
      "[5000]\tvalid_set's rmse: 0.0943226\n",
      "[6000]\tvalid_set's rmse: 0.094305\n",
      "[7000]\tvalid_set's rmse: 0.0942965\n",
      "[8000]\tvalid_set's rmse: 0.0942932\n",
      "[9000]\tvalid_set's rmse: 0.0942856\n",
      "[10000]\tvalid_set's rmse: 0.0942869\n",
      "[1000]\tvalid_set's rmse: 0.0647787\n",
      "[2000]\tvalid_set's rmse: 0.0642009\n",
      "[3000]\tvalid_set's rmse: 0.0641033\n",
      "[4000]\tvalid_set's rmse: 0.064062\n",
      "[5000]\tvalid_set's rmse: 0.0640569\n",
      "[1000]\tvalid_set's rmse: 0.0719951\n",
      "[2000]\tvalid_set's rmse: 0.0713947\n",
      "[3000]\tvalid_set's rmse: 0.0713365\n",
      "[4000]\tvalid_set's rmse: 0.0712994\n",
      "[5000]\tvalid_set's rmse: 0.0712782\n",
      "[6000]\tvalid_set's rmse: 0.0712658\n",
      "[7000]\tvalid_set's rmse: 0.0712558\n",
      "[8000]\tvalid_set's rmse: 0.0712516\n",
      "[9000]\tvalid_set's rmse: 0.0712503\n",
      "[10000]\tvalid_set's rmse: 0.0712492\n",
      "[1000]\tvalid_set's rmse: 0.08217\n",
      "[2000]\tvalid_set's rmse: 0.0788618\n",
      "[3000]\tvalid_set's rmse: 0.0779066\n",
      "[4000]\tvalid_set's rmse: 0.0776369\n",
      "[5000]\tvalid_set's rmse: 0.0775404\n",
      "[6000]\tvalid_set's rmse: 0.0775031\n",
      "[7000]\tvalid_set's rmse: 0.0774784\n",
      "[8000]\tvalid_set's rmse: 0.0774693\n",
      "[9000]\tvalid_set's rmse: 0.0774602\n",
      "[10000]\tvalid_set's rmse: 0.0774527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.074\t = Validation score   (-root_mean_squared_error)\n",
      "\t124.12s\t = Training   runtime\n",
      "\t1.16s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 768.78s of the 768.72s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.0812761\n",
      "[2000]\tvalid_set's rmse: 0.0811749\n",
      "[1000]\tvalid_set's rmse: 0.0680368\n",
      "[1000]\tvalid_set's rmse: 0.0845143\n",
      "[2000]\tvalid_set's rmse: 0.0842764\n",
      "[3000]\tvalid_set's rmse: 0.0842361\n",
      "[4000]\tvalid_set's rmse: 0.0841987\n",
      "[5000]\tvalid_set's rmse: 0.0841922\n",
      "[6000]\tvalid_set's rmse: 0.0841894\n",
      "[7000]\tvalid_set's rmse: 0.0841876\n",
      "[8000]\tvalid_set's rmse: 0.0841869\n",
      "[9000]\tvalid_set's rmse: 0.0841865\n",
      "[10000]\tvalid_set's rmse: 0.0841863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.0768\t = Validation score   (-root_mean_squared_error)\n",
      "\t82.6s\t = Training   runtime\n",
      "\t0.35s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 684.73s of the 684.67s of remaining time.\n",
      "\t-0.0771\t = Validation score   (-root_mean_squared_error)\n",
      "\t11.15s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 673.26s of the 673.20s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 4208.\n",
      "\tRan out of time, early stopping on iteration 4312.\n",
      "\tRan out of time, early stopping on iteration 9425.\n",
      "\t-0.0763\t = Validation score   (-root_mean_squared_error)\n",
      "\t373.11s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 299.90s of the 299.84s of remaining time.\n",
      "\t-0.0752\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.57s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 296.08s of the 296.02s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 5: early stopping\n",
      "\t-0.0918\t = Validation score   (-root_mean_squared_error)\n",
      "\t12.46s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 283.37s of the 283.31s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.0781\t = Validation score   (-root_mean_squared_error)\n",
      "\t43.58s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 239.56s of the 239.50s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.0806\t = Validation score   (-root_mean_squared_error)\n",
      "\t73.7s\t = Training   runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 165.16s of the 165.10s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.0944012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.0808\t = Validation score   (-root_mean_squared_error)\n",
      "\t88.29s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 75.97s of the 75.91s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 595.\n",
      "\tRan out of time, early stopping on iteration 619.\n",
      "\tRan out of time, early stopping on iteration 634.\n",
      "\t-0.0775\t = Validation score   (-root_mean_squared_error)\n",
      "\t54.35s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L2 ... Training model for up to 21.45s of the 21.39s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 16)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 17)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 18)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 18)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 21)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 25)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 31)\n",
      "\t-0.0861\t = Validation score   (-root_mean_squared_error)\n",
      "\t19.96s\t = Training   runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 0.58s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L2': 0.583, 'NeuralNetTorch_r86_BAG_L1': 0.25, 'ExtraTreesMSE_BAG_L2': 0.125, 'XGBoost_r89_BAG_L1': 0.042}\n",
      "\t-0.0722\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2698.11s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 54.3 rows/s (175 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/kaggle/working/AutogluonModels/ag-20250914_181610\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250914_191743\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.11.11\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP PREEMPT_DYNAMIC Sun Nov 10 10:07:59 UTC 2024\n",
      "CPU Count:          4\n",
      "Memory Avail:       29.17 GB / 31.35 GB (93.0%)\n",
      "Disk Space Avail:   14.14 GB / 19.52 GB (72.5%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
      "/usr/local/lib/python3.11/dist-packages/autogluon/tabular/predictor/predictor.py:1382: UserWarning: Failed to use ray for memory safe fits. Falling back to normal fit. Error: ValueError('ray==2.46.0 detected. 2.10.0 <= ray < 2.45.0 is required. You can use pip to install certain version of ray `pip install \"ray>=2.10.0,<2.45.0\"`')\n",
      "  stacked_overfitting = self._sub_fit_memory_save_wrapper(\n",
      "\t\tContext path: \"/kaggle/working/AutogluonModels/ag-20250914_191743/ds_sub_fit/sub_fit_ho\"\n",
      "Running DyStack sub-fit ...\n",
      "Beginning AutoGluon training ... Time limit = 900s\n",
      "AutoGluon will save models to \"/kaggle/working/AutogluonModels/ag-20250914_191743/ds_sub_fit/sub_fit_ho\"\n",
      "Train Data Rows:    545\n",
      "Train Data Columns: 206\n",
      "Label Column:       Rg\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    29871.81 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.86 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Density] 欠損 9398 件を AutoGluon で補完\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 31 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 32): ['NumRadicalElectrons', 'PEOE_VSA5', 'SMR_VSA8', 'SlogP_VSA9', 'fr_ArN', 'fr_C_S', 'fr_HOCCN', 'fr_N_O', 'fr_SH', 'fr_azide', 'fr_barbitur', 'fr_benzodiazepine', 'fr_diazo', 'fr_dihydropyridine', 'fr_epoxide', 'fr_guanido', 'fr_hdrzine', 'fr_hdrzone', 'fr_isocyan', 'fr_isothiocyan', 'fr_lactam', 'fr_nitroso', 'fr_oxazole', 'fr_oxime', 'fr_phos_acid', 'fr_phos_ester', 'fr_piperdine', 'fr_piperzine', 'fr_prisulfonamd', 'fr_term_acetylene', 'fr_tetrazole', 'fr_thiocyan']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 10): ['MaxEStateIndex', 'NumUnspecifiedAtomStereoCenters', 'fr_COO2', 'fr_Nhpyrrole', 'fr_amide', 'fr_benzene', 'fr_nitro_arom_nonortho', 'fr_phenol', 'fr_phenol_noOrthoHbond', 'fr_priamide']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 10 | ['MaxEStateIndex', 'NumUnspecifiedAtomStereoCenters', 'fr_COO2', 'fr_Nhpyrrole', 'fr_amide', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 164 | ['MaxAbsEStateIndex', 'MinAbsEStateIndex', 'MinEStateIndex', 'qed', 'SPS', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 136 | ['MaxAbsEStateIndex', 'MinAbsEStateIndex', 'MinEStateIndex', 'qed', 'SPS', ...]\n",
      "\t\t('int', ['bool']) :  28 | ['PEOE_VSA11', 'EState_VSA11', 'NumSaturatedHeterocycles', 'NumSpiroAtoms', 'fr_Al_COO', ...]\n",
      "\t1.1s = Fit runtime\n",
      "\t164 features in original data used to generate 164 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.58 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.16s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
      "Fitting 106 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 599.07s of the 898.82s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 2.30661\n",
      "[2000]\tvalid_set's rmse: 2.27046\n",
      "[3000]\tvalid_set's rmse: 2.26272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-2.6391\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.88s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 590.97s of the 890.72s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.7153\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.75s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 583.13s of the 882.88s of remaining time.\n",
      "\t-2.6971\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.62s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 579.34s of the 879.09s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.6225\t = Validation score   (-root_mean_squared_error)\n",
      "\t41.28s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 537.91s of the 837.66s of remaining time.\n",
      "\t-2.6111\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.43s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 536.27s of the 836.02s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 4: early stopping\n",
      "\t-3.2235\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.95s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 529.11s of the 828.86s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.8571\t = Validation score   (-root_mean_squared_error)\n",
      "\t22.66s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 506.29s of the 806.04s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.5748\t = Validation score   (-root_mean_squared_error)\n",
      "\t26.71s\t = Training   runtime\n",
      "\t0.5s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 478.99s of the 778.74s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.9455\t = Validation score   (-root_mean_squared_error)\n",
      "\t32.4s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 446.33s of the 746.08s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.6386\t = Validation score   (-root_mean_squared_error)\n",
      "\t35.57s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 410.62s of the 710.37s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.6783\t = Validation score   (-root_mean_squared_error)\n",
      "\t82.48s\t = Training   runtime\n",
      "\t0.49s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 327.53s of the 627.28s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 2.5315\n",
      "[2000]\tvalid_set's rmse: 2.50467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-2.7515\t = Validation score   (-root_mean_squared_error)\n",
      "\t14.84s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 312.39s of the 612.14s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 13: early stopping\n",
      "No improvement since epoch 14: early stopping\n",
      "No improvement since epoch 16: early stopping\n",
      "No improvement since epoch 18: early stopping\n",
      "No improvement since epoch 5: early stopping\n",
      "\t-3.1722\t = Validation score   (-root_mean_squared_error)\n",
      "\t11.58s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 300.56s of the 600.31s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.6369\t = Validation score   (-root_mean_squared_error)\n",
      "\t261.16s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 39.24s of the 338.99s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 2.93782\n",
      "[1000]\tvalid_set's rmse: 2.11713\n",
      "[2000]\tvalid_set's rmse: 2.08791\n",
      "[1000]\tvalid_set's rmse: 2.48893\n",
      "[2000]\tvalid_set's rmse: 2.47312\n",
      "[1000]\tvalid_set's rmse: 3.48057\n",
      "[2000]\tvalid_set's rmse: 3.44321\n",
      "[3000]\tvalid_set's rmse: 3.41861\n",
      "[1000]\tvalid_set's rmse: 2.47621\n",
      "[1000]\tvalid_set's rmse: 2.78656\n",
      "[2000]\tvalid_set's rmse: 2.72118\n",
      "[3000]\tvalid_set's rmse: 2.65461\n",
      "[4000]\tvalid_set's rmse: 2.6145\n",
      "[5000]\tvalid_set's rmse: 2.57626\n",
      "[6000]\tvalid_set's rmse: 2.55203\n",
      "[7000]\tvalid_set's rmse: 2.52934\n",
      "[8000]\tvalid_set's rmse: 2.51494\n",
      "[9000]\tvalid_set's rmse: 2.49831\n",
      "[10000]\tvalid_set's rmse: 2.48918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-2.6888\t = Validation score   (-root_mean_squared_error)\n",
      "\t11.4s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 27.32s of the 327.07s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 42)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 52)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 54)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 56)\n",
      "\t-2.6161\t = Validation score   (-root_mean_squared_error)\n",
      "\t23.86s\t = Training   runtime\n",
      "\t0.5s\t = Validation runtime\n",
      "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 2.86s of the 302.61s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-3.9499\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.69s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L1 ... Training model for up to 0.08s of the 299.83s of remaining time.\n",
      "\t-2.6114\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.14s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 298.43s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetTorch_BAG_L1': 0.526, 'ExtraTreesMSE_BAG_L1': 0.368, 'CatBoost_BAG_L1': 0.105}\n",
      "\t-2.4958\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 298.41s of the 298.36s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 2.81233\n",
      "[2000]\tvalid_set's rmse: 2.77889\n",
      "[3000]\tvalid_set's rmse: 2.76778\n",
      "[4000]\tvalid_set's rmse: 2.76609\n",
      "[5000]\tvalid_set's rmse: 2.76511\n",
      "[6000]\tvalid_set's rmse: 2.76495\n",
      "[7000]\tvalid_set's rmse: 2.76493\n",
      "[1000]\tvalid_set's rmse: 3.00761\n",
      "[2000]\tvalid_set's rmse: 2.97776\n",
      "[3000]\tvalid_set's rmse: 2.97246\n",
      "[4000]\tvalid_set's rmse: 2.9708\n",
      "[5000]\tvalid_set's rmse: 2.97022\n",
      "[6000]\tvalid_set's rmse: 2.96993\n",
      "[7000]\tvalid_set's rmse: 2.96987\n",
      "[8000]\tvalid_set's rmse: 2.96983\n",
      "[9000]\tvalid_set's rmse: 2.96981\n",
      "[10000]\tvalid_set's rmse: 2.96981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-2.5713\t = Validation score   (-root_mean_squared_error)\n",
      "\t18.65s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 278.91s of the 278.86s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.5178\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.15s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 270.65s of the 270.61s of remaining time.\n",
      "\t-2.6078\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.14s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 266.30s of the 266.25s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.5423\t = Validation score   (-root_mean_squared_error)\n",
      "\t37.2s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 228.95s of the 228.91s of remaining time.\n",
      "\t-2.5711\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.54s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 227.19s of the 227.14s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 1: early stopping\n",
      "\t-3.226\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.85s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 220.10s of the 220.06s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.5939\t = Validation score   (-root_mean_squared_error)\n",
      "\t26.36s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 193.57s of the 193.52s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.5939\t = Validation score   (-root_mean_squared_error)\n",
      "\t25.9s\t = Training   runtime\n",
      "\t0.5s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 167.07s of the 167.03s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 2.71384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-2.6834\t = Validation score   (-root_mean_squared_error)\n",
      "\t45.54s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 120.91s of the 120.86s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.5173\t = Validation score   (-root_mean_squared_error)\n",
      "\t32.1s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L2 ... Training model for up to 88.67s of the 88.63s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.6978\t = Validation score   (-root_mean_squared_error)\n",
      "\t36.57s\t = Training   runtime\n",
      "\t0.5s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L2 ... Training model for up to 51.50s of the 51.45s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 1.93532\n",
      "[1000]\tvalid_set's rmse: 2.96032\n",
      "[2000]\tvalid_set's rmse: 2.94826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-2.5492\t = Validation score   (-root_mean_squared_error)\n",
      "\t13.8s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L2 ... Training model for up to 37.39s of the 37.35s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 22: early stopping\n",
      "No improvement since epoch 14: early stopping\n",
      "No improvement since epoch 22: early stopping\n",
      "No improvement since epoch 13: early stopping\n",
      "\t-3.2106\t = Validation score   (-root_mean_squared_error)\n",
      "\t11.25s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L2 ... Training model for up to 25.87s of the 25.82s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 36.\n",
      "\tRan out of time, early stopping on iteration 39.\n",
      "\tRan out of time, early stopping on iteration 42.\n",
      "\tRan out of time, early stopping on iteration 44.\n",
      "\tRan out of time, early stopping on iteration 49.\n",
      "\tRan out of time, early stopping on iteration 50.\n",
      "\tRan out of time, early stopping on iteration 57.\n",
      "\tRan out of time, early stopping on iteration 67.\n",
      "\t-2.8479\t = Validation score   (-root_mean_squared_error)\n",
      "\t24.56s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 1.02s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM_BAG_L2': 0.4, 'NeuralNetTorch_BAG_L1': 0.32, 'CatBoost_r177_BAG_L2': 0.24, 'XGBoost_BAG_L2': 0.04}\n",
      "\t-2.4565\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 899.01s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 79.3 rows/s (69 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/kaggle/working/AutogluonModels/ag-20250914_191743/ds_sub_fit/sub_fit_ho\")\n",
      "Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                          model  score_holdout  score_val              eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0                XGBoost_BAG_L1      -2.692126  -2.857094  root_mean_squared_error        0.131035       0.033216   22.655836                 0.131035                0.033216          22.655836            1       True          7\n",
      "1             LightGBMXT_BAG_L2      -2.704143  -2.571341  root_mean_squared_error        1.398316       1.070258  133.800689                 0.277687                0.102375          18.649188            2       True         20\n",
      "2               CatBoost_BAG_L2      -2.743210  -2.542264  root_mean_squared_error        1.190742       1.037868  152.353282                 0.070113                0.069984          37.201780            2       True         23\n",
      "3          CatBoost_r177_BAG_L2      -2.754683  -2.517276  root_mean_squared_error        1.190459       1.036069  147.250741                 0.069830                0.068186          32.099239            2       True         29\n",
      "4               LightGBM_BAG_L2      -2.780438  -2.517799  root_mean_squared_error        1.158302       0.987679  123.298289                 0.037673                0.019796           8.146787            2       True         21\n",
      "5          ExtraTreesMSE_BAG_L2      -2.783817  -2.571090  root_mean_squared_error        1.218024       1.101565  116.696485                 0.097395                0.133682           1.544983            2       True         24\n",
      "6           WeightedEnsemble_L3      -2.788651  -2.456485  root_mean_squared_error        1.367493       1.094214  181.772580                 0.003956                0.000436           0.012208            3       True         34\n",
      "7          LightGBM_r131_BAG_L2      -2.791548  -2.549176  root_mean_squared_error        1.214381       1.000520  128.947235                 0.093752                0.032637          13.795733            2       True         31\n",
      "8        RandomForestMSE_BAG_L1      -2.811693  -2.697122  root_mean_squared_error        0.097173       0.127095    3.615621                 0.097173                0.127095           3.615621            1       True          3\n",
      "9        RandomForestMSE_BAG_L2      -2.848995  -2.607813  root_mean_squared_error        1.220521       1.103552  119.291617                 0.099892                0.135669           4.140115            2       True         22\n",
      "10    NeuralNetTorch_r79_BAG_L2      -2.862357  -2.697789  root_mean_squared_error        1.634980       1.469379  151.716677                 0.514351                0.501496          36.565175            2       True         30\n",
      "11         LightGBM_r131_BAG_L1      -2.866135  -2.751526  root_mean_squared_error        0.104287       0.030195   14.844482                 0.104287                0.030195          14.844482            1       True         12\n",
      "12         LightGBMLarge_BAG_L2      -2.877518  -2.683421  root_mean_squared_error        1.297889       1.006683  160.692269                 0.177260                0.038800          45.540767            2       True         28\n",
      "13               XGBoost_BAG_L2      -2.890256  -2.593875  root_mean_squared_error        1.256034       1.005797  141.514347                 0.135405                0.037914          26.362845            2       True         26\n",
      "14         ExtraTreesMSE_BAG_L1      -2.899074  -2.611093  root_mean_squared_error        0.107956       0.129393    1.434739                 0.107956                0.129393           1.434739            1       True          5\n",
      "15         LightGBMLarge_BAG_L1      -2.899132  -2.945476  root_mean_squared_error        0.078384       0.018367   32.398672                 0.078384                0.018367          32.398672            1       True          9\n",
      "16          WeightedEnsemble_L2      -2.899460  -2.495803  root_mean_squared_error        0.703194       0.696230   69.431578                 0.002818                0.000455           0.012889            2       True         19\n",
      "17    NeuralNetTorch_r79_BAG_L1      -2.909998  -2.678295  root_mean_squared_error        0.512125       0.494885   82.479584                 0.512125                0.494885          82.479584            1       True         11\n",
      "18              LightGBM_BAG_L1      -2.916343  -2.715279  root_mean_squared_error        0.031811       0.015747    7.753674                 0.031811                0.015747           7.753674            1       True          2\n",
      "19        ExtraTrees_r42_BAG_L1      -2.917000  -2.611416  root_mean_squared_error        0.096662       0.129515    1.142338                 0.096662                0.129515           1.142338            1       True         18\n",
      "20    NeuralNetTorch_r22_BAG_L1      -2.931834  -2.616112  root_mean_squared_error        0.494052       0.497051   23.859016                 0.494052                0.497051          23.859016            1       True         16\n",
      "21           CatBoost_r9_BAG_L1      -2.942930  -2.636866  root_mean_squared_error        0.115300       0.070466  261.158195                 0.115300                0.070466         261.158195            1       True         14\n",
      "22        NeuralNetTorch_BAG_L2      -2.954693  -2.593870  root_mean_squared_error        1.630375       1.465952  141.052722                 0.509746                0.498069          25.901220            2       True         27\n",
      "23        NeuralNetTorch_BAG_L1      -2.961741  -2.574777  root_mean_squared_error        0.506116       0.504112   26.705909                 0.506116                0.504112          26.705909            1       True          8\n",
      "24          LightGBM_r96_BAG_L1      -2.969765  -2.688794  root_mean_squared_error        0.196768       0.057215   11.395993                 0.196768                0.057215          11.395993            1       True         15\n",
      "25         CatBoost_r177_BAG_L1      -2.983239  -2.638638  root_mean_squared_error        0.084072       0.063070   35.565027                 0.084072                0.063070          35.565027            1       True         10\n",
      "26            LightGBMXT_BAG_L1      -2.984562  -2.639081  root_mean_squared_error        0.072542       0.026500    7.883021                 0.072542                0.026500           7.883021            1       True          1\n",
      "27  NeuralNetFastAI_r191_BAG_L2      -3.007606  -3.210648  root_mean_squared_error        1.240033       1.058808  126.406305                 0.119404                0.090925          11.254803            2       True         32\n",
      "28              CatBoost_BAG_L1      -3.029366  -2.622473  root_mean_squared_error        0.086303       0.062269   41.278041                 0.086303                0.062269          41.278041            1       True          4\n",
      "29           CatBoost_r9_BAG_L2      -3.095168  -2.847920  root_mean_squared_error        1.189685       1.054141  139.708991                 0.069056                0.086257          24.557489            2       True         33\n",
      "30       NeuralNetFastAI_BAG_L2      -3.146735  -3.226008  root_mean_squared_error        1.229892       1.050943  122.002600                 0.109263                0.083060           6.851098            2       True         25\n",
      "31  NeuralNetFastAI_r191_BAG_L1      -3.174076  -3.172195  root_mean_squared_error        0.119504       0.085297   11.578334                 0.119504                0.085297          11.578334            1       True         13\n",
      "32       NeuralNetFastAI_BAG_L1      -3.209487  -3.223525  root_mean_squared_error        0.124974       0.075045    6.946254                 0.124974                0.075045           6.946254            1       True          6\n",
      "33           XGBoost_r33_BAG_L1      -4.100428  -3.949910  root_mean_squared_error        0.050751       0.031788    2.685604                 0.050751                0.031788           2.685604            1       True         17\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t905s\t = DyStack   runtime |\t2695s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 2695s\n",
      "AutoGluon will save models to \"/kaggle/working/AutogluonModels/ag-20250914_191743\"\n",
      "Train Data Rows:    614\n",
      "Train Data Columns: 206\n",
      "Label Column:       Rg\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    29878.64 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.97 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 32 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 30): ['NumRadicalElectrons', 'PEOE_VSA5', 'SMR_VSA8', 'SlogP_VSA9', 'fr_ArN', 'fr_C_S', 'fr_HOCCN', 'fr_SH', 'fr_azide', 'fr_barbitur', 'fr_benzodiazepine', 'fr_diazo', 'fr_dihydropyridine', 'fr_epoxide', 'fr_guanido', 'fr_hdrzine', 'fr_hdrzone', 'fr_isocyan', 'fr_isothiocyan', 'fr_lactam', 'fr_nitroso', 'fr_oxazole', 'fr_oxime', 'fr_phos_acid', 'fr_phos_ester', 'fr_piperzine', 'fr_prisulfonamd', 'fr_term_acetylene', 'fr_tetrazole', 'fr_thiocyan']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 10): ['MaxEStateIndex', 'NumUnspecifiedAtomStereoCenters', 'fr_COO2', 'fr_Nhpyrrole', 'fr_amide', 'fr_benzene', 'fr_nitro_arom_nonortho', 'fr_phenol', 'fr_phenol_noOrthoHbond', 'fr_priamide']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 10 | ['MaxEStateIndex', 'NumUnspecifiedAtomStereoCenters', 'fr_COO2', 'fr_Nhpyrrole', 'fr_amide', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 166 | ['MaxAbsEStateIndex', 'MinAbsEStateIndex', 'MinEStateIndex', 'qed', 'SPS', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 137 | ['MaxAbsEStateIndex', 'MinAbsEStateIndex', 'MinEStateIndex', 'qed', 'SPS', ...]\n",
      "\t\t('int', ['bool']) :  29 | ['PEOE_VSA11', 'EState_VSA11', 'NumSaturatedHeterocycles', 'NumSpiroAtoms', 'fr_Al_COO', ...]\n",
      "\t1.1s = Fit runtime\n",
      "\t166 features in original data used to generate 166 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.66 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.12s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
      "Fitting 106 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1795.76s of the 2694.30s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 2.64011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-2.5587\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.38s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1787.20s of the 2685.74s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.6258\t = Validation score   (-root_mean_squared_error)\n",
      "\t11.96s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 1775.10s of the 2673.64s of remaining time.\n",
      "\t-2.6546\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.41s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1770.46s of the 2669.00s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.5931\t = Validation score   (-root_mean_squared_error)\n",
      "\t55.65s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 1714.65s of the 2613.20s of remaining time.\n",
      "\t-2.6037\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.59s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1712.87s of the 2611.41s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 6: early stopping\n",
      "\t-2.9194\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.58s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 1705.07s of the 2603.61s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.7171\t = Validation score   (-root_mean_squared_error)\n",
      "\t22.7s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 1682.21s of the 2580.75s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.5553\t = Validation score   (-root_mean_squared_error)\n",
      "\t40.79s\t = Training   runtime\n",
      "\t0.47s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 1640.85s of the 2539.39s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 2.78647\n",
      "[2000]\tvalid_set's rmse: 2.78638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-2.7041\t = Validation score   (-root_mean_squared_error)\n",
      "\t67.15s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 1572.78s of the 2471.32s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.6033\t = Validation score   (-root_mean_squared_error)\n",
      "\t42.39s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 1530.24s of the 2428.78s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.6362\t = Validation score   (-root_mean_squared_error)\n",
      "\t30.78s\t = Training   runtime\n",
      "\t0.48s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 1498.87s of the 2397.41s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 2.25892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-2.6301\t = Validation score   (-root_mean_squared_error)\n",
      "\t14.47s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 1484.13s of the 2382.67s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 19: early stopping\n",
      "No improvement since epoch 12: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "\t-3.0284\t = Validation score   (-root_mean_squared_error)\n",
      "\t15.15s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 1468.74s of the 2367.28s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.5901\t = Validation score   (-root_mean_squared_error)\n",
      "\t302.95s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 1165.60s of the 2064.14s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 2.24097\n",
      "[2000]\tvalid_set's rmse: 2.17341\n",
      "[3000]\tvalid_set's rmse: 2.14542\n",
      "[4000]\tvalid_set's rmse: 2.13389\n",
      "[1000]\tvalid_set's rmse: 2.97982\n",
      "[2000]\tvalid_set's rmse: 2.93971\n",
      "[3000]\tvalid_set's rmse: 2.91838\n",
      "[4000]\tvalid_set's rmse: 2.91151\n",
      "[5000]\tvalid_set's rmse: 2.91308\n",
      "[1000]\tvalid_set's rmse: 2.34598\n",
      "[2000]\tvalid_set's rmse: 2.3059\n",
      "[3000]\tvalid_set's rmse: 2.28748\n",
      "[4000]\tvalid_set's rmse: 2.26462\n",
      "[5000]\tvalid_set's rmse: 2.25238\n",
      "[6000]\tvalid_set's rmse: 2.24922\n",
      "[7000]\tvalid_set's rmse: 2.24931\n",
      "[8000]\tvalid_set's rmse: 2.24666\n",
      "[9000]\tvalid_set's rmse: 2.24714\n",
      "[10000]\tvalid_set's rmse: 2.25241\n",
      "[1000]\tvalid_set's rmse: 2.75146\n",
      "[2000]\tvalid_set's rmse: 2.66645\n",
      "[3000]\tvalid_set's rmse: 2.61634\n",
      "[4000]\tvalid_set's rmse: 2.59531\n",
      "[5000]\tvalid_set's rmse: 2.58088\n",
      "[6000]\tvalid_set's rmse: 2.57689\n",
      "[7000]\tvalid_set's rmse: 2.57183\n",
      "[8000]\tvalid_set's rmse: 2.57073\n",
      "[1000]\tvalid_set's rmse: 2.90902\n",
      "[2000]\tvalid_set's rmse: 2.86538\n",
      "[3000]\tvalid_set's rmse: 2.85606\n",
      "[4000]\tvalid_set's rmse: 2.8472\n",
      "[1000]\tvalid_set's rmse: 2.19648\n",
      "[1000]\tvalid_set's rmse: 2.36297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-2.604\t = Validation score   (-root_mean_squared_error)\n",
      "\t19.29s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 1145.46s of the 2044.00s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2000]\tvalid_set's rmse: 2.3591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-2.5014\t = Validation score   (-root_mean_squared_error)\n",
      "\t49.07s\t = Training   runtime\n",
      "\t0.48s\t = Validation runtime\n",
      "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 1095.81s of the 1994.36s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.6569\t = Validation score   (-root_mean_squared_error)\n",
      "\t104.24s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L1 ... Training model for up to 991.22s of the 1889.76s of remaining time.\n",
      "\t-2.641\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.28s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 989.72s of the 1888.26s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.6148\t = Validation score   (-root_mean_squared_error)\n",
      "\t39.69s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L1 ... Training model for up to 949.89s of the 1848.44s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 8: early stopping\n",
      "No improvement since epoch 5: early stopping\n",
      "\t-2.9062\t = Validation score   (-root_mean_squared_error)\n",
      "\t33.29s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: CatBoost_r13_BAG_L1 ... Training model for up to 916.33s of the 1814.87s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 3006.\n",
      "\tRan out of time, early stopping on iteration 3525.\n",
      "\t-2.5931\t = Validation score   (-root_mean_squared_error)\n",
      "\t378.84s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: RandomForest_r195_BAG_L1 ... Training model for up to 537.13s of the 1435.67s of remaining time.\n",
      "\t-2.6453\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.35s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: LightGBM_r188_BAG_L1 ... Training model for up to 533.59s of the 1432.13s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.5842\t = Validation score   (-root_mean_squared_error)\n",
      "\t11.83s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r145_BAG_L1 ... Training model for up to 521.52s of the 1420.06s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 9: early stopping\n",
      "No improvement since epoch 6: early stopping\n",
      "No improvement since epoch 0: early stopping\n",
      "\t-2.9831\t = Validation score   (-root_mean_squared_error)\n",
      "\t13.39s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: XGBoost_r89_BAG_L1 ... Training model for up to 507.88s of the 1406.43s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.6101\t = Validation score   (-root_mean_squared_error)\n",
      "\t15.38s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r30_BAG_L1 ... Training model for up to 492.34s of the 1390.88s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.6468\t = Validation score   (-root_mean_squared_error)\n",
      "\t58.01s\t = Training   runtime\n",
      "\t0.47s\t = Validation runtime\n",
      "Fitting model: LightGBM_r130_BAG_L1 ... Training model for up to 433.72s of the 1332.27s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 2.81306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-2.6036\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.64s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r86_BAG_L1 ... Training model for up to 427.96s of the 1326.51s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.4996\t = Validation score   (-root_mean_squared_error)\n",
      "\t60.67s\t = Training   runtime\n",
      "\t0.48s\t = Validation runtime\n",
      "Fitting model: CatBoost_r50_BAG_L1 ... Training model for up to 366.73s of the 1265.27s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.6498\t = Validation score   (-root_mean_squared_error)\n",
      "\t37.08s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r11_BAG_L1 ... Training model for up to 329.51s of the 1228.06s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.8427\t = Validation score   (-root_mean_squared_error)\n",
      "\t17.2s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: XGBoost_r194_BAG_L1 ... Training model for up to 312.07s of the 1210.61s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.6745\t = Validation score   (-root_mean_squared_error)\n",
      "\t23.73s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r172_BAG_L1 ... Training model for up to 288.08s of the 1186.63s of remaining time.\n",
      "\t-2.6523\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.8s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: CatBoost_r69_BAG_L1 ... Training model for up to 287.12s of the 1185.66s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.6072\t = Validation score   (-root_mean_squared_error)\n",
      "\t37.76s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r103_BAG_L1 ... Training model for up to 249.23s of the 1147.77s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 17: early stopping\n",
      "No improvement since epoch 20: early stopping\n",
      "\t-2.8872\t = Validation score   (-root_mean_squared_error)\n",
      "\t12.93s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r14_BAG_L1 ... Training model for up to 236.06s of the 1134.60s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.8611\t = Validation score   (-root_mean_squared_error)\n",
      "\t13.85s\t = Training   runtime\n",
      "\t0.47s\t = Validation runtime\n",
      "Fitting model: LightGBM_r161_BAG_L1 ... Training model for up to 221.65s of the 1120.19s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 2.17194\n",
      "[1000]\tvalid_set's rmse: 2.14371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-2.5921\t = Validation score   (-root_mean_squared_error)\n",
      "\t20.5s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r143_BAG_L1 ... Training model for up to 200.69s of the 1099.23s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 12: early stopping\n",
      "No improvement since epoch 11: early stopping\n",
      "No improvement since epoch 7: early stopping\n",
      "\t-2.8363\t = Validation score   (-root_mean_squared_error)\n",
      "\t45.52s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: CatBoost_r70_BAG_L1 ... Training model for up to 154.85s of the 1053.39s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 658.\n",
      "\tRan out of time, early stopping on iteration 749.\n",
      "\tRan out of time, early stopping on iteration 777.\n",
      "\t-2.6152\t = Validation score   (-root_mean_squared_error)\n",
      "\t102.83s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r156_BAG_L1 ... Training model for up to 51.86s of the 950.40s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 38)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 39)\n",
      "No improvement since epoch 18: early stopping\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 43)\n",
      "No improvement since epoch 5: early stopping\n",
      "No improvement since epoch 21: early stopping\n",
      "No improvement since epoch 23: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "\t-3.2292\t = Validation score   (-root_mean_squared_error)\n",
      "\t39.4s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: LightGBM_r196_BAG_L1 ... Training model for up to 12.16s of the 910.70s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 457. Best iteration is:\n",
      "\t[457]\tvalid_set's rmse: 2.30801\n",
      "\tRan out of time, early stopping on iteration 508. Best iteration is:\n",
      "\t[471]\tvalid_set's rmse: 3.27385\n",
      "\tRan out of time, early stopping on iteration 531. Best iteration is:\n",
      "\t[531]\tvalid_set's rmse: 2.92017\n",
      "\tRan out of time, early stopping on iteration 549. Best iteration is:\n",
      "\t[549]\tvalid_set's rmse: 2.40873\n",
      "\tRan out of time, early stopping on iteration 551. Best iteration is:\n",
      "\t[551]\tvalid_set's rmse: 2.78979\n",
      "\tRan out of time, early stopping on iteration 576. Best iteration is:\n",
      "\t[575]\tvalid_set's rmse: 2.86903\n",
      "\tRan out of time, early stopping on iteration 633. Best iteration is:\n",
      "\t[552]\tvalid_set's rmse: 2.10594\n",
      "\tRan out of time, early stopping on iteration 728. Best iteration is:\n",
      "\t[726]\tvalid_set's rmse: 2.31351\n",
      "\t-2.6512\t = Validation score   (-root_mean_squared_error)\n",
      "\t11.36s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForest_r39_BAG_L1 ... Training model for up to 0.21s of the 898.75s of remaining time.\n",
      "\t-2.6488\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.59s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 895.90s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetTorch_r86_BAG_L1': 0.522, 'LightGBMXT_BAG_L1': 0.304, 'NeuralNetFastAI_r143_BAG_L1': 0.13, 'XGBoost_r89_BAG_L1': 0.043}\n",
      "\t-2.4108\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 895.87s of the 895.80s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 2.98713\n",
      "[2000]\tvalid_set's rmse: 2.97853\n",
      "[3000]\tvalid_set's rmse: 2.97461\n",
      "[4000]\tvalid_set's rmse: 2.97429\n",
      "[5000]\tvalid_set's rmse: 2.97409\n",
      "[6000]\tvalid_set's rmse: 2.97403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-2.5964\t = Validation score   (-root_mean_squared_error)\n",
      "\t11.22s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 884.28s of the 884.21s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.6186\t = Validation score   (-root_mean_squared_error)\n",
      "\t10.49s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 873.64s of the 873.57s of remaining time.\n",
      "\t-2.5869\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.51s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 868.89s of the 868.81s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.5663\t = Validation score   (-root_mean_squared_error)\n",
      "\t37.54s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 831.20s of the 831.13s of remaining time.\n",
      "\t-2.5546\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.69s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 829.27s of the 829.20s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 8: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "\t-3.1323\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.4s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 821.63s of the 821.56s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.6512\t = Validation score   (-root_mean_squared_error)\n",
      "\t24.01s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 797.46s of the 797.38s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.5951\t = Validation score   (-root_mean_squared_error)\n",
      "\t35.24s\t = Training   runtime\n",
      "\t0.49s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 761.62s of the 761.54s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.6936\t = Validation score   (-root_mean_squared_error)\n",
      "\t45.15s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 715.97s of the 715.89s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.5573\t = Validation score   (-root_mean_squared_error)\n",
      "\t33.48s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L2 ... Training model for up to 682.33s of the 682.25s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.6417\t = Validation score   (-root_mean_squared_error)\n",
      "\t22.96s\t = Training   runtime\n",
      "\t0.49s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L2 ... Training model for up to 658.76s of the 658.68s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 2.55093\n",
      "[2000]\tvalid_set's rmse: 2.53429\n",
      "[3000]\tvalid_set's rmse: 2.53015\n",
      "[4000]\tvalid_set's rmse: 2.53155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-2.6221\t = Validation score   (-root_mean_squared_error)\n",
      "\t21.29s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L2 ... Training model for up to 637.03s of the 636.95s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 6: early stopping\n",
      "No improvement since epoch 10: early stopping\n",
      "No improvement since epoch 9: early stopping\n",
      "No improvement since epoch 22: early stopping\n",
      "\t-2.9151\t = Validation score   (-root_mean_squared_error)\n",
      "\t14.87s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L2 ... Training model for up to 621.91s of the 621.83s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.591\t = Validation score   (-root_mean_squared_error)\n",
      "\t198.04s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L2 ... Training model for up to 423.69s of the 423.62s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.5297\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.7s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L2 ... Training model for up to 418.88s of the 418.80s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.5584\t = Validation score   (-root_mean_squared_error)\n",
      "\t22.53s\t = Training   runtime\n",
      "\t0.49s\t = Validation runtime\n",
      "Fitting model: XGBoost_r33_BAG_L2 ... Training model for up to 395.75s of the 395.68s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.6204\t = Validation score   (-root_mean_squared_error)\n",
      "\t91.96s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L2 ... Training model for up to 303.50s of the 303.42s of remaining time.\n",
      "\t-2.5735\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.4s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L2 ... Training model for up to 301.86s of the 301.78s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.5359\t = Validation score   (-root_mean_squared_error)\n",
      "\t14.56s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L2 ... Training model for up to 287.16s of the 287.09s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 5: early stopping\n",
      "No improvement since epoch 6: early stopping\n",
      "No improvement since epoch 3: early stopping\n",
      "No improvement since epoch 2: early stopping\n",
      "No improvement since epoch 8: early stopping\n",
      "\t-3.0031\t = Validation score   (-root_mean_squared_error)\n",
      "\t31.09s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: CatBoost_r13_BAG_L2 ... Training model for up to 255.77s of the 255.69s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 1202.\n",
      "\t-2.5641\t = Validation score   (-root_mean_squared_error)\n",
      "\t155.71s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: RandomForest_r195_BAG_L2 ... Training model for up to 99.87s of the 99.79s of remaining time.\n",
      "\t-2.6094\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.52s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: LightGBM_r188_BAG_L2 ... Training model for up to 96.16s of the 96.08s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 2.89108\n",
      "[2000]\tvalid_set's rmse: 2.89074\n",
      "[3000]\tvalid_set's rmse: 2.89073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-2.6131\t = Validation score   (-root_mean_squared_error)\n",
      "\t15.57s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r145_BAG_L2 ... Training model for up to 80.14s of the 80.06s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 4: early stopping\n",
      "No improvement since epoch 4: early stopping\n",
      "No improvement since epoch 4: early stopping\n",
      "No improvement since epoch 5: early stopping\n",
      "\t-2.8685\t = Validation score   (-root_mean_squared_error)\n",
      "\t12.86s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: XGBoost_r89_BAG_L2 ... Training model for up to 67.03s of the 66.96s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.5855\t = Validation score   (-root_mean_squared_error)\n",
      "\t12.8s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r30_BAG_L2 ... Training model for up to 54.07s of the 53.99s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.7239\t = Validation score   (-root_mean_squared_error)\n",
      "\t29.49s\t = Training   runtime\n",
      "\t0.48s\t = Validation runtime\n",
      "Fitting model: LightGBM_r130_BAG_L2 ... Training model for up to 23.96s of the 23.89s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-2.5499\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.55s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r86_BAG_L2 ... Training model for up to 19.32s of the 19.25s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 30)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 35)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 37)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 40)\n",
      "\t-2.5614\t = Validation score   (-root_mean_squared_error)\n",
      "\t16.82s\t = Training   runtime\n",
      "\t0.49s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 1.72s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetTorch_r86_BAG_L1': 0.55, 'NeuralNetFastAI_r143_BAG_L1': 0.15, 'LightGBM_r96_BAG_L2': 0.1, 'XGBoost_r89_BAG_L2': 0.1, 'ExtraTreesMSE_BAG_L2': 0.05, 'CatBoost_r137_BAG_L2': 0.05}\n",
      "\t-2.4375\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2693.76s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 116.2 rows/s (77 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/kaggle/working/AutogluonModels/ag-20250914_191743\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Rg] 欠損 10183 件を AutoGluon で補完\n"
     ]
    }
   ],
   "source": [
    "# FFV補完（記述子のみ）\n",
    "train_df_with_desc, ffv_model = fill_with_autogluon(\n",
    "    train_df_with_desc,\n",
    "    target='FFV',\n",
    "    descriptors=filtered_descriptor_names,\n",
    "    time_limit=120\n",
    ")\n",
    "models['FFV'] = ffv_model\n",
    "\n",
    "# 学習済みモデルのパフォーマンス確認\n",
    "if ffv_model is not None:\n",
    "    leaderboard_df = ffv_model.leaderboard(silent=True)\n",
    "    print(leaderboard_df)\n",
    "\n",
    "# FFV列のNaN・inf・overflowを除去\n",
    "train_df_with_desc['FFV'] = train_df_with_desc['FFV'].replace([np.inf, -np.inf], np.nan)\n",
    "train_df_with_desc['FFV'] = train_df_with_desc['FFV'].apply(\n",
    "    lambda x: np.nan if isinstance(x, (int, float)) and abs(x) > np.finfo(np.float32).max else x\n",
    ")\n",
    "\n",
    "# 他ターゲット補完（FFV含む）\n",
    "extended_features = filtered_descriptor_names + ['FFV']\n",
    "for target in ['Tg', 'Tc', 'Density', 'Rg']:\n",
    "    train_df_with_desc, model = fill_with_autogluon(\n",
    "        train_df_with_desc,\n",
    "        target=target,\n",
    "        descriptors=extended_features,\n",
    "        time_limit=3600\n",
    "    )\n",
    "    models[target] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78859c5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T20:17:55.594801Z",
     "iopub.status.busy": "2025-09-14T20:17:55.594462Z",
     "iopub.status.idle": "2025-09-14T20:18:13.159352Z",
     "shell.execute_reply": "2025-09-14T20:18:13.158386Z"
    },
    "papermill": {
     "duration": 17.779273,
     "end_time": "2025-09-14T20:18:13.160811",
     "exception": false,
     "start_time": "2025-09-14T20:17:55.381538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/2844734425.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[df.index, target_col] = y_pred\n",
      "/tmp/ipykernel_13/2844734425.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[df.index, target_col] = y_pred\n",
      "/tmp/ipykernel_13/2844734425.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[df.index, target_col] = y_pred\n",
      "/tmp/ipykernel_13/2844734425.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[df.index, target_col] = y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 提出用ファイル 'submission.csv' を作成しました。\n",
      "           id          Tg       FFV        Tc   Density         Rg\n",
      "0  1109053969  163.082565  0.377299  0.163123  1.180020  21.536901\n",
      "1  1422188626  201.277557  0.379842  0.241983  1.102160  20.952915\n",
      "2  2032016830   98.791893  0.353015  0.257450  1.126908  21.392076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/2844734425.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[df.index, target_col] = y_pred\n"
     ]
    }
   ],
   "source": [
    "# FFV予測\n",
    "test_df_with_desc = predict_test_autogluon(\n",
    "    test_df_with_desc,\n",
    "    models['FFV'],\n",
    "    'FFV',\n",
    "    filtered_descriptor_names\n",
    ")\n",
    "\n",
    "# 他ターゲット予測\n",
    "for target in ['Tg', 'Tc', 'Density', 'Rg']:\n",
    "    test_df_with_desc = predict_test_autogluon(\n",
    "        test_df_with_desc,\n",
    "        models[target],\n",
    "        target,\n",
    "        extended_features\n",
    "    )\n",
    "\n",
    "# 提出ファイル作成\n",
    "targets = ['Tg', 'FFV', 'Tc', 'Density', 'Rg']\n",
    "submission = test_df_with_desc[['id'] + targets].copy()\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"✅ 提出用ファイル 'submission.csv' を作成しました。\")\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60ecab9",
   "metadata": {
    "papermill": {
     "duration": 0.211763,
     "end_time": "2025-09-14T20:18:13.584594",
     "exception": false,
     "start_time": "2025-09-14T20:18:13.372831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fed3ccd",
   "metadata": {
    "papermill": {
     "duration": 0.213486,
     "end_time": "2025-09-14T20:18:14.005396",
     "exception": false,
     "start_time": "2025-09-14T20:18:13.791910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63879f6",
   "metadata": {
    "papermill": {
     "duration": 0.216001,
     "end_time": "2025-09-14T20:18:14.438418",
     "exception": false,
     "start_time": "2025-09-14T20:18:14.222417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b45d96",
   "metadata": {
    "papermill": {
     "duration": 0.213732,
     "end_time": "2025-09-14T20:18:14.865010",
     "exception": false,
     "start_time": "2025-09-14T20:18:14.651278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 12966160,
     "sourceId": 74608,
     "sourceType": "competition"
    },
    {
     "datasetId": 7678100,
     "sourceId": 12189904,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7690162,
     "sourceId": 12207625,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7709869,
     "sourceId": 12330396,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 247698673,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 247701857,
     "sourceType": "kernelVersion"
    },
    {
     "modelId": 380893,
     "modelInstanceId": 359690,
     "sourceId": 442871,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 15113.273407,
   "end_time": "2025-09-14T20:18:18.145081",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-14T16:06:24.871674",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
