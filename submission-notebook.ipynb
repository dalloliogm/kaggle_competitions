{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99dcfeb6",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.002671,
     "end_time": "2025-04-28T19:53:25.696048",
     "exception": false,
     "start_time": "2025-04-28T19:53:25.693377",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BYU Locating Flagellar Motors\n",
    "\n",
    "## Submission Generation Notebook\n",
    "\n",
    "This is the fourth and final notebook in a series for the BYU Locating Bacterial Flagellar Motors 2025 Kaggle challenge. This notebook creates predictions on test data and generates the competition submission file.\n",
    "\n",
    "### Notebook Series:\n",
    "1. **[Parse Data](https://www.kaggle.com/code/andrewjdarley/parse-data)**: Extracting and preparing 2D slices containing motors to make a YOLO dataset\n",
    "2. **[Visualize Data](https://www.kaggle.com/code/andrewjdarley/visualize-data)**: Exploratory data analysis and visualization of annotated motor locations\n",
    "3. **[Train YOLO](https://www.kaggle.com/code/andrewjdarley/train-yolo)**: Fine tuning an YOLOv8 object detection model on the prepared dataset\n",
    "4. **Submission Notebook (Current)**: Running inference and generating submission files \n",
    "\n",
    "## Important: Offline Execution\n",
    "This notebook is designed to run in an offline environment. The Ultralytics YOLOv8 package has been installed using the offline installation method from [this reference notebook](https://www.kaggle.com/code/itsuki9180/ultralytics-for-offline-install). This implementation was brilliant. I use my own copy as input that works effectively the same as the original.\n",
    "\n",
    "## About this Notebook\n",
    "\n",
    "This submission notebook implements an optimized inference pipeline that:\n",
    "\n",
    "1. **Model Loading**: Loads the best trained YOLOv8 weights from the training notebook\n",
    "2. **GPU Optimization**: Configures CUDA optimizations, half-precision inference, and memory management\n",
    "3. **Parallel Processing**: Uses CUDA streams and batch processing for efficient GPU utilization\n",
    "4. **3D Detection**: Processes each slice to locate motors\n",
    "5. **Non-Maximum Suppression**: Applies 3D NMS to cluster and merge detections across slices\n",
    "6. **Submission Generation**: Creates the final CSV file with predicted motor coordinates\n",
    "\n",
    "The code includes advanced optimizations like dynamic batch sizing based on available GPU memory, preloading batches while processing the current batch, and GPU profiling to monitor performance. The CONCENTRATION parameter can be adjusted to trade off between processing speed and detection accuracy. The only reason you'd ever modify CONCENTRATION is just to verify submission capability since full submission takes a few hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afa026f0",
   "metadata": {
    "_kg_hide-input": false,
    "execution": {
     "iopub.execute_input": "2025-04-28T19:53:25.702308Z",
     "iopub.status.busy": "2025-04-28T19:53:25.701782Z",
     "iopub.status.idle": "2025-04-28T19:54:30.577888Z",
     "shell.execute_reply": "2025-04-28T19:54:30.576829Z"
    },
    "papermill": {
     "duration": 64.881203,
     "end_time": "2025-04-28T19:54:30.579678",
     "exception": false,
     "start_time": "2025-04-28T19:53:25.698475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./packages/\r\n",
      "./packages/networkx-3.4.2-py3-none-any.whl\r\n",
      "./packages/fsspec-2025.2.0-py3-none-any.whl\r\n",
      "./packages/python_dateutil-2.9.0.post0-py2.py3-none-any.whl\r\n",
      "./packages/jinja2-3.1.5-py3-none-any.whl\r\n",
      "./packages/pyparsing-3.2.1-py3-none-any.whl\r\n",
      "./packages/charset_normalizer-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "./packages/ultralytics_thop-2.0.14-py3-none-any.whl\r\n",
      "./packages/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl\r\n",
      "./packages/urllib3-2.3.0-py3-none-any.whl\r\n",
      "./packages/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl\r\n",
      "./packages/pytz-2025.1-py2.py3-none-any.whl\r\n",
      "./packages/MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "./packages/numpy-2.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "./packages/cycler-0.12.1-py3-none-any.whl\r\n",
      "./packages/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl\r\n",
      "./packages/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl\r\n",
      "./packages/torchvision-0.21.0-cp310-cp310-manylinux1_x86_64.whl\r\n",
      "./packages/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl\r\n",
      "./packages/ultralytics-8.3.80-py3-none-any.whl\r\n",
      "./packages/mpmath-1.3.0-py3-none-any.whl\r\n",
      "./packages/kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\r\n",
      "./packages/typing_extensions-4.12.2-py3-none-any.whl\r\n",
      "./packages/PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "./packages/contourpy-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "./packages/certifi-2025.1.31-py3-none-any.whl\r\n",
      "./packages/opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "./packages/tzdata-2025.1-py2.py3-none-any.whl\r\n",
      "./packages/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl\r\n",
      "./packages/nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl\r\n",
      "./packages/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl\r\n",
      "./packages/fonttools-4.56.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "./packages/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl\r\n",
      "./packages/tqdm-4.67.1-py3-none-any.whl\r\n",
      "./packages/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl\r\n",
      "./packages/py_cpuinfo-9.0.0-py3-none-any.whl\r\n",
      "./packages/psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "./packages/pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "./packages/torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl\r\n",
      "./packages/nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl\r\n",
      "./packages/triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "./packages/sympy-1.13.1-py3-none-any.whl\r\n",
      "./packages/seaborn-0.13.2-py3-none-any.whl\r\n",
      "./packages/scipy-1.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "./packages/idna-3.10-py3-none-any.whl\r\n",
      "./packages/packaging-24.2-py3-none-any.whl\r\n",
      "./packages/matplotlib-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "./packages/nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl\r\n",
      "./packages/nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl\r\n",
      "./packages/requests-2.32.3-py3-none-any.whl\r\n",
      "./packages/six-1.17.0-py2.py3-none-any.whl\r\n",
      "./packages/pillow-11.1.0-cp310-cp310-manylinux_2_28_x86_64.whl\r\n",
      "./packages/filelock-3.17.0-py3-none-any.whl\r\n",
      "Looking in links: ./packages\r\n",
      "Processing ./packages/ultralytics-8.3.80-py3-none-any.whl\r\n",
      "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\r\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.5)\r\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\r\n",
      "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\r\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\r\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\r\n",
      "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\r\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\r\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.67.1)\r\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\r\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\r\n",
      "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.3)\r\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\r\n",
      "Processing ./packages/ultralytics_thop-2.0.14-py3-none-any.whl (from ultralytics)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.3)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (2.4.1)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.17.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.12.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<=2.1.1,>=1.23.0->ultralytics) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (2024.2.0)\r\n",
      "Installing collected packages: ultralytics-thop, ultralytics\r\n",
      "Successfully installed ultralytics-8.3.80 ultralytics-thop-2.0.14\r\n"
     ]
    }
   ],
   "source": [
    "!tar xfvz /kaggle/input/ultralytics-for-offline-install/archive.tar.gz\n",
    "!pip install --no-index --find-links=./packages ultralytics\n",
    "!rm -rf ./packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f58bf01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T19:54:30.590059Z",
     "iopub.status.busy": "2025-04-28T19:54:30.589759Z",
     "iopub.status.idle": "2025-04-28T19:55:44.095922Z",
     "shell.execute_reply": "2025-04-28T19:55:44.094597Z"
    },
    "papermill": {
     "duration": 73.513262,
     "end_time": "2025-04-28T19:55:44.097699",
     "exception": false,
     "start_time": "2025-04-28T19:54:30.584437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
      "Using GPU: Tesla T4 with 15.83 GB memory\n",
      "Dynamic batch size set to 32 based on 15.83GB free memory\n",
      "Found 3 tomograms in test directory\n",
      "Found 500 image files in /kaggle/input/byu-locating-bacterial-flagellar-motors-2025/test/tomo_003acc\n",
      "PIL Image shape: (1912, 1847), dtype: uint8\n",
      "OpenCV Image shape: (1912, 1847), dtype: uint8\n",
      "OpenCV RGB Image shape: (1912, 1847, 3), dtype: uint8\n",
      "Image loading successful!\n",
      "YOLO model successfully processed the test image\n",
      "Loading YOLO model from /kaggle/input/train-yolo/yolo_weights/motor_detector/weights/best.pt\n",
      "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "Using half precision (FP16) for inference\n",
      "Processing tomogram tomo_003acc (1/3)\n",
      "Processing 500 out of 500 slices based on CONCENTRATION=1\n",
      "[PROFILE] Inference batch 1/4: 1.481s\n",
      "[PROFILE] Inference batch 2/4: 0.993s\n",
      "[PROFILE] Inference batch 3/4: 0.798s\n",
      "[PROFILE] Inference batch 4/4: 0.812s\n",
      "[PROFILE] Inference batch 1/4: 0.611s\n",
      "[PROFILE] Inference batch 2/4: 0.641s\n",
      "[PROFILE] Inference batch 3/4: 0.679s\n",
      "[PROFILE] Inference batch 4/4: 0.556s\n",
      "[PROFILE] Inference batch 1/4: 0.603s\n",
      "[PROFILE] Inference batch 2/4: 0.613s\n",
      "[PROFILE] Inference batch 3/4: 0.569s\n",
      "[PROFILE] Inference batch 4/4: 0.563s\n",
      "[PROFILE] Inference batch 1/4: 0.615s\n",
      "[PROFILE] Inference batch 2/4: 0.564s\n",
      "[PROFILE] Inference batch 3/4: 0.571s\n",
      "[PROFILE] Inference batch 4/4: 0.615s\n",
      "[PROFILE] Inference batch 1/4: 0.878s\n",
      "[PROFILE] Inference batch 2/4: 0.833s\n",
      "[PROFILE] Inference batch 3/4: 0.585s\n",
      "[PROFILE] Inference batch 4/4: 0.569s\n",
      "[PROFILE] Inference batch 1/4: 0.600s\n",
      "[PROFILE] Inference batch 2/4: 0.610s\n",
      "[PROFILE] Inference batch 3/4: 0.560s\n",
      "[PROFILE] Inference batch 4/4: 0.582s\n",
      "[PROFILE] Inference batch 1/4: 0.572s\n",
      "[PROFILE] Inference batch 2/4: 0.641s\n",
      "[PROFILE] Inference batch 3/4: 0.561s\n",
      "[PROFILE] Inference batch 4/4: 0.583s\n",
      "[PROFILE] Inference batch 1/4: 0.581s\n",
      "[PROFILE] Inference batch 2/4: 0.614s\n",
      "[PROFILE] Inference batch 3/4: 0.567s\n",
      "[PROFILE] Inference batch 4/4: 0.576s\n",
      "[PROFILE] Inference batch 1/4: 0.616s\n",
      "[PROFILE] Inference batch 2/4: 0.615s\n",
      "[PROFILE] Inference batch 3/4: 0.568s\n",
      "[PROFILE] Inference batch 4/4: 0.584s\n",
      "[PROFILE] Inference batch 1/4: 0.590s\n",
      "[PROFILE] Inference batch 2/4: 0.627s\n",
      "[PROFILE] Inference batch 3/4: 0.557s\n",
      "[PROFILE] Inference batch 4/4: 0.584s\n",
      "[PROFILE] Inference batch 1/4: 0.599s\n",
      "[PROFILE] Inference batch 2/4: 0.662s\n",
      "[PROFILE] Inference batch 3/4: 0.592s\n",
      "[PROFILE] Inference batch 4/4: 0.576s\n",
      "[PROFILE] Inference batch 1/4: 0.591s\n",
      "[PROFILE] Inference batch 2/4: 0.646s\n",
      "[PROFILE] Inference batch 3/4: 0.549s\n",
      "[PROFILE] Inference batch 4/4: 0.585s\n",
      "[PROFILE] Inference batch 1/4: 0.631s\n",
      "[PROFILE] Inference batch 2/4: 0.623s\n",
      "[PROFILE] Inference batch 3/4: 0.560s\n",
      "[PROFILE] Inference batch 4/4: 0.583s\n",
      "[PROFILE] Inference batch 1/4: 0.604s\n",
      "[PROFILE] Inference batch 2/4: 0.649s\n",
      "[PROFILE] Inference batch 3/4: 0.559s\n",
      "[PROFILE] Inference batch 4/4: 0.588s\n",
      "[PROFILE] Inference batch 1/4: 0.585s\n",
      "[PROFILE] Inference batch 2/4: 0.606s\n",
      "[PROFILE] Inference batch 3/4: 0.589s\n",
      "[PROFILE] Inference batch 4/4: 0.588s\n",
      "[PROFILE] Inference batch 1/4: 0.718s\n",
      "[PROFILE] Inference batch 2/4: 0.341s\n",
      "[PROFILE] Inference batch 3/4: 0.338s\n",
      "[PROFILE] Inference batch 4/4: 0.337s\n",
      "Processing tomogram tomo_00e047 (2/3)\n",
      "Motor found in tomo_003acc at position: z=-1, y=-1, x=-1\n",
      "Current detection rate: 1/1 (100.0%)\n",
      "Processing 300 out of 300 slices based on CONCENTRATION=1\n",
      "[PROFILE] Inference batch 1/4: 0.238s\n",
      "[PROFILE] Inference batch 2/4: 0.257s\n",
      "[PROFILE] Inference batch 3/4: 0.223s\n",
      "[PROFILE] Inference batch 4/4: 0.221s\n",
      "[PROFILE] Inference batch 1/4: 0.236s\n",
      "[PROFILE] Inference batch 2/4: 0.269s\n",
      "[PROFILE] Inference batch 3/4: 0.227s\n",
      "[PROFILE] Inference batch 4/4: 0.208s\n",
      "[PROFILE] Inference batch 1/4: 0.244s\n",
      "[PROFILE] Inference batch 2/4: 0.312s\n",
      "[PROFILE] Inference batch 3/4: 0.218s\n",
      "[PROFILE] Inference batch 4/4: 0.214s\n",
      "[PROFILE] Inference batch 1/4: 0.283s\n",
      "[PROFILE] Inference batch 2/4: 0.213s\n",
      "[PROFILE] Inference batch 3/4: 0.249s\n",
      "[PROFILE] Inference batch 4/4: 0.206s\n",
      "[PROFILE] Inference batch 1/4: 0.228s\n",
      "[PROFILE] Inference batch 2/4: 0.215s\n",
      "[PROFILE] Inference batch 3/4: 0.264s\n",
      "[PROFILE] Inference batch 4/4: 0.203s\n",
      "[PROFILE] Inference batch 1/4: 0.227s\n",
      "[PROFILE] Inference batch 2/4: 0.241s\n",
      "[PROFILE] Inference batch 3/4: 0.228s\n",
      "[PROFILE] Inference batch 4/4: 0.204s\n",
      "[PROFILE] Inference batch 1/4: 0.219s\n",
      "[PROFILE] Inference batch 2/4: 0.237s\n",
      "[PROFILE] Inference batch 3/4: 0.221s\n",
      "[PROFILE] Inference batch 4/4: 0.204s\n",
      "[PROFILE] Inference batch 1/4: 0.205s\n",
      "[PROFILE] Inference batch 2/4: 0.268s\n",
      "[PROFILE] Inference batch 3/4: 0.215s\n",
      "[PROFILE] Inference batch 4/4: 0.208s\n",
      "[PROFILE] Inference batch 1/4: 0.273s\n",
      "[PROFILE] Inference batch 2/4: 0.210s\n",
      "[PROFILE] Inference batch 3/4: 0.205s\n",
      "[PROFILE] Inference batch 4/4: 0.201s\n",
      "[PROFILE] Inference batch 1/4: 0.426s\n",
      "[PROFILE] Inference batch 2/4: 0.083s\n",
      "[PROFILE] Inference batch 3/4: 0.074s\n",
      "[PROFILE] Inference batch 4/4: 0.073s\n",
      "Processing tomogram tomo_01a877 (3/3)\n",
      "Motor found in tomo_00e047 at position: z=164, y=544, x=602\n",
      "Current detection rate: 2/2 (100.0%)\n",
      "Processing 300 out of 300 slices based on CONCENTRATION=1\n",
      "[PROFILE] Inference batch 1/4: 0.242s\n",
      "[PROFILE] Inference batch 2/4: 0.236s\n",
      "[PROFILE] Inference batch 3/4: 0.216s\n",
      "[PROFILE] Inference batch 4/4: 0.216s\n",
      "[PROFILE] Inference batch 1/4: 0.184s\n",
      "[PROFILE] Inference batch 2/4: 0.184s\n",
      "[PROFILE] Inference batch 3/4: 0.184s\n",
      "[PROFILE] Inference batch 4/4: 0.182s\n",
      "[PROFILE] Inference batch 1/4: 0.250s\n",
      "[PROFILE] Inference batch 2/4: 0.200s\n",
      "[PROFILE] Inference batch 3/4: 0.194s\n",
      "[PROFILE] Inference batch 4/4: 0.194s\n",
      "[PROFILE] Inference batch 1/4: 0.202s\n",
      "[PROFILE] Inference batch 2/4: 0.204s\n",
      "[PROFILE] Inference batch 3/4: 0.204s\n",
      "[PROFILE] Inference batch 4/4: 0.189s\n",
      "[PROFILE] Inference batch 1/4: 0.200s\n",
      "[PROFILE] Inference batch 2/4: 0.228s\n",
      "[PROFILE] Inference batch 3/4: 0.210s\n",
      "[PROFILE] Inference batch 4/4: 0.196s\n",
      "[PROFILE] Inference batch 1/4: 0.244s\n",
      "[PROFILE] Inference batch 2/4: 0.205s\n",
      "[PROFILE] Inference batch 3/4: 0.206s\n",
      "[PROFILE] Inference batch 4/4: 0.196s\n",
      "[PROFILE] Inference batch 1/4: 0.211s\n",
      "[PROFILE] Inference batch 2/4: 0.218s\n",
      "[PROFILE] Inference batch 3/4: 0.206s\n",
      "[PROFILE] Inference batch 4/4: 0.197s\n",
      "[PROFILE] Inference batch 1/4: 0.215s\n",
      "[PROFILE] Inference batch 2/4: 0.205s\n",
      "[PROFILE] Inference batch 3/4: 0.202s\n",
      "[PROFILE] Inference batch 4/4: 0.192s\n",
      "[PROFILE] Inference batch 1/4: 0.207s\n",
      "[PROFILE] Inference batch 2/4: 0.193s\n",
      "[PROFILE] Inference batch 3/4: 0.191s\n",
      "[PROFILE] Inference batch 4/4: 0.190s\n",
      "[PROFILE] Inference batch 1/4: 0.074s\n",
      "[PROFILE] Inference batch 2/4: 0.073s\n",
      "[PROFILE] Inference batch 3/4: 0.073s\n",
      "[PROFILE] Inference batch 4/4: 0.075s\n",
      "Motor found in tomo_01a877 at position: z=142, y=641, x=285\n",
      "Current detection rate: 3/3 (100.0%)\n",
      "\n",
      "Submission complete!\n",
      "Motors detected: 3/3 (100.0%)\n",
      "Submission saved to: /kaggle/working/submission.csv\n",
      "\n",
      "Submission preview:\n",
      "       tomo_id  Motor axis 0  Motor axis 1  Motor axis 2\n",
      "0  tomo_003acc            -1            -1            -1\n",
      "1  tomo_00e047           164           544           602\n",
      "2  tomo_01a877           142           641           285\n",
      "\n",
      "Total execution time: 62.13 seconds (1.04 minutes)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "from ultralytics import YOLO\n",
    "import threading\n",
    "import time\n",
    "from contextlib import nullcontext\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Define paths\n",
    "data_path = \"/kaggle/input/byu-locating-bacterial-flagellar-motors-2025/\"\n",
    "test_dir = os.path.join(data_path, \"test\")\n",
    "submission_path = \"/kaggle/working/submission.csv\"\n",
    "\n",
    "# Model path - adjust if your best model is saved in a different location\n",
    "model_path = \"/kaggle/input/train-yolo/yolo_weights/motor_detector/weights/best.pt\"\n",
    "\n",
    "# Detection parameters\n",
    "CONFIDENCE_THRESHOLD = 0.45  # Lower threshold to catch more potential motors\n",
    "MAX_DETECTIONS_PER_TOMO = 3  # Keep track of top N detections per tomogram\n",
    "NMS_IOU_THRESHOLD = 0.2  # Non-maximum suppression threshold for 3D clustering\n",
    "CONCENTRATION = 1 # ONLY PROCESS 1/20 slices for fast submission\n",
    "\n",
    "# GPU profiling context manager\n",
    "class GPUProfiler:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.start_time = None\n",
    "        \n",
    "    def __enter__(self):\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.synchronize()\n",
    "        self.start_time = time.time()\n",
    "        return self\n",
    "        \n",
    "    def __exit__(self, *args):\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.synchronize()\n",
    "        elapsed = time.time() - self.start_time\n",
    "        print(f\"[PROFILE] {self.name}: {elapsed:.3f}s\")\n",
    "\n",
    "# Check GPU availability and set up optimizations\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "BATCH_SIZE = 8  # Default batch size, will be adjusted dynamically if GPU available\n",
    "\n",
    "if device.startswith('cuda'):\n",
    "    # Set CUDA optimization flags\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True  # Allow TF32 on Ampere GPUs\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "    \n",
    "    # Print GPU info\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1e9  # Convert to GB\n",
    "    print(f\"Using GPU: {gpu_name} with {gpu_mem:.2f} GB memory\")\n",
    "    \n",
    "    # Get available GPU memory and set batch size accordingly\n",
    "    free_mem = gpu_mem - torch.cuda.memory_allocated(0) / 1e9\n",
    "    BATCH_SIZE = max(8, min(32, int(free_mem * 4)))  # 4 images per GB as rough estimate\n",
    "    print(f\"Dynamic batch size set to {BATCH_SIZE} based on {free_mem:.2f}GB free memory\")\n",
    "else:\n",
    "    print(\"GPU not available, using CPU\")\n",
    "    BATCH_SIZE = 4  # Reduce batch size for CPU\n",
    "\n",
    "def normalize_slice(slice_data):\n",
    "    \"\"\"\n",
    "    Normalize slice data using 2nd and 98th percentiles for better contrast\n",
    "    \"\"\"\n",
    "    p2 = np.percentile(slice_data, 2)\n",
    "    p98 = np.percentile(slice_data, 98)\n",
    "    clipped_data = np.clip(slice_data, p2, p98)\n",
    "    normalized = 255 * (clipped_data - p2) / (p98 - p2)\n",
    "    return np.uint8(normalized)\n",
    "\n",
    "def preload_image_batch(file_paths):\n",
    "    \"\"\"Preload a batch of images to CPU memory\"\"\"\n",
    "    images = []\n",
    "    for path in file_paths:\n",
    "        img = cv2.imread(path)\n",
    "        if img is None:\n",
    "            # Try with PIL as fallback\n",
    "            img = np.array(Image.open(path))\n",
    "        images.append(img)\n",
    "    return images\n",
    "\n",
    "def process_tomogram(tomo_id, model, index=0, total=1):\n",
    "    \"\"\"\n",
    "    Process a single tomogram and return the most confident motor detection\n",
    "    \"\"\"\n",
    "    print(f\"Processing tomogram {tomo_id} ({index}/{total})\")\n",
    "    \n",
    "    # Get all slice files for this tomogram\n",
    "    tomo_dir = os.path.join(test_dir, tomo_id)\n",
    "    slice_files = sorted([f for f in os.listdir(tomo_dir) if f.endswith('.jpg')])\n",
    "    \n",
    "    # Apply CONCENTRATION to reduce the number of slices processed\n",
    "    # This will process approximately CONCENTRATION fraction of all slices\n",
    "    selected_indices = np.linspace(0, len(slice_files)-1, int(len(slice_files) * CONCENTRATION))\n",
    "    selected_indices = np.round(selected_indices).astype(int)\n",
    "    slice_files = [slice_files[i] for i in selected_indices]\n",
    "    \n",
    "    print(f\"Processing {len(slice_files)} out of {len(os.listdir(tomo_dir))} slices based on CONCENTRATION={CONCENTRATION}\")\n",
    "    \n",
    "    # Create a list to store all detections\n",
    "    all_detections = []\n",
    "    \n",
    "    # Create CUDA streams for parallel processing if using GPU\n",
    "    if device.startswith('cuda'):\n",
    "        streams = [torch.cuda.Stream() for _ in range(min(4, BATCH_SIZE))]\n",
    "    else:\n",
    "        streams = [None]\n",
    "    \n",
    "    # Variables for preloading\n",
    "    next_batch_thread = None\n",
    "    next_batch_images = None\n",
    "    \n",
    "    # Process slices in batches\n",
    "    for batch_start in range(0, len(slice_files), BATCH_SIZE):\n",
    "        # Wait for previous preload thread if it exists\n",
    "        if next_batch_thread is not None:\n",
    "            next_batch_thread.join()\n",
    "            next_batch_images = None\n",
    "            \n",
    "        batch_end = min(batch_start + BATCH_SIZE, len(slice_files))\n",
    "        batch_files = slice_files[batch_start:batch_end]\n",
    "        \n",
    "        # Start preloading next batch\n",
    "        next_batch_start = batch_end\n",
    "        next_batch_end = min(next_batch_start + BATCH_SIZE, len(slice_files))\n",
    "        next_batch_files = slice_files[next_batch_start:next_batch_end] if next_batch_start < len(slice_files) else []\n",
    "        \n",
    "        if next_batch_files:\n",
    "            next_batch_paths = [os.path.join(tomo_dir, f) for f in next_batch_files]\n",
    "            next_batch_thread = threading.Thread(target=preload_image_batch, args=(next_batch_paths,))\n",
    "            next_batch_thread.start()\n",
    "        else:\n",
    "            next_batch_thread = None\n",
    "        \n",
    "        # Split batch across streams for parallel processing\n",
    "        sub_batches = np.array_split(batch_files, len(streams))\n",
    "        sub_batch_results = []\n",
    "        \n",
    "        for i, sub_batch in enumerate(sub_batches):\n",
    "            if len(sub_batch) == 0:\n",
    "                continue\n",
    "                \n",
    "            stream = streams[i % len(streams)]\n",
    "            with torch.cuda.stream(stream) if stream and device.startswith('cuda') else nullcontext():\n",
    "                # Process sub-batch\n",
    "                sub_batch_paths = [os.path.join(tomo_dir, slice_file) for slice_file in sub_batch]\n",
    "                sub_batch_slice_nums = [int(slice_file.split('_')[1].split('.')[0]) for slice_file in sub_batch]\n",
    "                \n",
    "                # Run inference with profiling\n",
    "                with GPUProfiler(f\"Inference batch {i+1}/{len(sub_batches)}\"):\n",
    "                    sub_results = model(sub_batch_paths, verbose=False)\n",
    "                \n",
    "                # Process each result in this sub-batch\n",
    "                for j, result in enumerate(sub_results):\n",
    "                    if len(result.boxes) > 0:\n",
    "                        boxes = result.boxes\n",
    "                        for box_idx, confidence in enumerate(boxes.conf):\n",
    "                            if confidence >= CONFIDENCE_THRESHOLD:\n",
    "                                # Get bounding box coordinates\n",
    "                                x1, y1, x2, y2 = boxes.xyxy[box_idx].cpu().numpy()\n",
    "                                \n",
    "                                # Calculate center coordinates\n",
    "                                x_center = (x1 + x2) / 2\n",
    "                                y_center = (y1 + y2) / 2\n",
    "                                \n",
    "                                # Store detection with 3D coordinates\n",
    "                                all_detections.append({\n",
    "                                    'z': round(sub_batch_slice_nums[j]),\n",
    "                                    'y': round(y_center),\n",
    "                                    'x': round(x_center),\n",
    "                                    'confidence': float(confidence)\n",
    "                                })\n",
    "        \n",
    "        # Synchronize streams\n",
    "        if device.startswith('cuda'):\n",
    "            torch.cuda.synchronize()\n",
    "    \n",
    "    # Clean up thread if still running\n",
    "    if next_batch_thread is not None:\n",
    "        next_batch_thread.join()\n",
    "    \n",
    "    # 3D Non-Maximum Suppression to merge nearby detections across slices\n",
    "    final_detections = perform_3d_nms(all_detections, NMS_IOU_THRESHOLD)\n",
    "    \n",
    "    # Sort detections by confidence (highest first)\n",
    "    final_detections.sort(key=lambda x: x['confidence'], reverse=True)\n",
    "    \n",
    "    # If there are no detections, return NA values\n",
    "    if not final_detections:\n",
    "        return {\n",
    "            'tomo_id': tomo_id,\n",
    "            'Motor axis 0': -1,\n",
    "            'Motor axis 1': -1,\n",
    "            'Motor axis 2': -1\n",
    "        }\n",
    "    \n",
    "    # Take the detection with highest confidence\n",
    "    best_detection = final_detections[0]\n",
    "    \n",
    "    # Return result with integer coordinates\n",
    "    return {\n",
    "        'tomo_id': tomo_id,\n",
    "        'Motor axis 0': round(best_detection['z']),\n",
    "        'Motor axis 1': round(best_detection['y']),\n",
    "        'Motor axis 2': round(best_detection['x'])\n",
    "    }\n",
    "\n",
    "def perform_3d_nms(detections, iou_threshold):\n",
    "    \"\"\"\n",
    "    Perform 3D Non-Maximum Suppression on detections to merge nearby motors\n",
    "    \"\"\"\n",
    "    if not detections:\n",
    "        return []\n",
    "    \n",
    "    # Sort by confidence (highest first)\n",
    "    detections = sorted(detections, key=lambda x: x['confidence'], reverse=True)\n",
    "    \n",
    "    # List to store final detections after NMS\n",
    "    final_detections = []\n",
    "    \n",
    "    # Define 3D distance function\n",
    "    def distance_3d(d1, d2):\n",
    "        return np.sqrt((d1['z'] - d2['z'])**2 + \n",
    "                       (d1['y'] - d2['y'])**2 + \n",
    "                       (d1['x'] - d2['x'])**2)\n",
    "    \n",
    "    # Maximum distance threshold (based on box size and slice gap)\n",
    "    box_size = 24  # Same as annotation box size\n",
    "    distance_threshold = box_size * iou_threshold\n",
    "    \n",
    "    # Process each detection\n",
    "    while detections:\n",
    "        # Take the detection with highest confidence\n",
    "        best_detection = detections.pop(0)\n",
    "        final_detections.append(best_detection)\n",
    "        \n",
    "        # Filter out detections that are too close to the best detection\n",
    "        detections = [d for d in detections if distance_3d(d, best_detection) > distance_threshold]\n",
    "    \n",
    "    return final_detections\n",
    "\n",
    "def debug_image_loading(tomo_id):\n",
    "    \"\"\"\n",
    "    Debug function to check image loading\n",
    "    \"\"\"\n",
    "    tomo_dir = os.path.join(test_dir, tomo_id)\n",
    "    slice_files = sorted([f for f in os.listdir(tomo_dir) if f.endswith('.jpg')])\n",
    "    \n",
    "    if not slice_files:\n",
    "        print(f\"No image files found in {tomo_dir}\")\n",
    "        return\n",
    "        \n",
    "    print(f\"Found {len(slice_files)} image files in {tomo_dir}\")\n",
    "    sample_file = slice_files[len(slice_files)//2]  # Middle slice\n",
    "    img_path = os.path.join(tomo_dir, sample_file)\n",
    "    \n",
    "    # Try different loading methods\n",
    "    try:\n",
    "        # Method 1: PIL\n",
    "        img_pil = Image.open(img_path)\n",
    "        img_array_pil = np.array(img_pil)\n",
    "        print(f\"PIL Image shape: {img_array_pil.shape}, dtype: {img_array_pil.dtype}\")\n",
    "        \n",
    "        # Method 2: OpenCV\n",
    "        img_cv2 = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        print(f\"OpenCV Image shape: {img_cv2.shape}, dtype: {img_cv2.dtype}\")\n",
    "        \n",
    "        # Method 3: Convert to RGB\n",
    "        img_rgb = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
    "        print(f\"OpenCV RGB Image shape: {img_rgb.shape}, dtype: {img_rgb.dtype}\")\n",
    "        \n",
    "        print(\"Image loading successful!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {img_path}: {e}\")\n",
    "        \n",
    "    # Also test with YOLO's built-in loader\n",
    "    try:\n",
    "        test_model = YOLO(model_path)\n",
    "        test_results = test_model([img_path], verbose=False)\n",
    "        print(\"YOLO model successfully processed the test image\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error with YOLO processing: {e}\")\n",
    "\n",
    "def generate_submission():\n",
    "    \"\"\"\n",
    "    Main function to generate the submission file\n",
    "    \"\"\"\n",
    "    # Get list of test tomograms\n",
    "    test_tomos = sorted([d for d in os.listdir(test_dir) if os.path.isdir(os.path.join(test_dir, d))])\n",
    "    total_tomos = len(test_tomos)\n",
    "    \n",
    "    print(f\"Found {total_tomos} tomograms in test directory\")\n",
    "    \n",
    "    # Debug image loading for the first tomogram\n",
    "    if test_tomos:\n",
    "        debug_image_loading(test_tomos[0])\n",
    "    \n",
    "    # Clear GPU cache before starting\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # Initialize model once outside the processing loop\n",
    "    print(f\"Loading YOLO model from {model_path}\")\n",
    "    model = YOLO(model_path)\n",
    "    model.to(device)\n",
    "    \n",
    "    # Additional optimizations for inference\n",
    "    if device.startswith('cuda'):\n",
    "        # Fuse conv and bn layers for faster inference\n",
    "        model.fuse()\n",
    "        \n",
    "        # Enable model half precision (FP16) if on compatible GPU\n",
    "        if torch.cuda.get_device_capability(0)[0] >= 7:  # Volta or newer\n",
    "            model.model.half()\n",
    "            print(\"Using half precision (FP16) for inference\")\n",
    "    \n",
    "    # Process tomograms with parallelization\n",
    "    results = []\n",
    "    motors_found = 0\n",
    "    \n",
    "    # Using ThreadPoolExecutor with max_workers=1 since each worker uses the GPU already\n",
    "    # and we're parallelizing within each tomogram processing\n",
    "    with ThreadPoolExecutor(max_workers=1) as executor:\n",
    "        future_to_tomo = {}\n",
    "        \n",
    "        # Submit all tomograms for processing\n",
    "        for i, tomo_id in enumerate(test_tomos, 1):\n",
    "            future = executor.submit(process_tomogram, tomo_id, model, i, total_tomos)\n",
    "            future_to_tomo[future] = tomo_id\n",
    "        \n",
    "        # Process completed futures as they complete\n",
    "        for future in future_to_tomo:\n",
    "            tomo_id = future_to_tomo[future]\n",
    "            try:\n",
    "                # Clear CUDA cache between tomograms\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                    \n",
    "                result = future.result()\n",
    "                results.append(result)\n",
    "                \n",
    "                # Update motors found count\n",
    "                has_motor = not pd.isna(result['Motor axis 0'])\n",
    "                if has_motor:\n",
    "                    motors_found += 1\n",
    "                    print(f\"Motor found in {tomo_id} at position: \"\n",
    "                          f\"z={result['Motor axis 0']}, y={result['Motor axis 1']}, x={result['Motor axis 2']}\")\n",
    "                else:\n",
    "                    print(f\"No motor detected in {tomo_id}\")\n",
    "                    \n",
    "                print(f\"Current detection rate: {motors_found}/{len(results)} ({motors_found/len(results)*100:.1f}%)\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {tomo_id}: {e}\")\n",
    "                # Create a default entry for failed tomograms\n",
    "                results.append({\n",
    "                    'tomo_id': tomo_id,\n",
    "                    'Motor axis 0': -1,\n",
    "                    'Motor axis 1': -1,\n",
    "                    'Motor axis 2': -1\n",
    "                })\n",
    "    \n",
    "    # Create submission dataframe\n",
    "    submission_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Ensure proper column order\n",
    "    submission_df = submission_df[['tomo_id', 'Motor axis 0', 'Motor axis 1', 'Motor axis 2']]\n",
    "    \n",
    "    # Save the submission file\n",
    "    submission_df.to_csv(submission_path, index=False)\n",
    "    \n",
    "    print(f\"\\nSubmission complete!\")\n",
    "    print(f\"Motors detected: {motors_found}/{total_tomos} ({motors_found/total_tomos*100:.1f}%)\")\n",
    "    print(f\"Submission saved to: {submission_path}\")\n",
    "    \n",
    "    # Display first few rows of submission\n",
    "    print(\"\\nSubmission preview:\")\n",
    "    print(submission_df.head())\n",
    "    \n",
    "    return submission_df\n",
    "\n",
    "# Run the submission pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    # Time entire process\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Generate submission\n",
    "    submission = generate_submission()\n",
    "    \n",
    "    # Print total execution time\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\nTotal execution time: {elapsed:.2f} seconds ({elapsed/60:.2f} minutes)\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11294684,
     "sourceId": 91249,
     "sourceType": "competition"
    },
    {
     "sourceId": 224916709,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 226382143,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 145.218517,
   "end_time": "2025-04-28T19:55:47.270046",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-28T19:53:22.051529",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
