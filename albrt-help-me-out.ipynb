{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":94147,"databundleVersionId":11390004,"sourceType":"competition"}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ALBRT, help me out\n\nThis notebook attempts to reproduce this paper: https://github.com/engrodawood/ALBRT\n\nThe paper used two datasets for training:\n\n- [NuCL](https://drive.google.com/drive/folders/1ER1fnse5FXotFeQnbrbjff09rI5wAnEn) (mostly cancer slices from TCGA)\n- ","metadata":{}},{"cell_type":"code","source":"# ================================\n# 1. Import Required Libraries\n# ================================\nimport os\nimport h5py\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport pickle\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Rectangle\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.multioutput import MultiOutputRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.applications.resnet50 import preprocess_input\nfrom tensorflow.keras.models import Model\n\nfrom skimage.registration import phase_cross_correlation\n\n# ================================\n# 2. Define Helper Functions and Transformers\n# ================================\ndef extract_patch(image, center, patch_size):\n    \"\"\"\n    Extract a square patch from the image centered at 'center'.\n    \"\"\"\n    x, y = int(center[0]), int(center[1])\n    half_size = patch_size // 2\n    y_min = max(y - half_size, 0)\n    y_max = min(y + half_size, image.shape[0])\n    x_min = max(x - half_size, 0)\n    x_max = min(x + half_size, image.shape[1])\n    patch = image[y_min:y_max, x_min:x_max, :]\n    return patch\n\n# Transformer to extract CNN features from image patches.\nclass PatchFeatureExtractor(BaseEstimator, TransformerMixin):\n    def __init__(self, image, patch_size, cnn_model):\n        self.image = image\n        self.patch_size = patch_size\n        self.cnn_model = cnn_model\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        patches = []\n        for coord in X:\n            patch = extract_patch(self.image, coord, self.patch_size)\n            patch_resized = cv2.resize(patch, (224, 224))\n            patches.append(patch_resized)\n        patches = np.array(patches)\n        patches_preprocessed = preprocess_input(patches.astype(np.float32))\n        features = self.cnn_model.predict(patches_preprocessed, verbose=0)\n        # Reshape features to 2D (one row per patch)\n        features = features.reshape(features.shape[0], -1)\n        return features\n\n# ================================\n# 3. Define the CellTypePipeline Class\n# ================================\nclass CellTypePipeline:\n    \"\"\"\n    Pipeline for training ALBRT on competition data.\n    This class loads training images and spot data from the H5 file,\n    extracts CNN features from patches using a pre-trained CNN,\n    and trains a multi-output regression model to predict cell type abundances.\n    \"\"\"\n    def __init__(self, h5_file_path, patch_size=64):\n        self.h5_file_path = h5_file_path\n        self.patch_size = patch_size\n        self.train_spot_tables = {}\n        self.train_images = {}\n        self.cell_type_columns = None\n        self.cnn_model = None  # Will be initialized below\n        self.feature_extractor_pipeline = None\n\n    def initialize_cnn_model(self):\n        \"\"\"\n        Initialize a ResNet50 CNN model.\n        Here you can choose to initialize with ImageNet weights or (if available)\n        fine-tune on histopathological data.\n        \"\"\"\n        base_model = ResNet50(weights='imagenet', include_top=False, pooling='avg')\n        self.cnn_model = Model(inputs=base_model.input, outputs=base_model.output)\n        print(\"CNN model initialized.\")\n\n    def load_train_data(self):\n        \"\"\"\n        Load training spot data from the H5 file.\n        Each slide's spot data is stored in a separate DataFrame.\n        \"\"\"\n        with h5py.File(self.h5_file_path, \"r\") as f:\n            train_spots = f[\"spots/Train\"]\n            for slide_name in train_spots.keys():\n                # Assume first two columns are coordinates and the rest are cell type abundances.\n                spot_array = np.array(train_spots[slide_name])\n                df = pd.DataFrame(spot_array, columns=[\"x\", \"y\"] + [f\"C{i}\" for i in range(1, 36)])\n                self.train_spot_tables[slide_name] = df\n        print(\"Training spot data loaded.\")\n\n    def load_train_images(self):\n        \"\"\"\n        Load training images from the H5 file.\n        \"\"\"\n        with h5py.File(self.h5_file_path, \"r\") as f:\n            train_imgs = f[\"images/Train\"]\n            for slide_name in train_imgs.keys():\n                image_array = np.array(train_imgs[slide_name])\n                self.train_images[slide_name] = image_array\n        print(\"Training images loaded.\")\n\n    def prepare_training_set(self, slide_id, cache_path=None):\n        \"\"\"\n        For a given slide, extract CNN features from patches around each spot and\n        return the features (X) along with the target cell type abundances (y).\n        Optionally, cache the extracted features.\n        \"\"\"\n        if cache_path is not None and os.path.exists(cache_path):\n            print(f\"Loading cached features from {cache_path} for slide {slide_id} ...\")\n            with open(cache_path, \"rb\") as f:\n                X_features, y = pickle.load(f)\n            return X_features, y\n\n        if slide_id not in self.train_spot_tables or slide_id not in self.train_images:\n            raise ValueError(f\"Slide {slide_id} not found in training data.\")\n\n        df = self.train_spot_tables[slide_id]\n        # Coordinates are the first two columns.\n        feature_cols = ['x', 'y']\n        # The remaining columns are the cell type abundances.\n        target_cols = [col for col in df.columns if col not in feature_cols]\n        self.cell_type_columns = target_cols\n\n        X_coords = df[feature_cols].values.astype(float)\n        y = df[target_cols].values.astype(float)\n\n        # (Optional) Registration/alignment could be applied here.\n        # For simplicity, we assume the spots are already well-aligned.\n\n        he_image = self.train_images[slide_id]\n        patch_extractor = PatchFeatureExtractor(he_image, self.patch_size, self.cnn_model)\n        self.feature_extractor_pipeline = Pipeline([\n            ('patch_extractor', patch_extractor),\n            ('scaler', StandardScaler())\n        ])\n\n        print(f\"Extracting CNN features for slide {slide_id} ...\")\n        X_features = self.feature_extractor_pipeline.fit_transform(X_coords)\n\n        if cache_path is not None:\n            with open(cache_path, \"wb\") as f:\n                pickle.dump((X_features, y), f)\n        return X_features, y\n\n    def prepare_all_training_set(self, cache_dir=None):\n        \"\"\"\n        Concatenate training features from all slides into a single training set.\n        \"\"\"\n        X_list, y_list = [], []\n        for slide_id in sorted(self.train_spot_tables.keys()):\n            slide_cache_path = os.path.join(cache_dir, f\"train_features_{slide_id}.pkl\") if cache_dir else None\n            X, y = self.prepare_training_set(slide_id, cache_path=slide_cache_path)\n            X_list.append(X)\n            y_list.append(y)\n        X_all = np.concatenate(X_list, axis=0)\n        y_all = np.concatenate(y_list, axis=0)\n        print(\"All training features extracted and concatenated.\")\n        return X_all, y_all\n\n    def build_regression_pipeline(self):\n        \"\"\"\n        Build a regression pipeline with a multi-output RandomForest regressor.\n        \"\"\"\n        pipeline = Pipeline([\n            ('regressor', MultiOutputRegressor(RandomForestRegressor(n_estimators=100, random_state=42)))\n        ])\n        return pipeline\n\n    def train(self, X, y):\n        \"\"\"\n        Train the regression model on the provided features and targets.\n        \"\"\"\n        reg_pipeline = self.build_regression_pipeline()\n        reg_pipeline.fit(X, y)\n        print(\"Regression model trained.\")\n        return reg_pipeline\n\n    def predict(self, reg_model, X_test):\n        \"\"\"\n        Predict cell type abundances using the regression model.\n        \"\"\"\n        predictions = reg_model.predict(X_test)\n        return predictions\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T12:15:17.964989Z","iopub.execute_input":"2025-04-03T12:15:17.965235Z","iopub.status.idle":"2025-04-03T12:15:35.890121Z","shell.execute_reply.started":"2025-04-03T12:15:17.965210Z","shell.execute_reply":"2025-04-03T12:15:35.889249Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!mkdir -p /working/cache_dir","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T12:21:11.070363Z","iopub.execute_input":"2025-04-03T12:21:11.070741Z","iopub.status.idle":"2025-04-03T12:21:11.224507Z","shell.execute_reply.started":"2025-04-03T12:21:11.070708Z","shell.execute_reply":"2025-04-03T12:21:11.223217Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ================================\n# 4. Train ALBRT on Competition Data\n# ================================\n# Update this path to point to your competition H5 file.\nh5_file_path = \"/kaggle/input/el-hackathon-2025/elucidata_ai_challenge_data.h5\"\n\n# Create the pipeline and load data.\npipeline = CellTypePipeline(h5_file_path, patch_size=64)\npipeline.initialize_cnn_model()\npipeline.load_train_data()\npipeline.load_train_images()\n\n# Prepare the full training set (optionally using a cache directory).\nX_train, y_train = pipeline.prepare_all_training_set(cache_dir=\"/working/cache_dir\")\n\nprint(\"Training a regression model\")\n# Train the regression model.\nreg_model = pipeline.train(X_train, y_train)\n\nprint(\"Writing to Pkl\")\n# Save the trained regression model for later inference.\nwith open(\"trained_regression_model.pkl\", \"wb\") as f:\n    pickle.dump(reg_model, f)\nprint(\"Trained regression model saved.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T12:21:12.670236Z","iopub.execute_input":"2025-04-03T12:21:12.670597Z","execution_failed":"2025-04-04T08:02:46.371Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# ================================\n# 5. Minimal Inference on a Test Slide\n# ================================\ndef load_test_data(h5_file_path, slide_id):\n    \"\"\"\n    Load test image and spot coordinates from the H5 file.\n    \"\"\"\n    with h5py.File(h5_file_path, \"r\") as f:\n        test_image = np.array(f[\"images/Test\"][slide_id])\n        test_spots_array = np.array(f[\"spots/Test\"][slide_id])\n        test_spots_df = pd.DataFrame(test_spots_array, columns=[\"x\", \"y\"])\n    print(f\"Test data for slide {slide_id} loaded.\")\n    return test_image, test_spots_df\n\ndef extract_features_test(image, spots_df, cnn_model, patch_size=64):\n    \"\"\"\n    Extract CNN features from test patches around each spot.\n    \"\"\"\n    features = []\n    for _, row in spots_df.iterrows():\n        coord = (row['x'], row['y'])\n        patch = extract_patch(image, coord, patch_size)\n        patch_resized = cv2.resize(patch, (224, 224))\n        patch_preprocessed = preprocess_input(np.expand_dims(patch_resized.astype(np.float32), axis=0))\n        feat = cnn_model.predict(patch_preprocessed, verbose=0)\n        features.append(feat.flatten())\n    features = np.array(features)\n    return features\n\ndef minimal_inference(h5_file_path, slide_id, cnn_model, reg_model, patch_size=64):\n    \"\"\"\n    Run minimal inference on a test slide:\n      1. Load test image and spot coordinates.\n      2. Extract CNN features from patches.\n      3. Predict cell type abundances.\n      4. Save a submission CSV.\n    \"\"\"\n    test_image, test_spots_df = load_test_data(h5_file_path, slide_id)\n    # (Optional: add registration here if needed.)\n    test_features = extract_features_test(test_image, test_spots_df, cnn_model, patch_size=patch_size)\n    predictions = reg_model.predict(test_features)\n    cell_type_columns = [f\"C{i}\" for i in range(1, 36)]\n    pred_df = pd.DataFrame(predictions, columns=cell_type_columns, index=test_spots_df.index)\n    pred_df.insert(0, 'ID', pred_df.index)\n    submission_filename = f\"submission_{slide_id}.csv\"\n    pred_df.to_csv(submission_filename, index=False)\n    print(f\"Submission file '{submission_filename}' created!\")\n    return predictions\n\n# Run minimal inference on a test slide (update the slide ID as needed)\ntest_slide_id = \"S_1\"  # Update as necessary\npredictions = minimal_inference(h5_file_path, test_slide_id, pipeline.cnn_model, reg_model, patch_size=64)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-04T08:02:46.373Z"}},"outputs":[],"execution_count":null}]}