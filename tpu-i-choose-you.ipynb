{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.16","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install -q pytorch-tabnet lightgbm catboost xgboost\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T20:36:01.304453Z","iopub.execute_input":"2025-05-03T20:36:01.304805Z","iopub.status.idle":"2025-05-03T20:36:05.005938Z","shell.execute_reply.started":"2025-05-03T20:36:01.304780Z","shell.execute_reply":"2025-05-03T20:36:05.000922Z"}},"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"!ls /input","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T20:36:05.009039Z","iopub.execute_input":"2025-05-03T20:36:05.009380Z","iopub.status.idle":"2025-05-03T20:36:05.161075Z","shell.execute_reply.started":"2025-05-03T20:36:05.009329Z","shell.execute_reply":"2025-05-03T20:36:05.154399Z"}},"outputs":[{"name":"stdout","text":"ls: cannot access '/input': No such file or directory\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_log_error\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch_xla\nimport torch_xla.core.xla_model as xm\nfrom torch.utils.data import Dataset, DataLoader, TensorDataset\n\nfrom pytorch_tabnet.tab_model import TabNetRegressor\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom catboost import CatBoostRegressor\n\n# RMSLE Metric\ndef rmsle(y_true, y_pred):\n    return np.sqrt(mean_squared_log_error(y_true, np.maximum(0, y_pred)))\n\n# Dataset\ndf = pd.read_csv(\"/kaggle/input/playground-series-s5e5/train.csv\")  # Replace with correct path\nTARGET = \"Calories\"\nNUM_FEATURES = [\"Age\", \"Height\", \"Weight\", \"Duration\", \"Heart_Rate\", \"Body_Temp\"]\nCAT_FEATURES = [\"Sex\"]\n\n# Preprocessing pipeline","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T20:36:05.162182Z","iopub.execute_input":"2025-05-03T20:36:05.162442Z","iopub.status.idle":"2025-05-03T20:36:05.685603Z","shell.execute_reply.started":"2025-05-03T20:36:05.162416Z","shell.execute_reply":"2025-05-03T20:36:05.680969Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"\npreprocessor = ColumnTransformer(transformers=[\n    ('num', StandardScaler(), NUM_FEATURES),\n    ('cat', OneHotEncoder(handle_unknown=\"ignore\"), CAT_FEATURES)\n])\n\nX = df[NUM_FEATURES + CAT_FEATURES]\ny = df[TARGET].values\nX_proc = preprocessor.fit_transform(X)\n\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\noof_preds = []\nmodels = []\n\n# Blend 5 models: LGBM, CatBoost, XGBoost, TabNet, PyTorch MLP\nfor fold, (train_idx, val_idx) in enumerate(kf.split(X_proc)):\n    print(f\"\\nFold {fold+1}\")\n    X_train, X_val = X_proc[train_idx], X_proc[val_idx]\n    y_train, y_val = y[train_idx], y[val_idx]\n\n    preds_fold = []\n\n    # LightGBM\n    model_lgb = lgb.LGBMRegressor(n_estimators=1000)\n    model_lgb.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=50, verbose=False)\n    preds_fold.append(model_lgb.predict(X_val))\n    \n    # CatBoost\n    model_cat = CatBoostRegressor(verbose=0, iterations=1000, early_stopping_rounds=50)\n    model_cat.fit(X_train, y_train, eval_set=(X_val, y_val))\n    preds_fold.append(model_cat.predict(X_val))\n    \n    # XGBoost\n    model_xgb = xgb.XGBRegressor(n_estimators=1000)\n    model_xgb.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=50, verbose=False)\n    preds_fold.append(model_xgb.predict(X_val))\n\n    # TabNet\n    tabnet = TabNetRegressor()\n    tabnet.fit(\n        X_train=X_train, y_train=y_train.reshape(-1, 1),\n        eval_set=[(X_val, y_val.reshape(-1, 1))],\n        eval_metric=['rmse'], max_epochs=200,\n        patience=20, verbose=0\n    )\n    preds_fold.append(tabnet.predict(X_val).ravel())\n\n    # MLP on TPU\n    class MLP(nn.Module):\n        def __init__(self, input_dim):\n            super().__init__()\n            self.model = nn.Sequential(\n                nn.Linear(input_dim, 128),\n                nn.ReLU(),\n                nn.Dropout(0.2),\n                nn.Linear(128, 64),\n                nn.ReLU(),\n                nn.Linear(64, 1)\n            )\n\n        def forward(self, x):\n            return self.model(x).squeeze(1)\n\n    device = xm.xla_device()\n    model_mlp = MLP(X_train.shape[1]).to(device)\n    loss_fn = nn.MSELoss()\n    optimizer = optim.Adam(model_mlp.parameters(), lr=1e-3)\n\n    train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32))\n    val_dataset = TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.float32))\n    train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False)\n\n    for epoch in range(20):  # Short training for demonstration\n        model_mlp.train()\n        for xb, yb in train_loader:\n            xb, yb = xb.to(device), yb.to(device)\n            optimizer.zero_grad()\n            preds = model_mlp(xb)\n            loss = loss_fn(preds, yb)\n            loss.backward()\n            xm.optimizer_step(optimizer)\n\n    model_mlp.eval()\n    with torch.no_grad():\n        val_tensor = torch.tensor(X_val, dtype=torch.float32).to(device)\n        preds_mlp = model_mlp(val_tensor).cpu().numpy()\n    preds_fold.append(preds_mlp)\n\n    # Blend predictions by mean\n    blended = np.mean(preds_fold, axis=0)\n    score = rmsle(y_val, blended)\n    print(f\"Fold RMSLE: {score:.4f}\")\n    oof_preds.extend(blended)\n    models.append({\n        'lgb': model_lgb,\n        'cat': model_cat,\n        'xgb': model_xgb,\n        'tabnet': tabnet,\n        'mlp': model_mlp\n    })\n\n\nfinal_score = rmsle(y, oof_preds)\nprint(f\"\\nOverall OOF RMSLE: {final_score:.4f}\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-03T20:36:05.688217Z","iopub.execute_input":"2025-05-03T20:36:05.688453Z","iopub.status.idle":"2025-05-03T20:36:06.144069Z","shell.execute_reply.started":"2025-05-03T20:36:05.688431Z","shell.execute_reply":"2025-05-03T20:36:06.138523Z"}},"outputs":[{"name":"stdout","text":"\nFold 1\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[11], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# LightGBM\u001b[39;00m\n\u001b[1;32m     23\u001b[0m model_lgb \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mLGBMRegressor(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m \u001b[43mmodel_lgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m preds_fold\u001b[38;5;241m.\u001b[39mappend(model_lgb\u001b[38;5;241m.\u001b[39mpredict(X_val))\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# CatBoost\u001b[39;00m\n","\u001b[0;31mTypeError\u001b[0m: LGBMRegressor.fit() got an unexpected keyword argument 'early_stopping_rounds'"],"ename":"TypeError","evalue":"LGBMRegressor.fit() got an unexpected keyword argument 'early_stopping_rounds'","output_type":"error"}],"execution_count":11},{"cell_type":"code","source":"# Read test set\ntest_df = pd.read_csv(\"/kaggle/input/playground-series-s5e5/test.csv\")\nX_test = test_df[NUM_FEATURES + CAT_FEATURES]\nX_test_proc = preprocessor.transform(X_test)\n\n# Initialize list to hold test predictions from each fold\ntest_preds = []\n\nfor fold in range(5):\n    fold_preds = []\n\n    # Predict with each model saved per fold\n    fold_preds.append(models[fold]['lgb'].predict(X_test_proc))\n    fold_preds.append(models[fold]['cat'].predict(X_test_proc))\n    fold_preds.append(models[fold]['xgb'].predict(X_test_proc))\n    fold_preds.append(models[fold]['tabnet'].predict(X_test_proc).ravel())\n\n    # MLP\n    model_mlp = models[fold]['mlp']\n    model_mlp.eval()\n    with torch.no_grad():\n        X_test_tensor = torch.tensor(X_test_proc, dtype=torch.float32).to(device)\n        preds_mlp = model_mlp(X_test_tensor).cpu().numpy()\n    fold_preds.append(preds_mlp)\n\n    # Average predictions from all 5 models for this fold\n    test_preds.append(np.mean(fold_preds, axis=0))\n\n# Average across folds\nfinal_preds = np.mean(test_preds, axis=0)\n\n# Prepare submission file\nsubmission = pd.DataFrame({\n    \"id\": test_df[\"id\"],\n    \"Calories\": final_preds\n})\nsubmission.to_csv(\"submission.csv\", index=False)\nprint(\"✅ submission.csv saved!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T20:36:06.146337Z","iopub.status.idle":"2025-05-03T20:36:06.148569Z","shell.execute_reply.started":"2025-05-03T20:36:06.146555Z","shell.execute_reply":"2025-05-03T20:36:06.146572Z"}},"outputs":[],"execution_count":null}]}