{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b4b0798",
   "metadata": {
    "papermill": {
     "duration": 0.003751,
     "end_time": "2025-12-14T14:42:12.085302",
     "exception": false,
     "start_time": "2025-12-14T14:42:12.081551",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ðŸ§  Hull Tactical Market Prediction â€” AutoGluon Baseline\n",
    "\n",
    "This notebook builds a baseline model for the [**Hull Tactical Market Prediction**](https://www.kaggle.com/competitions/hull-tactical-market-prediction) competition using **AutoGluon Tabular**. The goal is to predict trading positions that maximize a Sharpe-like performance metric.  \n",
    "\n",
    "## Overview\n",
    "- **Task:** Predict next-period trading positions (long / flat) using engineered financial features.\n",
    "- **Approach:** Train an AutoGluon model on historical data to predict *forward returns*, then post-process those predictions into positions for scoring and submission.\n",
    "- **Metric:** Custom approximation of the competitionâ€™s adjusted Sharpe ratio, which penalizes volatility and underperformance.\n",
    "- **Post-processing:** A unified `post_process_signal()` function ensures parity between local validation and leaderboard logic by converting model predictions into bounded investment positions.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98082ae8",
   "metadata": {
    "papermill": {
     "duration": 0.002508,
     "end_time": "2025-12-14T14:42:12.090814",
     "exception": false,
     "start_time": "2025-12-14T14:42:12.088306",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Install Autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed084645",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T14:42:12.097717Z",
     "iopub.status.busy": "2025-12-14T14:42:12.097359Z",
     "iopub.status.idle": "2025-12-14T14:44:46.983328Z",
     "shell.execute_reply": "2025-12-14T14:44:46.982002Z"
    },
    "papermill": {
     "duration": 154.891631,
     "end_time": "2025-12-14T14:44:46.985159",
     "exception": false,
     "start_time": "2025-12-14T14:42:12.093528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\r\n",
      "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.5.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "WHEELS = Path(\"/kaggle/input/autogluon-1-4-0-offline\")  # <- your dataset\n",
    "\n",
    "!pip install --no-index --quiet --find-links=\"{WHEELS}\" \\\n",
    "  \"torch==2.5.1\" \"torchvision==0.20.1\" \"torchaudio==2.5.1\" \"bitsandbytes>=0.46.1\" \"mlforecast==0.14.0\" \"optuna==4.3.0\"\n",
    "\n",
    "!pip install --no-index --quiet --find-links=\"{WHEELS}\" \\\n",
    "    \"autogluon.tabular\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc548ebf",
   "metadata": {
    "papermill": {
     "duration": 0.002685,
     "end_time": "2025-12-14T14:44:46.991075",
     "exception": false,
     "start_time": "2025-12-14T14:44:46.988390",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Parameters and Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d45194b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T14:44:46.998400Z",
     "iopub.status.busy": "2025-12-14T14:44:46.998058Z",
     "iopub.status.idle": "2025-12-14T14:44:53.102488Z",
     "shell.execute_reply": "2025-12-14T14:44:53.101606Z"
    },
    "papermill": {
     "duration": 6.110299,
     "end_time": "2025-12-14T14:44:53.104285",
     "exception": false,
     "start_time": "2025-12-14T14:44:46.993986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Hull Tactical Kaggle â€” AutoGluon train/infer + organizer metric selection\n",
    "# Copy/paste notebook cell(s)\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "# -------------------------\n",
    "# USER CONTROLS\n",
    "# -------------------------\n",
    "# notebook_mode:\n",
    "#   \"training\"  -> fit model (and optionally tune postprocess on holdout), save under /kaggle/working\n",
    "#   \"inference\" -> load model from Kaggle dataset input and only predict\n",
    "notebook_mode = \"training\"\n",
    "assert notebook_mode in (\"training\", \"inference\")\n",
    "\n",
    "# approach:\n",
    "#   \"rmse_forward\"  -> predict forward_returns (classic regression)\n",
    "#   \"rmse_excess\"   -> predict excess returns: forward_returns - risk_free_rate (often aligns better with scorer)\n",
    "#   \"metric_tune\"   -> still trains RMSE, but selects tau/alpha by maximizing organizer score on a holdout split\n",
    "approach = \"rmse_forward\"\n",
    "assert approach in (\"rmse_forward\", \"rmse_excess\", \"metric_tune\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b37aefa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T14:44:53.112023Z",
     "iopub.status.busy": "2025-12-14T14:44:53.111511Z",
     "iopub.status.idle": "2025-12-14T14:44:53.117575Z",
     "shell.execute_reply": "2025-12-14T14:44:53.116613Z"
    },
    "papermill": {
     "duration": 0.011586,
     "end_time": "2025-12-14T14:44:53.119081",
     "exception": false,
     "start_time": "2025-12-14T14:44:53.107495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Where the competition data is\n",
    "DATA_PATH = \"/kaggle/input/hull-tactical-market-prediction/\"\n",
    "\n",
    "# Where a pre-trained AutoGluon model is stored (input dataset)\n",
    "PRETRAINED_MODEL_DIR = Path(\"/kaggle/input/hull-tactical-autogluon-train-and-infer-tabular/AutogluonModels\")\n",
    "\n",
    "# Where to write models when training in this notebook\n",
    "WORKING_MODEL_DIR = Path(\"/kaggle/working/AutogluonModels\")\n",
    "\n",
    "# Train settings (adjust)\n",
    "AG_PRESET = \"best_quality\" \n",
    "TIME_LIMIT_SECS = 60 * 60 * 0.2\n",
    "\n",
    "# Holdout split for metric_tune\n",
    "HOLDOUT_FRAC = 0.2\n",
    "\n",
    "# Postprocess (defaults; may be overwritten by metric tuning)\n",
    "MIN_INVESTMENT = 0.0\n",
    "MAX_INVESTMENT = 2.0\n",
    "TAU_ABS_FOR_SCORER = 9.43717e-05\n",
    "ALPHA_FOR_SCORER = 0.600132\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94dadc06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T14:44:53.126636Z",
     "iopub.status.busy": "2025-12-14T14:44:53.126302Z",
     "iopub.status.idle": "2025-12-14T14:44:53.139022Z",
     "shell.execute_reply": "2025-12-14T14:44:53.137793Z"
    },
    "papermill": {
     "duration": 0.018506,
     "end_time": "2025-12-14T14:44:53.140724",
     "exception": false,
     "start_time": "2025-12-14T14:44:53.122218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# ORGANIZER SCORER (as provided)\n",
    "# =========================\n",
    "import pandas.api.types\n",
    "\n",
    "class ParticipantVisibleError(Exception):\n",
    "    pass\n",
    "\n",
    "def organizer_score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str) -> float:\n",
    "    if not pandas.api.types.is_numeric_dtype(submission['prediction']):\n",
    "        raise ParticipantVisibleError('Predictions must be numeric')\n",
    "\n",
    "    solution = solution.copy()\n",
    "    solution['position'] = submission['prediction']\n",
    "\n",
    "    if solution['position'].max() > MAX_INVESTMENT:\n",
    "        raise ParticipantVisibleError(f'Position of {solution[\"position\"].max()} exceeds maximum of {MAX_INVESTMENT}')\n",
    "    if solution['position'].min() < MIN_INVESTMENT:\n",
    "        raise ParticipantVisibleError(f'Position of {solution[\"position\"].min()} below minimum of {MIN_INVESTMENT}')\n",
    "\n",
    "    solution['strategy_returns'] = solution['risk_free_rate'] * (1 - solution['position']) + solution['position'] * solution['forward_returns']\n",
    "\n",
    "    # Calculate strategy's Sharpe ratio\n",
    "    strategy_excess_returns = solution['strategy_returns'] - solution['risk_free_rate']\n",
    "    strategy_excess_cumulative = (1 + strategy_excess_returns).prod()\n",
    "    strategy_mean_excess_return = (strategy_excess_cumulative) ** (1 / len(solution)) - 1\n",
    "    strategy_std = solution['strategy_returns'].std()\n",
    "\n",
    "    trading_days_per_yr = 252\n",
    "    if strategy_std == 0:\n",
    "        raise ParticipantVisibleError('Division by zero, strategy std is zero')\n",
    "    sharpe = strategy_mean_excess_return / strategy_std * np.sqrt(trading_days_per_yr)\n",
    "    strategy_volatility = float(strategy_std * np.sqrt(trading_days_per_yr) * 100)\n",
    "\n",
    "    # Calculate market return and volatility\n",
    "    market_excess_returns = solution['forward_returns'] - solution['risk_free_rate']\n",
    "    market_excess_cumulative = (1 + market_excess_returns).prod()\n",
    "    market_mean_excess_return = (market_excess_cumulative) ** (1 / len(solution)) - 1\n",
    "    market_std = solution['forward_returns'].std()\n",
    "\n",
    "    market_volatility = float(market_std * np.sqrt(trading_days_per_yr) * 100)\n",
    "\n",
    "    if market_volatility == 0:\n",
    "        raise ParticipantVisibleError('Division by zero, market std is zero')\n",
    "\n",
    "    # Calculate the volatility penalty\n",
    "    excess_vol = max(0, strategy_volatility / market_volatility - 1.2) if market_volatility > 0 else 0\n",
    "    vol_penalty = 1 + excess_vol\n",
    "\n",
    "    # Calculate the return penalty\n",
    "    return_gap = max(\n",
    "        0,\n",
    "        (market_mean_excess_return - strategy_mean_excess_return) * 100 * trading_days_per_yr,\n",
    "    )\n",
    "    return_penalty = 1 + (return_gap**2) / 100\n",
    "\n",
    "    adjusted_sharpe = sharpe / (vol_penalty * return_penalty)\n",
    "    return min(float(adjusted_sharpe), 1_000_000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad5f40e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T14:44:53.148369Z",
     "iopub.status.busy": "2025-12-14T14:44:53.148036Z",
     "iopub.status.idle": "2025-12-14T14:44:53.154635Z",
     "shell.execute_reply": "2025-12-14T14:44:53.153567Z"
    },
    "papermill": {
     "duration": 0.012441,
     "end_time": "2025-12-14T14:44:53.156363",
     "exception": false,
     "start_time": "2025-12-14T14:44:53.143922",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# =========================\n",
    "# POST-PROCESS: raw prediction -> position in [0,2]\n",
    "# =========================\n",
    "def post_process_signal(y_pred,\n",
    "                        *,\n",
    "                        tau: float = TAU_ABS_FOR_SCORER,\n",
    "                        alpha: float = ALPHA_FOR_SCORER,\n",
    "                        min_investment: float = MIN_INVESTMENT,\n",
    "                        max_investment: float = MAX_INVESTMENT):\n",
    "    sig = np.asarray(y_pred, dtype=float).ravel()\n",
    "    pos = np.where(sig > tau, alpha, 0.0)\n",
    "    return np.clip(pos, min_investment, max_investment)\n",
    "\n",
    "# =========================\n",
    "# COLUMNS\n",
    "# =========================\n",
    "# Keep these for scorer / sanity.\n",
    "NEEDED_FOR_SCORER = [\"risk_free_rate\", \"forward_returns\"]\n",
    "\n",
    "# Non-feature columns to drop at inference & (optionally) training.\n",
    "# NOTE: do NOT drop risk_free_rate in rmse_excess / metric_tune (it can be a useful feature).\n",
    "DROP_ALWAYS = [\"row_id\", \"id\", \"market_forward_excess_returns\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75fd5752",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T14:44:53.164213Z",
     "iopub.status.busy": "2025-12-14T14:44:53.163884Z",
     "iopub.status.idle": "2025-12-14T14:44:53.399726Z",
     "shell.execute_reply": "2025-12-14T14:44:53.398568Z"
    },
    "papermill": {
     "duration": 0.242,
     "end_time": "2025-12-14T14:44:53.401699",
     "exception": false,
     "start_time": "2025-12-14T14:44:53.159699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# LOAD TRAIN (only if training)\n",
    "# =========================\n",
    "train = None\n",
    "target_col = None\n",
    "\n",
    "if notebook_mode == \"training\":\n",
    "    train = pd.read_csv(f\"{DATA_PATH}train.csv\")\n",
    "\n",
    "    # Choose target based on approach\n",
    "    if approach == \"rmse_forward\":\n",
    "        target_col = \"forward_returns\"\n",
    "    else:\n",
    "        # rmse_excess or metric_tune\n",
    "        train[\"excess_forward_returns\"] = train[\"forward_returns\"] - train[\"risk_free_rate\"]\n",
    "        target_col = \"excess_forward_returns\"\n",
    "\n",
    "    # Basic checks\n",
    "    for c in NEEDED_FOR_SCORER:\n",
    "        if c not in train.columns:\n",
    "            raise ValueError(f\"Expected '{c}' in train.csv but not found\")\n",
    "\n",
    "    if target_col not in train.columns:\n",
    "        raise ValueError(f\"Expected target '{target_col}' in train.csv but not found\")\n",
    "\n",
    "    # Build training frame: drop obvious IDs/leaks; keep risk_free_rate\n",
    "    use_cols = [c for c in train.columns if c not in DROP_ALWAYS]\n",
    "    train = train[use_cols].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d7fe2f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T14:44:53.409303Z",
     "iopub.status.busy": "2025-12-14T14:44:53.408989Z",
     "iopub.status.idle": "2025-12-14T15:00:38.211938Z",
     "shell.execute_reply": "2025-12-14T15:00:38.210896Z"
    },
    "papermill": {
     "duration": 944.80947,
     "end_time": "2025-12-14T15:00:38.214401",
     "exception": false,
     "start_time": "2025-12-14T14:44:53.404931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.11.13\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Sep 27 10:16:09 UTC 2025\n",
      "CPU Count:          4\n",
      "Memory Avail:       30.21 GB / 31.35 GB (96.4%)\n",
      "Disk Space Avail:   19.50 GB / 19.52 GB (99.9%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Using hyperparameters preset: hyperparameters='zeroshot'\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 180s of the 720.0s of remaining time (25%).\n",
      "/usr/local/lib/python3.11/dist-packages/autogluon/tabular/predictor/predictor.py:1444: UserWarning: Failed to use ray for memory safe fits. Falling back to normal fit. Error: ValueError('ray==2.49.2 detected. 2.10.0 <= ray < 2.45.0 is required. You can use pip to install certain version of ray `pip install \"ray>=2.10.0,<2.45.0\"`')\n",
      "  stacked_overfitting = self._sub_fit_memory_save_wrapper(\n",
      "\t\tContext path: \"/kaggle/working/AutogluonModels/ds_sub_fit/sub_fit_ho\"\n",
      "Running DyStack sub-fit ...\n",
      "Beginning AutoGluon training ... Time limit = 173s\n",
      "AutoGluon will save models to \"/kaggle/working/AutogluonModels/ds_sub_fit/sub_fit_ho\"\n",
      "Train Data Rows:    8042\n",
      "Train Data Columns: 96\n",
      "Label Column:       forward_returns\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    30901.44 MB\n",
      "\tTrain Data (Original)  Memory Usage: 5.89 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 9 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['D2']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('int', []) : 1 | ['D2']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 86 | ['E1', 'E10', 'E11', 'E12', 'E13', ...]\n",
      "\t\t('int', [])   :  9 | ['date_id', 'D1', 'D3', 'D4', 'D5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 86 | ['E1', 'E10', 'E11', 'E12', 'E13', ...]\n",
      "\t\t('int', [])       :  1 | ['date_id']\n",
      "\t\t('int', ['bool']) :  8 | ['D1', 'D3', 'D4', 'D5', 'D6', ...]\n",
      "\t0.5s = Fit runtime\n",
      "\t95 features in original data used to generate 95 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 5.40 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.5s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 106 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 114.85s of the 172.31s of remaining time.\n",
      "Will use sequential fold fitting strategy because import of ray failed. Reason: ray==2.49.2 detected. 2.10.0 <= ray < 2.45.0 is required. You can use pip to install certain version of ray `pip install \"ray>=2.10.0,<2.45.0\"`\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=2, gpus=0)\n",
      "\t-0.0106\t = Validation score   (-root_mean_squared_error)\n",
      "\t22.34s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 89.83s of the 147.29s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=2, gpus=0)\n",
      "\t-0.0106\t = Validation score   (-root_mean_squared_error)\n",
      "\t21.78s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 67.94s of the 125.40s of remaining time.\n",
      "\t-0.0109\t = Validation score   (-root_mean_squared_error)\n",
      "\t224.99s\t = Training   runtime\n",
      "\t0.9s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 172.32s of the -101.69s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM_BAG_L1': 0.5, 'LightGBMXT_BAG_L1': 0.417, 'RandomForestMSE_BAG_L1': 0.083}\n",
      "\t-0.0105\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 172.32s of the -101.81s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM_BAG_L1': 0.5, 'LightGBMXT_BAG_L1': 0.417, 'RandomForestMSE_BAG_L1': 0.083}\n",
      "\t-0.0105\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 274.68s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 6867.9 rows/s (1006 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/kaggle/working/AutogluonModels/ds_sub_fit/sub_fit_ho\")\n",
      "Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                    model  score_holdout  score_val              eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0     WeightedEnsemble_L3      -0.010245  -0.010547  root_mean_squared_error        0.615391       0.936894  269.113801                 0.002407                0.000625           0.010666            3       True          5\n",
      "1     WeightedEnsemble_L2      -0.010245  -0.010547  root_mean_squared_error        0.616191       0.936971  269.122728                 0.003207                0.000701           0.019592            2       True          4\n",
      "2       LightGBMXT_BAG_L1      -0.010247  -0.010558  root_mean_squared_error        0.026735       0.018781   22.337229                 0.026735                0.018781          22.337229            1       True          1\n",
      "3         LightGBM_BAG_L1      -0.010248  -0.010556  root_mean_squared_error        0.019038       0.014673   21.779999                 0.019038                0.014673          21.779999            1       True          2\n",
      "4  RandomForestMSE_BAG_L1      -0.010548  -0.010858  root_mean_squared_error        0.567211       0.902815  224.985907                 0.567211                0.902815         224.985907            1       True          3\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t284s\t = DyStack   runtime |\t436s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 436s\n",
      "AutoGluon will save models to \"/kaggle/working/AutogluonModels\"\n",
      "Train Data Rows:    9048\n",
      "Train Data Columns: 96\n",
      "Label Column:       forward_returns\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    30639.39 MB\n",
      "\tTrain Data (Original)  Memory Usage: 6.63 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 9 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['D2']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('int', []) : 1 | ['D2']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 86 | ['E1', 'E10', 'E11', 'E12', 'E13', ...]\n",
      "\t\t('int', [])   :  9 | ['date_id', 'D1', 'D3', 'D4', 'D5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 86 | ['E1', 'E10', 'E11', 'E12', 'E13', ...]\n",
      "\t\t('int', [])       :  1 | ['date_id']\n",
      "\t\t('int', ['bool']) :  8 | ['D1', 'D3', 'D4', 'D5', 'D6', ...]\n",
      "\t0.5s = Fit runtime\n",
      "\t95 features in original data used to generate 95 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 6.07 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.55s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 106 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 290.25s of the 435.47s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=2, gpus=0)\n",
      "\t-0.0105\t = Validation score   (-root_mean_squared_error)\n",
      "\t18.1s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 272.02s of the 417.24s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=2, gpus=0)\n",
      "\t-0.0105\t = Validation score   (-root_mean_squared_error)\n",
      "\t23.09s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 248.80s of the 394.03s of remaining time.\n",
      "\t-0.0108\t = Validation score   (-root_mean_squared_error)\n",
      "\t258.94s\t = Training   runtime\n",
      "\t1.03s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 133.34s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.5, 'LightGBM_BAG_L1': 0.5}\n",
      "\t-0.0105\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 133.32s of the 133.30s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=2, gpus=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.0109028\n",
      "[2000]\tvalid_set's rmse: 0.0107763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 2490. Best iteration is:\n",
      "\t[2449]\tvalid_set's rmse: 0.0107562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.0102969\n",
      "[2000]\tvalid_set's rmse: 0.0102111\n",
      "[3000]\tvalid_set's rmse: 0.0101537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 3050. Best iteration is:\n",
      "\t[3031]\tvalid_set's rmse: 0.0101521\n",
      "\t-0.0104\t = Validation score   (-root_mean_squared_error)\n",
      "\t47.35s\t = Training   runtime\n",
      "\t0.46s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 84.91s of the 84.89s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=2, gpus=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.0107614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 1154. Best iteration is:\n",
      "\t[1150]\tvalid_set's rmse: 0.0107457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.0100511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 1196. Best iteration is:\n",
      "\t[1185]\tvalid_set's rmse: 0.0100377\n",
      "\t-0.0105\t = Validation score   (-root_mean_squared_error)\n",
      "\t39.33s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 45.09s of the 45.07s of remaining time.\n",
      "\t-0.0107\t = Validation score   (-root_mean_squared_error)\n",
      "\t266.1s\t = Training   runtime\n",
      "\t0.99s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the -223.34s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L2': 0.429, 'LightGBM_BAG_L2': 0.429, 'LightGBMXT_BAG_L1': 0.143}\n",
      "\t-0.0104\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 659.42s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 1352.7 rows/s (1131 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/kaggle/working/AutogluonModels\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[training] Trained. Models saved to: /kaggle/working/AutogluonModels\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# TRAIN OR LOAD PREDICTOR\n",
    "# =========================\n",
    "predictor = None\n",
    "\n",
    "if notebook_mode == \"inference\":\n",
    "    predictor = TabularPredictor.load(str(PRETRAINED_MODEL_DIR))\n",
    "    print(f\"[inference] Loaded predictor from: {PRETRAINED_MODEL_DIR}\")\n",
    "\n",
    "else:\n",
    "    predictor = TabularPredictor(\n",
    "        label=target_col,\n",
    "        eval_metric=\"rmse\",\n",
    "        problem_type=\"regression\",\n",
    "        path=str(WORKING_MODEL_DIR),\n",
    "    )\n",
    "\n",
    "    predictor.fit(\n",
    "        train_data=train,\n",
    "        presets=AG_PRESET,\n",
    "        time_limit=TIME_LIMIT_SECS,\n",
    "    )\n",
    "\n",
    "    print(f\"[training] Trained. Models saved to: {WORKING_MODEL_DIR}\")\n",
    "\n",
    "# Cache model feature list (works in both modes)\n",
    "MODEL_FEATURES = predictor.feature_metadata.get_features()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e434fb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T15:00:38.246874Z",
     "iopub.status.busy": "2025-12-14T15:00:38.244037Z",
     "iopub.status.idle": "2025-12-14T15:00:38.256402Z",
     "shell.execute_reply": "2025-12-14T15:00:38.255389Z"
    },
    "papermill": {
     "duration": 0.030416,
     "end_time": "2025-12-14T15:00:38.258126",
     "exception": false,
     "start_time": "2025-12-14T15:00:38.227710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# OPTIONAL: Tune tau/alpha using organizer metric on a holdout\n",
    "# (Only when training + approach == metric_tune)\n",
    "# =========================\n",
    "if notebook_mode == \"training\" and approach == \"metric_tune\":\n",
    "    n = len(train)\n",
    "    cut = int(n * (1.0 - HOLDOUT_FRAC))\n",
    "    if cut <= 0 or cut >= n:\n",
    "        raise ValueError(\"Bad HOLDOUT_FRAC; leads to empty train or empty holdout.\")\n",
    "\n",
    "    train_tr = train.iloc[:cut].copy()\n",
    "    train_va = train.iloc[cut:].copy()\n",
    "\n",
    "    # Refit quickly on the train_tr subset? (optional)\n",
    "    # For simplicity, we keep the trained predictor and just tune postprocess on the holdout portion.\n",
    "    # If you want strict separation, train predictor on train_tr from the start.\n",
    "\n",
    "    # Build solution df for scorer (must contain forward_returns and risk_free_rate)\n",
    "    # Note: train_va still has original forward_returns and risk_free_rate because we kept them\n",
    "    solution = train_va[NEEDED_FOR_SCORER].copy()\n",
    "\n",
    "    # Build X_va: drop label column only; keep other columns\n",
    "    X_va = train_va.drop(columns=[predictor.label], errors=\"ignore\")\n",
    "\n",
    "    raw = predictor.predict(X_va).to_numpy()\n",
    "\n",
    "    taus = np.logspace(-7, -3, 25)\n",
    "    alphas = np.linspace(0.05, 2.0, 40)\n",
    "\n",
    "    best_score = -np.inf\n",
    "    best_tau = TAU_ABS_FOR_SCORER\n",
    "    best_alpha = ALPHA_FOR_SCORER\n",
    "\n",
    "    # Make a fresh copy each loop because organizer_score mutates solution\n",
    "    for tau in taus:\n",
    "        for alpha in alphas:\n",
    "            pos = post_process_signal(raw, tau=tau, alpha=alpha)\n",
    "            sub = pd.DataFrame({\"prediction\": pos})\n",
    "            try:\n",
    "                s = organizer_score(solution.copy(), sub, row_id_column_name=\"row_id\")\n",
    "            except ParticipantVisibleError:\n",
    "                continue\n",
    "            if s > best_score:\n",
    "                best_score = s\n",
    "                best_tau = float(tau)\n",
    "                best_alpha = float(alpha)\n",
    "\n",
    "    TAU_ABS_FOR_SCORER = best_tau\n",
    "    ALPHA_FOR_SCORER = best_alpha\n",
    "\n",
    "    print(f\"[metric_tune] Best holdout organizer metric: {best_score:.6f}\")\n",
    "    print(f\"[metric_tune] Using tau={TAU_ABS_FOR_SCORER:.6g}, alpha={ALPHA_FOR_SCORER:.6g}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47decd72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T15:00:38.284082Z",
     "iopub.status.busy": "2025-12-14T15:00:38.283708Z",
     "iopub.status.idle": "2025-12-14T15:00:38.291064Z",
     "shell.execute_reply": "2025-12-14T15:00:38.290131Z"
    },
    "papermill": {
     "duration": 0.02234,
     "end_time": "2025-12-14T15:00:38.292684",
     "exception": false,
     "start_time": "2025-12-14T15:00:38.270344",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# PREDICT FUNCTION FOR KAGGLE EVAL SERVER\n",
    "# =========================\n",
    "def predict(test: pl.DataFrame) -> float:\n",
    "    \"\"\"Return a single post-processed position for a single-row Polars DataFrame.\"\"\"\n",
    "    if not isinstance(test, pl.DataFrame):\n",
    "        raise TypeError(\"predict(test): expected a Polars DataFrame input\")\n",
    "    if test.height != 1:\n",
    "        raise ValueError(f\"predict(test): expected a single-row Polars DataFrame, got {test.height} rows\")\n",
    "\n",
    "    # Drop always-drop columns if present\n",
    "    drop_cols = [c for c in DROP_ALWAYS if c in test.columns]\n",
    "    test_pl = test.drop(drop_cols) if drop_cols else test\n",
    "\n",
    "    # Ensure label is not present\n",
    "    if predictor.label in test_pl.columns:\n",
    "        test_pl = test_pl.drop(predictor.label)\n",
    "\n",
    "    # Polars -> Pandas\n",
    "    test_pd = test_pl.to_pandas()\n",
    "\n",
    "    # Align columns to model features (drops extras, fills missing with 0)\n",
    "    test_pd = test_pd.reindex(columns=MODEL_FEATURES, fill_value=0)\n",
    "\n",
    "    raw = predictor.predict(test_pd)\n",
    "    pos = post_process_signal(\n",
    "        raw,\n",
    "        tau=TAU_ABS_FOR_SCORER,\n",
    "        alpha=ALPHA_FOR_SCORER,\n",
    "        min_investment=MIN_INVESTMENT,\n",
    "        max_investment=MAX_INVESTMENT,\n",
    "    )\n",
    "    return float(np.asarray(pos).ravel()[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47241cf8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T15:00:38.317944Z",
     "iopub.status.busy": "2025-12-14T15:00:38.317611Z",
     "iopub.status.idle": "2025-12-14T15:00:44.343562Z",
     "shell.execute_reply": "2025-12-14T15:00:44.342268Z"
    },
    "papermill": {
     "duration": 6.041004,
     "end_time": "2025-12-14T15:00:44.345711",
     "exception": false,
     "start_time": "2025-12-14T15:00:38.304707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import kaggle_evaluation.default_inference_server as kis\n",
    "import os\n",
    "\n",
    "# ---------- KAGGLE SERVER BOOTSTRAP ----------\n",
    "inference_server = kis.DefaultInferenceServer(predict)\n",
    "\n",
    "if os.getenv(\"KAGGLE_IS_COMPETITION_RERUN\"):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway(('/kaggle/input/hull-tactical-market-prediction/',))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14861981,
     "sourceId": 111543,
     "sourceType": "competition"
    },
    {
     "datasetId": 8353464,
     "sourceId": 13183252,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1120.474344,
   "end_time": "2025-12-14T15:00:47.394621",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-14T14:42:06.920277",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
