{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb3f85c8",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-01T07:23:43.526853Z",
     "iopub.status.busy": "2025-10-01T07:23:43.526656Z",
     "iopub.status.idle": "2025-10-01T07:25:45.961256Z",
     "shell.execute_reply": "2025-10-01T07:25:45.960456Z"
    },
    "papermill": {
     "duration": 122.44152,
     "end_time": "2025-10-01T07:25:45.962756",
     "exception": false,
     "start_time": "2025-10-01T07:23:43.521236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (8.1.5)\r\n",
      "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (0.2.2)\r\n",
      "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (7.34.0)\r\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (5.7.1)\r\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (4.0.14)\r\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (3.0.15)\r\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (75.2.0)\r\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\r\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (4.4.2)\r\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\r\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\r\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\r\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\r\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\r\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\r\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\r\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\r\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.13)\r\n",
      "Collecting autogluon\r\n",
      "  Downloading autogluon-1.4.0-py3-none-any.whl.metadata (11 kB)\r\n",
      "Collecting scikit-learn==1.5.2\r\n",
      "  Downloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\r\n",
      "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (1.15.3)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (1.5.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (3.6.0)\r\n",
      "Collecting autogluon.core==1.4.0 (from autogluon.core[all]==1.4.0->autogluon)\r\n",
      "  Downloading autogluon.core-1.4.0-py3-none-any.whl.metadata (12 kB)\r\n",
      "Collecting autogluon.features==1.4.0 (from autogluon)\r\n",
      "  Downloading autogluon.features-1.4.0-py3-none-any.whl.metadata (11 kB)\r\n",
      "Collecting autogluon.tabular==1.4.0 (from autogluon.tabular[all]==1.4.0->autogluon)\r\n",
      "  Downloading autogluon.tabular-1.4.0-py3-none-any.whl.metadata (16 kB)\r\n",
      "Collecting autogluon.multimodal==1.4.0 (from autogluon)\r\n",
      "  Downloading autogluon.multimodal-1.4.0-py3-none-any.whl.metadata (13 kB)\r\n",
      "Collecting autogluon.timeseries==1.4.0 (from autogluon.timeseries[all]==1.4.0->autogluon)\r\n",
      "  Downloading autogluon.timeseries-1.4.0-py3-none-any.whl.metadata (12 kB)\r\n",
      "Requirement already satisfied: networkx<4,>=3.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (3.5)\r\n",
      "Requirement already satisfied: pandas<2.4.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (2.2.3)\r\n",
      "Requirement already satisfied: tqdm<5,>=4.38 in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (4.67.1)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (2.32.4)\r\n",
      "Requirement already satisfied: matplotlib<3.11,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (3.7.2)\r\n",
      "Requirement already satisfied: boto3<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (1.39.1)\r\n",
      "Collecting autogluon.common==1.4.0 (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon)\r\n",
      "  Downloading autogluon.common-1.4.0-py3-none-any.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: hyperopt<0.2.8,>=0.2.7 in /usr/local/lib/python3.11/dist-packages (from autogluon.core[all]==1.4.0->autogluon) (0.2.7)\r\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.core[all]==1.4.0->autogluon) (19.0.1)\r\n",
      "Collecting ray<2.45,>=2.10.0 (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\r\n",
      "  Downloading ray-2.44.1-cp311-cp311-manylinux2014_x86_64.whl.metadata (19 kB)\r\n",
      "Requirement already satisfied: Pillow<12,>=10.0.1 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (11.2.1)\r\n",
      "Requirement already satisfied: torch<2.8,>=2.2 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (2.6.0+cu124)\r\n",
      "Collecting lightning<2.8,>=2.2 (from autogluon.multimodal==1.4.0->autogluon)\r\n",
      "  Downloading lightning-2.5.5-py3-none-any.whl.metadata (39 kB)\r\n",
      "Collecting transformers<4.50,>=4.38.0 (from transformers[sentencepiece]<4.50,>=4.38.0->autogluon.multimodal==1.4.0->autogluon)\r\n",
      "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: accelerate<2.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (1.8.1)\r\n",
      "Collecting fsspec<=2025.3 (from fsspec[http]<=2025.3->autogluon.multimodal==1.4.0->autogluon)\r\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\r\n",
      "Collecting jsonschema<4.24,>=4.18 (from autogluon.multimodal==1.4.0->autogluon)\r\n",
      "  Downloading jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\r\n",
      "Collecting seqeval<1.3.0,>=1.2.2 (from autogluon.multimodal==1.4.0->autogluon)\r\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Collecting evaluate<0.5.0,>=0.4.0 (from autogluon.multimodal==1.4.0->autogluon)\r\n",
      "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\r\n",
      "Collecting timm<1.0.7,>=0.9.5 (from autogluon.multimodal==1.4.0->autogluon)\r\n",
      "  Downloading timm-1.0.3-py3-none-any.whl.metadata (43 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: torchvision<0.23.0,>=0.16.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (0.21.0+cu124)\r\n",
      "Requirement already satisfied: scikit-image<0.26.0,>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (0.25.2)\r\n",
      "Requirement already satisfied: text-unidecode<1.4,>=1.3 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (1.3)\r\n",
      "Requirement already satisfied: torchmetrics<1.8,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (1.7.3)\r\n",
      "Requirement already satisfied: omegaconf<2.4.0,>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (2.3.0)\r\n",
      "Collecting pytorch-metric-learning<2.9,>=1.3.0 (from autogluon.multimodal==1.4.0->autogluon)\r\n",
      "  Downloading pytorch_metric_learning-2.8.1-py3-none-any.whl.metadata (18 kB)\r\n",
      "Collecting nlpaug<1.2.0,>=1.1.10 (from autogluon.multimodal==1.4.0->autogluon)\r\n",
      "  Downloading nlpaug-1.1.11-py3-none-any.whl.metadata (14 kB)\r\n",
      "Requirement already satisfied: nltk<3.10,>=3.4.5 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (3.9.1)\r\n",
      "Collecting openmim<0.4.0,>=0.3.7 (from autogluon.multimodal==1.4.0->autogluon)\r\n",
      "  Downloading openmim-0.3.9-py2.py3-none-any.whl.metadata (16 kB)\r\n",
      "Requirement already satisfied: defusedxml<0.7.2,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (0.7.1)\r\n",
      "Requirement already satisfied: jinja2<3.2,>=3.0.3 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (3.1.6)\r\n",
      "Requirement already satisfied: tensorboard<3,>=2.9 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (2.18.0)\r\n",
      "Requirement already satisfied: pytesseract<0.4,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (0.3.13)\r\n",
      "Collecting nvidia-ml-py3<8.0,>=7.352.0 (from autogluon.multimodal==1.4.0->autogluon)\r\n",
      "  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: pdf2image<1.19,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (1.17.0)\r\n",
      "Requirement already satisfied: catboost<1.3,>=1.2 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]==1.4.0->autogluon) (1.2.8)\r\n",
      "Requirement already satisfied: fastai<2.9,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]==1.4.0->autogluon) (2.7.19)\r\n",
      "Collecting loguru (from autogluon.tabular[all]==1.4.0->autogluon)\r\n",
      "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\r\n",
      "Requirement already satisfied: lightgbm<4.7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]==1.4.0->autogluon) (4.5.0)\r\n",
      "Collecting einx (from autogluon.tabular[all]==1.4.0->autogluon)\r\n",
      "  Downloading einx-0.3.0-py3-none-any.whl.metadata (6.9 kB)\r\n",
      "Requirement already satisfied: xgboost<3.1,>=2.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]==1.4.0->autogluon) (2.0.3)\r\n",
      "Requirement already satisfied: spacy<3.9 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]==1.4.0->autogluon) (3.8.7)\r\n",
      "Requirement already satisfied: huggingface-hub[torch] in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]==1.4.0->autogluon) (0.33.1)\r\n",
      "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.11/dist-packages (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (2.5.2)\r\n",
      "Collecting gluonts<0.17,>=0.15.0 (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\r\n",
      "  Downloading gluonts-0.16.2-py3-none-any.whl.metadata (9.8 kB)\r\n",
      "Collecting statsforecast<2.0.2,>=1.7.0 (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\r\n",
      "  Downloading statsforecast-2.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (29 kB)\r\n",
      "Collecting mlforecast<0.15.0,>=0.14.0 (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\r\n",
      "  Downloading mlforecast-0.14.0-py3-none-any.whl.metadata (12 kB)\r\n",
      "Collecting utilsforecast<0.2.12,>=0.2.3 (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\r\n",
      "  Downloading utilsforecast-0.2.11-py3-none-any.whl.metadata (7.7 kB)\r\n",
      "Collecting coreforecast<0.0.17,>=0.0.12 (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\r\n",
      "  Downloading coreforecast-0.0.16-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\r\n",
      "Collecting fugue>=0.9.0 (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\r\n",
      "  Downloading fugue-0.9.1-py3-none-any.whl.metadata (18 kB)\r\n",
      "Requirement already satisfied: orjson~=3.9 in /usr/local/lib/python3.11/dist-packages (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (3.10.18)\r\n",
      "Requirement already satisfied: psutil<7.1.0,>=5.7.3 in /usr/local/lib/python3.11/dist-packages (from autogluon.common==1.4.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (7.0.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn==1.5.2) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn==1.5.2) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn==1.5.2) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn==1.5.2) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn==1.5.2) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn==1.5.2) (2.4.1)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate<2.0,>=0.34.0->autogluon.multimodal==1.4.0->autogluon) (25.0)\r\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate<2.0,>=0.34.0->autogluon.multimodal==1.4.0->autogluon) (6.0.2)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate<2.0,>=0.34.0->autogluon.multimodal==1.4.0->autogluon) (0.5.3)\r\n",
      "Requirement already satisfied: botocore<1.40.0,>=1.39.1 in /usr/local/lib/python3.11/dist-packages (from boto3<2,>=1.10->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (1.39.1)\r\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from boto3<2,>=1.10->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (1.0.1)\r\n",
      "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from boto3<2,>=1.10->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (0.13.0)\r\n",
      "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.4.0->autogluon) (0.21)\r\n",
      "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.4.0->autogluon) (5.24.1)\r\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.4.0->autogluon) (1.17.0)\r\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.4.0->autogluon) (3.6.0)\r\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.4.0->autogluon) (0.3.8)\r\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.4.0->autogluon) (3.5.0)\r\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.4.0->autogluon) (0.70.16)\r\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.4.0->autogluon) (24.1.2)\r\n",
      "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.4.0->autogluon) (0.0.7)\r\n",
      "Requirement already satisfied: fastcore<1.8,>=1.5.29 in /usr/local/lib/python3.11/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.4.0->autogluon) (1.7.29)\r\n",
      "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.11/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.4.0->autogluon) (1.0.3)\r\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3->autogluon.multimodal==1.4.0->autogluon) (3.12.13)\r\n",
      "Collecting triad>=0.9.7 (from fugue>=0.9.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\r\n",
      "  Downloading triad-0.9.8-py3-none-any.whl.metadata (6.3 kB)\r\n",
      "Collecting adagio>=0.2.4 (from fugue>=0.9.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\r\n",
      "  Downloading adagio-0.2.6-py3-none-any.whl.metadata (1.8 kB)\r\n",
      "Requirement already satisfied: pydantic<3,>=1.7 in /usr/local/lib/python3.11/dist-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (2.11.7)\r\n",
      "Collecting toolz~=0.10 (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\r\n",
      "  Downloading toolz-0.12.1-py3-none-any.whl.metadata (5.1 kB)\r\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (4.14.0)\r\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.4.0->autogluon) (1.0.0)\r\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.4.0->autogluon) (3.1.1)\r\n",
      "Requirement already satisfied: py4j in /usr/local/lib/python3.11/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.4.0->autogluon) (0.10.9.7)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2<3.2,>=3.0.3->autogluon.multimodal==1.4.0->autogluon) (3.0.2)\r\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.4.0->autogluon) (25.3.0)\r\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.4.0->autogluon) (2025.4.1)\r\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.4.0->autogluon) (0.36.2)\r\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.4.0->autogluon) (0.25.1)\r\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from lightning<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (0.14.3)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (1.3.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (4.58.4)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (1.4.8)\r\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (2.9.0.post0)\r\n",
      "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (0.60.0)\r\n",
      "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (from mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (4.4.0)\r\n",
      "Collecting window-ops (from mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\r\n",
      "  Downloading window_ops-0.0.15-py3-none-any.whl.metadata (6.8 kB)\r\n",
      "Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.4.0->autogluon) (5.2.0)\r\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk<3.10,>=3.4.5->autogluon.multimodal==1.4.0->autogluon) (8.2.1)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk<3.10,>=3.4.5->autogluon.multimodal==1.4.0->autogluon) (2024.11.6)\r\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf<2.4.0,>=2.1.1->autogluon.multimodal==1.4.0->autogluon) (4.9.3)\r\n",
      "Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon) (0.4.6)\r\n",
      "Collecting model-index (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon)\r\n",
      "  Downloading model_index-0.1.11-py3-none-any.whl.metadata (3.9 kB)\r\n",
      "Collecting opendatalab (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon)\r\n",
      "  Downloading opendatalab-0.0.10-py3-none-any.whl.metadata (6.4 kB)\r\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon) (14.0.0)\r\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon) (0.9.0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.4.0,>=2.0.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<2.4.0,>=2.0.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (2025.2)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (3.18.0)\r\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (1.1.1)\r\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.11/dist-packages (from ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (3.20.3)\r\n",
      "Requirement already satisfied: aiosignal in /usr/local/lib/python3.11/dist-packages (from ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (1.3.2)\r\n",
      "Requirement already satisfied: frozenlist in /usr/local/lib/python3.11/dist-packages (from ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (1.7.0)\r\n",
      "Collecting aiohttp_cors (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\r\n",
      "  Downloading aiohttp_cors-0.8.1-py3-none-any.whl.metadata (20 kB)\r\n",
      "Collecting colorful (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\r\n",
      "  Downloading colorful-0.5.7-py2.py3-none-any.whl.metadata (16 kB)\r\n",
      "Collecting py-spy>=0.2.0 (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\r\n",
      "  Downloading py_spy-0.4.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (510 bytes)\r\n",
      "Requirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (1.73.1)\r\n",
      "Collecting opencensus (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\r\n",
      "  Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\r\n",
      "Requirement already satisfied: prometheus_client>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (0.22.1)\r\n",
      "Requirement already satisfied: smart_open in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (7.1.0)\r\n",
      "Collecting virtualenv!=20.21.1,>=20.0.24 (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\r\n",
      "  Downloading virtualenv-20.34.0-py3-none-any.whl.metadata (4.6 kB)\r\n",
      "Collecting tensorboardX>=1.9 (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\r\n",
      "  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (2025.6.15)\r\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image<0.26.0,>=0.19.1->autogluon.multimodal==1.4.0->autogluon) (2.37.0)\r\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image<0.26.0,>=0.19.1->autogluon.multimodal==1.4.0->autogluon) (2025.6.11)\r\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image<0.26.0,>=0.19.1->autogluon.multimodal==1.4.0->autogluon) (0.4)\r\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (3.0.12)\r\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (1.0.5)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (1.0.13)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (2.0.11)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (3.0.10)\r\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (8.3.6)\r\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (1.1.3)\r\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (2.5.1)\r\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (2.0.10)\r\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (0.4.1)\r\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (0.16.0)\r\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (75.2.0)\r\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (3.5.0)\r\n",
      "Requirement already satisfied: statsmodels>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from statsforecast<2.0.2,>=1.7.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (0.14.4)\r\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.4.0->autogluon) (1.4.0)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.4.0->autogluon) (3.8.2)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.4.0->autogluon) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.4.0->autogluon) (3.1.3)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\r\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\r\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\r\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\r\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\r\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\r\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\r\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (0.6.2)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (12.4.127)\r\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (3.2.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (1.3.0)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<4.50,>=4.38.0->transformers[sentencepiece]<4.50,>=4.38.0->autogluon.multimodal==1.4.0->autogluon) (0.21.2)\r\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]<4.50,>=4.38.0->autogluon.multimodal==1.4.0->autogluon) (0.2.0)\r\n",
      "Requirement already satisfied: frozendict in /usr/local/lib/python3.11/dist-packages (from einx->autogluon.tabular[all]==1.4.0->autogluon) (2.4.6)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub[torch]; extra == \"all\"->autogluon.tabular[all]==1.4.0->autogluon) (1.1.5)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.5->scikit-learn==1.5.2) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.5->scikit-learn==1.5.2) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.5->scikit-learn==1.5.2) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.19.5->scikit-learn==1.5.2) (2024.2.0)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3->autogluon.multimodal==1.4.0->autogluon) (2.6.1)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3->autogluon.multimodal==1.4.0->autogluon) (6.6.3)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3->autogluon.multimodal==1.4.0->autogluon) (0.3.2)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3->autogluon.multimodal==1.4.0->autogluon) (1.20.1)\r\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.4.0->autogluon) (4.13.4)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.19.5->scikit-learn==1.5.2) (2024.2.0)\r\n",
      "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (1.3.0)\r\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (0.43.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (2.33.2)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (0.4.1)\r\n",
      "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.13.2->statsforecast<2.0.2,>=1.7.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (1.0.1)\r\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (1.3.0)\r\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (0.1.5)\r\n",
      "INFO: pip is looking at multiple versions of thinc to determine which version is compatible with other requirements. This could take a while.\r\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon)\r\n",
      "  Downloading thinc-8.3.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\r\n",
      "Collecting blis<1.3.0,>=1.2.0 (from thinc<8.4.0,>=8.3.4->spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon)\r\n",
      "  Downloading blis-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\r\n",
      "Collecting fs (from triad>=0.9.7->fugue>=0.9.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\r\n",
      "  Downloading fs-2.4.16-py2.py3-none-any.whl.metadata (6.3 kB)\r\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (1.5.4)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon) (2.19.2)\r\n",
      "Collecting distlib<1,>=0.3.7 (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\r\n",
      "  Downloading distlib-0.4.0-py2.py3-none-any.whl.metadata (5.2 kB)\r\n",
      "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.11/dist-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (4.3.8)\r\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (0.21.1)\r\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart_open->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (1.17.2)\r\n",
      "Collecting ordered-set (from model-index->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon)\r\n",
      "  Downloading ordered_set-4.1.0-py3-none-any.whl.metadata (5.3 kB)\r\n",
      "Collecting opencensus-context>=0.1.3 (from opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\r\n",
      "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\r\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (1.34.1)\r\n",
      "Requirement already satisfied: pycryptodome in /usr/local/lib/python3.11/dist-packages (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon) (3.23.0)\r\n",
      "Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon)\r\n",
      "  Downloading openxlab-0.1.2-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (1.16.2)\r\n",
      "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (6.9.0)\r\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (2.0.41)\r\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost<1.3,>=1.2->autogluon.tabular[all]==1.4.0->autogluon) (8.5.0)\r\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (1.3.10)\r\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (1.70.0)\r\n",
      "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (2.40.3)\r\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (1.2.1)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon) (0.1.2)\r\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (3.2.3)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.4.0->autogluon) (2.7)\r\n",
      "Collecting appdirs~=1.4.3 (from fs->triad>=0.9.7->fugue>=0.9.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\r\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\r\n",
      "Collecting filelock (from ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\r\n",
      "  Downloading filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\r\n",
      "Collecting oss2~=2.17.0 (from openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon)\r\n",
      "  Downloading oss2-2.17.0.tar.gz (259 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Collecting packaging>=20.0 (from accelerate<2.0,>=0.34.0->autogluon.multimodal==1.4.0->autogluon)\r\n",
      "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\r\n",
      "Collecting pytz>=2020.1 (from pandas<2.4.0,>=2.0.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon)\r\n",
      "  Downloading pytz-2023.4-py2.py3-none-any.whl.metadata (22 kB)\r\n",
      "INFO: pip is looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\r\n",
      "Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon)\r\n",
      "  Downloading openxlab-0.1.1-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "  Downloading openxlab-0.1.0-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "  Downloading openxlab-0.0.38-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "  Downloading openxlab-0.0.37-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "  Downloading openxlab-0.0.36-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "  Downloading openxlab-0.0.35-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "  Downloading openxlab-0.0.34-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "INFO: pip is still looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\r\n",
      "  Downloading openxlab-0.0.33-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "  Downloading openxlab-0.0.32-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "  Downloading openxlab-0.0.31-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "  Downloading openxlab-0.0.30-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "  Downloading openxlab-0.0.29-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\r\n",
      "  Downloading openxlab-0.0.28-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "  Downloading openxlab-0.0.27-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "  Downloading openxlab-0.0.26-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "  Downloading openxlab-0.0.25-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "  Downloading openxlab-0.0.24-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "  Downloading openxlab-0.0.23-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "  Downloading openxlab-0.0.22-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "  Downloading openxlab-0.0.21-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "  Downloading openxlab-0.0.20-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "  Downloading openxlab-0.0.19-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "  Downloading openxlab-0.0.18-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "  Downloading openxlab-0.0.17-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "  Downloading openxlab-0.0.16-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "  Downloading openxlab-0.0.15-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "  Downloading openxlab-0.0.14-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "  Downloading openxlab-0.0.13-py3-none-any.whl.metadata (4.5 kB)\r\n",
      "  Downloading openxlab-0.0.12-py3-none-any.whl.metadata (4.5 kB)\r\n",
      "  Downloading openxlab-0.0.11-py3-none-any.whl.metadata (4.3 kB)\r\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.4.0->autogluon) (1.7.1)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (5.5.2)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (0.4.2)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (4.9.1)\r\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (0.6.1)\r\n",
      "Downloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m92.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading autogluon-1.4.0-py3-none-any.whl (9.8 kB)\r\n",
      "Downloading autogluon.core-1.4.0-py3-none-any.whl (225 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.1/225.1 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading autogluon.features-1.4.0-py3-none-any.whl (64 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading autogluon.multimodal-1.4.0-py3-none-any.whl (454 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.9/454.9 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading autogluon.tabular-1.4.0-py3-none-any.whl (487 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m487.3/487.3 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading autogluon.timeseries-1.4.0-py3-none-any.whl (189 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.7/189.7 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading autogluon.common-1.4.0-py3-none-any.whl (70 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.0/71.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading coreforecast-0.0.16-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (285 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m285.8/285.8 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading evaluate-0.4.6-py3-none-any.whl (84 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading fugue-0.9.1-py3-none-any.whl (278 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading gluonts-0.16.2-py3-none-any.whl (1.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading jsonschema-4.23.0-py3-none-any.whl (88 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.5/88.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading lightning-2.5.5-py3-none-any.whl (828 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m828.5/828.5 kB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading mlforecast-0.14.0-py3-none-any.whl (71 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pytorch_metric_learning-2.8.1-py3-none-any.whl (125 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.9/125.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading ray-2.44.1-cp311-cp311-manylinux2014_x86_64.whl (68.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.1/68.1 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading statsforecast-2.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (354 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m354.4/354.4 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading timm-1.0.3-py3-none-any.whl (2.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m90.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m101.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading utilsforecast-0.2.11-py3-none-any.whl (41 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading einx-0.3.0-py3-none-any.whl (102 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.0/103.0 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading adagio-0.2.6-py3-none-any.whl (19 kB)\r\n",
      "Downloading py_spy-0.4.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading thinc-8.3.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m91.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading toolz-0.12.1-py3-none-any.whl (56 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading triad-0.9.8-py3-none-any.whl (62 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading virtualenv-20.34.0-py3-none-any.whl (6.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m109.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading aiohttp_cors-0.8.1-py3-none-any.whl (25 kB)\r\n",
      "Downloading colorful-0.5.7-py2.py3-none-any.whl (201 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.5/201.5 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading model_index-0.1.11-py3-none-any.whl (34 kB)\r\n",
      "Downloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading opendatalab-0.0.10-py3-none-any.whl (29 kB)\r\n",
      "Downloading window_ops-0.0.15-py3-none-any.whl (15 kB)\r\n",
      "Downloading blis-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m101.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading distlib-0.4.0-py2.py3-none-any.whl (469 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\r\n",
      "Downloading fs-2.4.16-py2.py3-none-any.whl (135 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.3/135.3 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading openxlab-0.0.11-py3-none-any.whl (55 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\r\n",
      "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\r\n",
      "Building wheels for collected packages: nvidia-ml-py3, seqeval\r\n",
      "  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=19172 sha256=e368078bca6100e3b3666e8c0a2298859197a8e00c8632f260b8eee554d5eca6\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/47/50/9e/29dc79037d74c3c1bb4a8661fb608e8674b7e4260d6a3f8f51\r\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=d92ad3ef05651b4869ab193c6e9c5515620590be298d4238cd00383dfacc04f8\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/bc/92/f0/243288f899c2eacdfa8c5f9aede4c71a9bad0ee26a01dc5ead\r\n",
      "Successfully built nvidia-ml-py3 seqeval\r\n",
      "Installing collected packages: py-spy, opencensus-context, nvidia-ml-py3, distlib, colorful, appdirs, virtualenv, toolz, ordered-set, openxlab, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, loguru, fsspec, fs, nvidia-cusparse-cu12, nvidia-cudnn-cu12, model-index, opendatalab, nvidia-cusolver-cu12, jsonschema, aiohttp_cors, ray, opencensus, triad, scikit-learn, autogluon.common, tensorboardX, blis, autogluon.features, autogluon.core, adagio, window-ops, utilsforecast, transformers, thinc, fugue, coreforecast, autogluon.tabular, statsforecast, mlforecast, lightning, gluonts, timm, seqeval, pytorch-metric-learning, openmim, nlpaug, evaluate, einx, autogluon.timeseries, autogluon.multimodal, autogluon\r\n",
      "  Attempting uninstall: toolz\r\n",
      "    Found existing installation: toolz 1.0.0\r\n",
      "    Uninstalling toolz-1.0.0:\r\n",
      "      Successfully uninstalled toolz-1.0.0\r\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\r\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\r\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\r\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\r\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\r\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\r\n",
      "  Attempting uninstall: fsspec\r\n",
      "    Found existing installation: fsspec 2025.5.1\r\n",
      "    Uninstalling fsspec-2025.5.1:\r\n",
      "      Successfully uninstalled fsspec-2025.5.1\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\r\n",
      "  Attempting uninstall: jsonschema\r\n",
      "    Found existing installation: jsonschema 4.24.0\r\n",
      "    Uninstalling jsonschema-4.24.0:\r\n",
      "      Successfully uninstalled jsonschema-4.24.0\r\n",
      "  Attempting uninstall: ray\r\n",
      "    Found existing installation: ray 2.47.1\r\n",
      "    Uninstalling ray-2.47.1:\r\n",
      "      Successfully uninstalled ray-2.47.1\r\n",
      "  Attempting uninstall: scikit-learn\r\n",
      "    Found existing installation: scikit-learn 1.2.2\r\n",
      "    Uninstalling scikit-learn-1.2.2:\r\n",
      "      Successfully uninstalled scikit-learn-1.2.2\r\n",
      "  Attempting uninstall: blis\r\n",
      "    Found existing installation: blis 1.3.0\r\n",
      "    Uninstalling blis-1.3.0:\r\n",
      "      Successfully uninstalled blis-1.3.0\r\n",
      "  Attempting uninstall: transformers\r\n",
      "    Found existing installation: transformers 4.52.4\r\n",
      "    Uninstalling transformers-4.52.4:\r\n",
      "      Successfully uninstalled transformers-4.52.4\r\n",
      "  Attempting uninstall: thinc\r\n",
      "    Found existing installation: thinc 8.3.6\r\n",
      "    Uninstalling thinc-8.3.6:\r\n",
      "      Successfully uninstalled thinc-8.3.6\r\n",
      "  Attempting uninstall: timm\r\n",
      "    Found existing installation: timm 1.0.15\r\n",
      "    Uninstalling timm-1.0.15:\r\n",
      "      Successfully uninstalled timm-1.0.15\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\r\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\r\n",
      "bigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\r\n",
      "bigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed adagio-0.2.6 aiohttp_cors-0.8.1 appdirs-1.4.4 autogluon-1.4.0 autogluon.common-1.4.0 autogluon.core-1.4.0 autogluon.features-1.4.0 autogluon.multimodal-1.4.0 autogluon.tabular-1.4.0 autogluon.timeseries-1.4.0 blis-1.2.1 colorful-0.5.7 coreforecast-0.0.16 distlib-0.4.0 einx-0.3.0 evaluate-0.4.6 fs-2.4.16 fsspec-2025.3.0 fugue-0.9.1 gluonts-0.16.2 jsonschema-4.23.0 lightning-2.5.5 loguru-0.7.3 mlforecast-0.14.0 model-index-0.1.11 nlpaug-1.1.11 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-ml-py3-7.352.0 nvidia-nvjitlink-cu12-12.4.127 opencensus-0.11.4 opencensus-context-0.1.3 opendatalab-0.0.10 openmim-0.3.9 openxlab-0.0.11 ordered-set-4.1.0 py-spy-0.4.1 pytorch-metric-learning-2.8.1 ray-2.44.1 scikit-learn-1.5.2 seqeval-1.2.2 statsforecast-2.0.1 tensorboardX-2.6.4 thinc-8.3.4 timm-1.0.3 toolz-0.12.1 transformers-4.49.0 triad-0.9.8 utilsforecast-0.2.11 virtualenv-20.34.0 window-ops-0.0.15\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets\n",
    "!pip install autogluon scikit-learn==1.5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4145cba2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T07:25:46.029061Z",
     "iopub.status.busy": "2025-10-01T07:25:46.028592Z",
     "iopub.status.idle": "2025-10-01T07:25:48.436849Z",
     "shell.execute_reply": "2025-10-01T07:25:48.436063Z"
    },
    "papermill": {
     "duration": 2.442158,
     "end_time": "2025-10-01T07:25:48.438128",
     "exception": false,
     "start_time": "2025-10-01T07:25:45.995970",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>road_type</th>\n",
       "      <th>num_lanes</th>\n",
       "      <th>curvature</th>\n",
       "      <th>speed_limit</th>\n",
       "      <th>lighting</th>\n",
       "      <th>weather</th>\n",
       "      <th>road_signs_present</th>\n",
       "      <th>public_road</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>holiday</th>\n",
       "      <th>school_season</th>\n",
       "      <th>num_reported_accidents</th>\n",
       "      <th>accident_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>urban</td>\n",
       "      <td>2</td>\n",
       "      <td>0.06</td>\n",
       "      <td>35</td>\n",
       "      <td>daylight</td>\n",
       "      <td>rainy</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>urban</td>\n",
       "      <td>4</td>\n",
       "      <td>0.99</td>\n",
       "      <td>35</td>\n",
       "      <td>daylight</td>\n",
       "      <td>clear</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>evening</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>rural</td>\n",
       "      <td>4</td>\n",
       "      <td>0.63</td>\n",
       "      <td>70</td>\n",
       "      <td>dim</td>\n",
       "      <td>clear</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>morning</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>highway</td>\n",
       "      <td>4</td>\n",
       "      <td>0.07</td>\n",
       "      <td>35</td>\n",
       "      <td>dim</td>\n",
       "      <td>rainy</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>morning</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>rural</td>\n",
       "      <td>1</td>\n",
       "      <td>0.58</td>\n",
       "      <td>60</td>\n",
       "      <td>daylight</td>\n",
       "      <td>foggy</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>evening</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id road_type  num_lanes  curvature  speed_limit  lighting weather  \\\n",
       "0   0     urban          2       0.06           35  daylight   rainy   \n",
       "1   1     urban          4       0.99           35  daylight   clear   \n",
       "2   2     rural          4       0.63           70       dim   clear   \n",
       "3   3   highway          4       0.07           35       dim   rainy   \n",
       "4   4     rural          1       0.58           60  daylight   foggy   \n",
       "\n",
       "   road_signs_present  public_road time_of_day  holiday  school_season  \\\n",
       "0               False         True   afternoon    False           True   \n",
       "1                True        False     evening     True           True   \n",
       "2               False         True     morning     True          False   \n",
       "3                True         True     morning    False          False   \n",
       "4               False        False     evening     True          False   \n",
       "\n",
       "   num_reported_accidents  accident_risk  \n",
       "0                       1           0.13  \n",
       "1                       0           0.35  \n",
       "2                       2           0.30  \n",
       "3                       1           0.21  \n",
       "4                       1           0.56  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train=pd.read_csv('/kaggle/input/playground-series-s5e10/train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cb0c6ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T07:25:48.549703Z",
     "iopub.status.busy": "2025-10-01T07:25:48.549213Z",
     "iopub.status.idle": "2025-10-01T07:25:48.821578Z",
     "shell.execute_reply": "2025-10-01T07:25:48.820859Z"
    },
    "papermill": {
     "duration": 0.351187,
     "end_time": "2025-10-01T07:25:48.822668",
     "exception": false,
     "start_time": "2025-10-01T07:25:48.471481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>road_type</th>\n",
       "      <th>num_lanes</th>\n",
       "      <th>curvature</th>\n",
       "      <th>speed_limit</th>\n",
       "      <th>lighting</th>\n",
       "      <th>weather</th>\n",
       "      <th>road_signs_present</th>\n",
       "      <th>public_road</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>holiday</th>\n",
       "      <th>school_season</th>\n",
       "      <th>num_reported_accidents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>517754</td>\n",
       "      <td>highway</td>\n",
       "      <td>2</td>\n",
       "      <td>0.34</td>\n",
       "      <td>45</td>\n",
       "      <td>night</td>\n",
       "      <td>clear</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>517755</td>\n",
       "      <td>urban</td>\n",
       "      <td>3</td>\n",
       "      <td>0.04</td>\n",
       "      <td>45</td>\n",
       "      <td>dim</td>\n",
       "      <td>foggy</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>517756</td>\n",
       "      <td>urban</td>\n",
       "      <td>2</td>\n",
       "      <td>0.59</td>\n",
       "      <td>35</td>\n",
       "      <td>dim</td>\n",
       "      <td>clear</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>517757</td>\n",
       "      <td>rural</td>\n",
       "      <td>4</td>\n",
       "      <td>0.95</td>\n",
       "      <td>35</td>\n",
       "      <td>daylight</td>\n",
       "      <td>rainy</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>517758</td>\n",
       "      <td>highway</td>\n",
       "      <td>2</td>\n",
       "      <td>0.86</td>\n",
       "      <td>35</td>\n",
       "      <td>daylight</td>\n",
       "      <td>clear</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>evening</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id road_type  num_lanes  curvature  speed_limit  lighting weather  \\\n",
       "0  517754   highway          2       0.34           45     night   clear   \n",
       "1  517755     urban          3       0.04           45       dim   foggy   \n",
       "2  517756     urban          2       0.59           35       dim   clear   \n",
       "3  517757     rural          4       0.95           35  daylight   rainy   \n",
       "4  517758   highway          2       0.86           35  daylight   clear   \n",
       "\n",
       "   road_signs_present  public_road time_of_day  holiday  school_season  \\\n",
       "0                True         True   afternoon     True           True   \n",
       "1                True        False   afternoon     True          False   \n",
       "2                True        False   afternoon     True           True   \n",
       "3               False        False   afternoon    False          False   \n",
       "4                True        False     evening    False           True   \n",
       "\n",
       "   num_reported_accidents  \n",
       "0                       1  \n",
       "1                       0  \n",
       "2                       1  \n",
       "3                       2  \n",
       "4                       3  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=pd.read_csv('/kaggle/input/playground-series-s5e10/test.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fe2ba62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T07:25:48.888827Z",
     "iopub.status.busy": "2025-10-01T07:25:48.888584Z",
     "iopub.status.idle": "2025-10-01T07:25:49.003420Z",
     "shell.execute_reply": "2025-10-01T07:25:49.002548Z"
    },
    "papermill": {
     "duration": 0.148623,
     "end_time": "2025-10-01T07:25:49.004676",
     "exception": false,
     "start_time": "2025-10-01T07:25:48.856053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 517754 entries, 0 to 517753\n",
      "Data columns (total 14 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   id                      517754 non-null  int64  \n",
      " 1   road_type               517754 non-null  object \n",
      " 2   num_lanes               517754 non-null  int64  \n",
      " 3   curvature               517754 non-null  float64\n",
      " 4   speed_limit             517754 non-null  int64  \n",
      " 5   lighting                517754 non-null  object \n",
      " 6   weather                 517754 non-null  object \n",
      " 7   road_signs_present      517754 non-null  bool   \n",
      " 8   public_road             517754 non-null  bool   \n",
      " 9   time_of_day             517754 non-null  object \n",
      " 10  holiday                 517754 non-null  bool   \n",
      " 11  school_season           517754 non-null  bool   \n",
      " 12  num_reported_accidents  517754 non-null  int64  \n",
      " 13  accident_risk           517754 non-null  float64\n",
      "dtypes: bool(4), float64(2), int64(4), object(4)\n",
      "memory usage: 41.5+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e3cf569",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T07:25:49.070285Z",
     "iopub.status.busy": "2025-10-01T07:25:49.069715Z",
     "iopub.status.idle": "2025-10-01T07:25:49.204965Z",
     "shell.execute_reply": "2025-10-01T07:25:49.204138Z"
    },
    "papermill": {
     "duration": 0.16891,
     "end_time": "2025-10-01T07:25:49.206325",
     "exception": false,
     "start_time": "2025-10-01T07:25:49.037415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                        517754\n",
       "road_type                      3\n",
       "num_lanes                      4\n",
       "curvature                    261\n",
       "speed_limit                    5\n",
       "lighting                       3\n",
       "weather                        3\n",
       "road_signs_present             2\n",
       "public_road                    2\n",
       "time_of_day                    3\n",
       "holiday                        2\n",
       "school_season                  2\n",
       "num_reported_accidents         8\n",
       "accident_risk                 98\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4aa0d6e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T07:25:49.272699Z",
     "iopub.status.busy": "2025-10-01T07:25:49.272202Z",
     "iopub.status.idle": "2025-10-01T07:25:49.307550Z",
     "shell.execute_reply": "2025-10-01T07:25:49.306736Z"
    },
    "papermill": {
     "duration": 0.070361,
     "end_time": "2025-10-01T07:25:49.309202",
     "exception": false,
     "start_time": "2025-10-01T07:25:49.238841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>road_type</th>\n",
       "      <th>num_lanes</th>\n",
       "      <th>curvature</th>\n",
       "      <th>speed_limit</th>\n",
       "      <th>lighting</th>\n",
       "      <th>weather</th>\n",
       "      <th>road_signs_present</th>\n",
       "      <th>public_road</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>holiday</th>\n",
       "      <th>school_season</th>\n",
       "      <th>num_reported_accidents</th>\n",
       "      <th>accident_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>urban</td>\n",
       "      <td>2</td>\n",
       "      <td>0.06</td>\n",
       "      <td>35</td>\n",
       "      <td>daylight</td>\n",
       "      <td>rainy</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>urban</td>\n",
       "      <td>4</td>\n",
       "      <td>0.99</td>\n",
       "      <td>35</td>\n",
       "      <td>daylight</td>\n",
       "      <td>clear</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>evening</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rural</td>\n",
       "      <td>4</td>\n",
       "      <td>0.63</td>\n",
       "      <td>70</td>\n",
       "      <td>dim</td>\n",
       "      <td>clear</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>morning</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>highway</td>\n",
       "      <td>4</td>\n",
       "      <td>0.07</td>\n",
       "      <td>35</td>\n",
       "      <td>dim</td>\n",
       "      <td>rainy</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>morning</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rural</td>\n",
       "      <td>1</td>\n",
       "      <td>0.58</td>\n",
       "      <td>60</td>\n",
       "      <td>daylight</td>\n",
       "      <td>foggy</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>evening</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  road_type  num_lanes  curvature  speed_limit  lighting weather  \\\n",
       "0     urban          2       0.06           35  daylight   rainy   \n",
       "1     urban          4       0.99           35  daylight   clear   \n",
       "2     rural          4       0.63           70       dim   clear   \n",
       "3   highway          4       0.07           35       dim   rainy   \n",
       "4     rural          1       0.58           60  daylight   foggy   \n",
       "\n",
       "   road_signs_present  public_road time_of_day  holiday  school_season  \\\n",
       "0               False         True   afternoon    False           True   \n",
       "1                True        False     evening     True           True   \n",
       "2               False         True     morning     True          False   \n",
       "3                True         True     morning    False          False   \n",
       "4               False        False     evening     True          False   \n",
       "\n",
       "   num_reported_accidents  accident_risk  \n",
       "0                       1           0.13  \n",
       "1                       0           0.35  \n",
       "2                       2           0.30  \n",
       "3                       1           0.21  \n",
       "4                       1           0.56  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=train.drop(['id'],axis=1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ac78ec3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T07:25:49.383571Z",
     "iopub.status.busy": "2025-10-01T07:25:49.383335Z",
     "iopub.status.idle": "2025-10-01T07:25:49.398995Z",
     "shell.execute_reply": "2025-10-01T07:25:49.398395Z"
    },
    "papermill": {
     "duration": 0.051175,
     "end_time": "2025-10-01T07:25:49.400006",
     "exception": false,
     "start_time": "2025-10-01T07:25:49.348831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>road_type</th>\n",
       "      <th>num_lanes</th>\n",
       "      <th>curvature</th>\n",
       "      <th>speed_limit</th>\n",
       "      <th>lighting</th>\n",
       "      <th>weather</th>\n",
       "      <th>road_signs_present</th>\n",
       "      <th>public_road</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>holiday</th>\n",
       "      <th>school_season</th>\n",
       "      <th>num_reported_accidents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>highway</td>\n",
       "      <td>2</td>\n",
       "      <td>0.34</td>\n",
       "      <td>45</td>\n",
       "      <td>night</td>\n",
       "      <td>clear</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>urban</td>\n",
       "      <td>3</td>\n",
       "      <td>0.04</td>\n",
       "      <td>45</td>\n",
       "      <td>dim</td>\n",
       "      <td>foggy</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>urban</td>\n",
       "      <td>2</td>\n",
       "      <td>0.59</td>\n",
       "      <td>35</td>\n",
       "      <td>dim</td>\n",
       "      <td>clear</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rural</td>\n",
       "      <td>4</td>\n",
       "      <td>0.95</td>\n",
       "      <td>35</td>\n",
       "      <td>daylight</td>\n",
       "      <td>rainy</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>highway</td>\n",
       "      <td>2</td>\n",
       "      <td>0.86</td>\n",
       "      <td>35</td>\n",
       "      <td>daylight</td>\n",
       "      <td>clear</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>evening</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  road_type  num_lanes  curvature  speed_limit  lighting weather  \\\n",
       "0   highway          2       0.34           45     night   clear   \n",
       "1     urban          3       0.04           45       dim   foggy   \n",
       "2     urban          2       0.59           35       dim   clear   \n",
       "3     rural          4       0.95           35  daylight   rainy   \n",
       "4   highway          2       0.86           35  daylight   clear   \n",
       "\n",
       "   road_signs_present  public_road time_of_day  holiday  school_season  \\\n",
       "0                True         True   afternoon     True           True   \n",
       "1                True        False   afternoon     True          False   \n",
       "2                True        False   afternoon     True           True   \n",
       "3               False        False   afternoon    False          False   \n",
       "4                True        False     evening    False           True   \n",
       "\n",
       "   num_reported_accidents  \n",
       "0                       1  \n",
       "1                       0  \n",
       "2                       1  \n",
       "3                       2  \n",
       "4                       3  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=test.drop(['id'],axis=1)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87c332f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T07:25:49.471766Z",
     "iopub.status.busy": "2025-10-01T07:25:49.471546Z",
     "iopub.status.idle": "2025-10-01T07:25:49.568556Z",
     "shell.execute_reply": "2025-10-01T07:25:49.567976Z"
    },
    "papermill": {
     "duration": 0.134472,
     "end_time": "2025-10-01T07:25:49.569714",
     "exception": false,
     "start_time": "2025-10-01T07:25:49.435242",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_lanes</th>\n",
       "      <th>curvature</th>\n",
       "      <th>speed_limit</th>\n",
       "      <th>num_reported_accidents</th>\n",
       "      <th>accident_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>517754.000000</td>\n",
       "      <td>517754.000000</td>\n",
       "      <td>517754.000000</td>\n",
       "      <td>517754.000000</td>\n",
       "      <td>517754.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.491511</td>\n",
       "      <td>0.488719</td>\n",
       "      <td>46.112575</td>\n",
       "      <td>1.187970</td>\n",
       "      <td>0.352377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.120434</td>\n",
       "      <td>0.272563</td>\n",
       "      <td>15.788521</td>\n",
       "      <td>0.895961</td>\n",
       "      <td>0.166417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.460000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           num_lanes      curvature    speed_limit  num_reported_accidents  \\\n",
       "count  517754.000000  517754.000000  517754.000000           517754.000000   \n",
       "mean        2.491511       0.488719      46.112575                1.187970   \n",
       "std         1.120434       0.272563      15.788521                0.895961   \n",
       "min         1.000000       0.000000      25.000000                0.000000   \n",
       "25%         1.000000       0.260000      35.000000                1.000000   \n",
       "50%         2.000000       0.510000      45.000000                1.000000   \n",
       "75%         3.000000       0.710000      60.000000                2.000000   \n",
       "max         4.000000       1.000000      70.000000                7.000000   \n",
       "\n",
       "       accident_risk  \n",
       "count  517754.000000  \n",
       "mean        0.352377  \n",
       "std         0.166417  \n",
       "min         0.000000  \n",
       "25%         0.230000  \n",
       "50%         0.340000  \n",
       "75%         0.460000  \n",
       "max         1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97c4874f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T07:25:49.646739Z",
     "iopub.status.busy": "2025-10-01T07:25:49.646509Z",
     "iopub.status.idle": "2025-10-01T07:25:49.742481Z",
     "shell.execute_reply": "2025-10-01T07:25:49.741831Z"
    },
    "papermill": {
     "duration": 0.13615,
     "end_time": "2025-10-01T07:25:49.743728",
     "exception": false,
     "start_time": "2025-10-01T07:25:49.607578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "road_type                 0\n",
       "num_lanes                 0\n",
       "curvature                 0\n",
       "speed_limit               0\n",
       "lighting                  0\n",
       "weather                   0\n",
       "road_signs_present        0\n",
       "public_road               0\n",
       "time_of_day               0\n",
       "holiday                   0\n",
       "school_season             0\n",
       "num_reported_accidents    0\n",
       "accident_risk             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1aaabcae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T07:25:49.817864Z",
     "iopub.status.busy": "2025-10-01T07:25:49.817627Z",
     "iopub.status.idle": "2025-10-01T07:25:49.929197Z",
     "shell.execute_reply": "2025-10-01T07:25:49.928414Z"
    },
    "papermill": {
     "duration": 0.151061,
     "end_time": "2025-10-01T07:25:49.930697",
     "exception": false,
     "start_time": "2025-10-01T07:25:49.779636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "road_type                 0.0\n",
       "num_lanes                 0.0\n",
       "curvature                 0.0\n",
       "speed_limit               0.0\n",
       "lighting                  0.0\n",
       "weather                   0.0\n",
       "road_signs_present        0.0\n",
       "public_road               0.0\n",
       "time_of_day               0.0\n",
       "holiday                   0.0\n",
       "school_season             0.0\n",
       "num_reported_accidents    0.0\n",
       "accident_risk             0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(train.isnull().sum()*100/len(train),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "989a1d1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T07:25:50.004095Z",
     "iopub.status.busy": "2025-10-01T07:25:50.003857Z",
     "iopub.status.idle": "2025-10-01T07:25:50.099247Z",
     "shell.execute_reply": "2025-10-01T07:25:50.098501Z"
    },
    "papermill": {
     "duration": 0.131833,
     "end_time": "2025-10-01T07:25:50.100378",
     "exception": false,
     "start_time": "2025-10-01T07:25:49.968545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>road_type</th>\n",
       "      <th>num_lanes</th>\n",
       "      <th>curvature</th>\n",
       "      <th>speed_limit</th>\n",
       "      <th>lighting</th>\n",
       "      <th>weather</th>\n",
       "      <th>road_signs_present</th>\n",
       "      <th>public_road</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>holiday</th>\n",
       "      <th>school_season</th>\n",
       "      <th>num_reported_accidents</th>\n",
       "      <th>accident_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [road_type, num_lanes, curvature, speed_limit, lighting, weather, road_signs_present, public_road, time_of_day, holiday, school_season, num_reported_accidents, accident_risk]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.isna().any(axis=1)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7665c359",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T07:25:50.176243Z",
     "iopub.status.busy": "2025-10-01T07:25:50.176025Z",
     "iopub.status.idle": "2025-10-01T07:25:50.297826Z",
     "shell.execute_reply": "2025-10-01T07:25:50.297184Z"
    },
    "papermill": {
     "duration": 0.156129,
     "end_time": "2025-10-01T07:25:50.299050",
     "exception": false,
     "start_time": "2025-10-01T07:25:50.142921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No work needed\n"
     ]
    }
   ],
   "source": [
    "counter=0\n",
    "for i in test.select_dtypes(include=['object']).columns.tolist():\n",
    "    if (len(list(set(train[i].unique().tolist())^set(test[i].unique().tolist())))!=0):\n",
    "        print(i ,'need to be worked on')\n",
    "        counter+=1\n",
    "    else:\n",
    "        continue\n",
    "if(counter==0):\n",
    "    print('No work needed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6728ab1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T07:25:50.376592Z",
     "iopub.status.busy": "2025-10-01T07:25:50.376382Z",
     "iopub.status.idle": "2025-10-01T07:25:50.399434Z",
     "shell.execute_reply": "2025-10-01T07:25:50.398737Z"
    },
    "papermill": {
     "duration": 0.065094,
     "end_time": "2025-10-01T07:25:50.400558",
     "exception": false,
     "start_time": "2025-10-01T07:25:50.335464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>road_type</th>\n",
       "      <th>lighting</th>\n",
       "      <th>weather</th>\n",
       "      <th>road_signs_present</th>\n",
       "      <th>public_road</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>holiday</th>\n",
       "      <th>school_season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>urban</td>\n",
       "      <td>daylight</td>\n",
       "      <td>rainy</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>urban</td>\n",
       "      <td>daylight</td>\n",
       "      <td>clear</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>evening</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rural</td>\n",
       "      <td>dim</td>\n",
       "      <td>clear</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>morning</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>highway</td>\n",
       "      <td>dim</td>\n",
       "      <td>rainy</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>morning</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rural</td>\n",
       "      <td>daylight</td>\n",
       "      <td>foggy</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>evening</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  road_type  lighting weather  road_signs_present  public_road time_of_day  \\\n",
       "0     urban  daylight   rainy               False         True   afternoon   \n",
       "1     urban  daylight   clear                True        False     evening   \n",
       "2     rural       dim   clear               False         True     morning   \n",
       "3   highway       dim   rainy                True         True     morning   \n",
       "4     rural  daylight   foggy               False        False     evening   \n",
       "\n",
       "   holiday  school_season  \n",
       "0    False           True  \n",
       "1     True           True  \n",
       "2     True          False  \n",
       "3    False          False  \n",
       "4     True          False  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[test.select_dtypes(include=['object','bool']).columns.tolist()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f208d87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T07:25:50.473345Z",
     "iopub.status.busy": "2025-10-01T07:25:50.472920Z",
     "iopub.status.idle": "2025-10-01T07:25:50.511671Z",
     "shell.execute_reply": "2025-10-01T07:25:50.510978Z"
    },
    "papermill": {
     "duration": 0.076304,
     "end_time": "2025-10-01T07:25:50.512811",
     "exception": false,
     "start_time": "2025-10-01T07:25:50.436507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>road_type</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>highway</td>\n",
       "      <td>173672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rural</td>\n",
       "      <td>172719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>urban</td>\n",
       "      <td>171363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  road_type   count\n",
       "0   highway  173672\n",
       "1     rural  172719\n",
       "2     urban  171363"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "road_type=train['road_type'].value_counts().to_frame()\n",
    "road_type.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e6b332b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T07:25:50.580989Z",
     "iopub.status.busy": "2025-10-01T07:25:50.580786Z",
     "iopub.status.idle": "2025-10-01T07:25:50.618282Z",
     "shell.execute_reply": "2025-10-01T07:25:50.617756Z"
    },
    "papermill": {
     "duration": 0.072792,
     "end_time": "2025-10-01T07:25:50.619354",
     "exception": false,
     "start_time": "2025-10-01T07:25:50.546562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lighting</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dim</td>\n",
       "      <td>183826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>daylight</td>\n",
       "      <td>178015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>night</td>\n",
       "      <td>155913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lighting   count\n",
       "0       dim  183826\n",
       "1  daylight  178015\n",
       "2     night  155913"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lighting=train['lighting'].value_counts().to_frame()\n",
    "lighting.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fd736ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T07:25:50.688108Z",
     "iopub.status.busy": "2025-10-01T07:25:50.687848Z",
     "iopub.status.idle": "2025-10-01T07:25:50.725786Z",
     "shell.execute_reply": "2025-10-01T07:25:50.725082Z"
    },
    "papermill": {
     "duration": 0.07356,
     "end_time": "2025-10-01T07:25:50.726910",
     "exception": false,
     "start_time": "2025-10-01T07:25:50.653350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weather</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>foggy</td>\n",
       "      <td>181463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clear</td>\n",
       "      <td>179306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rainy</td>\n",
       "      <td>156985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  weather   count\n",
       "0   foggy  181463\n",
       "1   clear  179306\n",
       "2   rainy  156985"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather=train['weather'].value_counts().to_frame()\n",
    "weather.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5851ae39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T07:25:50.798072Z",
     "iopub.status.busy": "2025-10-01T07:25:50.797850Z",
     "iopub.status.idle": "2025-10-01T07:25:50.836195Z",
     "shell.execute_reply": "2025-10-01T07:25:50.835443Z"
    },
    "papermill": {
     "duration": 0.077353,
     "end_time": "2025-10-01T07:25:50.837422",
     "exception": false,
     "start_time": "2025-10-01T07:25:50.760069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>morning</td>\n",
       "      <td>173410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>evening</td>\n",
       "      <td>172837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>afternoon</td>\n",
       "      <td>171507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  time_of_day   count\n",
       "0     morning  173410\n",
       "1     evening  172837\n",
       "2   afternoon  171507"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_of_day=train['time_of_day'].value_counts().to_frame()\n",
    "time_of_day.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb897222",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T07:25:50.907658Z",
     "iopub.status.busy": "2025-10-01T07:25:50.907459Z",
     "iopub.status.idle": "2025-10-01T07:25:50.918147Z",
     "shell.execute_reply": "2025-10-01T07:25:50.917564Z"
    },
    "papermill": {
     "duration": 0.047287,
     "end_time": "2025-10-01T07:25:50.919316",
     "exception": false,
     "start_time": "2025-10-01T07:25:50.872029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>road_signs_present</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>259289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>258465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   road_signs_present   count\n",
       "0               False  259289\n",
       "1                True  258465"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "road_signs_present=train['road_signs_present'].value_counts().to_frame()\n",
    "road_signs_present.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70da58b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T07:25:50.987166Z",
     "iopub.status.busy": "2025-10-01T07:25:50.986926Z",
     "iopub.status.idle": "2025-10-01T07:25:50.996147Z",
     "shell.execute_reply": "2025-10-01T07:25:50.995571Z"
    },
    "papermill": {
     "duration": 0.044915,
     "end_time": "2025-10-01T07:25:50.997283",
     "exception": false,
     "start_time": "2025-10-01T07:25:50.952368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>public_road</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>260045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>257709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   public_road   count\n",
       "0         True  260045\n",
       "1        False  257709"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "public_road=train['public_road'].value_counts().to_frame()\n",
    "public_road.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1032a49f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T07:25:51.065370Z",
     "iopub.status.busy": "2025-10-01T07:25:51.065178Z",
     "iopub.status.idle": "2025-10-01T07:25:51.074156Z",
     "shell.execute_reply": "2025-10-01T07:25:51.073606Z"
    },
    "papermill": {
     "duration": 0.043906,
     "end_time": "2025-10-01T07:25:51.075132",
     "exception": false,
     "start_time": "2025-10-01T07:25:51.031226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holiday</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>260688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>257066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   holiday   count\n",
       "0     True  260688\n",
       "1    False  257066"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holiday=train['holiday'].value_counts().to_frame()\n",
    "holiday.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07e705c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T07:25:51.142622Z",
     "iopub.status.busy": "2025-10-01T07:25:51.142427Z",
     "iopub.status.idle": "2025-10-01T07:25:51.151619Z",
     "shell.execute_reply": "2025-10-01T07:25:51.150954Z"
    },
    "papermill": {
     "duration": 0.044183,
     "end_time": "2025-10-01T07:25:51.152801",
     "exception": false,
     "start_time": "2025-10-01T07:25:51.108618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_season</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>260164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>257590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   school_season   count\n",
       "0          False  260164\n",
       "1           True  257590"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "school_season=train['school_season'].value_counts().to_frame()\n",
    "school_season.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "baab21d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T07:25:51.222686Z",
     "iopub.status.busy": "2025-10-01T07:25:51.222489Z",
     "iopub.status.idle": "2025-10-01T07:25:51.433672Z",
     "shell.execute_reply": "2025-10-01T07:25:51.432875Z"
    },
    "papermill": {
     "duration": 0.247362,
     "end_time": "2025-10-01T07:25:51.434984",
     "exception": false,
     "start_time": "2025-10-01T07:25:51.187622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    517098\n",
       "True        656\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3763a4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T07:25:51.505363Z",
     "iopub.status.busy": "2025-10-01T07:25:51.504847Z",
     "iopub.status.idle": "2025-10-01T07:25:51.529885Z",
     "shell.execute_reply": "2025-10-01T07:25:51.529393Z"
    },
    "papermill": {
     "duration": 0.061175,
     "end_time": "2025-10-01T07:25:51.531096",
     "exception": false,
     "start_time": "2025-10-01T07:25:51.469921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    517754.000000\n",
       "mean          0.352377\n",
       "std           0.166417\n",
       "min           0.000000\n",
       "25%           0.230000\n",
       "50%           0.340000\n",
       "75%           0.460000\n",
       "max           1.000000\n",
       "Name: accident_risk, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['accident_risk'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8188860c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T07:25:51.601332Z",
     "iopub.status.busy": "2025-10-01T07:25:51.600737Z",
     "iopub.status.idle": "2025-10-01T07:25:51.625486Z",
     "shell.execute_reply": "2025-10-01T07:25:51.624922Z"
    },
    "papermill": {
     "duration": 0.060252,
     "end_time": "2025-10-01T07:25:51.626553",
     "exception": false,
     "start_time": "2025-10-01T07:25:51.566301",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    517754.000000\n",
       "mean          0.352377\n",
       "std           0.166417\n",
       "min           0.000000\n",
       "25%           0.230000\n",
       "50%           0.340000\n",
       "75%           0.460000\n",
       "max           1.000000\n",
       "Name: accident_risk, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = 'accident_risk'\n",
    "train[label].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d9c0cf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T07:25:51.695008Z",
     "iopub.status.busy": "2025-10-01T07:25:51.694802Z",
     "iopub.status.idle": "2025-10-01T07:25:53.978910Z",
     "shell.execute_reply": "2025-10-01T07:25:53.978366Z"
    },
    "papermill": {
     "duration": 2.319836,
     "end_time": "2025-10-01T07:25:53.980300",
     "exception": false,
     "start_time": "2025-10-01T07:25:51.660464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e815c5bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T07:25:54.050299Z",
     "iopub.status.busy": "2025-10-01T07:25:54.049521Z",
     "iopub.status.idle": "2025-10-01T11:13:33.821870Z",
     "shell.execute_reply": "2025-10-01T11:13:33.820982Z"
    },
    "papermill": {
     "duration": 13659.808135,
     "end_time": "2025-10-01T11:13:33.823352",
     "exception": false,
     "start_time": "2025-10-01T07:25:54.015217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20251001_072554\"\n",
      "Verbosity: 3 (Detailed Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.11.13\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP PREEMPT_DYNAMIC Sun Nov 10 10:07:59 UTC 2024\n",
      "CPU Count:          4\n",
      "GPU Count:          2\n",
      "Memory Avail:       29.99 GB / 31.35 GB (95.7%)\n",
      "Disk Space Avail:   19.50 GB / 19.52 GB (99.9%)\n",
      "===================================================\n",
      "Presets specified: ['good_quality']\n",
      "============ fit kwarg info ============\n",
      "User Specified kwargs:\n",
      "{'ag_args_fit': {'num_gpus': 1},\n",
      " 'auto_stack': True,\n",
      " 'num_bag_sets': 1,\n",
      " 'refit_full': True,\n",
      " 'save_bag_folds': False,\n",
      " 'set_best_to_refit_full': True,\n",
      " 'verbosity': 3}\n",
      "Full kwargs:\n",
      "{'_experimental_dynamic_hyperparameters': False,\n",
      " '_feature_generator_kwargs': None,\n",
      " '_save_bag_folds': None,\n",
      " 'ag_args': None,\n",
      " 'ag_args_ensemble': None,\n",
      " 'ag_args_fit': {'num_gpus': 1},\n",
      " 'auto_stack': True,\n",
      " 'calibrate': 'auto',\n",
      " 'delay_bag_sets': False,\n",
      " 'ds_args': {'clean_up_fits': True,\n",
      "             'detection_time_frac': 0.25,\n",
      "             'enable_callbacks': False,\n",
      "             'enable_ray_logging': True,\n",
      "             'holdout_data': None,\n",
      "             'holdout_frac': 0.1111111111111111,\n",
      "             'memory_safe_fits': True,\n",
      "             'n_folds': 2,\n",
      "             'n_repeats': 1,\n",
      "             'validation_procedure': 'holdout'},\n",
      " 'excluded_model_types': None,\n",
      " 'feature_generator': 'auto',\n",
      " 'feature_prune_kwargs': None,\n",
      " 'holdout_frac': None,\n",
      " 'hyperparameter_tune_kwargs': None,\n",
      " 'included_model_types': None,\n",
      " 'keep_only_best': False,\n",
      " 'learning_curves': False,\n",
      " 'name_suffix': None,\n",
      " 'num_bag_folds': None,\n",
      " 'num_bag_sets': 1,\n",
      " 'num_stack_levels': None,\n",
      " 'pseudo_data': None,\n",
      " 'raise_on_model_failure': False,\n",
      " 'raise_on_no_models_fitted': True,\n",
      " 'refit_full': True,\n",
      " 'save_bag_folds': False,\n",
      " 'save_space': False,\n",
      " 'set_best_to_refit_full': True,\n",
      " 'test_data': None,\n",
      " 'unlabeled_data': None,\n",
      " 'use_bag_holdout': False,\n",
      " 'verbosity': 3}\n",
      "========================================\n",
      "Using hyperparameters preset: hyperparameters='light'\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Note: `save_bag_folds=False`! This will greatly reduce peak disk usage during fit (by ~8x), but runs the risk of an out-of-memory error during model refit if memory is small relative to the data size.\n",
      "\tYou can avoid this risk by setting `save_bag_folds=True`.\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 8100s of the 32400s of remaining time (25%).\n",
      "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
      "2025-10-01 07:25:59,956\tINFO worker.py:1843 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\t\tContext path: \"/kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Running DyStack sub-fit ...\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/learner.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/predictor.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Beginning AutoGluon training ... Time limit = 8096s\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m AutoGluon will save models to \"/kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Train Data Rows:    460225\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Train Data Columns: 12\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Label Column:       accident_risk\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Problem Type:       regression\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Preprocessing data ...\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Using Feature Generators to preprocess the data ...\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tAvailable Memory:                    29827.71 MB\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tTrain Data (Original)  Memory Usage: 126.25 MB (0.4% of available memory)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tStage 1 Generators:\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t\t('bool', 'bool')     : 4 | ['road_signs_present', 'public_road', 'holiday', 'school_season']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t\t('float64', 'float') : 1 | ['curvature']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t\t('int64', 'int')     : 3 | ['num_lanes', 'speed_limit', 'num_reported_accidents']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t\t('object', 'object') : 4 | ['road_type', 'lighting', 'weather', 'time_of_day']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t\t('bool', [])   : 4 | ['road_signs_present', 'public_road', 'holiday', 'school_season']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t\t('float', [])  : 1 | ['curvature']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t\t('int', [])    : 3 | ['num_lanes', 'speed_limit', 'num_reported_accidents']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t\t('object', []) : 4 | ['road_type', 'lighting', 'weather', 'time_of_day']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t\t('float', [])     : 1 | ['curvature']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t\t('int', [])       : 3 | ['num_lanes', 'speed_limit', 'num_reported_accidents']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t\t('int', ['bool']) : 4 | ['road_signs_present', 'public_road', 'holiday', 'school_season']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t\t('object', [])    : 4 | ['road_type', 'lighting', 'weather', 'time_of_day']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t0.2s = Fit runtime\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t12 features in original data used to generate 12 features in processed data.\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tStage 2 Generators:\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t\t('float', [])     : 1 | ['curvature']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t\t('int', [])       : 3 | ['num_lanes', 'speed_limit', 'num_reported_accidents']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t\t('int', ['bool']) : 4 | ['road_signs_present', 'public_road', 'holiday', 'school_season']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t\t('object', [])    : 4 | ['road_type', 'lighting', 'weather', 'time_of_day']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t\t('float', [])     : 1 | ['curvature']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t\t('int', [])       : 3 | ['num_lanes', 'speed_limit', 'num_reported_accidents']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t\t('int', ['bool']) : 4 | ['road_signs_present', 'public_road', 'holiday', 'school_season']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t\t('object', [])    : 4 | ['road_type', 'lighting', 'weather', 'time_of_day']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t0.2s = Fit runtime\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t12 features in original data used to generate 12 features in processed data.\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tStage 3 Generators:\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t\t('float', [])     : 1 | ['curvature']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t\t('int', [])       : 3 | ['num_lanes', 'speed_limit', 'num_reported_accidents']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t\t('int', ['bool']) : 4 | ['road_signs_present', 'public_road', 'holiday', 'school_season']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t\t('float', [])     : 1 | ['curvature']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t\t('int', [])       : 3 | ['num_lanes', 'speed_limit', 'num_reported_accidents']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t\t('int', ['bool']) : 4 | ['road_signs_present', 'public_road', 'holiday', 'school_season']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t0.1s = Fit runtime\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t8 features in original data used to generate 8 features in processed data.\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\tFitting CategoryFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t\t\t('category', []) : 4 | ['road_type', 'lighting', 'weather', 'time_of_day']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t\t\t('category', []) : 4 | ['road_type', 'lighting', 'weather', 'time_of_day']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t\t0.1s = Fit runtime\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t\t('object', []) : 4 | ['road_type', 'lighting', 'weather', 'time_of_day']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t\t('category', []) : 4 | ['road_type', 'lighting', 'weather', 'time_of_day']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t0.2s = Fit runtime\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tStage 4 Generators:\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t\t('category', [])  : 4 | ['road_type', 'lighting', 'weather', 'time_of_day']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t\t('float', [])     : 1 | ['curvature']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t\t('int', [])       : 3 | ['num_lanes', 'speed_limit', 'num_reported_accidents']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t\t('int', ['bool']) : 4 | ['road_signs_present', 'public_road', 'holiday', 'school_season']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t\t('category', [])  : 4 | ['road_type', 'lighting', 'weather', 'time_of_day']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t\t('float', [])     : 1 | ['curvature']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t\t('int', [])       : 3 | ['num_lanes', 'speed_limit', 'num_reported_accidents']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t\t('int', ['bool']) : 4 | ['road_signs_present', 'public_road', 'holiday', 'school_season']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t0.1s = Fit runtime\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t12 features in original data used to generate 12 features in processed data.\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tStage 5 Generators:\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t\t('category', [])  : 4 | ['road_type', 'lighting', 'weather', 'time_of_day']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t\t('float', [])     : 1 | ['curvature']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t\t('int', [])       : 3 | ['num_lanes', 'speed_limit', 'num_reported_accidents']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t\t('int', ['bool']) : 4 | ['road_signs_present', 'public_road', 'holiday', 'school_season']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t\t('category', [])  : 4 | ['road_type', 'lighting', 'weather', 'time_of_day']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t\t('float', [])     : 1 | ['curvature']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t\t('int', [])       : 3 | ['num_lanes', 'speed_limit', 'num_reported_accidents']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t\t('int', ['bool']) : 4 | ['road_signs_present', 'public_road', 'holiday', 'school_season']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t0.1s = Fit runtime\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t\t12 features in original data used to generate 12 features in processed data.\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tTypes of features in original data (exact raw dtype, raw dtype):\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t('bool', 'bool')     : 4 | ['road_signs_present', 'public_road', 'holiday', 'school_season']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t('float64', 'float') : 1 | ['curvature']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t('int64', 'int')     : 3 | ['num_lanes', 'speed_limit', 'num_reported_accidents']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t('object', 'object') : 4 | ['road_type', 'lighting', 'weather', 'time_of_day']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t('bool', [])   : 4 | ['road_signs_present', 'public_road', 'holiday', 'school_season']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t('float', [])  : 1 | ['curvature']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t('int', [])    : 3 | ['num_lanes', 'speed_limit', 'num_reported_accidents']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t('object', []) : 4 | ['road_type', 'lighting', 'weather', 'time_of_day']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t('category', 'category') : 4 | ['road_type', 'lighting', 'weather', 'time_of_day']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t('float64', 'float')     : 1 | ['curvature']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t('int64', 'int')         : 3 | ['num_lanes', 'speed_limit', 'num_reported_accidents']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t('int8', 'int')          : 4 | ['road_signs_present', 'public_road', 'holiday', 'school_season']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t('category', [])  : 4 | ['road_type', 'lighting', 'weather', 'time_of_day']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t('float', [])     : 1 | ['curvature']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t('int', [])       : 3 | ['num_lanes', 'speed_limit', 'num_reported_accidents']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\t('int', ['bool']) : 4 | ['road_signs_present', 'public_road', 'holiday', 'school_season']\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t1.3s = Fit runtime\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t12 features in original data used to generate 12 features in processed data.\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tTrain Data (Processed) Memory Usage: 17.56 MB (0.1% of available memory)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Data preprocessing and feature engineering runtime = 1.41s ...\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/learner.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m User-specified model hyperparameters to be fit:\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m {\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t'NN_TORCH': [{}],\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t'CAT': [{}],\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t'XGB': [{}],\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t'FASTAI': [{}],\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m }\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/utils/data/X.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/utils/data/y.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Model configs that will be trained (in order):\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tLightGBMXT_BAG_L1: \t{'extra_trees': True, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}, 'ag_args_ensemble': {'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tLightGBM_BAG_L1: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}, 'ag_args_ensemble': {'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tRandomForestMSE_BAG_L1: \t{'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'problem_types': ['regression', 'quantile'], 'name_suffix': 'MSE', 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True, 'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tCatBoost_BAG_L1: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}, 'ag_args_ensemble': {'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tExtraTreesMSE_BAG_L1: \t{'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'problem_types': ['regression', 'quantile'], 'name_suffix': 'MSE', 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True, 'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tNeuralNetFastAI_BAG_L1: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}, 'ag_args_ensemble': {'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tXGBoost_BAG_L1: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}, 'ag_args_ensemble': {'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tNeuralNetTorch_BAG_L1: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}, 'ag_args_ensemble': {'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tLightGBMLarge_BAG_L1: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_ensemble': {'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Fitting 9 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 5394.84s of the 8094.27s of remaining time.\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tFitting LightGBMXT_BAG_L1 with 'num_gpus': 2, 'num_cpus': 4\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=0.49%)\n",
      "\u001b[36m(_ray_fit pid=610)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=610)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True, 'device': 'gpu'}\n",
      "\u001b[36m(_ray_fit pid=610)\u001b[0m 1 warning generated.\n",
      "\u001b[36m(_ray_fit pid=611)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=611)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True, 'device': 'gpu'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=610)\u001b[0m [50]\tvalid_set's rmse: 0.0671003\n",
      "\u001b[36m(_ray_fit pid=610)\u001b[0m [300]\tvalid_set's rmse: 0.0567838\u001b[32m [repeated 10x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=610)\u001b[0m [600]\tvalid_set's rmse: 0.0565547\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=611)\u001b[0m [1000]\tvalid_set's rmse: 0.0566702\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=611)\u001b[0m [1450]\tvalid_set's rmse: 0.0566406\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=610)\u001b[0m [1900]\tvalid_set's rmse: 0.0564498\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=610)\u001b[0m [2350]\tvalid_set's rmse: 0.0564524\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=611)\u001b[0m [2800]\tvalid_set's rmse: 0.0566326\u001b[32m [repeated 14x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=610)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/S1F1/model.pkl\n",
      "\u001b[36m(_ray_fit pid=611)\u001b[0m 1 warning generated.\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=700)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=700)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True, 'device': 'gpu'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=700)\u001b[0m [50]\tvalid_set's rmse: 0.0655788\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=611)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/S1F2/model.pkl\n",
      "\u001b[36m(_ray_fit pid=741)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=741)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True, 'device': 'gpu'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=700)\u001b[0m [300]\tvalid_set's rmse: 0.0571948\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=700)\u001b[0m [650]\tvalid_set's rmse: 0.0570127\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=700)\u001b[0m [1100]\tvalid_set's rmse: 0.0569644\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=700)\u001b[0m [1550]\tvalid_set's rmse: 0.0569491\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=700)\u001b[0m [2000]\tvalid_set's rmse: 0.056948\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=700)\u001b[0m [2450]\tvalid_set's rmse: 0.056946\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=700)\u001b[0m [2900]\tvalid_set's rmse: 0.0569562\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=741)\u001b[0m [2600]\tvalid_set's rmse: 0.0562825\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=741)\u001b[0m [3050]\tvalid_set's rmse: 0.0562925\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=700)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/S1F3/model.pkl\n",
      "\u001b[36m(_ray_fit pid=790)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=790)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True, 'device': 'gpu'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=790)\u001b[0m [50]\tvalid_set's rmse: 0.0667877\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=741)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/S1F4/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=790)\u001b[0m [300]\tvalid_set's rmse: 0.0564723\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=831)\u001b[0m \tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=831)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True, 'device': 'gpu'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=790)\u001b[0m [650]\tvalid_set's rmse: 0.0562638\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=790)\u001b[0m [1050]\tvalid_set's rmse: 0.0562211\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=790)\u001b[0m [1500]\tvalid_set's rmse: 0.0561887\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=790)\u001b[0m [1950]\tvalid_set's rmse: 0.056183\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=790)\u001b[0m [2400]\tvalid_set's rmse: 0.0561789\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=790)\u001b[0m [2850]\tvalid_set's rmse: 0.0561802\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=790)\u001b[0m [3300]\tvalid_set's rmse: 0.0561919\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=831)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/S1F6/model.pkl\n",
      "\u001b[36m(_ray_fit pid=878)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=878)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True, 'device': 'gpu'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=878)\u001b[0m [50]\tvalid_set's rmse: 0.0678604\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=790)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/S1F5/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=878)\u001b[0m [300]\tvalid_set's rmse: 0.0569391\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=919)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=919)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True, 'device': 'gpu'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=919)\u001b[0m [50]\tvalid_set's rmse: 0.0661115\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=878)\u001b[0m [1000]\tvalid_set's rmse: 0.0566616\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=919)\u001b[0m [600]\tvalid_set's rmse: 0.0565367\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=878)\u001b[0m [1850]\tvalid_set's rmse: 0.0566127\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=878)\u001b[0m [2300]\tvalid_set's rmse: 0.0566112\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=878)\u001b[0m [2750]\tvalid_set's rmse: 0.0566109\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=919)\u001b[0m [2200]\tvalid_set's rmse: 0.0564396\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=919)\u001b[0m [2650]\tvalid_set's rmse: 0.056438\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=878)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/S1F7/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=919)\u001b[0m [3100]\tvalid_set's rmse: 0.0564414\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=288)\u001b[0m \t-0.0564\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t227.8s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t97.27s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t591.4\t = Inference  throughput (rows/s | 57529 batch size)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 5147.53s of the 7846.97s of remaining time.\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/trainer.pkl\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tFitting LightGBM_BAG_L1 with 'num_gpus': 2, 'num_cpus': 4\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=0.49%)\n",
      "\u001b[36m(_ray_fit pid=1062)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=1062)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'device': 'gpu'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1062)\u001b[0m [50]\tvalid_set's rmse: 0.0585022\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1062)\u001b[0m [350]\tvalid_set's rmse: 0.0561552\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1062)\u001b[0m [850]\tvalid_set's rmse: 0.0561167\u001b[32m [repeated 19x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1063)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/S1F2/model.pkl\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1063)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=1063)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'device': 'gpu'}\n",
      "\u001b[36m(_ray_fit pid=1145)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=1145)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'device': 'gpu'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1145)\u001b[0m [50]\tvalid_set's rmse: 0.0590831\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1145)\u001b[0m [350]\tvalid_set's rmse: 0.0566538\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1145)\u001b[0m [850]\tvalid_set's rmse: 0.0566219\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1145)\u001b[0m [1400]\tvalid_set's rmse: 0.0566265\u001b[32m [repeated 17x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1176)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/S1F4/model.pkl\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1176)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=1176)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'device': 'gpu'}\n",
      "\u001b[36m(_ray_fit pid=1229)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=1229)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'device': 'gpu'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1229)\u001b[0m [50]\tvalid_set's rmse: 0.0583491\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1145)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/S1F3/model.pkl\n",
      "\u001b[36m(_ray_fit pid=1268)\u001b[0m \tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=1268)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'device': 'gpu'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1229)\u001b[0m [350]\tvalid_set's rmse: 0.0558873\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1268)\u001b[0m [250]\tvalid_set's rmse: 0.0556701\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1229)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/S1F5/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1268)\u001b[0m [700]\tvalid_set's rmse: 0.0556096\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1310)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=1310)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'device': 'gpu'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1310)\u001b[0m [150]\tvalid_set's rmse: 0.05649\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1268)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/S1F6/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1310)\u001b[0m [550]\tvalid_set's rmse: 0.0563445\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1351)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=1351)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'device': 'gpu'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1351)\u001b[0m [100]\tvalid_set's rmse: 0.0563245\u001b[32m [repeated 10x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1310)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/S1F7/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1351)\u001b[0m [450]\tvalid_set's rmse: 0.0560376\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=288)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/model.pkl\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t-0.0561\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t90.47s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t28.16s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t2042.9\t = Inference  throughput (rows/s | 57529 batch size)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 5052.78s of the 7752.22s of remaining time.\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tFitting RandomForestMSE_BAG_L1 with 'num_gpus': 1, 'num_cpus': 4\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/RandomForestMSE_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t70.97s\t= Estimated out-of-fold prediction time...\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/RandomForestMSE_BAG_L1/utils/model_template.pkl\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t-0.0566\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t117.5s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t13.93s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t33030.6\t = Inference  throughput (rows/s | 460225 batch size)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 4920.07s of the 7619.51s of remaining time.\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/trainer.pkl\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tFitting CatBoost_BAG_L1 with 'num_gpus': 2, 'num_cpus': 4\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=1.80%)\n",
      "\u001b[36m(_ray_fit pid=1533)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=1533)\u001b[0m \tCatboost model hyperparameters: {'iterations': 10000, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'RMSE', 'thread_count': 1, 'loss_function': 'RMSE', 'task_type': 'GPU'}\n",
      "\u001b[36m(_ray_fit pid=1533)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1533)\u001b[0m 0:\tlearn: 0.1617314\ttest: 0.1618882\tbest: 0.1618882 (0)\ttotal: 128ms\tremaining: 128ms\n",
      "\u001b[36m(_ray_fit pid=1533)\u001b[0m 1:\tlearn: 0.1573398\ttest: 0.1574666\tbest: 0.1574666 (1)\ttotal: 139ms\tremaining: 0us\n",
      "\u001b[36m(_ray_fit pid=1533)\u001b[0m bestTest = 0.1574665974\n",
      "\u001b[36m(_ray_fit pid=1533)\u001b[0m bestIteration = 1\n",
      "\u001b[36m(_ray_fit pid=1351)\u001b[0m [750]\tvalid_set's rmse: 0.0560347\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1532)\u001b[0m 140:\tlearn: 0.0564669\ttest: 0.0567135\tbest: 0.0567135 (140)\ttotal: 3.64s\tremaining: 26.4s\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1532)\u001b[0m bestTest = 0.1572838261\n",
      "\u001b[36m(_ray_fit pid=1532)\u001b[0m bestIteration = 1\n",
      "\u001b[36m(_ray_fit pid=1533)\u001b[0m 340:\tlearn: 0.0564966\ttest: 0.0563486\tbest: 0.0563486 (340)\ttotal: 8.91s\tremaining: 21.4s\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1533)\u001b[0m 540:\tlearn: 0.0563545\ttest: 0.0562802\tbest: 0.0562802 (540)\ttotal: 14s\tremaining: 16.1s\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1532)\u001b[0m 740:\tlearn: 0.0559746\ttest: 0.0564034\tbest: 0.0564032 (736)\ttotal: 19.2s\tremaining: 10.9s\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1532)\u001b[0m 940:\tlearn: 0.0558999\ttest: 0.0563788\tbest: 0.0563788 (940)\ttotal: 24.3s\tremaining: 5.73s\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1532)\u001b[0m 1140:\tlearn: 0.0558292\ttest: 0.0563589\tbest: 0.0563589 (1140)\ttotal: 29.4s\tremaining: 567ms\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1533)\u001b[0m bestTest = 0.05618674281\n",
      "\u001b[36m(_ray_fit pid=1533)\u001b[0m bestIteration = 1157\n",
      "\u001b[36m(_ray_fit pid=1533)\u001b[0m Shrink model to first 1158 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1533)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/S1F1/model.pkl\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1532)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=1532)\u001b[0m \tCatboost model hyperparameters: {'iterations': 10000, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'RMSE', 'thread_count': 1, 'loss_function': 'RMSE', 'task_type': 'GPU'}\n",
      "\u001b[36m(_ray_fit pid=1532)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\u001b[36m(_ray_fit pid=1629)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=1629)\u001b[0m \tCatboost model hyperparameters: {'iterations': 10000, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'RMSE', 'thread_count': 1, 'loss_function': 'RMSE', 'task_type': 'GPU'}\n",
      "\u001b[36m(_ray_fit pid=1629)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1636)\u001b[0m 1:\tlearn: 0.1574392\ttest: 0.1567770\tbest: 0.1567770 (1)\ttotal: 34.2ms\tremaining: 0us\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1636)\u001b[0m bestTest = 0.156777047\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1636)\u001b[0m bestIteration = 1\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1532)\u001b[0m Shrink model to first 1161 iterations.\n",
      "\u001b[36m(_ray_fit pid=1629)\u001b[0m 200:\tlearn: 0.0563084\ttest: 0.0569482\tbest: 0.0569482 (200)\ttotal: 5.17s\tremaining: 40.9s\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1636)\u001b[0m 360:\tlearn: 0.0562891\ttest: 0.0562407\tbest: 0.0562407 (360)\ttotal: 8.98s\tremaining: 21.5s\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1629)\u001b[0m 620:\tlearn: 0.0559882\ttest: 0.0567737\tbest: 0.0567733 (617)\ttotal: 15.7s\tremaining: 29.6s\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1629)\u001b[0m 820:\tlearn: 0.0558947\ttest: 0.0567361\tbest: 0.0567361 (820)\ttotal: 20.8s\tremaining: 24.6s\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1629)\u001b[0m 1020:\tlearn: 0.0558196\ttest: 0.0567116\tbest: 0.0567115 (1014)\ttotal: 25.9s\tremaining: 19.5s\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1636)\u001b[0m 1180:\tlearn: 0.0558861\ttest: 0.0560745\tbest: 0.0560744 (1179)\ttotal: 29.9s\tremaining: 1.14s\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1636)\u001b[0m bestTest = 0.056069535\n",
      "\u001b[36m(_ray_fit pid=1636)\u001b[0m bestIteration = 1225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1636)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/S1F4/model.pkl\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1636)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=1636)\u001b[0m \tCatboost model hyperparameters: {'iterations': 10000, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'RMSE', 'thread_count': 1, 'loss_function': 'RMSE', 'task_type': 'GPU'}\n",
      "\u001b[36m(_ray_fit pid=1636)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\u001b[36m(_ray_fit pid=1733)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=1733)\u001b[0m \tCatboost model hyperparameters: {'iterations': 10000, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'RMSE', 'thread_count': 1, 'loss_function': 'RMSE', 'task_type': 'GPU'}\n",
      "\u001b[36m(_ray_fit pid=1733)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1629)\u001b[0m 1420:\tlearn: 0.0556887\ttest: 0.0566707\tbest: 0.0566706 (1417)\ttotal: 36.6s\tremaining: 9.52s\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1733)\u001b[0m bestTest = 0.1566714137\n",
      "\u001b[36m(_ray_fit pid=1733)\u001b[0m bestIteration = 1\n",
      "\u001b[36m(_ray_fit pid=1629)\u001b[0m 1620:\tlearn: 0.0556326\ttest: 0.0566600\tbest: 0.0566599 (1618)\ttotal: 41.7s\tremaining: 4.37s\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1629)\u001b[0m bestTest = 0.05665354827\n",
      "\u001b[36m(_ray_fit pid=1629)\u001b[0m bestIteration = 1775\n",
      "\u001b[36m(_ray_fit pid=1629)\u001b[0m Shrink model to first 1776 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1629)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/S1F3/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1733)\u001b[0m 340:\tlearn: 0.0562731\ttest: 0.0560712\tbest: 0.0560712 (340)\ttotal: 8.97s\tremaining: 34.6s\u001b[32m [repeated 20x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1785)\u001b[0m \tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=1785)\u001b[0m \tCatboost model hyperparameters: {'iterations': 10000, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'RMSE', 'thread_count': 1, 'loss_function': 'RMSE', 'task_type': 'GPU'}\n",
      "\u001b[36m(_ray_fit pid=1785)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1785)\u001b[0m bestTest = 0.1572759269\n",
      "\u001b[36m(_ray_fit pid=1785)\u001b[0m bestIteration = 1\n",
      "\u001b[36m(_ray_fit pid=1733)\u001b[0m 540:\tlearn: 0.0561353\ttest: 0.0559910\tbest: 0.0559910 (540)\ttotal: 14.5s\tremaining: 29.8s\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1733)\u001b[0m 740:\tlearn: 0.0560359\ttest: 0.0559521\tbest: 0.0559521 (740)\ttotal: 19.7s\tremaining: 24.3s\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1733)\u001b[0m 940:\tlearn: 0.0559547\ttest: 0.0559285\tbest: 0.0559284 (939)\ttotal: 24.8s\tremaining: 18.9s\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1733)\u001b[0m 1140:\tlearn: 0.0558874\ttest: 0.0559101\tbest: 0.0559100 (1139)\ttotal: 29.9s\tremaining: 13.5s\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1733)\u001b[0m 1340:\tlearn: 0.0558267\ttest: 0.0558943\tbest: 0.0558943 (1340)\ttotal: 35s\tremaining: 8.26s\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1733)\u001b[0m 1540:\tlearn: 0.0557711\ttest: 0.0558828\tbest: 0.0558827 (1539)\ttotal: 40.2s\tremaining: 3.02s\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1733)\u001b[0m bestTest = 0.05587471317\n",
      "\u001b[36m(_ray_fit pid=1733)\u001b[0m bestIteration = 1656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1733)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/S1F5/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1785)\u001b[0m 1220:\tlearn: 0.0559048\ttest: 0.0556510\tbest: 0.0556510 (1220)\ttotal: 31.5s\tremaining: 11.5s\u001b[32m [repeated 16x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1840)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=1840)\u001b[0m \tCatboost model hyperparameters: {'iterations': 10000, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'RMSE', 'thread_count': 1, 'loss_function': 'RMSE', 'task_type': 'GPU'}\n",
      "\u001b[36m(_ray_fit pid=1840)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1840)\u001b[0m bestTest = 0.1585835225\n",
      "\u001b[36m(_ray_fit pid=1840)\u001b[0m bestIteration = 1\n",
      "\u001b[36m(_ray_fit pid=1785)\u001b[0m 1420:\tlearn: 0.0558453\ttest: 0.0556404\tbest: 0.0556401 (1412)\ttotal: 36.6s\tremaining: 6.34s\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1785)\u001b[0m bestTest = 0.05563343278\n",
      "\u001b[36m(_ray_fit pid=1785)\u001b[0m bestIteration = 1540\n",
      "\u001b[36m(_ray_fit pid=1785)\u001b[0m Shrink model to first 1541 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1785)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/S1F6/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1840)\u001b[0m 260:\tlearn: 0.0563123\ttest: 0.0566253\tbest: 0.0566253 (260)\ttotal: 7s\tremaining: 38.8s\u001b[32m [repeated 19x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1891)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=1891)\u001b[0m \tCatboost model hyperparameters: {'iterations': 10000, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'RMSE', 'thread_count': 1, 'loss_function': 'RMSE', 'task_type': 'GPU'}\n",
      "\u001b[36m(_ray_fit pid=1891)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1891)\u001b[0m bestTest = 0.1570049408\n",
      "\u001b[36m(_ray_fit pid=1891)\u001b[0m bestIteration = 1\n",
      "\u001b[36m(_ray_fit pid=1891)\u001b[0m 20:\tlearn: 0.0808788\ttest: 0.0806949\tbest: 0.0806949 (20)\ttotal: 540ms\tremaining: 42.1s\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1840)\u001b[0m 660:\tlearn: 0.0560294\ttest: 0.0564896\tbest: 0.0564894 (658)\ttotal: 17.4s\tremaining: 27.4s\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1840)\u001b[0m 860:\tlearn: 0.0559320\ttest: 0.0564522\tbest: 0.0564516 (857)\ttotal: 22.5s\tremaining: 22s\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1840)\u001b[0m 1060:\tlearn: 0.0558535\ttest: 0.0564275\tbest: 0.0564275 (1060)\ttotal: 27.7s\tremaining: 16.8s\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1840)\u001b[0m 1260:\tlearn: 0.0557890\ttest: 0.0564168\tbest: 0.0564164 (1253)\ttotal: 32.9s\tremaining: 11.6s\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1840)\u001b[0m bestTest = 0.05640777264\n",
      "\u001b[36m(_ray_fit pid=1840)\u001b[0m bestIteration = 1408\n",
      "\u001b[36m(_ray_fit pid=1840)\u001b[0m Shrink model to first 1409 iterations.\n",
      "\u001b[36m(_ray_fit pid=1891)\u001b[0m 1040:\tlearn: 0.0559199\ttest: 0.0561195\tbest: 0.0561190 (1035)\ttotal: 26.2s\tremaining: 15.6s\u001b[32m [repeated 19x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1840)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/S1F7/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1891)\u001b[0m 1260:\tlearn: 0.0558484\ttest: 0.0561047\tbest: 0.0561047 (1260)\ttotal: 31.8s\tremaining: 10.1s\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1891)\u001b[0m 1480:\tlearn: 0.0557858\ttest: 0.0560957\tbest: 0.0560957 (1480)\ttotal: 37.2s\tremaining: 4.5s\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1891)\u001b[0m bestTest = 0.05609015888\n",
      "\u001b[36m(_ray_fit pid=1891)\u001b[0m bestIteration = 1607\n",
      "\u001b[36m(_ray_fit pid=1891)\u001b[0m Shrink model to first 1608 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=288)\u001b[0m \t-0.0562\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t180.32s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t0.96s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t59841.1\t = Inference  throughput (rows/s | 57529 batch size)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 4737.43s of the 7436.87s of remaining time.\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/trainer.pkl\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tFitting ExtraTreesMSE_BAG_L1 with 'num_gpus': 1, 'num_cpus': 4\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/ExtraTreesMSE_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t71.13s\t= Estimated out-of-fold prediction time...\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/ExtraTreesMSE_BAG_L1/utils/model_template.pkl\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t-0.0563\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t88.83s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t13.45s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t34210.7\t = Inference  throughput (rows/s | 460225 batch size)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 4633.82s of the 7333.26s of remaining time.\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tFitting NeuralNetFastAI_BAG_L1 with 'num_gpus': 2, 'num_cpus': 4\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=0.81%)\n",
      "\u001b[36m(_ray_fit pid=2088)\u001b[0m Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 'auto', 'lr': 0.01, 'epochs': 'auto', 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
      "\u001b[36m(_ray_fit pid=2088)\u001b[0m Using 4/4 categorical features\n",
      "\u001b[36m(_ray_fit pid=2088)\u001b[0m Using 8 cont features\n",
      "\u001b[36m(_ray_fit pid=2088)\u001b[0m Automated batch size selection: 512\n",
      "\u001b[36m(_ray_fit pid=2088)\u001b[0m TabularModel(\n",
      "\u001b[36m(_ray_fit pid=2088)\u001b[0m   (embeds): ModuleList(\n",
      "\u001b[36m(_ray_fit pid=2088)\u001b[0m     (0-3): 4 x Embedding(4, 3)\n",
      "\u001b[36m(_ray_fit pid=2088)\u001b[0m   )\n",
      "\u001b[36m(_ray_fit pid=2088)\u001b[0m   (emb_drop): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=2088)\u001b[0m   (bn_cont): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "\u001b[36m(_ray_fit pid=2088)\u001b[0m   (layers): Sequential(\n",
      "\u001b[36m(_ray_fit pid=2088)\u001b[0m     (0): LinBnDrop(\n",
      "\u001b[36m(_ray_fit pid=2088)\u001b[0m       (0): Linear(in_features=20, out_features=200, bias=False)\n",
      "\u001b[36m(_ray_fit pid=2088)\u001b[0m       (1): ReLU(inplace=True)\n",
      "\u001b[36m(_ray_fit pid=2088)\u001b[0m       (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "\u001b[36m(_ray_fit pid=2088)\u001b[0m       (3): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=2088)\u001b[0m     )\n",
      "\u001b[36m(_ray_fit pid=2088)\u001b[0m     (1): LinBnDrop(\n",
      "\u001b[36m(_ray_fit pid=2088)\u001b[0m       (0): Linear(in_features=200, out_features=100, bias=False)\n",
      "\u001b[36m(_ray_fit pid=2088)\u001b[0m       (1): ReLU(inplace=True)\n",
      "\u001b[36m(_ray_fit pid=2088)\u001b[0m       (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "\u001b[36m(_ray_fit pid=2088)\u001b[0m       (3): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=2088)\u001b[0m     )\n",
      "\u001b[36m(_ray_fit pid=2088)\u001b[0m     (2): LinBnDrop(\n",
      "\u001b[36m(_ray_fit pid=2088)\u001b[0m       (0): Linear(in_features=100, out_features=1, bias=True)\n",
      "\u001b[36m(_ray_fit pid=2088)\u001b[0m     )\n",
      "\u001b[36m(_ray_fit pid=2088)\u001b[0m   )\n",
      "\u001b[36m(_ray_fit pid=2088)\u001b[0m )\n",
      "\u001b[36m(_ray_fit pid=2088)\u001b[0m Automated epochs selection: training for 30 epoch(s). Estimated time budget use 258.49 / 925.80 sec\n",
      "\u001b[36m(_ray_fit pid=2087)\u001b[0m Better model found at epoch 0 with _rmse value: 0.35447967052459717.\n",
      "\u001b[36m(_ray_fit pid=2087)\u001b[0m Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 'auto', 'lr': 0.01, 'epochs': 'auto', 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
      "\u001b[36m(_ray_fit pid=2087)\u001b[0m Using 4/4 categorical features\n",
      "\u001b[36m(_ray_fit pid=2087)\u001b[0m Using 8 cont features\n",
      "\u001b[36m(_ray_fit pid=2087)\u001b[0m Automated batch size selection: 512\n",
      "\u001b[36m(_ray_fit pid=2087)\u001b[0m TabularModel(\n",
      "\u001b[36m(_ray_fit pid=2087)\u001b[0m   (embeds): ModuleList(\n",
      "\u001b[36m(_ray_fit pid=2087)\u001b[0m     (0-3): 4 x Embedding(4, 3)\n",
      "\u001b[36m(_ray_fit pid=2087)\u001b[0m )\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2087)\u001b[0m   (emb_drop): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=2087)\u001b[0m   (bn_cont): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "\u001b[36m(_ray_fit pid=2087)\u001b[0m   (layers): Sequential(\n",
      "\u001b[36m(_ray_fit pid=2087)\u001b[0m     (2): LinBnDrop(\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2087)\u001b[0m       (0): Linear(in_features=200, out_features=100, bias=False)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2087)\u001b[0m       (1): ReLU(inplace=True)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2087)\u001b[0m       (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2087)\u001b[0m       (3): Dropout(p=0.1, inplace=False)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2087)\u001b[0m       (0): Linear(in_features=100, out_features=1, bias=True)\n",
      "\u001b[36m(_ray_fit pid=2087)\u001b[0m Automated epochs selection: training for 30 epoch(s). Estimated time budget use 255.18 / 925.80 sec\n",
      "\u001b[36m(_ray_fit pid=2087)\u001b[0m Better model found at epoch 1 with _rmse value: 0.34588006138801575.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2087)\u001b[0m Better model found at epoch 2 with _rmse value: 0.34465157985687256.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2088)\u001b[0m Better model found at epoch 9 with _rmse value: 0.34532153606414795.\n",
      "\u001b[36m(_ray_fit pid=2088)\u001b[0m Better model found at epoch 11 with _rmse value: 0.3426763117313385.\n",
      "\u001b[36m(_ray_fit pid=2087)\u001b[0m Better model found at epoch 12 with _rmse value: 0.34219980239868164.\n",
      "\u001b[36m(_ray_fit pid=2087)\u001b[0m Better model found at epoch 14 with _rmse value: 0.34142443537712097.\n",
      "\u001b[36m(_ray_fit pid=2088)\u001b[0m Better model found at epoch 16 with _rmse value: 0.3423053026199341.\n",
      "\u001b[36m(_ray_fit pid=2087)\u001b[0m Better model found at epoch 19 with _rmse value: 0.340786337852478.\n",
      "\u001b[36m(_ray_fit pid=2087)\u001b[0m Better model found at epoch 23 with _rmse value: 0.3402903974056244.\n",
      "\u001b[36m(_ray_fit pid=2088)\u001b[0m Better model found at epoch 23 with _rmse value: 0.34177273511886597.\n",
      "\u001b[36m(_ray_fit pid=2088)\u001b[0m Better model found at epoch 24 with _rmse value: 0.34143564105033875.\n",
      "\u001b[36m(_ray_fit pid=2087)\u001b[0m Better model found at epoch 25 with _rmse value: 0.34012919664382935.\n",
      "\u001b[36m(_ray_fit pid=2087)\u001b[0m Better model found at epoch 26 with _rmse value: 0.33980846405029297.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2087)\u001b[0m Better model found at epoch 27 with _rmse value: 0.33968648314476013.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2087)\u001b[0m Model validation metrics: 0.33968648314476013\n",
      "\u001b[36m(_ray_fit pid=2088)\u001b[0m Better model found at epoch 27 with _rmse value: 0.34101325273513794.\n",
      "\u001b[36m(_ray_fit pid=2087)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/NeuralNetFastAI_BAG_L1/S1F1/model.pkl\n",
      "\u001b[36m(_ray_fit pid=2220)\u001b[0m Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 'auto', 'lr': 0.01, 'epochs': 'auto', 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
      "\u001b[36m(_ray_fit pid=2088)\u001b[0m Model validation metrics: 0.34101325273513794\n",
      "\u001b[36m(_ray_fit pid=2088)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/NeuralNetFastAI_BAG_L1/S1F2/model.pkl\n",
      "\u001b[36m(_ray_fit pid=2220)\u001b[0m Using 4/4 categorical features\n",
      "\u001b[36m(_ray_fit pid=2220)\u001b[0m Using 8 cont features\n",
      "\u001b[36m(_ray_fit pid=2220)\u001b[0m Automated batch size selection: 512\n",
      "\u001b[36m(_ray_fit pid=2220)\u001b[0m TabularModel(\n",
      "\u001b[36m(_ray_fit pid=2220)\u001b[0m   (embeds): ModuleList(\n",
      "\u001b[36m(_ray_fit pid=2220)\u001b[0m     (0-3): 4 x Embedding(4, 3)\n",
      "\u001b[36m(_ray_fit pid=2220)\u001b[0m   )\n",
      "\u001b[36m(_ray_fit pid=2220)\u001b[0m   (emb_drop): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=2220)\u001b[0m   (bn_cont): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "\u001b[36m(_ray_fit pid=2220)\u001b[0m   (layers): Sequential(\n",
      "\u001b[36m(_ray_fit pid=2220)\u001b[0m     (0): LinBnDrop(\n",
      "\u001b[36m(_ray_fit pid=2220)\u001b[0m       (0): Linear(in_features=20, out_features=200, bias=False)\n",
      "\u001b[36m(_ray_fit pid=2220)\u001b[0m       (1): ReLU(inplace=True)\n",
      "\u001b[36m(_ray_fit pid=2220)\u001b[0m       (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "\u001b[36m(_ray_fit pid=2220)\u001b[0m       (3): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=2220)\u001b[0m     )\n",
      "\u001b[36m(_ray_fit pid=2220)\u001b[0m     (1): LinBnDrop(\n",
      "\u001b[36m(_ray_fit pid=2220)\u001b[0m       (0): Linear(in_features=200, out_features=100, bias=False)\n",
      "\u001b[36m(_ray_fit pid=2220)\u001b[0m       (1): ReLU(inplace=True)\n",
      "\u001b[36m(_ray_fit pid=2220)\u001b[0m       (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "\u001b[36m(_ray_fit pid=2220)\u001b[0m       (3): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=2220)\u001b[0m     )\n",
      "\u001b[36m(_ray_fit pid=2220)\u001b[0m     (2): LinBnDrop(\n",
      "\u001b[36m(_ray_fit pid=2220)\u001b[0m       (0): Linear(in_features=100, out_features=1, bias=True)\n",
      "\u001b[36m(_ray_fit pid=2220)\u001b[0m     )\n",
      "\u001b[36m(_ray_fit pid=2220)\u001b[0m   )\n",
      "\u001b[36m(_ray_fit pid=2220)\u001b[0m )\n",
      "\u001b[36m(_ray_fit pid=2220)\u001b[0m Automated epochs selection: training for 30 epoch(s). Estimated time budget use 252.75 / 925.95 sec\n",
      "\u001b[36m(_ray_fit pid=2220)\u001b[0m Better model found at epoch 0 with _rmse value: 0.3583236038684845.\n",
      "\u001b[36m(_ray_fit pid=2252)\u001b[0m Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 'auto', 'lr': 0.01, 'epochs': 'auto', 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
      "\u001b[36m(_ray_fit pid=2252)\u001b[0m Using 4/4 categorical features\n",
      "\u001b[36m(_ray_fit pid=2252)\u001b[0m Using 8 cont features\n",
      "\u001b[36m(_ray_fit pid=2252)\u001b[0m Automated batch size selection: 512\n",
      "\u001b[36m(_ray_fit pid=2252)\u001b[0m TabularModel(\n",
      "\u001b[36m(_ray_fit pid=2252)\u001b[0m   (embeds): ModuleList(\n",
      "\u001b[36m(_ray_fit pid=2252)\u001b[0m     (0-3): 4 x Embedding(4, 3)\n",
      "\u001b[36m(_ray_fit pid=2252)\u001b[0m )\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2252)\u001b[0m   (emb_drop): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=2252)\u001b[0m   (bn_cont): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "\u001b[36m(_ray_fit pid=2252)\u001b[0m   (layers): Sequential(\n",
      "\u001b[36m(_ray_fit pid=2252)\u001b[0m     (2): LinBnDrop(\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2252)\u001b[0m       (0): Linear(in_features=200, out_features=100, bias=False)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2252)\u001b[0m       (1): ReLU(inplace=True)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2252)\u001b[0m       (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2252)\u001b[0m       (3): Dropout(p=0.1, inplace=False)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2252)\u001b[0m       (0): Linear(in_features=100, out_features=1, bias=True)\n",
      "\u001b[36m(_ray_fit pid=2252)\u001b[0m Automated epochs selection: training for 30 epoch(s). Estimated time budget use 260.20 / 925.94 sec\n",
      "\u001b[36m(_ray_fit pid=2220)\u001b[0m Better model found at epoch 1 with _rmse value: 0.35127100348472595.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2220)\u001b[0m Better model found at epoch 2 with _rmse value: 0.35057976841926575.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2220)\u001b[0m Better model found at epoch 4 with _rmse value: 0.3501824140548706.\n",
      "\u001b[36m(_ray_fit pid=2252)\u001b[0m Better model found at epoch 4 with _rmse value: 0.34481990337371826.\n",
      "\u001b[36m(_ray_fit pid=2252)\u001b[0m Better model found at epoch 5 with _rmse value: 0.34440577030181885.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2252)\u001b[0m Better model found at epoch 6 with _rmse value: 0.34387218952178955.\n",
      "\u001b[36m(_ray_fit pid=2252)\u001b[0m Better model found at epoch 8 with _rmse value: 0.34188786149024963.\n",
      "\u001b[36m(_ray_fit pid=2220)\u001b[0m Better model found at epoch 10 with _rmse value: 0.3464003801345825.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2252)\u001b[0m Better model found at epoch 14 with _rmse value: 0.3414815664291382.\n",
      "\u001b[36m(_ray_fit pid=2220)\u001b[0m Better model found at epoch 16 with _rmse value: 0.3445947468280792.\n",
      "\u001b[36m(_ray_fit pid=2252)\u001b[0m Better model found at epoch 18 with _rmse value: 0.34045299887657166.\n",
      "\u001b[36m(_ray_fit pid=2252)\u001b[0m Better model found at epoch 19 with _rmse value: 0.3402884900569916.\n",
      "\u001b[36m(_ray_fit pid=2252)\u001b[0m Better model found at epoch 21 with _rmse value: 0.34013426303863525.\n",
      "\u001b[36m(_ray_fit pid=2252)\u001b[0m Better model found at epoch 22 with _rmse value: 0.3397897481918335.\n",
      "\u001b[36m(_ray_fit pid=2220)\u001b[0m Better model found at epoch 23 with _rmse value: 0.34438490867614746.\n",
      "\u001b[36m(_ray_fit pid=2220)\u001b[0m Better model found at epoch 25 with _rmse value: 0.34390896558761597.\n",
      "\u001b[36m(_ray_fit pid=2220)\u001b[0m Better model found at epoch 27 with _rmse value: 0.3434201776981354.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2220)\u001b[0m Better model found at epoch 28 with _rmse value: 0.34302303194999695.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2220)\u001b[0m Model validation metrics: 0.34302303194999695\n",
      "\u001b[36m(_ray_fit pid=2220)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/NeuralNetFastAI_BAG_L1/S1F3/model.pkl\n",
      "\u001b[36m(_ray_fit pid=2352)\u001b[0m Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 'auto', 'lr': 0.01, 'epochs': 'auto', 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
      "\u001b[36m(_ray_fit pid=2252)\u001b[0m Model validation metrics: 0.33852100372314453\n",
      "\u001b[36m(_ray_fit pid=2252)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/NeuralNetFastAI_BAG_L1/S1F4/model.pkl\n",
      "\u001b[36m(_ray_fit pid=2352)\u001b[0m Using 4/4 categorical features\n",
      "\u001b[36m(_ray_fit pid=2352)\u001b[0m Using 8 cont features\n",
      "\u001b[36m(_ray_fit pid=2352)\u001b[0m Automated batch size selection: 512\n",
      "\u001b[36m(_ray_fit pid=2352)\u001b[0m TabularModel(\n",
      "\u001b[36m(_ray_fit pid=2352)\u001b[0m   (embeds): ModuleList(\n",
      "\u001b[36m(_ray_fit pid=2352)\u001b[0m     (0-3): 4 x Embedding(4, 3)\n",
      "\u001b[36m(_ray_fit pid=2352)\u001b[0m   )\n",
      "\u001b[36m(_ray_fit pid=2352)\u001b[0m   (emb_drop): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=2352)\u001b[0m   (bn_cont): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "\u001b[36m(_ray_fit pid=2352)\u001b[0m   (layers): Sequential(\n",
      "\u001b[36m(_ray_fit pid=2352)\u001b[0m     (0): LinBnDrop(\n",
      "\u001b[36m(_ray_fit pid=2352)\u001b[0m       (0): Linear(in_features=20, out_features=200, bias=False)\n",
      "\u001b[36m(_ray_fit pid=2352)\u001b[0m       (1): ReLU(inplace=True)\n",
      "\u001b[36m(_ray_fit pid=2352)\u001b[0m       (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "\u001b[36m(_ray_fit pid=2352)\u001b[0m       (3): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=2352)\u001b[0m     )\n",
      "\u001b[36m(_ray_fit pid=2352)\u001b[0m     (1): LinBnDrop(\n",
      "\u001b[36m(_ray_fit pid=2352)\u001b[0m       (0): Linear(in_features=200, out_features=100, bias=False)\n",
      "\u001b[36m(_ray_fit pid=2352)\u001b[0m       (1): ReLU(inplace=True)\n",
      "\u001b[36m(_ray_fit pid=2352)\u001b[0m       (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "\u001b[36m(_ray_fit pid=2352)\u001b[0m       (3): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=2352)\u001b[0m     )\n",
      "\u001b[36m(_ray_fit pid=2352)\u001b[0m     (2): LinBnDrop(\n",
      "\u001b[36m(_ray_fit pid=2352)\u001b[0m       (0): Linear(in_features=100, out_features=1, bias=True)\n",
      "\u001b[36m(_ray_fit pid=2352)\u001b[0m     )\n",
      "\u001b[36m(_ray_fit pid=2352)\u001b[0m   )\n",
      "\u001b[36m(_ray_fit pid=2352)\u001b[0m )\n",
      "\u001b[36m(_ray_fit pid=2352)\u001b[0m Automated epochs selection: training for 30 epoch(s). Estimated time budget use 253.05 / 925.95 sec\n",
      "\u001b[36m(_ray_fit pid=2352)\u001b[0m Better model found at epoch 0 with _rmse value: 0.35479530692100525.\n",
      "\u001b[36m(_ray_fit pid=2385)\u001b[0m Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 'auto', 'lr': 0.01, 'epochs': 'auto', 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
      "\u001b[36m(_ray_fit pid=2385)\u001b[0m Using 4/4 categorical features\n",
      "\u001b[36m(_ray_fit pid=2385)\u001b[0m Using 8 cont features\n",
      "\u001b[36m(_ray_fit pid=2385)\u001b[0m Automated batch size selection: 512\n",
      "\u001b[36m(_ray_fit pid=2385)\u001b[0m TabularModel(\n",
      "\u001b[36m(_ray_fit pid=2385)\u001b[0m   (embeds): ModuleList(\n",
      "\u001b[36m(_ray_fit pid=2385)\u001b[0m     (0-3): 4 x Embedding(4, 3)\n",
      "\u001b[36m(_ray_fit pid=2385)\u001b[0m )\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2385)\u001b[0m   (emb_drop): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=2385)\u001b[0m   (bn_cont): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "\u001b[36m(_ray_fit pid=2385)\u001b[0m   (layers): Sequential(\n",
      "\u001b[36m(_ray_fit pid=2385)\u001b[0m     (2): LinBnDrop(\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2385)\u001b[0m       (0): Linear(in_features=200, out_features=100, bias=False)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2385)\u001b[0m       (1): ReLU(inplace=True)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2385)\u001b[0m       (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2385)\u001b[0m       (3): Dropout(p=0.1, inplace=False)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2385)\u001b[0m       (0): Linear(in_features=100, out_features=1, bias=True)\n",
      "\u001b[36m(_ray_fit pid=2385)\u001b[0m Automated epochs selection: training for 30 epoch(s). Estimated time budget use 276.75 / 925.89 sec\n",
      "\u001b[36m(_ray_fit pid=2352)\u001b[0m Better model found at epoch 1 with _rmse value: 0.344587504863739.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2385)\u001b[0m Better model found at epoch 2 with _rmse value: 0.3428073227405548.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2352)\u001b[0m Better model found at epoch 3 with _rmse value: 0.34297069907188416.\n",
      "\u001b[36m(_ray_fit pid=2385)\u001b[0m Better model found at epoch 4 with _rmse value: 0.3426184356212616.\n",
      "\u001b[36m(_ray_fit pid=2385)\u001b[0m Better model found at epoch 6 with _rmse value: 0.34117642045021057.\n",
      "\u001b[36m(_ray_fit pid=2352)\u001b[0m Better model found at epoch 8 with _rmse value: 0.3418010175228119.\n",
      "\u001b[36m(_ray_fit pid=2385)\u001b[0m Better model found at epoch 9 with _rmse value: 0.3409386873245239.\n",
      "\u001b[36m(_ray_fit pid=2352)\u001b[0m Better model found at epoch 12 with _rmse value: 0.341126412153244.\n",
      "\u001b[36m(_ray_fit pid=2352)\u001b[0m Better model found at epoch 13 with _rmse value: 0.3411249816417694.\n",
      "\u001b[36m(_ray_fit pid=2352)\u001b[0m Better model found at epoch 14 with _rmse value: 0.3402653634548187.\n",
      "\u001b[36m(_ray_fit pid=2385)\u001b[0m Better model found at epoch 15 with _rmse value: 0.3393516540527344.\n",
      "\u001b[36m(_ray_fit pid=2352)\u001b[0m Better model found at epoch 19 with _rmse value: 0.3399466574192047.\n",
      "\u001b[36m(_ray_fit pid=2352)\u001b[0m Better model found at epoch 20 with _rmse value: 0.339201956987381.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2385)\u001b[0m Better model found at epoch 22 with _rmse value: 0.3373357951641083.\n",
      "\u001b[36m(_ray_fit pid=2352)\u001b[0m Better model found at epoch 23 with _rmse value: 0.33916446566581726.\n",
      "\u001b[36m(_ray_fit pid=2352)\u001b[0m Better model found at epoch 24 with _rmse value: 0.3384380638599396.\n",
      "\u001b[36m(_ray_fit pid=2385)\u001b[0m Better model found at epoch 25 with _rmse value: 0.33662861585617065.\n",
      "\u001b[36m(_ray_fit pid=2352)\u001b[0m Better model found at epoch 27 with _rmse value: 0.33813610672950745.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2352)\u001b[0m Better model found at epoch 29 with _rmse value: 0.3379877507686615.\n",
      "\u001b[36m(_ray_fit pid=2352)\u001b[0m Model validation metrics: 0.3379877507686615\n",
      "\u001b[36m(_ray_fit pid=2352)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/NeuralNetFastAI_BAG_L1/S1F5/model.pkl\n",
      "\u001b[36m(_ray_fit pid=2485)\u001b[0m Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 'auto', 'lr': 0.01, 'epochs': 'auto', 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
      "\u001b[36m(_ray_fit pid=2385)\u001b[0m Model validation metrics: 0.33662861585617065\n",
      "\u001b[36m(_ray_fit pid=2385)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/NeuralNetFastAI_BAG_L1/S1F6/model.pkl\n",
      "\u001b[36m(_ray_fit pid=2485)\u001b[0m Using 4/4 categorical features\n",
      "\u001b[36m(_ray_fit pid=2485)\u001b[0m Using 8 cont features\n",
      "\u001b[36m(_ray_fit pid=2485)\u001b[0m Automated batch size selection: 512\n",
      "\u001b[36m(_ray_fit pid=2485)\u001b[0m TabularModel(\n",
      "\u001b[36m(_ray_fit pid=2485)\u001b[0m   (embeds): ModuleList(\n",
      "\u001b[36m(_ray_fit pid=2485)\u001b[0m     (0-3): 4 x Embedding(4, 3)\n",
      "\u001b[36m(_ray_fit pid=2485)\u001b[0m   )\n",
      "\u001b[36m(_ray_fit pid=2485)\u001b[0m   (emb_drop): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=2485)\u001b[0m   (bn_cont): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "\u001b[36m(_ray_fit pid=2485)\u001b[0m   (layers): Sequential(\n",
      "\u001b[36m(_ray_fit pid=2485)\u001b[0m     (0): LinBnDrop(\n",
      "\u001b[36m(_ray_fit pid=2485)\u001b[0m       (0): Linear(in_features=20, out_features=200, bias=False)\n",
      "\u001b[36m(_ray_fit pid=2485)\u001b[0m       (1): ReLU(inplace=True)\n",
      "\u001b[36m(_ray_fit pid=2485)\u001b[0m       (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "\u001b[36m(_ray_fit pid=2485)\u001b[0m       (3): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=2485)\u001b[0m     )\n",
      "\u001b[36m(_ray_fit pid=2485)\u001b[0m     (1): LinBnDrop(\n",
      "\u001b[36m(_ray_fit pid=2485)\u001b[0m       (0): Linear(in_features=200, out_features=100, bias=False)\n",
      "\u001b[36m(_ray_fit pid=2485)\u001b[0m       (1): ReLU(inplace=True)\n",
      "\u001b[36m(_ray_fit pid=2485)\u001b[0m       (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "\u001b[36m(_ray_fit pid=2485)\u001b[0m       (3): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=2485)\u001b[0m     )\n",
      "\u001b[36m(_ray_fit pid=2485)\u001b[0m     (2): LinBnDrop(\n",
      "\u001b[36m(_ray_fit pid=2485)\u001b[0m       (0): Linear(in_features=100, out_features=1, bias=True)\n",
      "\u001b[36m(_ray_fit pid=2485)\u001b[0m     )\n",
      "\u001b[36m(_ray_fit pid=2485)\u001b[0m   )\n",
      "\u001b[36m(_ray_fit pid=2485)\u001b[0m )\n",
      "\u001b[36m(_ray_fit pid=2485)\u001b[0m Automated epochs selection: training for 30 epoch(s). Estimated time budget use 355.46 / 925.94 sec\n",
      "\u001b[36m(_ray_fit pid=2516)\u001b[0m Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 'auto', 'lr': 0.01, 'epochs': 'auto', 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
      "\u001b[36m(_ray_fit pid=2485)\u001b[0m Better model found at epoch 0 with _rmse value: 0.35789409279823303.\n",
      "\u001b[36m(_ray_fit pid=2516)\u001b[0m Using 4/4 categorical features\n",
      "\u001b[36m(_ray_fit pid=2516)\u001b[0m Using 8 cont features\n",
      "\u001b[36m(_ray_fit pid=2516)\u001b[0m Automated batch size selection: 512\n",
      "\u001b[36m(_ray_fit pid=2516)\u001b[0m TabularModel(\n",
      "\u001b[36m(_ray_fit pid=2516)\u001b[0m   (embeds): ModuleList(\n",
      "\u001b[36m(_ray_fit pid=2516)\u001b[0m     (0-3): 4 x Embedding(4, 3)\n",
      "\u001b[36m(_ray_fit pid=2516)\u001b[0m )\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2516)\u001b[0m   (emb_drop): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=2516)\u001b[0m   (bn_cont): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "\u001b[36m(_ray_fit pid=2516)\u001b[0m   (layers): Sequential(\n",
      "\u001b[36m(_ray_fit pid=2516)\u001b[0m     (2): LinBnDrop(\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2516)\u001b[0m       (0): Linear(in_features=200, out_features=100, bias=False)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2516)\u001b[0m       (1): ReLU(inplace=True)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2516)\u001b[0m       (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2516)\u001b[0m       (3): Dropout(p=0.1, inplace=False)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2516)\u001b[0m       (0): Linear(in_features=100, out_features=1, bias=True)\n",
      "\u001b[36m(_ray_fit pid=2516)\u001b[0m Automated epochs selection: training for 30 epoch(s). Estimated time budget use 275.87 / 925.91 sec\n",
      "\u001b[36m(_ray_fit pid=2485)\u001b[0m Better model found at epoch 1 with _rmse value: 0.3509160876274109.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2485)\u001b[0m Better model found at epoch 2 with _rmse value: 0.34700965881347656.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2516)\u001b[0m Better model found at epoch 3 with _rmse value: 0.34398773312568665.\n",
      "\u001b[36m(_ray_fit pid=2485)\u001b[0m Better model found at epoch 4 with _rmse value: 0.3467428684234619.\n",
      "\u001b[36m(_ray_fit pid=2485)\u001b[0m Better model found at epoch 7 with _rmse value: 0.3456985652446747.\n",
      "\u001b[36m(_ray_fit pid=2485)\u001b[0m Better model found at epoch 11 with _rmse value: 0.345015287399292.\n",
      "\u001b[36m(_ray_fit pid=2485)\u001b[0m Better model found at epoch 13 with _rmse value: 0.3439686596393585.\n",
      "\u001b[36m(_ray_fit pid=2516)\u001b[0m Better model found at epoch 13 with _rmse value: 0.3433094322681427.\n",
      "\u001b[36m(_ray_fit pid=2485)\u001b[0m Better model found at epoch 16 with _rmse value: 0.3428036868572235.\n",
      "\u001b[36m(_ray_fit pid=2516)\u001b[0m Better model found at epoch 18 with _rmse value: 0.3412982225418091.\n",
      "\u001b[36m(_ray_fit pid=2485)\u001b[0m Better model found at epoch 21 with _rmse value: 0.3419119715690613.\n",
      "\u001b[36m(_ray_fit pid=2485)\u001b[0m Better model found at epoch 22 with _rmse value: 0.34175270795822144.\n",
      "\u001b[36m(_ray_fit pid=2485)\u001b[0m Better model found at epoch 25 with _rmse value: 0.3413005769252777.\n",
      "\u001b[36m(_ray_fit pid=2516)\u001b[0m Better model found at epoch 25 with _rmse value: 0.340143620967865.\n",
      "\u001b[36m(_ray_fit pid=2485)\u001b[0m Better model found at epoch 28 with _rmse value: 0.34127315878868103.\n",
      "\u001b[36m(_ray_fit pid=2516)\u001b[0m Better model found at epoch 28 with _rmse value: 0.3396645784378052.\n",
      "\u001b[36m(_ray_fit pid=2485)\u001b[0m Model validation metrics: 0.34127315878868103\n",
      "\u001b[36m(_ray_fit pid=2485)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/NeuralNetFastAI_BAG_L1/S1F7/model.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t-0.0565\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t1013.46s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t3.42s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t16824.0\t = Inference  throughput (rows/s | 57529 batch size)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Fitting model: XGBoost_BAG_L1 ... Training model for up to 3617.81s of the 6317.25s of remaining time.\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tFitting XGBoost_BAG_L1 with 'num_gpus': 2, 'num_cpus': 4\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=0.66%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2709)\u001b[0m [0]\tvalidation_0-rmse:0.15206\n",
      "\u001b[36m(_ray_fit pid=1891)\u001b[0m 1640:\tlearn: 0.0557422\ttest: 0.0560910\tbest: 0.0560902 (1607)\ttotal: 41.1s\tremaining: 476ms\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2708)\u001b[0m [0]\tvalidation_0-rmse:0.15188\n",
      "\u001b[36m(_ray_fit pid=2709)\u001b[0m [50]\tvalidation_0-rmse:0.05625\n",
      "\u001b[36m(_ray_fit pid=2708)\u001b[0m [50]\tvalidation_0-rmse:0.05643\n",
      "\u001b[36m(_ray_fit pid=2709)\u001b[0m [100]\tvalidation_0-rmse:0.05616\n",
      "\u001b[36m(_ray_fit pid=2708)\u001b[0m [100]\tvalidation_0-rmse:0.05630\n",
      "\u001b[36m(_ray_fit pid=2709)\u001b[0m [150]\tvalidation_0-rmse:0.05614\n",
      "\u001b[36m(_ray_fit pid=2708)\u001b[0m [150]\tvalidation_0-rmse:0.05628\n",
      "\u001b[36m(_ray_fit pid=2709)\u001b[0m [200]\tvalidation_0-rmse:0.05612\n",
      "\u001b[36m(_ray_fit pid=2708)\u001b[0m [200]\tvalidation_0-rmse:0.05627\n",
      "\u001b[36m(_ray_fit pid=2709)\u001b[0m [250]\tvalidation_0-rmse:0.05612\n",
      "\u001b[36m(_ray_fit pid=2708)\u001b[0m [250]\tvalidation_0-rmse:0.05625\n",
      "\u001b[36m(_ray_fit pid=2709)\u001b[0m [300]\tvalidation_0-rmse:0.05612\n",
      "\u001b[36m(_ray_fit pid=2708)\u001b[0m [300]\tvalidation_0-rmse:0.05626\n",
      "\u001b[36m(_ray_fit pid=2709)\u001b[0m [350]\tvalidation_0-rmse:0.05613\n",
      "\u001b[36m(_ray_fit pid=2708)\u001b[0m [334]\tvalidation_0-rmse:0.05627\n",
      "\u001b[36m(_ray_fit pid=2709)\u001b[0m [354]\tvalidation_0-rmse:0.05613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2709)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [07:55:49] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "\u001b[36m(_ray_fit pid=2709)\u001b[0m Potential solutions:\n",
      "\u001b[36m(_ray_fit pid=2709)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n",
      "\u001b[36m(_ray_fit pid=2709)\u001b[0m - Set the device for booster before call to inplace_predict.\n",
      "\u001b[36m(_ray_fit pid=2709)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=2709)\u001b[0m This warning will only be shown once.\n",
      "\u001b[36m(_ray_fit pid=2709)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=2709)\u001b[0m   warnings.warn(smsg, UserWarning)\n",
      "\u001b[36m(_ray_fit pid=2516)\u001b[0m Model validation metrics: 0.3396645784378052\n",
      "\u001b[36m(_ray_fit pid=2709)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L1/S1F1/model.pkl\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2708)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=2708)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2777)\u001b[0m [0]\tvalidation_0-rmse:0.15237\n",
      "\u001b[36m(_ray_fit pid=2778)\u001b[0m [0]\tvalidation_0-rmse:0.15144\n",
      "\u001b[36m(_ray_fit pid=2777)\u001b[0m [50]\tvalidation_0-rmse:0.05680\n",
      "\u001b[36m(_ray_fit pid=2778)\u001b[0m [50]\tvalidation_0-rmse:0.05613\n",
      "\u001b[36m(_ray_fit pid=2777)\u001b[0m [100]\tvalidation_0-rmse:0.05667\n",
      "\u001b[36m(_ray_fit pid=2778)\u001b[0m [100]\tvalidation_0-rmse:0.05602\n",
      "\u001b[36m(_ray_fit pid=2777)\u001b[0m [150]\tvalidation_0-rmse:0.05664\n",
      "\u001b[36m(_ray_fit pid=2778)\u001b[0m [150]\tvalidation_0-rmse:0.05600\n",
      "\u001b[36m(_ray_fit pid=2777)\u001b[0m [200]\tvalidation_0-rmse:0.05663\n",
      "\u001b[36m(_ray_fit pid=2778)\u001b[0m [200]\tvalidation_0-rmse:0.05599\n",
      "\u001b[36m(_ray_fit pid=2777)\u001b[0m [250]\tvalidation_0-rmse:0.05663\n",
      "\u001b[36m(_ray_fit pid=2778)\u001b[0m [250]\tvalidation_0-rmse:0.05600\n",
      "\u001b[36m(_ray_fit pid=2777)\u001b[0m [300]\tvalidation_0-rmse:0.05664\n",
      "\u001b[36m(_ray_fit pid=2778)\u001b[0m [300]\tvalidation_0-rmse:0.05601\n",
      "\u001b[36m(_ray_fit pid=2778)\u001b[0m [302]\tvalidation_0-rmse:0.05600\n",
      "\u001b[36m(_ray_fit pid=2777)\u001b[0m [318]\tvalidation_0-rmse:0.05663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2778)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=2778)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=2778)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [07:55:56] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2778)\u001b[0m Potential solutions:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2778)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2778)\u001b[0m - Set the device for booster before call to inplace_predict.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2778)\u001b[0m This warning will only be shown once.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2778)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2708)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L1/S1F2/model.pkl\n",
      "\u001b[36m(_ray_fit pid=2777)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=2777)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=2778)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L1/S1F4/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2846)\u001b[0m [0]\tvalidation_0-rmse:0.15124\n",
      "\u001b[36m(_ray_fit pid=2848)\u001b[0m [0]\tvalidation_0-rmse:0.15184\n",
      "\u001b[36m(_ray_fit pid=2846)\u001b[0m [50]\tvalidation_0-rmse:0.05601\n",
      "\u001b[36m(_ray_fit pid=2848)\u001b[0m [50]\tvalidation_0-rmse:0.05577\n",
      "\u001b[36m(_ray_fit pid=2846)\u001b[0m [100]\tvalidation_0-rmse:0.05588\n",
      "\u001b[36m(_ray_fit pid=2848)\u001b[0m [100]\tvalidation_0-rmse:0.05564\n",
      "\u001b[36m(_ray_fit pid=2846)\u001b[0m [150]\tvalidation_0-rmse:0.05585\n",
      "\u001b[36m(_ray_fit pid=2846)\u001b[0m [200]\tvalidation_0-rmse:0.05585\n",
      "\u001b[36m(_ray_fit pid=2848)\u001b[0m [150]\tvalidation_0-rmse:0.05561\n",
      "\u001b[36m(_ray_fit pid=2848)\u001b[0m [200]\tvalidation_0-rmse:0.05560\n",
      "\u001b[36m(_ray_fit pid=2846)\u001b[0m [244]\tvalidation_0-rmse:0.05584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2846)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=2846)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=2846)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [07:56:02] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2846)\u001b[0m Potential solutions:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2846)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2846)\u001b[0m - Set the device for booster before call to inplace_predict.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2846)\u001b[0m This warning will only be shown once.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2846)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2846)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L1/S1F5/model.pkl\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2848)\u001b[0m [241]\tvalidation_0-rmse:0.05560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2848)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=2848)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2915)\u001b[0m [0]\tvalidation_0-rmse:0.15313\n",
      "\u001b[36m(_ray_fit pid=2917)\u001b[0m [0]\tvalidation_0-rmse:0.15157\n",
      "\u001b[36m(_ray_fit pid=2915)\u001b[0m [50]\tvalidation_0-rmse:0.05649\n",
      "\u001b[36m(_ray_fit pid=2915)\u001b[0m [100]\tvalidation_0-rmse:0.05637\n",
      "\u001b[36m(_ray_fit pid=2917)\u001b[0m [50]\tvalidation_0-rmse:0.05617\n",
      "\u001b[36m(_ray_fit pid=2915)\u001b[0m [150]\tvalidation_0-rmse:0.05635\n",
      "\u001b[36m(_ray_fit pid=2917)\u001b[0m [100]\tvalidation_0-rmse:0.05607\n",
      "\u001b[36m(_ray_fit pid=2915)\u001b[0m [200]\tvalidation_0-rmse:0.05634\n",
      "\u001b[36m(_ray_fit pid=2917)\u001b[0m [150]\tvalidation_0-rmse:0.05603\n",
      "\u001b[36m(_ray_fit pid=2915)\u001b[0m [236]\tvalidation_0-rmse:0.05635\n",
      "\u001b[36m(_ray_fit pid=2917)\u001b[0m [200]\tvalidation_0-rmse:0.05602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2915)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=2915)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=2915)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [07:56:08] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2915)\u001b[0m Potential solutions:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2915)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2915)\u001b[0m - Set the device for booster before call to inplace_predict.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2915)\u001b[0m This warning will only be shown once.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2915)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2915)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L1/S1F7/model.pkl\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2917)\u001b[0m [250]\tvalidation_0-rmse:0.05601\n",
      "\u001b[36m(_ray_fit pid=2917)\u001b[0m [300]\tvalidation_0-rmse:0.05603\n",
      "\u001b[36m(_ray_fit pid=2917)\u001b[0m [322]\tvalidation_0-rmse:0.05603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=288)\u001b[0m \t-0.0561\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t24.35s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t1.43s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t40158.5\t = Inference  throughput (rows/s | 57529 batch size)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 3590.85s of the 6290.29s of remaining time.\n",
      "\u001b[36m(_ray_fit pid=2917)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=2917)\u001b[0m \n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tFitting NeuralNetTorch_BAG_L1 with 'num_gpus': 2, 'num_cpus': 4\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=0.46%)\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m Tabular Neural Network treats features as the following types:\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m {\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m     \"continuous\": [\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m         \"num_lanes\",\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m         \"curvature\",\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m         \"speed_limit\",\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m         \"num_reported_accidents\"\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m     ],\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m     \"skewed\": [],\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m     \"onehot\": [\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m         \"road_type\",\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m         \"lighting\",\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m         \"weather\",\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m         \"time_of_day\"\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m     ],\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m     \"embed\": [],\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m     \"language\": [],\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m     \"bool\": [\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m         \"road_signs_present\",\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m         \"public_road\",\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m         \"holiday\",\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m         \"school_season\"\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m     ]\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m }\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=2917)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [07:56:09] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "\u001b[36m(_ray_fit pid=2917)\u001b[0m Potential solutions:\n",
      "\u001b[36m(_ray_fit pid=2917)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n",
      "\u001b[36m(_ray_fit pid=2917)\u001b[0m - Set the device for booster before call to inplace_predict.\n",
      "\u001b[36m(_ray_fit pid=2917)\u001b[0m This warning will only be shown once.\n",
      "\u001b[36m(_ray_fit pid=2917)\u001b[0m   warnings.warn(smsg, UserWarning)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3077)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=3077)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m Training data for TabularNeuralNetTorchModel has: 402696 examples, 12 features (12 vector, 0 embedding)\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m Training on GPU (CUDA)\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m Neural network architecture:\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m EmbedNet(\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m   (main_block): Sequential(\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m     (0): Linear(in_features=20, out_features=128, bias=True)\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m     (1): ReLU()\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m     (2): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m     (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m     (4): ReLU()\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m     (5): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m     (6): Linear(in_features=128, out_features=128, bias=True)\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m     (7): ReLU()\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m     (8): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m     (9): Linear(in_features=128, out_features=128, bias=True)\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m     (10): ReLU()\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m     (11): Linear(in_features=128, out_features=1, bias=True)\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m   )\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m )\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m Training tabular neural network for up to 1000 epochs...\n",
      "\u001b[36m(_ray_fit pid=3077)\u001b[0m Tabular Neural Network treats features as the following types:\n",
      "\u001b[36m(_ray_fit pid=3077)\u001b[0m {\n",
      "\u001b[36m(_ray_fit pid=3077)\u001b[0m     \"continuous\": [\n",
      "\u001b[36m(_ray_fit pid=3077)\u001b[0m         \"num_lanes\",\n",
      "\u001b[36m(_ray_fit pid=3077)\u001b[0m         \"curvature\",\n",
      "\u001b[36m(_ray_fit pid=3077)\u001b[0m         \"speed_limit\",\n",
      "\u001b[36m(_ray_fit pid=3077)\u001b[0m         \"num_reported_accidents\"\n",
      "\u001b[36m(_ray_fit pid=3077)\u001b[0m     ],\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3077)\u001b[0m     \"skewed\": [],\n",
      "\u001b[36m(_ray_fit pid=3077)\u001b[0m     \"onehot\": [\n",
      "\u001b[36m(_ray_fit pid=3077)\u001b[0m         \"road_type\",\n",
      "\u001b[36m(_ray_fit pid=3077)\u001b[0m         \"lighting\",\n",
      "\u001b[36m(_ray_fit pid=3077)\u001b[0m         \"weather\",\n",
      "\u001b[36m(_ray_fit pid=3077)\u001b[0m         \"time_of_day\"\n",
      "\u001b[36m(_ray_fit pid=3077)\u001b[0m     \"embed\": [],\n",
      "\u001b[36m(_ray_fit pid=3077)\u001b[0m     \"language\": [],\n",
      "\u001b[36m(_ray_fit pid=3077)\u001b[0m     \"bool\": [\n",
      "\u001b[36m(_ray_fit pid=3077)\u001b[0m         \"road_signs_present\",\n",
      "\u001b[36m(_ray_fit pid=3077)\u001b[0m         \"public_road\",\n",
      "\u001b[36m(_ray_fit pid=3077)\u001b[0m         \"holiday\",\n",
      "\u001b[36m(_ray_fit pid=3077)\u001b[0m         \"school_season\"\n",
      "\u001b[36m(_ray_fit pid=3077)\u001b[0m     ]\n",
      "\u001b[36m(_ray_fit pid=3077)\u001b[0m }\n",
      "\u001b[36m(_ray_fit pid=3077)\u001b[0m Training data for TabularNeuralNetTorchModel has: 402697 examples, 12 features (12 vector, 0 embedding)\n",
      "\u001b[36m(_ray_fit pid=3077)\u001b[0m Training on GPU (CUDA)\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m Epoch 1 (Update 1573).\tTrain loss: 0.0563, Val root_mean_squared_error: -0.0585, Best Epoch: 1\n",
      "\u001b[36m(_ray_fit pid=3077)\u001b[0m Neural network architecture:\n",
      "\u001b[36m(_ray_fit pid=3077)\u001b[0m EmbedNet(\n",
      "\u001b[36m(_ray_fit pid=3077)\u001b[0m   (main_block): Sequential(\n",
      "\u001b[36m(_ray_fit pid=3077)\u001b[0m     (11): Linear(in_features=128, out_features=1, bias=True)\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3077)\u001b[0m     (10): ReLU()\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3077)\u001b[0m     (8): Dropout(p=0.1, inplace=False)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3077)\u001b[0m )\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3077)\u001b[0m Training tabular neural network for up to 1000 epochs...\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m Epoch 3 (Update 4719).\tTrain loss: 0.0458, Val root_mean_squared_error: -0.0574, Best Epoch: 3\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m Epoch 5 (Update 7865).\tTrain loss: 0.0452, Val root_mean_squared_error: -0.0573, Best Epoch: 5\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m Epoch 7 (Update 11011).\tTrain loss: 0.0448, Val root_mean_squared_error: -0.0572, Best Epoch: 7\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m Epoch 9 (Update 14157).\tTrain loss: 0.0446, Val root_mean_squared_error: -0.0573, Best Epoch: 8\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m Epoch 11 (Update 17303).\tTrain loss: 0.0445, Val root_mean_squared_error: -0.0574, Best Epoch: 8\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m Epoch 13 (Update 20449).\tTrain loss: 0.0444, Val root_mean_squared_error: -0.057, Best Epoch: 13\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3077)\u001b[0m Epoch 14 (Update 22022).\tTrain loss: 0.0444, Val root_mean_squared_error: -0.058, Best Epoch: 7\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m Epoch 16 (Update 25168).\tTrain loss: 0.0443, Val root_mean_squared_error: -0.0571, Best Epoch: 15\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3077)\u001b[0m Epoch 17 (Update 26741).\tTrain loss: 0.0443, Val root_mean_squared_error: -0.0575, Best Epoch: 7\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m Epoch 19 (Update 29887).\tTrain loss: 0.0443, Val root_mean_squared_error: -0.057, Best Epoch: 15\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3077)\u001b[0m Epoch 20 (Update 31460).\tTrain loss: 0.0443, Val root_mean_squared_error: -0.057, Best Epoch: 20\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m Epoch 22 (Update 34606).\tTrain loss: 0.0442, Val root_mean_squared_error: -0.0568, Best Epoch: 22\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3077)\u001b[0m Epoch 23 (Update 36179).\tTrain loss: 0.0442, Val root_mean_squared_error: -0.0574, Best Epoch: 20\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m Epoch 25 (Update 39325).\tTrain loss: 0.0441, Val root_mean_squared_error: -0.057, Best Epoch: 22\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3077)\u001b[0m Epoch 26 (Update 40898).\tTrain loss: 0.0442, Val root_mean_squared_error: -0.0576, Best Epoch: 20\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m Epoch 28 (Update 44044).\tTrain loss: 0.0441, Val root_mean_squared_error: -0.0571, Best Epoch: 22\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3077)\u001b[0m Epoch 29 (Update 45617).\tTrain loss: 0.0441, Val root_mean_squared_error: -0.0577, Best Epoch: 20\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m Epoch 31 (Update 48763).\tTrain loss: 0.044, Val root_mean_squared_error: -0.058, Best Epoch: 22\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3077)\u001b[0m Epoch 32 (Update 50336).\tTrain loss: 0.0441, Val root_mean_squared_error: -0.0575, Best Epoch: 20\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m Epoch 34 (Update 53482).\tTrain loss: 0.044, Val root_mean_squared_error: -0.057, Best Epoch: 22\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3077)\u001b[0m Epoch 35 (Update 55055).\tTrain loss: 0.0441, Val root_mean_squared_error: -0.0576, Best Epoch: 20\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m Epoch 37 (Update 58201).\tTrain loss: 0.044, Val root_mean_squared_error: -0.0573, Best Epoch: 22\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3077)\u001b[0m Epoch 38 (Update 59774).\tTrain loss: 0.044, Val root_mean_squared_error: -0.0577, Best Epoch: 20\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m Epoch 40 (Update 62920).\tTrain loss: 0.044, Val root_mean_squared_error: -0.0571, Best Epoch: 22\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3077)\u001b[0m Epoch 41 (Update 64493).\tTrain loss: 0.044, Val root_mean_squared_error: -0.0579, Best Epoch: 20\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m Epoch 43 (Update 67639).\tTrain loss: 0.0439, Val root_mean_squared_error: -0.0581, Best Epoch: 22\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3077)\u001b[0m Epoch 44 (Update 69212).\tTrain loss: 0.044, Val root_mean_squared_error: -0.0579, Best Epoch: 20\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m Epoch 46 (Update 72358).\tTrain loss: 0.0439, Val root_mean_squared_error: -0.0589, Best Epoch: 22\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3077)\u001b[0m Epoch 47 (Update 73931).\tTrain loss: 0.0439, Val root_mean_squared_error: -0.0574, Best Epoch: 20\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m Epoch 49 (Update 77077).\tTrain loss: 0.0439, Val root_mean_squared_error: -0.0578, Best Epoch: 22\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3077)\u001b[0m Best model found on Epoch 20 (Update 31460). Val root_mean_squared_error: -0.05703915283083916\n",
      "\u001b[36m(_ray_fit pid=3077)\u001b[0m Epoch 50 (Update 78650).\tTrain loss: 0.0439, Val root_mean_squared_error: -0.0579, Best Epoch: 20\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3077)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1/S1F2/model.pkl\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m Tabular Neural Network treats features as the following types:\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m {\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m     \"continuous\": [\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m         \"num_lanes\",\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m         \"curvature\",\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m         \"speed_limit\",\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m         \"num_reported_accidents\"\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m     ],\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m     \"skewed\": [],\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m     \"onehot\": [\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m         \"road_type\",\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m         \"lighting\",\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m         \"weather\",\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m         \"time_of_day\"\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m     ],\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m     \"embed\": [],\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m     \"language\": [],\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m     \"bool\": [\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m         \"road_signs_present\",\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m         \"public_road\",\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m         \"holiday\",\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m         \"school_season\"\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m     ]\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m }\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m Training data for TabularNeuralNetTorchModel has: 402697 examples, 12 features (12 vector, 0 embedding)\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m Training on GPU (CUDA)\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m Epoch 51 (Update 80223).\tTrain loss: 0.0439, Val root_mean_squared_error: -0.0568, Best Epoch: 51\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m Neural network architecture:\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m EmbedNet(\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m   (main_block): Sequential(\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m     (0): Linear(in_features=20, out_features=128, bias=True)\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m     (1): ReLU()\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m     (2): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m     (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m     (4): ReLU()\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m     (5): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m     (6): Linear(in_features=128, out_features=128, bias=True)\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m     (7): ReLU()\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m     (8): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m     (9): Linear(in_features=128, out_features=128, bias=True)\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m     (10): ReLU()\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m     (11): Linear(in_features=128, out_features=1, bias=True)\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m   )\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m )\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m Training tabular neural network for up to 1000 epochs...\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m Epoch 52 (Update 81796).\tTrain loss: 0.0438, Val root_mean_squared_error: -0.0569, Best Epoch: 51\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m Epoch 53 (Update 83369).\tTrain loss: 0.0439, Val root_mean_squared_error: -0.058, Best Epoch: 51\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m Epoch 54 (Update 84942).\tTrain loss: 0.0439, Val root_mean_squared_error: -0.0578, Best Epoch: 51\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m Epoch 3 (Update 4719).\tTrain loss: 0.0459, Val root_mean_squared_error: -0.0584, Best Epoch: 3\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m Epoch 57 (Update 89661).\tTrain loss: 0.0438, Val root_mean_squared_error: -0.0571, Best Epoch: 51\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m Epoch 59 (Update 92807).\tTrain loss: 0.0438, Val root_mean_squared_error: -0.0576, Best Epoch: 51\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m Epoch 61 (Update 95953).\tTrain loss: 0.0438, Val root_mean_squared_error: -0.0574, Best Epoch: 51\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m Epoch 63 (Update 99099).\tTrain loss: 0.0438, Val root_mean_squared_error: -0.0572, Best Epoch: 51\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m Epoch 12 (Update 18876).\tTrain loss: 0.0445, Val root_mean_squared_error: -0.0588, Best Epoch: 7\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m Epoch 66 (Update 103818).\tTrain loss: 0.0438, Val root_mean_squared_error: -0.0576, Best Epoch: 51\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m Epoch 15 (Update 23595).\tTrain loss: 0.0443, Val root_mean_squared_error: -0.058, Best Epoch: 7\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m Epoch 69 (Update 108537).\tTrain loss: 0.0438, Val root_mean_squared_error: -0.0575, Best Epoch: 51\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m Epoch 71 (Update 111683).\tTrain loss: 0.0438, Val root_mean_squared_error: -0.0574, Best Epoch: 51\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m Epoch 20 (Update 31460).\tTrain loss: 0.0442, Val root_mean_squared_error: -0.0577, Best Epoch: 19\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m Epoch 74 (Update 116402).\tTrain loss: 0.0437, Val root_mean_squared_error: -0.0582, Best Epoch: 51\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m Epoch 23 (Update 36179).\tTrain loss: 0.0442, Val root_mean_squared_error: -0.0581, Best Epoch: 19\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m Epoch 77 (Update 121121).\tTrain loss: 0.0437, Val root_mean_squared_error: -0.0571, Best Epoch: 51\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m Epoch 26 (Update 40898).\tTrain loss: 0.0441, Val root_mean_squared_error: -0.0575, Best Epoch: 19\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m Epoch 80 (Update 125840).\tTrain loss: 0.0437, Val root_mean_squared_error: -0.0574, Best Epoch: 51\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m Epoch 29 (Update 45617).\tTrain loss: 0.044, Val root_mean_squared_error: -0.0574, Best Epoch: 28\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m Epoch 83 (Update 130559).\tTrain loss: 0.0437, Val root_mean_squared_error: -0.0579, Best Epoch: 51\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m Epoch 32 (Update 50336).\tTrain loss: 0.044, Val root_mean_squared_error: -0.0585, Best Epoch: 28\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m Epoch 86 (Update 135278).\tTrain loss: 0.0437, Val root_mean_squared_error: -0.0578, Best Epoch: 51\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m Epoch 35 (Update 55055).\tTrain loss: 0.044, Val root_mean_squared_error: -0.0582, Best Epoch: 28\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m Epoch 89 (Update 139997).\tTrain loss: 0.0437, Val root_mean_squared_error: -0.0582, Best Epoch: 51\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m Epoch 38 (Update 59774).\tTrain loss: 0.0439, Val root_mean_squared_error: -0.059, Best Epoch: 28\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m Epoch 92 (Update 144716).\tTrain loss: 0.0437, Val root_mean_squared_error: -0.0576, Best Epoch: 51\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m Epoch 41 (Update 64493).\tTrain loss: 0.0439, Val root_mean_squared_error: -0.0589, Best Epoch: 28\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m Epoch 95 (Update 149435).\tTrain loss: 0.0437, Val root_mean_squared_error: -0.0576, Best Epoch: 51\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m Best model found on Epoch 51 (Update 80223). Val root_mean_squared_error: -0.05684271454811096\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1/S1F1/model.pkl\n",
      "\u001b[36m(_ray_fit pid=3076)\u001b[0m Epoch 96 (Update 151008).\tTrain loss: 0.0437, Val root_mean_squared_error: -0.0581, Best Epoch: 51\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m Tabular Neural Network treats features as the following types:\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m {\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m     \"continuous\": [\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m         \"num_lanes\",\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m         \"curvature\",\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m         \"speed_limit\",\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m         \"num_reported_accidents\"\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m     ],\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m     \"skewed\": [],\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m     \"onehot\": [\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m         \"road_type\",\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m         \"lighting\",\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m         \"weather\",\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m         \"time_of_day\"\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m     ],\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m     \"embed\": [],\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m     \"language\": [],\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m     \"bool\": [\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m         \"road_signs_present\",\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m         \"public_road\",\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m         \"holiday\",\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m         \"school_season\"\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m     ]\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m }\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m Epoch 45 (Update 70785).\tTrain loss: 0.0439, Val root_mean_squared_error: -0.0584, Best Epoch: 28\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m Training data for TabularNeuralNetTorchModel has: 402697 examples, 12 features (12 vector, 0 embedding)\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m Training on GPU (CUDA)\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m Neural network architecture:\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m EmbedNet(\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m   (main_block): Sequential(\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m     (0): Linear(in_features=20, out_features=128, bias=True)\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m     (1): ReLU()\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m     (2): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m     (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m     (4): ReLU()\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m     (5): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m     (6): Linear(in_features=128, out_features=128, bias=True)\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m     (7): ReLU()\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m     (8): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m     (9): Linear(in_features=128, out_features=128, bias=True)\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m     (10): ReLU()\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m     (11): Linear(in_features=128, out_features=1, bias=True)\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m   )\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m )\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m Training tabular neural network for up to 1000 epochs...\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m Epoch 1 (Update 1573).\tTrain loss: 0.0562, Val root_mean_squared_error: -0.0582, Best Epoch: 1\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m Epoch 48 (Update 75504).\tTrain loss: 0.0439, Val root_mean_squared_error: -0.0579, Best Epoch: 28\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m Epoch 4 (Update 6292).\tTrain loss: 0.0455, Val root_mean_squared_error: -0.057, Best Epoch: 4\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m Epoch 51 (Update 80223).\tTrain loss: 0.0439, Val root_mean_squared_error: -0.058, Best Epoch: 28\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m Epoch 7 (Update 11011).\tTrain loss: 0.0449, Val root_mean_squared_error: -0.0573, Best Epoch: 5\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m Epoch 54 (Update 84942).\tTrain loss: 0.0438, Val root_mean_squared_error: -0.0582, Best Epoch: 28\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m Epoch 10 (Update 15730).\tTrain loss: 0.0446, Val root_mean_squared_error: -0.0574, Best Epoch: 9\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m Epoch 57 (Update 89661).\tTrain loss: 0.0438, Val root_mean_squared_error: -0.0587, Best Epoch: 28\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m Epoch 13 (Update 20449).\tTrain loss: 0.0445, Val root_mean_squared_error: -0.0575, Best Epoch: 9\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m Epoch 60 (Update 94380).\tTrain loss: 0.0438, Val root_mean_squared_error: -0.058, Best Epoch: 28\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m Epoch 16 (Update 25168).\tTrain loss: 0.0444, Val root_mean_squared_error: -0.0568, Best Epoch: 14\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m Best model found on Epoch 28 (Update 44044). Val root_mean_squared_error: -0.05742933601140976\n",
      "\u001b[36m(_ray_fit pid=3199)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1/S1F3/model.pkl\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m Tabular Neural Network treats features as the following types:\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m {\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m     \"continuous\": [\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m         \"num_lanes\",\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m         \"curvature\",\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m         \"speed_limit\",\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m         \"num_reported_accidents\"\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m     ],\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m     \"skewed\": [],\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m     \"onehot\": [\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m         \"road_type\",\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m         \"lighting\",\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m         \"weather\",\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m         \"time_of_day\"\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m     ],\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m     \"embed\": [],\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m     \"language\": [],\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m     \"bool\": [\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m         \"road_signs_present\",\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m         \"public_road\",\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m         \"holiday\",\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m         \"school_season\"\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m     ]\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m }\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m Epoch 17 (Update 26741).\tTrain loss: 0.0444, Val root_mean_squared_error: -0.0576, Best Epoch: 14\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m Training data for TabularNeuralNetTorchModel has: 402697 examples, 12 features (12 vector, 0 embedding)\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m Training on GPU (CUDA)\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m Neural network architecture:\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m EmbedNet(\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m   (main_block): Sequential(\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m     (0): Linear(in_features=20, out_features=128, bias=True)\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m     (1): ReLU()\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m     (2): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m     (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m     (4): ReLU()\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m     (5): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m     (6): Linear(in_features=128, out_features=128, bias=True)\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m     (7): ReLU()\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m     (8): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m     (9): Linear(in_features=128, out_features=128, bias=True)\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m     (10): ReLU()\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m     (11): Linear(in_features=128, out_features=1, bias=True)\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m   )\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m )\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m Training tabular neural network for up to 1000 epochs...\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m Epoch 19 (Update 29887).\tTrain loss: 0.0443, Val root_mean_squared_error: -0.0569, Best Epoch: 14\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m Epoch 2 (Update 3146).\tTrain loss: 0.0468, Val root_mean_squared_error: -0.0576, Best Epoch: 2\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m Epoch 22 (Update 34606).\tTrain loss: 0.0443, Val root_mean_squared_error: -0.0578, Best Epoch: 14\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m Epoch 5 (Update 7865).\tTrain loss: 0.0452, Val root_mean_squared_error: -0.0569, Best Epoch: 5\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m Epoch 25 (Update 39325).\tTrain loss: 0.0442, Val root_mean_squared_error: -0.0569, Best Epoch: 14\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m Epoch 8 (Update 12584).\tTrain loss: 0.0448, Val root_mean_squared_error: -0.0568, Best Epoch: 8\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m Epoch 28 (Update 44044).\tTrain loss: 0.0442, Val root_mean_squared_error: -0.0574, Best Epoch: 14\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m Epoch 11 (Update 17303).\tTrain loss: 0.0446, Val root_mean_squared_error: -0.0569, Best Epoch: 8\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m Epoch 31 (Update 48763).\tTrain loss: 0.0441, Val root_mean_squared_error: -0.0571, Best Epoch: 14\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m Epoch 14 (Update 22022).\tTrain loss: 0.0444, Val root_mean_squared_error: -0.0569, Best Epoch: 12\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m Epoch 34 (Update 53482).\tTrain loss: 0.0441, Val root_mean_squared_error: -0.0571, Best Epoch: 14\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m Epoch 17 (Update 26741).\tTrain loss: 0.0443, Val root_mean_squared_error: -0.058, Best Epoch: 16\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m Epoch 37 (Update 58201).\tTrain loss: 0.0441, Val root_mean_squared_error: -0.0574, Best Epoch: 14\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m Epoch 20 (Update 31460).\tTrain loss: 0.0443, Val root_mean_squared_error: -0.0576, Best Epoch: 18\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m Epoch 40 (Update 62920).\tTrain loss: 0.0441, Val root_mean_squared_error: -0.0573, Best Epoch: 38\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m Epoch 23 (Update 36179).\tTrain loss: 0.0442, Val root_mean_squared_error: -0.0568, Best Epoch: 18\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m Epoch 43 (Update 67639).\tTrain loss: 0.044, Val root_mean_squared_error: -0.0569, Best Epoch: 38\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m Epoch 26 (Update 40898).\tTrain loss: 0.0441, Val root_mean_squared_error: -0.057, Best Epoch: 25\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m Epoch 46 (Update 72358).\tTrain loss: 0.044, Val root_mean_squared_error: -0.0572, Best Epoch: 38\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m Epoch 29 (Update 45617).\tTrain loss: 0.0441, Val root_mean_squared_error: -0.0569, Best Epoch: 25\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m Epoch 49 (Update 77077).\tTrain loss: 0.044, Val root_mean_squared_error: -0.0567, Best Epoch: 38\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m Epoch 32 (Update 50336).\tTrain loss: 0.0441, Val root_mean_squared_error: -0.0567, Best Epoch: 25\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m Epoch 52 (Update 81796).\tTrain loss: 0.044, Val root_mean_squared_error: -0.0569, Best Epoch: 38\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m Epoch 54 (Update 84942).\tTrain loss: 0.044, Val root_mean_squared_error: -0.0573, Best Epoch: 38\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m Epoch 37 (Update 58201).\tTrain loss: 0.044, Val root_mean_squared_error: -0.0575, Best Epoch: 25\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m Epoch 57 (Update 89661).\tTrain loss: 0.0439, Val root_mean_squared_error: -0.0571, Best Epoch: 38\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m Epoch 40 (Update 62920).\tTrain loss: 0.044, Val root_mean_squared_error: -0.0573, Best Epoch: 25\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m Epoch 60 (Update 94380).\tTrain loss: 0.0439, Val root_mean_squared_error: -0.0572, Best Epoch: 38\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m Epoch 43 (Update 67639).\tTrain loss: 0.044, Val root_mean_squared_error: -0.0571, Best Epoch: 25\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m Epoch 63 (Update 99099).\tTrain loss: 0.0439, Val root_mean_squared_error: -0.0572, Best Epoch: 38\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m Epoch 46 (Update 72358).\tTrain loss: 0.044, Val root_mean_squared_error: -0.0568, Best Epoch: 25\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m Epoch 66 (Update 103818).\tTrain loss: 0.0439, Val root_mean_squared_error: -0.0572, Best Epoch: 38\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m Epoch 49 (Update 77077).\tTrain loss: 0.0439, Val root_mean_squared_error: -0.0575, Best Epoch: 25\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m Epoch 69 (Update 108537).\tTrain loss: 0.0439, Val root_mean_squared_error: -0.0578, Best Epoch: 38\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m Epoch 70 (Update 110110).\tTrain loss: 0.0439, Val root_mean_squared_error: -0.0574, Best Epoch: 38\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m Epoch 72 (Update 113256).\tTrain loss: 0.0439, Val root_mean_squared_error: -0.0571, Best Epoch: 38\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m Epoch 74 (Update 116402).\tTrain loss: 0.0439, Val root_mean_squared_error: -0.0571, Best Epoch: 38\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m Best model found on Epoch 25 (Update 39325). Val root_mean_squared_error: -0.056524086743593216\n",
      "\u001b[36m(_ray_fit pid=3333)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1/S1F5/model.pkl\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m Epoch 76 (Update 119548).\tTrain loss: 0.0438, Val root_mean_squared_error: -0.057, Best Epoch: 38\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m Tabular Neural Network treats features as the following types:\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m {\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m     \"continuous\": [\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m         \"num_lanes\",\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m         \"curvature\",\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m         \"speed_limit\",\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m         \"num_reported_accidents\"\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m     ],\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m     \"skewed\": [],\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m     \"onehot\": [\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m         \"road_type\",\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m         \"lighting\",\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m         \"weather\",\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m         \"time_of_day\"\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m     ],\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m     \"embed\": [],\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m     \"language\": [],\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m     \"bool\": [\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m         \"road_signs_present\",\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m         \"public_road\",\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m         \"holiday\",\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m         \"school_season\"\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m     ]\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m }\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m Best model found on Epoch 38 (Update 59774). Val root_mean_squared_error: -0.05671665817499161\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m Training data for TabularNeuralNetTorchModel has: 402697 examples, 12 features (12 vector, 0 embedding)\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m Training on GPU (CUDA)\n",
      "\u001b[36m(_ray_fit pid=3280)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1/S1F4/model.pkl\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m Neural network architecture:\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m EmbedNet(\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m   (main_block): Sequential(\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m     (0): Linear(in_features=20, out_features=128, bias=True)\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m     (1): ReLU()\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m     (2): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m     (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m     (4): ReLU()\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m     (5): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m     (6): Linear(in_features=128, out_features=128, bias=True)\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m     (7): ReLU()\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m     (8): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m     (9): Linear(in_features=128, out_features=128, bias=True)\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m     (10): ReLU()\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m     (11): Linear(in_features=128, out_features=1, bias=True)\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m   )\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m )\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m Training tabular neural network for up to 1000 epochs...\n",
      "\u001b[36m(_ray_fit pid=3458)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=3458)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=3458)\u001b[0m Tabular Neural Network treats features as the following types:\n",
      "\u001b[36m(_ray_fit pid=3458)\u001b[0m {\n",
      "\u001b[36m(_ray_fit pid=3458)\u001b[0m     \"continuous\": [\n",
      "\u001b[36m(_ray_fit pid=3458)\u001b[0m         \"num_lanes\",\n",
      "\u001b[36m(_ray_fit pid=3458)\u001b[0m         \"curvature\",\n",
      "\u001b[36m(_ray_fit pid=3458)\u001b[0m         \"speed_limit\",\n",
      "\u001b[36m(_ray_fit pid=3458)\u001b[0m         \"num_reported_accidents\"\n",
      "\u001b[36m(_ray_fit pid=3458)\u001b[0m     ],\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3458)\u001b[0m     \"skewed\": [],\n",
      "\u001b[36m(_ray_fit pid=3458)\u001b[0m     \"onehot\": [\n",
      "\u001b[36m(_ray_fit pid=3458)\u001b[0m         \"road_type\",\n",
      "\u001b[36m(_ray_fit pid=3458)\u001b[0m         \"lighting\",\n",
      "\u001b[36m(_ray_fit pid=3458)\u001b[0m         \"weather\",\n",
      "\u001b[36m(_ray_fit pid=3458)\u001b[0m         \"time_of_day\"\n",
      "\u001b[36m(_ray_fit pid=3458)\u001b[0m     \"embed\": [],\n",
      "\u001b[36m(_ray_fit pid=3458)\u001b[0m     \"language\": [],\n",
      "\u001b[36m(_ray_fit pid=3458)\u001b[0m     \"bool\": [\n",
      "\u001b[36m(_ray_fit pid=3458)\u001b[0m         \"road_signs_present\",\n",
      "\u001b[36m(_ray_fit pid=3458)\u001b[0m         \"public_road\",\n",
      "\u001b[36m(_ray_fit pid=3458)\u001b[0m         \"holiday\",\n",
      "\u001b[36m(_ray_fit pid=3458)\u001b[0m         \"school_season\"\n",
      "\u001b[36m(_ray_fit pid=3458)\u001b[0m     ]\n",
      "\u001b[36m(_ray_fit pid=3458)\u001b[0m }\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m Epoch 1 (Update 1573).\tTrain loss: 0.0561, Val root_mean_squared_error: -0.0578, Best Epoch: 1\n",
      "\u001b[36m(_ray_fit pid=3458)\u001b[0m Training data for TabularNeuralNetTorchModel has: 402697 examples, 12 features (12 vector, 0 embedding)\n",
      "\u001b[36m(_ray_fit pid=3458)\u001b[0m Training on GPU (CUDA)\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m Epoch 2 (Update 3146).\tTrain loss: 0.0468, Val root_mean_squared_error: -0.0576, Best Epoch: 2\n",
      "\u001b[36m(_ray_fit pid=3458)\u001b[0m Neural network architecture:\n",
      "\u001b[36m(_ray_fit pid=3458)\u001b[0m EmbedNet(\n",
      "\u001b[36m(_ray_fit pid=3458)\u001b[0m   (main_block): Sequential(\n",
      "\u001b[36m(_ray_fit pid=3458)\u001b[0m     (11): Linear(in_features=128, out_features=1, bias=True)\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3458)\u001b[0m     (10): ReLU()\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3458)\u001b[0m     (8): Dropout(p=0.1, inplace=False)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3458)\u001b[0m )\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3458)\u001b[0m Training tabular neural network for up to 1000 epochs...\n",
      "\u001b[36m(_ray_fit pid=3458)\u001b[0m Epoch 1 (Update 1573).\tTrain loss: 0.0561, Val root_mean_squared_error: -0.0583, Best Epoch: 1\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m Epoch 3 (Update 4719).\tTrain loss: 0.0458, Val root_mean_squared_error: -0.0572, Best Epoch: 3\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m Epoch 4 (Update 6292).\tTrain loss: 0.0454, Val root_mean_squared_error: -0.0574, Best Epoch: 3\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m Epoch 6 (Update 9438).\tTrain loss: 0.045, Val root_mean_squared_error: -0.0565, Best Epoch: 6\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m Epoch 8 (Update 12584).\tTrain loss: 0.0448, Val root_mean_squared_error: -0.0571, Best Epoch: 6\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m Epoch 10 (Update 15730).\tTrain loss: 0.0446, Val root_mean_squared_error: -0.0565, Best Epoch: 6\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3458)\u001b[0m Epoch 11 (Update 17303).\tTrain loss: 0.0445, Val root_mean_squared_error: -0.058, Best Epoch: 8\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m Epoch 13 (Update 20449).\tTrain loss: 0.0445, Val root_mean_squared_error: -0.0567, Best Epoch: 12\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3458)\u001b[0m Epoch 14 (Update 22022).\tTrain loss: 0.0444, Val root_mean_squared_error: -0.0572, Best Epoch: 8\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m Epoch 16 (Update 25168).\tTrain loss: 0.0444, Val root_mean_squared_error: -0.0571, Best Epoch: 12\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m Epoch 17 (Update 26741).\tTrain loss: 0.0443, Val root_mean_squared_error: -0.0575, Best Epoch: 12\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3458)\u001b[0m Epoch 18 (Update 28314).\tTrain loss: 0.0443, Val root_mean_squared_error: -0.0571, Best Epoch: 16\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m Epoch 20 (Update 31460).\tTrain loss: 0.0443, Val root_mean_squared_error: -0.0575, Best Epoch: 19\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3458)\u001b[0m Epoch 21 (Update 33033).\tTrain loss: 0.0442, Val root_mean_squared_error: -0.0575, Best Epoch: 16\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m Epoch 23 (Update 36179).\tTrain loss: 0.0442, Val root_mean_squared_error: -0.0569, Best Epoch: 21\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m Epoch 24 (Update 37752).\tTrain loss: 0.0442, Val root_mean_squared_error: -0.0569, Best Epoch: 21\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3458)\u001b[0m Epoch 25 (Update 39325).\tTrain loss: 0.0441, Val root_mean_squared_error: -0.0582, Best Epoch: 16\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m Epoch 27 (Update 42471).\tTrain loss: 0.0441, Val root_mean_squared_error: -0.0566, Best Epoch: 21\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3458)\u001b[0m Epoch 28 (Update 44044).\tTrain loss: 0.0441, Val root_mean_squared_error: -0.0573, Best Epoch: 16\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3458)\u001b[0m Epoch 29 (Update 45617).\tTrain loss: 0.0441, Val root_mean_squared_error: -0.0578, Best Epoch: 16\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m Epoch 31 (Update 48763).\tTrain loss: 0.0441, Val root_mean_squared_error: -0.0571, Best Epoch: 21\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m Epoch 32 (Update 50336).\tTrain loss: 0.0441, Val root_mean_squared_error: -0.0567, Best Epoch: 21\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3458)\u001b[0m Epoch 33 (Update 51909).\tTrain loss: 0.044, Val root_mean_squared_error: -0.0576, Best Epoch: 16\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m Epoch 35 (Update 55055).\tTrain loss: 0.044, Val root_mean_squared_error: -0.0577, Best Epoch: 21\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3458)\u001b[0m Epoch 36 (Update 56628).\tTrain loss: 0.044, Val root_mean_squared_error: -0.0574, Best Epoch: 16\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m Epoch 38 (Update 59774).\tTrain loss: 0.044, Val root_mean_squared_error: -0.0576, Best Epoch: 21\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3458)\u001b[0m Epoch 39 (Update 61347).\tTrain loss: 0.044, Val root_mean_squared_error: -0.0579, Best Epoch: 16\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m Epoch 41 (Update 64493).\tTrain loss: 0.044, Val root_mean_squared_error: -0.0572, Best Epoch: 21\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3458)\u001b[0m Epoch 42 (Update 66066).\tTrain loss: 0.0439, Val root_mean_squared_error: -0.0578, Best Epoch: 16\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m Epoch 44 (Update 69212).\tTrain loss: 0.0439, Val root_mean_squared_error: -0.0574, Best Epoch: 21\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3458)\u001b[0m Best model found on Epoch 16 (Update 25168). Val root_mean_squared_error: -0.056990087032318115\n",
      "\u001b[36m(_ray_fit pid=3458)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1/S1F7/model.pkl\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m Epoch 45 (Update 70785).\tTrain loss: 0.044, Val root_mean_squared_error: -0.0566, Best Epoch: 21\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m Tabular Neural Network treats features as the following types:\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m {\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m     \"continuous\": [\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m         \"num_lanes\",\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m         \"curvature\",\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m         \"speed_limit\",\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m         \"num_reported_accidents\"\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m     ],\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m     \"skewed\": [],\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m     \"onehot\": [\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m         \"road_type\",\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m         \"lighting\",\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m         \"weather\",\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m         \"time_of_day\"\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m     ],\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m     \"embed\": [],\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m     \"language\": [],\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m     \"bool\": [\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m         \"road_signs_present\",\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m         \"public_road\",\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m         \"holiday\",\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m         \"school_season\"\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m     ]\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m }\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m Training data for TabularNeuralNetTorchModel has: 402697 examples, 12 features (12 vector, 0 embedding)\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m Training on GPU (CUDA)\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m Epoch 46 (Update 72358).\tTrain loss: 0.0439, Val root_mean_squared_error: -0.057, Best Epoch: 21\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m Neural network architecture:\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m EmbedNet(\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m   (main_block): Sequential(\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m     (0): Linear(in_features=20, out_features=128, bias=True)\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m     (1): ReLU()\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m     (2): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m     (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m     (4): ReLU()\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m     (5): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m     (6): Linear(in_features=128, out_features=128, bias=True)\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m     (7): ReLU()\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m     (8): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m     (9): Linear(in_features=128, out_features=128, bias=True)\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m     (10): ReLU()\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m     (11): Linear(in_features=128, out_features=1, bias=True)\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m   )\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m )\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m Training tabular neural network for up to 1000 epochs...\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m Epoch 47 (Update 73931).\tTrain loss: 0.0439, Val root_mean_squared_error: -0.0579, Best Epoch: 21\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m Epoch 48 (Update 75504).\tTrain loss: 0.0439, Val root_mean_squared_error: -0.0572, Best Epoch: 21\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m Epoch 3 (Update 4719).\tTrain loss: 0.0459, Val root_mean_squared_error: -0.0575, Best Epoch: 3\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m Best model found on Epoch 21 (Update 33033). Val root_mean_squared_error: -0.05634443089365959\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m Epoch 51 (Update 80223).\tTrain loss: 0.0439, Val root_mean_squared_error: -0.058, Best Epoch: 21\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3426)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1/S1F6/model.pkl\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m Epoch 6 (Update 9438).\tTrain loss: 0.045, Val root_mean_squared_error: -0.0569, Best Epoch: 6\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m Epoch 8 (Update 12584).\tTrain loss: 0.0448, Val root_mean_squared_error: -0.057, Best Epoch: 6\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m Epoch 10 (Update 15730).\tTrain loss: 0.0446, Val root_mean_squared_error: -0.057, Best Epoch: 6\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m Epoch 12 (Update 18876).\tTrain loss: 0.0445, Val root_mean_squared_error: -0.0575, Best Epoch: 6\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m Epoch 14 (Update 22022).\tTrain loss: 0.0445, Val root_mean_squared_error: -0.0576, Best Epoch: 6\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m Epoch 16 (Update 25168).\tTrain loss: 0.0444, Val root_mean_squared_error: -0.0571, Best Epoch: 6\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m Epoch 18 (Update 28314).\tTrain loss: 0.0443, Val root_mean_squared_error: -0.0575, Best Epoch: 6\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m Epoch 20 (Update 31460).\tTrain loss: 0.0443, Val root_mean_squared_error: -0.0577, Best Epoch: 6\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m Epoch 22 (Update 34606).\tTrain loss: 0.0442, Val root_mean_squared_error: -0.0575, Best Epoch: 6\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m Epoch 24 (Update 37752).\tTrain loss: 0.0442, Val root_mean_squared_error: -0.0582, Best Epoch: 6\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m Epoch 26 (Update 40898).\tTrain loss: 0.0442, Val root_mean_squared_error: -0.0574, Best Epoch: 6\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m Best model found on Epoch 6 (Update 9438). Val root_mean_squared_error: -0.05693811923265457\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m Epoch 28 (Update 44044).\tTrain loss: 0.0441, Val root_mean_squared_error: -0.0575, Best Epoch: 6\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3544)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1/S1F8/model.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t-0.0569\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t1201.47s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t1.4s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t41198.8\t = Inference  throughput (rows/s | 57529 batch size)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 2386.92s of the 5086.36s of remaining time.\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tFitting LightGBMLarge_BAG_L1 with 'num_gpus': 2, 'num_cpus': 4\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=0.56%)\n",
      "\u001b[36m(_ray_fit pid=3696)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=3696)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'device': 'gpu'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=3695)\u001b[0m [50]\tvalid_set's rmse: 0.0691434\n",
      "\u001b[36m(_ray_fit pid=3695)\u001b[0m [200]\tvalid_set's rmse: 0.0560379\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=3695)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L1/S1F1/model.pkl\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3695)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=3695)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'device': 'gpu'}\n",
      "\u001b[36m(_ray_fit pid=3777)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=3777)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'device': 'gpu'}\n",
      "\u001b[36m(_ray_fit pid=3696)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L1/S1F2/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=3777)\u001b[0m [50]\tvalid_set's rmse: 0.0696892\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3808)\u001b[0m [150]\tvalid_set's rmse: 0.0560185\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3777)\u001b[0m [400]\tvalid_set's rmse: 0.0565354\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=3777)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L1/S1F3/model.pkl\n",
      "\u001b[36m(_ray_fit pid=3808)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=3808)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'device': 'gpu'}\n",
      "\u001b[36m(_ray_fit pid=3860)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=3860)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'device': 'gpu'}\n",
      "\u001b[36m(_ray_fit pid=3808)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L1/S1F4/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=3860)\u001b[0m [50]\tvalid_set's rmse: 0.068729\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3890)\u001b[0m [150]\tvalid_set's rmse: 0.055634\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3890)\u001b[0m [350]\tvalid_set's rmse: 0.0555355\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=3890)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L1/S1F6/model.pkl\n",
      "\u001b[36m(_ray_fit pid=3890)\u001b[0m \tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=3890)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'device': 'gpu'}\n",
      "\u001b[36m(_ray_fit pid=3942)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=3942)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'device': 'gpu'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=3942)\u001b[0m [50]\tvalid_set's rmse: 0.0696672\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3942)\u001b[0m [200]\tvalid_set's rmse: 0.0562556\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=3942)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L1/S1F7/model.pkl\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3957)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=3957)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'device': 'gpu'}\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t-0.056\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t79.11s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t14.73s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t3906.7\t = Inference  throughput (rows/s | 57529 batch size)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/RandomForestMSE_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/ExtraTreesMSE_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Model configs that will be trained (in order):\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tWeightedEnsemble_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': False}}\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 539.48s of the 5003.18s of remaining time.\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 4\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Ensemble size: 13\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Ensemble weights: \n",
      "\u001b[36m(_dystack pid=288)\u001b[0m [0.         0.07692308 0.07692308 0.         0.07692308 0.\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m  0.15384615 0.         0.61538462]\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t2.63s\t= Estimated out-of-fold prediction time...\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tEnsemble Weights: {'LightGBMLarge_BAG_L1': 0.615, 'XGBoost_BAG_L1': 0.154, 'LightGBM_BAG_L1': 0.077, 'RandomForestMSE_BAG_L1': 0.077, 'ExtraTreesMSE_BAG_L1': 0.077}\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t-0.056\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t0.7s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t1205.0\t = Inference  throughput (rows/s | 57529 batch size)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Model configs that will be trained (in order):\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tLightGBMXT_BAG_L2: \t{'extra_trees': True, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}, 'ag_args_ensemble': {'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tLightGBM_BAG_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}, 'ag_args_ensemble': {'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tRandomForestMSE_BAG_L2: \t{'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'problem_types': ['regression', 'quantile'], 'name_suffix': 'MSE', 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True, 'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tCatBoost_BAG_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}, 'ag_args_ensemble': {'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tExtraTreesMSE_BAG_L2: \t{'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'problem_types': ['regression', 'quantile'], 'name_suffix': 'MSE', 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True, 'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tNeuralNetFastAI_BAG_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}, 'ag_args_ensemble': {'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tXGBoost_BAG_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}, 'ag_args_ensemble': {'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tNeuralNetTorch_BAG_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}, 'ag_args_ensemble': {'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tLightGBMLarge_BAG_L2: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_ensemble': {'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Fitting 9 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/RandomForestMSE_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/ExtraTreesMSE_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 5002.41s of the 5002.34s of remaining time.\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tFitting LightGBMXT_BAG_L2 with 'num_gpus': 2, 'num_cpus': 4\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=0.83%)\n",
      "\u001b[36m(_ray_fit pid=4122)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=4122)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True, 'device': 'gpu'}\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/utils/model_template.pkl\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=4121)\u001b[0m [50]\tvalid_set's rmse: 0.0582176\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=4122)\u001b[0m [350]\tvalid_set's rmse: 0.0560364\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=4121)\u001b[0m [800]\tvalid_set's rmse: 0.0561774\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=4121)\u001b[0m [1250]\tvalid_set's rmse: 0.0561726\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=4121)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=4121)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True, 'device': 'gpu'}\n",
      "\u001b[36m(_ray_fit pid=4122)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/S1F2/model.pkl\n",
      "\u001b[36m(_ray_fit pid=4121)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/S1F1/model.pkl\n",
      "\u001b[36m(_ray_fit pid=4204)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=4204)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True, 'device': 'gpu'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=4204)\u001b[0m [50]\tvalid_set's rmse: 0.0580274\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=4204)\u001b[0m [350]\tvalid_set's rmse: 0.0561643\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=4204)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/S1F3/model.pkl\n",
      "\u001b[36m(_ray_fit pid=4233)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=4233)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True, 'device': 'gpu'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=4233)\u001b[0m [700]\tvalid_set's rmse: 0.0563666\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=4284)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=4284)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True, 'device': 'gpu'}\n",
      "\u001b[36m(_ray_fit pid=4233)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/S1F4/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=4284)\u001b[0m [100]\tvalid_set's rmse: 0.0560871\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=4325)\u001b[0m \tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=4325)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True, 'device': 'gpu'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=4284)\u001b[0m [450]\tvalid_set's rmse: 0.0559486\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=4284)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/S1F5/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=4325)\u001b[0m [300]\tvalid_set's rmse: 0.0561375\u001b[32m [repeated 10x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=4367)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=4367)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True, 'device': 'gpu'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=4325)\u001b[0m [700]\tvalid_set's rmse: 0.0561222\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=4325)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/S1F6/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=4367)\u001b[0m [300]\tvalid_set's rmse: 0.0560153\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=4407)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=4407)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True, 'device': 'gpu'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=4367)\u001b[0m [750]\tvalid_set's rmse: 0.0560017\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=4367)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/S1F7/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=4407)\u001b[0m [300]\tvalid_set's rmse: 0.055985\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=4407)\u001b[0m [750]\tvalid_set's rmse: 0.0559602\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=288)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/model.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t-0.0561\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t85.86s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t23.85s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t329.4\t = Inference  throughput (rows/s | 57529 batch size)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 4911.54s of the 4911.47s of remaining time.\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tFitting LightGBM_BAG_L2 with 'num_gpus': 2, 'num_cpus': 4\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=0.84%)\n",
      "\u001b[36m(_ray_fit pid=4547)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=4547)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'device': 'gpu'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=4547)\u001b[0m [50]\tvalid_set's rmse: 0.0575135\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=4548)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2/S1F2/model.pkl\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=4548)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=4548)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'device': 'gpu'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=4547)\u001b[0m [450]\tvalid_set's rmse: 0.0560917\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=4626)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=4626)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'device': 'gpu'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=4626)\u001b[0m [50]\tvalid_set's rmse: 0.057427\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=4547)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2/S1F1/model.pkl\n",
      "\u001b[36m(_ray_fit pid=4626)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2/S1F3/model.pkl\n",
      "\u001b[36m(_ray_fit pid=4659)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=4659)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'device': 'gpu'}\n",
      "\u001b[36m(_ray_fit pid=4706)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=4706)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'device': 'gpu'}\n",
      "\u001b[36m(_ray_fit pid=4659)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2/S1F4/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=4706)\u001b[0m [50]\tvalid_set's rmse: 0.0571449\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=4706)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2/S1F5/model.pkl\n",
      "\u001b[36m(_ray_fit pid=4738)\u001b[0m \tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=4738)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'device': 'gpu'}\n",
      "\u001b[36m(_ray_fit pid=4788)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=4788)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'device': 'gpu'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=4788)\u001b[0m [50]\tvalid_set's rmse: 0.0572404\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=4788)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2/S1F7/model.pkl\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=4789)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=4789)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'device': 'gpu'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=4789)\u001b[0m [450]\tvalid_set's rmse: 0.0558319\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=288)\u001b[0m \t-0.056\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t44.95s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t5.55s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t368.0\t = Inference  throughput (rows/s | 57529 batch size)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 4863.13s of the 4863.06s of remaining time.\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tFitting RandomForestMSE_BAG_L2 with 'num_gpus': 1, 'num_cpus': 4\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/RandomForestMSE_BAG_L2/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t71.84s\t= Estimated out-of-fold prediction time...\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/RandomForestMSE_BAG_L2/utils/model_template.pkl\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t-0.056\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t773.61s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t12.9s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t377.5\t = Inference  throughput (rows/s | 57529 batch size)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Fitting model: CatBoost_BAG_L2 ... Training model for up to 4075.75s of the 4075.69s of remaining time.\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/trainer.pkl\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tFitting CatBoost_BAG_L2 with 'num_gpus': 2, 'num_cpus': 4\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=2.18%)\n",
      "\u001b[36m(_ray_fit pid=5144)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=5144)\u001b[0m \tCatboost model hyperparameters: {'iterations': 10000, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'RMSE', 'thread_count': 1, 'loss_function': 'RMSE', 'task_type': 'GPU'}\n",
      "\u001b[36m(_ray_fit pid=5144)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=5145)\u001b[0m 0:\tlearn: 0.1594307\ttest: 0.1594551\tbest: 0.1594551 (0)\ttotal: 22.5ms\tremaining: 22.5ms\n",
      "\u001b[36m(_ray_fit pid=5145)\u001b[0m 1:\tlearn: 0.1527826\ttest: 0.1528139\tbest: 0.1528139 (1)\ttotal: 33.6ms\tremaining: 0us\n",
      "\u001b[36m(_ray_fit pid=5145)\u001b[0m bestTest = 0.1528138795\n",
      "\u001b[36m(_ray_fit pid=5145)\u001b[0m bestIteration = 1\n",
      "\u001b[36m(_ray_fit pid=4789)\u001b[0m [500]\tvalid_set's rmse: 0.0558344\n",
      "\u001b[36m(_ray_fit pid=5145)\u001b[0m 120:\tlearn: 0.0560203\ttest: 0.0559907\tbest: 0.0559907 (120)\ttotal: 3.24s\tremaining: 22.5s\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5144)\u001b[0m bestTest = 0.1523963543\n",
      "\u001b[36m(_ray_fit pid=5144)\u001b[0m bestIteration = 1\n",
      "\u001b[36m(_ray_fit pid=5144)\u001b[0m 320:\tlearn: 0.0558757\ttest: 0.0561291\tbest: 0.0561287 (318)\ttotal: 8.29s\tremaining: 10.9s\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5144)\u001b[0m 520:\tlearn: 0.0557786\ttest: 0.0561154\tbest: 0.0561154 (494)\ttotal: 13.3s\tremaining: 5.63s\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5144)\u001b[0m 720:\tlearn: 0.0556945\ttest: 0.0561067\tbest: 0.0561064 (709)\ttotal: 18.3s\tremaining: 533ms\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5144)\u001b[0m bestTest = 0.05610509931\n",
      "\u001b[36m(_ray_fit pid=5144)\u001b[0m bestIteration = 741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=5144)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/S1F1/model.pkl\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5145)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=5145)\u001b[0m \tCatboost model hyperparameters: {'iterations': 10000, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'RMSE', 'thread_count': 1, 'loss_function': 'RMSE', 'task_type': 'GPU'}\n",
      "\u001b[36m(_ray_fit pid=5145)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=5145)\u001b[0m Shrink model to first 763 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=5239)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=5239)\u001b[0m \tCatboost model hyperparameters: {'iterations': 10000, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'RMSE', 'thread_count': 1, 'loss_function': 'RMSE', 'task_type': 'GPU'}\n",
      "\u001b[36m(_ray_fit pid=5239)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=5239)\u001b[0m 1:\tlearn: 0.1526891\ttest: 0.1533262\tbest: 0.1533262 (1)\ttotal: 37.3ms\tremaining: 0us\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5239)\u001b[0m bestTest = 0.1533261602\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5239)\u001b[0m bestIteration = 1\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=5145)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/S1F2/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=5275)\u001b[0m 60:\tlearn: 0.0566475\ttest: 0.0569121\tbest: 0.0569121 (60)\ttotal: 1.61s\tremaining: 24.3s\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5275)\u001b[0m bestTest = 0.1524995796\n",
      "\u001b[36m(_ray_fit pid=5275)\u001b[0m bestIteration = 1\n",
      "\u001b[36m(_ray_fit pid=5239)\u001b[0m 340:\tlearn: 0.0558568\ttest: 0.0561173\tbest: 0.0561173 (338)\ttotal: 8.65s\tremaining: 17.1s\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5239)\u001b[0m 540:\tlearn: 0.0557577\ttest: 0.0560983\tbest: 0.0560983 (540)\ttotal: 13.6s\tremaining: 12s\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5239)\u001b[0m 740:\tlearn: 0.0556706\ttest: 0.0560907\tbest: 0.0560907 (740)\ttotal: 18.8s\tremaining: 6.97s\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5275)\u001b[0m bestTest = 0.05626660499\n",
      "\u001b[36m(_ray_fit pid=5275)\u001b[0m bestIteration = 759\n",
      "\u001b[36m(_ray_fit pid=5275)\u001b[0m Shrink model to first 760 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=5275)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/S1F4/model.pkl\n",
      "\u001b[36m(_ray_fit pid=5275)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=5275)\u001b[0m \tCatboost model hyperparameters: {'iterations': 10000, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'RMSE', 'thread_count': 1, 'loss_function': 'RMSE', 'task_type': 'GPU'}\n",
      "\u001b[36m(_ray_fit pid=5275)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=5239)\u001b[0m 920:\tlearn: 0.0555967\ttest: 0.0560839\tbest: 0.0560839 (920)\ttotal: 23.8s\tremaining: 2.46s\u001b[32m [repeated 17x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=5342)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=5342)\u001b[0m \tCatboost model hyperparameters: {'iterations': 10000, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'RMSE', 'thread_count': 1, 'loss_function': 'RMSE', 'task_type': 'GPU'}\n",
      "\u001b[36m(_ray_fit pid=5342)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=5239)\u001b[0m bestTest = 0.05608210746\n",
      "\u001b[36m(_ray_fit pid=5239)\u001b[0m bestIteration = 968\n",
      "\u001b[36m(_ray_fit pid=5239)\u001b[0m Shrink model to first 969 iterations.\n",
      "\u001b[36m(_ray_fit pid=5342)\u001b[0m bestTest = 0.1530178147\n",
      "\u001b[36m(_ray_fit pid=5342)\u001b[0m bestIteration = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=5239)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/S1F3/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=5342)\u001b[0m 0:\tlearn: 0.1593778\ttest: 0.1596821\tbest: 0.1596821 (0)\ttotal: 38.8ms\tremaining: 32.3s\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5385)\u001b[0m bestTest = 0.1526485084\n",
      "\u001b[36m(_ray_fit pid=5385)\u001b[0m bestIteration = 1\n",
      "\u001b[36m(_ray_fit pid=5385)\u001b[0m 80:\tlearn: 0.0561409\ttest: 0.0561876\tbest: 0.0561876 (80)\ttotal: 2.02s\tremaining: 24.7s\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5385)\u001b[0m 280:\tlearn: 0.0559121\ttest: 0.0560599\tbest: 0.0560599 (278)\ttotal: 7.08s\tremaining: 19.9s\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5342)\u001b[0m 600:\tlearn: 0.0557638\ttest: 0.0558920\tbest: 0.0558914 (595)\ttotal: 15.6s\tremaining: 6.05s\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5385)\u001b[0m bestTest = 0.05604498268\n",
      "\u001b[36m(_ray_fit pid=5385)\u001b[0m bestIteration = 572\n",
      "\u001b[36m(_ray_fit pid=5385)\u001b[0m Shrink model to first 573 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=5385)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/S1F6/model.pkl\n",
      "\u001b[36m(_ray_fit pid=5385)\u001b[0m \tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=5385)\u001b[0m \tCatboost model hyperparameters: {'iterations': 10000, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'RMSE', 'thread_count': 1, 'loss_function': 'RMSE', 'task_type': 'GPU'}\n",
      "\u001b[36m(_ray_fit pid=5385)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=5342)\u001b[0m 780:\tlearn: 0.0556898\ttest: 0.0558859\tbest: 0.0558854 (765)\ttotal: 20.7s\tremaining: 1.4s\u001b[32m [repeated 16x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=5443)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=5443)\u001b[0m \tCatboost model hyperparameters: {'iterations': 10000, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'RMSE', 'thread_count': 1, 'loss_function': 'RMSE', 'task_type': 'GPU'}\n",
      "\u001b[36m(_ray_fit pid=5443)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=5443)\u001b[0m bestTest = 0.1527259646\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5443)\u001b[0m bestIteration = 1\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5342)\u001b[0m Shrink model to first 791 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=5342)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/S1F5/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=5443)\u001b[0m 20:\tlearn: 0.0796165\ttest: 0.0795141\tbest: 0.0795141 (20)\ttotal: 561ms\tremaining: 25.7s\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5486)\u001b[0m bestTest = 0.1528474653\n",
      "\u001b[36m(_ray_fit pid=5486)\u001b[0m bestIteration = 1\n",
      "\u001b[36m(_ray_fit pid=5443)\u001b[0m 220:\tlearn: 0.0559553\ttest: 0.0559746\tbest: 0.0559746 (220)\ttotal: 5.87s\tremaining: 20.2s\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5443)\u001b[0m 420:\tlearn: 0.0558423\ttest: 0.0559464\tbest: 0.0559464 (420)\ttotal: 11s\tremaining: 14.6s\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5486)\u001b[0m bestTest = 0.05590043162\n",
      "\u001b[36m(_ray_fit pid=5486)\u001b[0m bestIteration = 420\n",
      "\u001b[36m(_ray_fit pid=5486)\u001b[0m Shrink model to first 421 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=5486)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/S1F8/model.pkl\n",
      "\u001b[36m(_ray_fit pid=5486)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=5486)\u001b[0m \tCatboost model hyperparameters: {'iterations': 10000, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'RMSE', 'thread_count': 1, 'loss_function': 'RMSE', 'task_type': 'GPU'}\n",
      "\u001b[36m(_ray_fit pid=5486)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=5443)\u001b[0m 620:\tlearn: 0.0557466\ttest: 0.0559388\tbest: 0.0559379 (612)\ttotal: 16.1s\tremaining: 9.39s\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5443)\u001b[0m 840:\tlearn: 0.0556578\ttest: 0.0559339\tbest: 0.0559328 (809)\ttotal: 21.5s\tremaining: 3.63s\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5443)\u001b[0m bestTest = 0.05593281556\n",
      "\u001b[36m(_ray_fit pid=5443)\u001b[0m bestIteration = 809\n",
      "\u001b[36m(_ray_fit pid=5443)\u001b[0m Shrink model to first 810 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=288)\u001b[0m \t-0.056\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t107.79s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t0.62s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t379.9\t = Inference  throughput (rows/s | 57529 batch size)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 3965.50s of the 3965.43s of remaining time.\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/trainer.pkl\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tFitting ExtraTreesMSE_BAG_L2 with 'num_gpus': 1, 'num_cpus': 4\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/ExtraTreesMSE_BAG_L2/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t71.62s\t= Estimated out-of-fold prediction time...\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/ExtraTreesMSE_BAG_L2/utils/model_template.pkl\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t-0.0559\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t150.21s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t13.76s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t377.2\t = Inference  throughput (rows/s | 57529 batch size)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 3800.29s of the 3800.22s of remaining time.\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/trainer.pkl\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tFitting NeuralNetFastAI_BAG_L2 with 'num_gpus': 2, 'num_cpus': 4\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/NeuralNetFastAI_BAG_L2/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=1.42%)\n",
      "\u001b[36m(_ray_fit pid=5702)\u001b[0m Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 'auto', 'lr': 0.01, 'epochs': 'auto', 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/NeuralNetFastAI_BAG_L2/utils/model_template.pkl\n",
      "\u001b[36m(_ray_fit pid=5703)\u001b[0m Using 4/4 categorical features\n",
      "\u001b[36m(_ray_fit pid=5703)\u001b[0m Using 17 cont features\n",
      "\u001b[36m(_ray_fit pid=5703)\u001b[0m Automated batch size selection: 512\n",
      "\u001b[36m(_ray_fit pid=5703)\u001b[0m TabularModel(\n",
      "\u001b[36m(_ray_fit pid=5703)\u001b[0m   (embeds): ModuleList(\n",
      "\u001b[36m(_ray_fit pid=5703)\u001b[0m     (0-3): 4 x Embedding(4, 3)\n",
      "\u001b[36m(_ray_fit pid=5703)\u001b[0m   )\n",
      "\u001b[36m(_ray_fit pid=5703)\u001b[0m   (emb_drop): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=5703)\u001b[0m   (bn_cont): BatchNorm1d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "\u001b[36m(_ray_fit pid=5703)\u001b[0m   (layers): Sequential(\n",
      "\u001b[36m(_ray_fit pid=5703)\u001b[0m     (0): LinBnDrop(\n",
      "\u001b[36m(_ray_fit pid=5703)\u001b[0m       (0): Linear(in_features=29, out_features=200, bias=False)\n",
      "\u001b[36m(_ray_fit pid=5703)\u001b[0m       (1): ReLU(inplace=True)\n",
      "\u001b[36m(_ray_fit pid=5703)\u001b[0m       (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "\u001b[36m(_ray_fit pid=5703)\u001b[0m       (3): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=5703)\u001b[0m     )\n",
      "\u001b[36m(_ray_fit pid=5703)\u001b[0m     (1): LinBnDrop(\n",
      "\u001b[36m(_ray_fit pid=5703)\u001b[0m       (0): Linear(in_features=200, out_features=100, bias=False)\n",
      "\u001b[36m(_ray_fit pid=5703)\u001b[0m       (1): ReLU(inplace=True)\n",
      "\u001b[36m(_ray_fit pid=5703)\u001b[0m       (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "\u001b[36m(_ray_fit pid=5703)\u001b[0m       (3): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=5703)\u001b[0m     )\n",
      "\u001b[36m(_ray_fit pid=5703)\u001b[0m     (2): LinBnDrop(\n",
      "\u001b[36m(_ray_fit pid=5703)\u001b[0m       (0): Linear(in_features=100, out_features=1, bias=True)\n",
      "\u001b[36m(_ray_fit pid=5703)\u001b[0m     )\n",
      "\u001b[36m(_ray_fit pid=5703)\u001b[0m   )\n",
      "\u001b[36m(_ray_fit pid=5703)\u001b[0m )\n",
      "\u001b[36m(_ray_fit pid=5702)\u001b[0m Automated epochs selection: training for 30 epoch(s). Estimated time budget use 266.95 / 758.63 sec\n",
      "\u001b[36m(_ray_fit pid=5702)\u001b[0m Better model found at epoch 0 with _rmse value: 0.3391076624393463.\n",
      "\u001b[36m(_ray_fit pid=5703)\u001b[0m Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 'auto', 'lr': 0.01, 'epochs': 'auto', 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
      "\u001b[36m(_ray_fit pid=5702)\u001b[0m Using 4/4 categorical features\n",
      "\u001b[36m(_ray_fit pid=5702)\u001b[0m Using 17 cont features\n",
      "\u001b[36m(_ray_fit pid=5702)\u001b[0m Automated batch size selection: 512\n",
      "\u001b[36m(_ray_fit pid=5702)\u001b[0m TabularModel(\n",
      "\u001b[36m(_ray_fit pid=5702)\u001b[0m   (embeds): ModuleList(\n",
      "\u001b[36m(_ray_fit pid=5702)\u001b[0m     (0-3): 4 x Embedding(4, 3)\n",
      "\u001b[36m(_ray_fit pid=5702)\u001b[0m )\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5702)\u001b[0m   (emb_drop): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=5702)\u001b[0m   (bn_cont): BatchNorm1d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "\u001b[36m(_ray_fit pid=5702)\u001b[0m   (layers): Sequential(\n",
      "\u001b[36m(_ray_fit pid=5702)\u001b[0m     (2): LinBnDrop(\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5702)\u001b[0m       (0): Linear(in_features=200, out_features=100, bias=False)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5702)\u001b[0m       (1): ReLU(inplace=True)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5702)\u001b[0m       (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5702)\u001b[0m       (3): Dropout(p=0.1, inplace=False)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5702)\u001b[0m       (0): Linear(in_features=100, out_features=1, bias=True)\n",
      "\u001b[36m(_ray_fit pid=5703)\u001b[0m Automated epochs selection: training for 30 epoch(s). Estimated time budget use 277.15 / 758.66 sec\n",
      "\u001b[36m(_ray_fit pid=5702)\u001b[0m Better model found at epoch 1 with _rmse value: 0.338528573513031.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5703)\u001b[0m Better model found at epoch 8 with _rmse value: 0.3361944854259491.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5702)\u001b[0m Better model found at epoch 9 with _rmse value: 0.33827751874923706.\n",
      "\u001b[36m(_ray_fit pid=5702)\u001b[0m Better model found at epoch 11 with _rmse value: 0.3382497727870941.\n",
      "\u001b[36m(_ray_fit pid=5702)\u001b[0m Better model found at epoch 12 with _rmse value: 0.3377929627895355.\n",
      "\u001b[36m(_ray_fit pid=5702)\u001b[0m Better model found at epoch 15 with _rmse value: 0.33733394742012024.\n",
      "\u001b[36m(_ray_fit pid=5702)\u001b[0m Better model found at epoch 17 with _rmse value: 0.33709388971328735.\n",
      "\u001b[36m(_ray_fit pid=5702)\u001b[0m Better model found at epoch 22 with _rmse value: 0.3370308578014374.\n",
      "\u001b[36m(_ray_fit pid=5702)\u001b[0m Better model found at epoch 24 with _rmse value: 0.3369884788990021.\n",
      "\u001b[36m(_ray_fit pid=5703)\u001b[0m Better model found at epoch 24 with _rmse value: 0.33592844009399414.\n",
      "\u001b[36m(_ray_fit pid=5702)\u001b[0m Better model found at epoch 25 with _rmse value: 0.33693793416023254.\n",
      "\u001b[36m(_ray_fit pid=5703)\u001b[0m Better model found at epoch 27 with _rmse value: 0.33588096499443054.\n",
      "\u001b[36m(_ray_fit pid=5702)\u001b[0m Model validation metrics: 0.33693793416023254\n",
      "\u001b[36m(_ray_fit pid=5702)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/NeuralNetFastAI_BAG_L2/S1F1/model.pkl\n",
      "\u001b[36m(_ray_fit pid=5836)\u001b[0m Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 'auto', 'lr': 0.01, 'epochs': 'auto', 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
      "\u001b[36m(_ray_fit pid=5703)\u001b[0m Model validation metrics: 0.33588096499443054\n",
      "\u001b[36m(_ray_fit pid=5703)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/NeuralNetFastAI_BAG_L2/S1F2/model.pkl\n",
      "\u001b[36m(_ray_fit pid=5836)\u001b[0m Using 4/4 categorical features\n",
      "\u001b[36m(_ray_fit pid=5836)\u001b[0m Using 17 cont features\n",
      "\u001b[36m(_ray_fit pid=5836)\u001b[0m Automated batch size selection: 512\n",
      "\u001b[36m(_ray_fit pid=5836)\u001b[0m TabularModel(\n",
      "\u001b[36m(_ray_fit pid=5836)\u001b[0m   (embeds): ModuleList(\n",
      "\u001b[36m(_ray_fit pid=5836)\u001b[0m     (0-3): 4 x Embedding(4, 3)\n",
      "\u001b[36m(_ray_fit pid=5836)\u001b[0m   )\n",
      "\u001b[36m(_ray_fit pid=5836)\u001b[0m   (emb_drop): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=5836)\u001b[0m   (bn_cont): BatchNorm1d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "\u001b[36m(_ray_fit pid=5836)\u001b[0m   (layers): Sequential(\n",
      "\u001b[36m(_ray_fit pid=5836)\u001b[0m     (0): LinBnDrop(\n",
      "\u001b[36m(_ray_fit pid=5836)\u001b[0m       (0): Linear(in_features=29, out_features=200, bias=False)\n",
      "\u001b[36m(_ray_fit pid=5836)\u001b[0m       (1): ReLU(inplace=True)\n",
      "\u001b[36m(_ray_fit pid=5836)\u001b[0m       (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "\u001b[36m(_ray_fit pid=5836)\u001b[0m       (3): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=5836)\u001b[0m     )\n",
      "\u001b[36m(_ray_fit pid=5836)\u001b[0m     (1): LinBnDrop(\n",
      "\u001b[36m(_ray_fit pid=5836)\u001b[0m       (0): Linear(in_features=200, out_features=100, bias=False)\n",
      "\u001b[36m(_ray_fit pid=5836)\u001b[0m       (1): ReLU(inplace=True)\n",
      "\u001b[36m(_ray_fit pid=5836)\u001b[0m       (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "\u001b[36m(_ray_fit pid=5836)\u001b[0m       (3): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=5836)\u001b[0m     )\n",
      "\u001b[36m(_ray_fit pid=5836)\u001b[0m     (2): LinBnDrop(\n",
      "\u001b[36m(_ray_fit pid=5836)\u001b[0m       (0): Linear(in_features=100, out_features=1, bias=True)\n",
      "\u001b[36m(_ray_fit pid=5836)\u001b[0m     )\n",
      "\u001b[36m(_ray_fit pid=5836)\u001b[0m   )\n",
      "\u001b[36m(_ray_fit pid=5836)\u001b[0m )\n",
      "\u001b[36m(_ray_fit pid=5836)\u001b[0m Automated epochs selection: training for 30 epoch(s). Estimated time budget use 270.98 / 758.61 sec\n",
      "\u001b[36m(_ray_fit pid=5836)\u001b[0m Better model found at epoch 0 with _rmse value: 0.3387119472026825.\n",
      "\u001b[36m(_ray_fit pid=5866)\u001b[0m Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 'auto', 'lr': 0.01, 'epochs': 'auto', 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
      "\u001b[36m(_ray_fit pid=5866)\u001b[0m Using 4/4 categorical features\n",
      "\u001b[36m(_ray_fit pid=5866)\u001b[0m Using 17 cont features\n",
      "\u001b[36m(_ray_fit pid=5866)\u001b[0m Automated batch size selection: 512\n",
      "\u001b[36m(_ray_fit pid=5866)\u001b[0m TabularModel(\n",
      "\u001b[36m(_ray_fit pid=5866)\u001b[0m   (embeds): ModuleList(\n",
      "\u001b[36m(_ray_fit pid=5866)\u001b[0m     (0-3): 4 x Embedding(4, 3)\n",
      "\u001b[36m(_ray_fit pid=5866)\u001b[0m )\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5866)\u001b[0m   (emb_drop): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=5866)\u001b[0m   (bn_cont): BatchNorm1d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "\u001b[36m(_ray_fit pid=5866)\u001b[0m   (layers): Sequential(\n",
      "\u001b[36m(_ray_fit pid=5866)\u001b[0m     (2): LinBnDrop(\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5866)\u001b[0m       (0): Linear(in_features=200, out_features=100, bias=False)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5866)\u001b[0m       (1): ReLU(inplace=True)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5866)\u001b[0m       (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5866)\u001b[0m       (3): Dropout(p=0.1, inplace=False)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5866)\u001b[0m       (0): Linear(in_features=100, out_features=1, bias=True)\n",
      "\u001b[36m(_ray_fit pid=5866)\u001b[0m Automated epochs selection: training for 30 epoch(s). Estimated time budget use 291.46 / 758.65 sec\n",
      "\u001b[36m(_ray_fit pid=5866)\u001b[0m Better model found at epoch 2 with _rmse value: 0.33917462825775146.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5866)\u001b[0m Better model found at epoch 7 with _rmse value: 0.33842650055885315.\n",
      "\u001b[36m(_ray_fit pid=5836)\u001b[0m Better model found at epoch 9 with _rmse value: 0.3377029001712799.\n",
      "\u001b[36m(_ray_fit pid=5836)\u001b[0m Better model found at epoch 11 with _rmse value: 0.3372158408164978.\n",
      "\u001b[36m(_ray_fit pid=5866)\u001b[0m Better model found at epoch 17 with _rmse value: 0.3378100097179413.\n",
      "\u001b[36m(_ray_fit pid=5836)\u001b[0m Better model found at epoch 24 with _rmse value: 0.33719339966773987.\n",
      "\u001b[36m(_ray_fit pid=5836)\u001b[0m Better model found at epoch 25 with _rmse value: 0.3370487689971924.\n",
      "\u001b[36m(_ray_fit pid=5836)\u001b[0m Better model found at epoch 26 with _rmse value: 0.33700141310691833.\n",
      "\u001b[36m(_ray_fit pid=5836)\u001b[0m Better model found at epoch 27 with _rmse value: 0.3369590938091278.\n",
      "\u001b[36m(_ray_fit pid=5836)\u001b[0m Model validation metrics: 0.3369590938091278\n",
      "\u001b[36m(_ray_fit pid=5866)\u001b[0m Better model found at epoch 27 with _rmse value: 0.3377983570098877.\n",
      "\u001b[36m(_ray_fit pid=5836)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/NeuralNetFastAI_BAG_L2/S1F3/model.pkl\n",
      "\u001b[36m(_ray_fit pid=5866)\u001b[0m Better model found at epoch 29 with _rmse value: 0.3377719819545746.\n",
      "\u001b[36m(_ray_fit pid=5970)\u001b[0m Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 'auto', 'lr': 0.01, 'epochs': 'auto', 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
      "\u001b[36m(_ray_fit pid=5866)\u001b[0m Model validation metrics: 0.3377719819545746\n",
      "\u001b[36m(_ray_fit pid=5866)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/NeuralNetFastAI_BAG_L2/S1F4/model.pkl\n",
      "\u001b[36m(_ray_fit pid=5970)\u001b[0m Using 4/4 categorical features\n",
      "\u001b[36m(_ray_fit pid=5970)\u001b[0m Using 17 cont features\n",
      "\u001b[36m(_ray_fit pid=5970)\u001b[0m Automated batch size selection: 512\n",
      "\u001b[36m(_ray_fit pid=5970)\u001b[0m TabularModel(\n",
      "\u001b[36m(_ray_fit pid=5970)\u001b[0m   (embeds): ModuleList(\n",
      "\u001b[36m(_ray_fit pid=5970)\u001b[0m     (0-3): 4 x Embedding(4, 3)\n",
      "\u001b[36m(_ray_fit pid=5970)\u001b[0m   )\n",
      "\u001b[36m(_ray_fit pid=5970)\u001b[0m   (emb_drop): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=5970)\u001b[0m   (bn_cont): BatchNorm1d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "\u001b[36m(_ray_fit pid=5970)\u001b[0m   (layers): Sequential(\n",
      "\u001b[36m(_ray_fit pid=5970)\u001b[0m     (0): LinBnDrop(\n",
      "\u001b[36m(_ray_fit pid=5970)\u001b[0m       (0): Linear(in_features=29, out_features=200, bias=False)\n",
      "\u001b[36m(_ray_fit pid=5970)\u001b[0m       (1): ReLU(inplace=True)\n",
      "\u001b[36m(_ray_fit pid=5970)\u001b[0m       (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "\u001b[36m(_ray_fit pid=5970)\u001b[0m       (3): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=5970)\u001b[0m     )\n",
      "\u001b[36m(_ray_fit pid=5970)\u001b[0m     (1): LinBnDrop(\n",
      "\u001b[36m(_ray_fit pid=5970)\u001b[0m       (0): Linear(in_features=200, out_features=100, bias=False)\n",
      "\u001b[36m(_ray_fit pid=5970)\u001b[0m       (1): ReLU(inplace=True)\n",
      "\u001b[36m(_ray_fit pid=5970)\u001b[0m       (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "\u001b[36m(_ray_fit pid=5970)\u001b[0m       (3): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=5970)\u001b[0m     )\n",
      "\u001b[36m(_ray_fit pid=5970)\u001b[0m     (2): LinBnDrop(\n",
      "\u001b[36m(_ray_fit pid=5970)\u001b[0m       (0): Linear(in_features=100, out_features=1, bias=True)\n",
      "\u001b[36m(_ray_fit pid=5970)\u001b[0m     )\n",
      "\u001b[36m(_ray_fit pid=5970)\u001b[0m   )\n",
      "\u001b[36m(_ray_fit pid=5970)\u001b[0m )\n",
      "\u001b[36m(_ray_fit pid=5970)\u001b[0m Automated epochs selection: training for 30 epoch(s). Estimated time budget use 247.96 / 758.65 sec\n",
      "\u001b[36m(_ray_fit pid=6003)\u001b[0m Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 'auto', 'lr': 0.01, 'epochs': 'auto', 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
      "\u001b[36m(_ray_fit pid=6003)\u001b[0m Using 4/4 categorical features\n",
      "\u001b[36m(_ray_fit pid=6003)\u001b[0m Using 17 cont features\n",
      "\u001b[36m(_ray_fit pid=6003)\u001b[0m Automated batch size selection: 512\n",
      "\u001b[36m(_ray_fit pid=6003)\u001b[0m TabularModel(\n",
      "\u001b[36m(_ray_fit pid=6003)\u001b[0m   (embeds): ModuleList(\n",
      "\u001b[36m(_ray_fit pid=6003)\u001b[0m     (0-3): 4 x Embedding(4, 3)\n",
      "\u001b[36m(_ray_fit pid=6003)\u001b[0m )\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6003)\u001b[0m   (emb_drop): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=6003)\u001b[0m   (bn_cont): BatchNorm1d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "\u001b[36m(_ray_fit pid=6003)\u001b[0m   (layers): Sequential(\n",
      "\u001b[36m(_ray_fit pid=6003)\u001b[0m     (2): LinBnDrop(\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6003)\u001b[0m       (0): Linear(in_features=200, out_features=100, bias=False)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6003)\u001b[0m       (1): ReLU(inplace=True)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6003)\u001b[0m       (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6003)\u001b[0m       (3): Dropout(p=0.1, inplace=False)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6003)\u001b[0m       (0): Linear(in_features=100, out_features=1, bias=True)\n",
      "\u001b[36m(_ray_fit pid=5970)\u001b[0m Better model found at epoch 0 with _rmse value: 0.3376484513282776.\n",
      "\u001b[36m(_ray_fit pid=6003)\u001b[0m Automated epochs selection: training for 30 epoch(s). Estimated time budget use 282.22 / 758.62 sec\n",
      "\u001b[36m(_ray_fit pid=5970)\u001b[0m Better model found at epoch 1 with _rmse value: 0.33749550580978394.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6003)\u001b[0m Better model found at epoch 2 with _rmse value: 0.33708974719047546.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5970)\u001b[0m Better model found at epoch 4 with _rmse value: 0.33619168400764465.\n",
      "\u001b[36m(_ray_fit pid=6003)\u001b[0m Better model found at epoch 13 with _rmse value: 0.3369329273700714.\n",
      "\u001b[36m(_ray_fit pid=5970)\u001b[0m Better model found at epoch 15 with _rmse value: 0.3361244797706604.\n",
      "\u001b[36m(_ray_fit pid=5970)\u001b[0m Better model found at epoch 16 with _rmse value: 0.33597996830940247.\n",
      "\u001b[36m(_ray_fit pid=5970)\u001b[0m Better model found at epoch 20 with _rmse value: 0.3358865976333618.\n",
      "\u001b[36m(_ray_fit pid=6003)\u001b[0m Better model found at epoch 24 with _rmse value: 0.3368430733680725.\n",
      "\u001b[36m(_ray_fit pid=6003)\u001b[0m Better model found at epoch 25 with _rmse value: 0.33665230870246887.\n",
      "\u001b[36m(_ray_fit pid=5970)\u001b[0m Better model found at epoch 27 with _rmse value: 0.33588555455207825.\n",
      "\u001b[36m(_ray_fit pid=5970)\u001b[0m Better model found at epoch 28 with _rmse value: 0.33585605025291443.\n",
      "\u001b[36m(_ray_fit pid=6003)\u001b[0m Better model found at epoch 28 with _rmse value: 0.3364914655685425.\n",
      "\u001b[36m(_ray_fit pid=5970)\u001b[0m Model validation metrics: 0.33585605025291443\n",
      "\u001b[36m(_ray_fit pid=5970)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/NeuralNetFastAI_BAG_L2/S1F5/model.pkl\n",
      "\u001b[36m(_ray_fit pid=6003)\u001b[0m Model validation metrics: 0.3364914655685425\n",
      "\u001b[36m(_ray_fit pid=6103)\u001b[0m Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 'auto', 'lr': 0.01, 'epochs': 'auto', 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
      "\u001b[36m(_ray_fit pid=6003)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/NeuralNetFastAI_BAG_L2/S1F6/model.pkl\n",
      "\u001b[36m(_ray_fit pid=6103)\u001b[0m Using 4/4 categorical features\n",
      "\u001b[36m(_ray_fit pid=6103)\u001b[0m Using 17 cont features\n",
      "\u001b[36m(_ray_fit pid=6103)\u001b[0m Automated batch size selection: 512\n",
      "\u001b[36m(_ray_fit pid=6103)\u001b[0m TabularModel(\n",
      "\u001b[36m(_ray_fit pid=6103)\u001b[0m   (embeds): ModuleList(\n",
      "\u001b[36m(_ray_fit pid=6103)\u001b[0m     (0-3): 4 x Embedding(4, 3)\n",
      "\u001b[36m(_ray_fit pid=6103)\u001b[0m   )\n",
      "\u001b[36m(_ray_fit pid=6103)\u001b[0m   (emb_drop): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=6103)\u001b[0m   (bn_cont): BatchNorm1d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "\u001b[36m(_ray_fit pid=6103)\u001b[0m   (layers): Sequential(\n",
      "\u001b[36m(_ray_fit pid=6103)\u001b[0m     (0): LinBnDrop(\n",
      "\u001b[36m(_ray_fit pid=6103)\u001b[0m       (0): Linear(in_features=29, out_features=200, bias=False)\n",
      "\u001b[36m(_ray_fit pid=6103)\u001b[0m       (1): ReLU(inplace=True)\n",
      "\u001b[36m(_ray_fit pid=6103)\u001b[0m       (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "\u001b[36m(_ray_fit pid=6103)\u001b[0m       (3): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=6103)\u001b[0m     )\n",
      "\u001b[36m(_ray_fit pid=6103)\u001b[0m     (1): LinBnDrop(\n",
      "\u001b[36m(_ray_fit pid=6103)\u001b[0m       (0): Linear(in_features=200, out_features=100, bias=False)\n",
      "\u001b[36m(_ray_fit pid=6103)\u001b[0m       (1): ReLU(inplace=True)\n",
      "\u001b[36m(_ray_fit pid=6103)\u001b[0m       (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "\u001b[36m(_ray_fit pid=6103)\u001b[0m       (3): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=6103)\u001b[0m     )\n",
      "\u001b[36m(_ray_fit pid=6103)\u001b[0m     (2): LinBnDrop(\n",
      "\u001b[36m(_ray_fit pid=6103)\u001b[0m       (0): Linear(in_features=100, out_features=1, bias=True)\n",
      "\u001b[36m(_ray_fit pid=6103)\u001b[0m     )\n",
      "\u001b[36m(_ray_fit pid=6103)\u001b[0m   )\n",
      "\u001b[36m(_ray_fit pid=6103)\u001b[0m )\n",
      "\u001b[36m(_ray_fit pid=6103)\u001b[0m Automated epochs selection: training for 30 epoch(s). Estimated time budget use 234.45 / 758.36 sec\n",
      "\u001b[36m(_ray_fit pid=6136)\u001b[0m Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 'auto', 'lr': 0.01, 'epochs': 'auto', 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
      "\u001b[36m(_ray_fit pid=6136)\u001b[0m Using 4/4 categorical features\n",
      "\u001b[36m(_ray_fit pid=6136)\u001b[0m Using 17 cont features\n",
      "\u001b[36m(_ray_fit pid=6136)\u001b[0m Automated batch size selection: 512\n",
      "\u001b[36m(_ray_fit pid=6136)\u001b[0m TabularModel(\n",
      "\u001b[36m(_ray_fit pid=6136)\u001b[0m   (embeds): ModuleList(\n",
      "\u001b[36m(_ray_fit pid=6136)\u001b[0m     (0-3): 4 x Embedding(4, 3)\n",
      "\u001b[36m(_ray_fit pid=6136)\u001b[0m )\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6136)\u001b[0m   (emb_drop): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=6136)\u001b[0m   (bn_cont): BatchNorm1d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "\u001b[36m(_ray_fit pid=6136)\u001b[0m   (layers): Sequential(\n",
      "\u001b[36m(_ray_fit pid=6136)\u001b[0m     (2): LinBnDrop(\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6136)\u001b[0m       (0): Linear(in_features=200, out_features=100, bias=False)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6136)\u001b[0m       (1): ReLU(inplace=True)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6136)\u001b[0m       (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6136)\u001b[0m       (3): Dropout(p=0.1, inplace=False)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6136)\u001b[0m       (0): Linear(in_features=100, out_features=1, bias=True)\n",
      "\u001b[36m(_ray_fit pid=6103)\u001b[0m Better model found at epoch 0 with _rmse value: 0.33933815360069275.\n",
      "\u001b[36m(_ray_fit pid=6136)\u001b[0m Automated epochs selection: training for 30 epoch(s). Estimated time budget use 264.53 / 758.66 sec\n",
      "\u001b[36m(_ray_fit pid=6136)\u001b[0m Better model found at epoch 1 with _rmse value: 0.3381555676460266.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6136)\u001b[0m Better model found at epoch 2 with _rmse value: 0.337489515542984.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6103)\u001b[0m Better model found at epoch 4 with _rmse value: 0.3360154330730438.\n",
      "\u001b[36m(_ray_fit pid=6136)\u001b[0m Better model found at epoch 10 with _rmse value: 0.3367626667022705.\n",
      "\u001b[36m(_ray_fit pid=6136)\u001b[0m Better model found at epoch 17 with _rmse value: 0.336665540933609.\n",
      "\u001b[36m(_ray_fit pid=6136)\u001b[0m Better model found at epoch 20 with _rmse value: 0.3356713056564331.\n",
      "\u001b[36m(_ray_fit pid=6103)\u001b[0m No improvement since epoch 4: early stopping\n",
      "\u001b[36m(_ray_fit pid=6103)\u001b[0m Model validation metrics: 0.3360154330730438\n",
      "\u001b[36m(_ray_fit pid=6103)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/NeuralNetFastAI_BAG_L2/S1F7/model.pkl\n",
      "\u001b[36m(_ray_fit pid=6136)\u001b[0m Better model found at epoch 26 with _rmse value: 0.3356664180755615.\n",
      "\u001b[36m(_ray_fit pid=6136)\u001b[0m Model validation metrics: 0.3356664180755615\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/NeuralNetFastAI_BAG_L2/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/NeuralNetFastAI_BAG_L2/model.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t-0.056\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t1031.55s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t3.61s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t372.6\t = Inference  throughput (rows/s | 57529 batch size)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Fitting model: XGBoost_BAG_L2 ... Training model for up to 2765.91s of the 2765.84s of remaining time.\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tFitting XGBoost_BAG_L2 with 'num_gpus': 2, 'num_cpus': 4\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L2/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=1.14%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=6333)\u001b[0m [0]\tvalidation_0-rmse:0.15141\n",
      "\u001b[36m(_ray_fit pid=6334)\u001b[0m [0]\tvalidation_0-rmse:0.15181\n",
      "\u001b[36m(_ray_fit pid=6333)\u001b[0m [50]\tvalidation_0-rmse:0.05611\n",
      "\u001b[36m(_ray_fit pid=6334)\u001b[0m [50]\tvalidation_0-rmse:0.05591\n",
      "\u001b[36m(_ray_fit pid=6333)\u001b[0m [97]\tvalidation_0-rmse:0.05610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=6333)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [08:55:00] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "\u001b[36m(_ray_fit pid=6333)\u001b[0m Potential solutions:\n",
      "\u001b[36m(_ray_fit pid=6333)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n",
      "\u001b[36m(_ray_fit pid=6333)\u001b[0m - Set the device for booster before call to inplace_predict.\n",
      "\u001b[36m(_ray_fit pid=6333)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=6333)\u001b[0m This warning will only be shown once.\n",
      "\u001b[36m(_ray_fit pid=6333)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=6333)\u001b[0m   warnings.warn(smsg, UserWarning)\n",
      "\u001b[36m(_ray_fit pid=6333)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L2/S1F1/model.pkl\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=6334)\u001b[0m [100]\tvalidation_0-rmse:0.05590\n",
      "\u001b[36m(_ray_fit pid=6334)\u001b[0m [148]\tvalidation_0-rmse:0.05590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=6334)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=6334)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=6402)\u001b[0m [0]\tvalidation_0-rmse:0.15235\n",
      "\u001b[36m(_ray_fit pid=6402)\u001b[0m [50]\tvalidation_0-rmse:0.05609\n",
      "\u001b[36m(_ray_fit pid=6431)\u001b[0m [0]\tvalidation_0-rmse:0.15150\n",
      "\u001b[36m(_ray_fit pid=6402)\u001b[0m [94]\tvalidation_0-rmse:0.05609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=6402)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=6402)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=6402)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [08:55:07] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6402)\u001b[0m Potential solutions:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6402)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6402)\u001b[0m - Set the device for booster before call to inplace_predict.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6402)\u001b[0m This warning will only be shown once.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6402)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6334)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L2/S1F2/model.pkl\n",
      "\u001b[36m(_ray_fit pid=6402)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L2/S1F3/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=6431)\u001b[0m [50]\tvalidation_0-rmse:0.05625\n",
      "\u001b[36m(_ray_fit pid=6431)\u001b[0m [84]\tvalidation_0-rmse:0.05625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=6431)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=6431)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=6470)\u001b[0m [0]\tvalidation_0-rmse:0.15202\n",
      "\u001b[36m(_ray_fit pid=6470)\u001b[0m [50]\tvalidation_0-rmse:0.05587\n",
      "\u001b[36m(_ray_fit pid=6470)\u001b[0m [98]\tvalidation_0-rmse:0.05587\n",
      "\u001b[36m(_ray_fit pid=6487)\u001b[0m [0]\tvalidation_0-rmse:0.15162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=6470)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=6470)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=6470)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [08:55:14] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6470)\u001b[0m Potential solutions:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6470)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6470)\u001b[0m - Set the device for booster before call to inplace_predict.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6470)\u001b[0m This warning will only be shown once.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6470)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6470)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L2/S1F5/model.pkl\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=6487)\u001b[0m [50]\tvalidation_0-rmse:0.05603\n",
      "\u001b[36m(_ray_fit pid=6487)\u001b[0m [82]\tvalidation_0-rmse:0.05603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=6487)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=6487)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=6540)\u001b[0m [0]\tvalidation_0-rmse:0.15171\n",
      "\u001b[36m(_ray_fit pid=6540)\u001b[0m [50]\tvalidation_0-rmse:0.05592\n",
      "\u001b[36m(_ray_fit pid=6540)\u001b[0m [98]\tvalidation_0-rmse:0.05592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=6540)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=6540)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=6540)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [08:55:20] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6540)\u001b[0m Potential solutions:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6540)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6540)\u001b[0m - Set the device for booster before call to inplace_predict.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6540)\u001b[0m This warning will only be shown once.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6540)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6487)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L2/S1F6/model.pkl\n",
      "\u001b[36m(_ray_fit pid=6540)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L2/S1F7/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=6571)\u001b[0m [0]\tvalidation_0-rmse:0.15184\n",
      "\u001b[36m(_ray_fit pid=6571)\u001b[0m [50]\tvalidation_0-rmse:0.05585\n",
      "\u001b[36m(_ray_fit pid=6571)\u001b[0m [100]\tvalidation_0-rmse:0.05585\n",
      "\u001b[36m(_ray_fit pid=6571)\u001b[0m [150]\tvalidation_0-rmse:0.05585\n",
      "\u001b[36m(_ray_fit pid=6571)\u001b[0m [158]\tvalidation_0-rmse:0.05585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=6571)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=6571)\u001b[0m \n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t-0.056\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t25.32s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t1.9s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t376.8\t = Inference  throughput (rows/s | 57529 batch size)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 2737.79s of the 2737.72s of remaining time.\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tFitting NeuralNetTorch_BAG_L2 with 'num_gpus': 2, 'num_cpus': 4\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L2/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=0.80%)\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m Tabular Neural Network treats features as the following types:\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m {\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m     \"continuous\": [\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m         \"LightGBMXT_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m         \"LightGBM_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m         \"RandomForestMSE_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m         \"CatBoost_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m         \"ExtraTreesMSE_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m         \"NeuralNetFastAI_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m         \"XGBoost_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m         \"NeuralNetTorch_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m         \"LightGBMLarge_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m         \"num_lanes\",\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m         \"curvature\",\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m         \"speed_limit\",\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m         \"num_reported_accidents\"\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m     ],\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m     \"skewed\": [],\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m     \"onehot\": [\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m         \"road_type\",\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m         \"lighting\",\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m         \"weather\",\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m         \"time_of_day\"\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m     ],\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m     \"embed\": [],\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m     \"language\": [],\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m     \"bool\": [\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m         \"road_signs_present\",\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m         \"public_road\",\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m         \"holiday\",\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m         \"school_season\"\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m     ]\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m }\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=6571)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [08:55:22] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "\u001b[36m(_ray_fit pid=6571)\u001b[0m Potential solutions:\n",
      "\u001b[36m(_ray_fit pid=6571)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n",
      "\u001b[36m(_ray_fit pid=6571)\u001b[0m - Set the device for booster before call to inplace_predict.\n",
      "\u001b[36m(_ray_fit pid=6571)\u001b[0m This warning will only be shown once.\n",
      "\u001b[36m(_ray_fit pid=6571)\u001b[0m   warnings.warn(smsg, UserWarning)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L2/utils/model_template.pkl\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m         \"LightGBMXT_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m         \"LightGBM_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m         \"RandomForestMSE_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m         \"CatBoost_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m         \"ExtraTreesMSE_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m         \"NeuralNetFastAI_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m         \"XGBoost_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m         \"NeuralNetTorch_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m         \"LightGBMLarge_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m Training data for TabularNeuralNetTorchModel has: 402696 examples, 21 features (21 vector, 0 embedding)\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m Training on GPU (CUDA)\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m Neural network architecture:\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m EmbedNet(\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m   (main_block): Sequential(\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m     (0): Linear(in_features=29, out_features=128, bias=True)\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m     (1): ReLU()\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m     (2): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m     (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m     (4): ReLU()\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m     (5): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m     (6): Linear(in_features=128, out_features=128, bias=True)\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m     (7): ReLU()\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m     (8): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m     (9): Linear(in_features=128, out_features=128, bias=True)\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m     (10): ReLU()\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m     (11): Linear(in_features=128, out_features=1, bias=True)\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m   )\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m )\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m Training tabular neural network for up to 1000 epochs...\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m Epoch 1 (Update 1573).\tTrain loss: 0.0477, Val root_mean_squared_error: -0.0573, Best Epoch: 1\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m Tabular Neural Network treats features as the following types:\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m {\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m     \"continuous\": [\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m         \"num_lanes\",\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m         \"curvature\",\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m         \"speed_limit\",\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m         \"num_reported_accidents\"\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m     ],\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m     \"skewed\": [],\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m     \"onehot\": [\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m         \"road_type\",\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m         \"lighting\",\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m         \"weather\",\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m         \"time_of_day\"\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m     \"embed\": [],\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m     \"language\": [],\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m     \"bool\": [\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m         \"road_signs_present\",\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m         \"public_road\",\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m         \"holiday\",\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m         \"school_season\"\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m     ]\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m }\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m Training data for TabularNeuralNetTorchModel has: 402697 examples, 21 features (21 vector, 0 embedding)\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m Training on GPU (CUDA)\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m Neural network architecture:\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m EmbedNet(\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m   (main_block): Sequential(\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m     (11): Linear(in_features=128, out_features=1, bias=True)\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m     (10): ReLU()\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m     (8): Dropout(p=0.1, inplace=False)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m )\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m Training tabular neural network for up to 1000 epochs...\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m Epoch 3 (Update 4719).\tTrain loss: 0.0444, Val root_mean_squared_error: -0.0574, Best Epoch: 2\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m Epoch 4 (Update 6292).\tTrain loss: 0.0443, Val root_mean_squared_error: -0.0569, Best Epoch: 2\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m Epoch 5 (Update 7865).\tTrain loss: 0.0443, Val root_mean_squared_error: -0.0585, Best Epoch: 1\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m Epoch 6 (Update 9438).\tTrain loss: 0.0442, Val root_mean_squared_error: -0.0573, Best Epoch: 1\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m Epoch 7 (Update 11011).\tTrain loss: 0.0441, Val root_mean_squared_error: -0.0575, Best Epoch: 1\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m Epoch 8 (Update 12584).\tTrain loss: 0.044, Val root_mean_squared_error: -0.0581, Best Epoch: 1\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m Epoch 9 (Update 14157).\tTrain loss: 0.044, Val root_mean_squared_error: -0.0589, Best Epoch: 1\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m Epoch 11 (Update 17303).\tTrain loss: 0.0439, Val root_mean_squared_error: -0.0583, Best Epoch: 2\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m Epoch 12 (Update 18876).\tTrain loss: 0.0439, Val root_mean_squared_error: -0.0602, Best Epoch: 1\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m Epoch 13 (Update 20449).\tTrain loss: 0.0438, Val root_mean_squared_error: -0.0587, Best Epoch: 1\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m Epoch 15 (Update 23595).\tTrain loss: 0.0438, Val root_mean_squared_error: -0.0593, Best Epoch: 2\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m Epoch 16 (Update 25168).\tTrain loss: 0.0438, Val root_mean_squared_error: -0.0604, Best Epoch: 1\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m Epoch 17 (Update 26741).\tTrain loss: 0.0438, Val root_mean_squared_error: -0.0602, Best Epoch: 1\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m Epoch 19 (Update 29887).\tTrain loss: 0.0437, Val root_mean_squared_error: -0.0591, Best Epoch: 2\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m Epoch 20 (Update 31460).\tTrain loss: 0.0437, Val root_mean_squared_error: -0.0619, Best Epoch: 1\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m Best model found on Epoch 1 (Update 1573). Val root_mean_squared_error: -0.05636510252952576\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m Epoch 21 (Update 33033).\tTrain loss: 0.0437, Val root_mean_squared_error: -0.0606, Best Epoch: 1\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6707)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L2/S1F2/model.pkl\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m Tabular Neural Network treats features as the following types:\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m {\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m     \"continuous\": [\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m         \"LightGBMXT_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m         \"LightGBM_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m         \"RandomForestMSE_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m         \"CatBoost_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m         \"ExtraTreesMSE_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m         \"NeuralNetFastAI_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m         \"XGBoost_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m         \"NeuralNetTorch_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m         \"LightGBMLarge_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m         \"num_lanes\",\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m         \"curvature\",\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m         \"speed_limit\",\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m         \"num_reported_accidents\"\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m     ],\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m     \"skewed\": [],\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m     \"onehot\": [\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m         \"road_type\",\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m         \"lighting\",\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m         \"weather\",\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m         \"time_of_day\"\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m     ],\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m     \"embed\": [],\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m     \"language\": [],\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m     \"bool\": [\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m         \"road_signs_present\",\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m         \"public_road\",\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m         \"holiday\",\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m         \"school_season\"\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m     ]\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m }\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m Best model found on Epoch 2 (Update 3146). Val root_mean_squared_error: -0.05672548711299896\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m Epoch 22 (Update 34606).\tTrain loss: 0.0437, Val root_mean_squared_error: -0.06, Best Epoch: 2\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m Training data for TabularNeuralNetTorchModel has: 402697 examples, 21 features (21 vector, 0 embedding)\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m Training on GPU (CUDA)\n",
      "\u001b[36m(_ray_fit pid=6706)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L2/S1F1/model.pkl\n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m         \"LightGBMXT_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m         \"LightGBM_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m         \"RandomForestMSE_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m         \"CatBoost_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m         \"ExtraTreesMSE_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m         \"NeuralNetFastAI_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m         \"XGBoost_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m         \"NeuralNetTorch_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m         \"LightGBMLarge_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m Neural network architecture:\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m EmbedNet(\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m   (main_block): Sequential(\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m     (0): Linear(in_features=29, out_features=128, bias=True)\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m     (1): ReLU()\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m     (2): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m     (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m     (4): ReLU()\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m     (5): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m     (6): Linear(in_features=128, out_features=128, bias=True)\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m     (7): ReLU()\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m     (8): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m     (9): Linear(in_features=128, out_features=128, bias=True)\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m     (10): ReLU()\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m     (11): Linear(in_features=128, out_features=1, bias=True)\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m   )\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m )\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m Training tabular neural network for up to 1000 epochs...\n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m Tabular Neural Network treats features as the following types:\n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m {\n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m     \"continuous\": [\n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m         \"num_lanes\",\n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m         \"curvature\",\n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m         \"speed_limit\",\n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m         \"num_reported_accidents\"\n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m     ],\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m     \"skewed\": [],\n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m     \"onehot\": [\n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m         \"road_type\",\n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m         \"lighting\",\n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m         \"weather\",\n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m         \"time_of_day\"\n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m     \"embed\": [],\n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m     \"language\": [],\n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m     \"bool\": [\n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m         \"road_signs_present\",\n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m         \"public_road\",\n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m         \"holiday\",\n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m         \"school_season\"\n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m     ]\n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m }\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m Epoch 1 (Update 1573).\tTrain loss: 0.0477, Val root_mean_squared_error: -0.0565, Best Epoch: 1\n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m Training data for TabularNeuralNetTorchModel has: 402697 examples, 21 features (21 vector, 0 embedding)\n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m Training on GPU (CUDA)\n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m Neural network architecture:\n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m EmbedNet(\n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m   (main_block): Sequential(\n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m     (11): Linear(in_features=128, out_features=1, bias=True)\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m     (10): ReLU()\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m     (8): Dropout(p=0.1, inplace=False)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m )\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m Training tabular neural network for up to 1000 epochs...\n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m Epoch 2 (Update 3146).\tTrain loss: 0.0446, Val root_mean_squared_error: -0.0568, Best Epoch: 2\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m Epoch 4 (Update 6292).\tTrain loss: 0.0443, Val root_mean_squared_error: -0.0585, Best Epoch: 1\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m Epoch 5 (Update 7865).\tTrain loss: 0.0443, Val root_mean_squared_error: -0.0576, Best Epoch: 2\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m Epoch 7 (Update 11011).\tTrain loss: 0.0441, Val root_mean_squared_error: -0.0617, Best Epoch: 1\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m Epoch 8 (Update 12584).\tTrain loss: 0.044, Val root_mean_squared_error: -0.0578, Best Epoch: 2\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m Epoch 10 (Update 15730).\tTrain loss: 0.0439, Val root_mean_squared_error: -0.06, Best Epoch: 1\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m Epoch 11 (Update 17303).\tTrain loss: 0.0439, Val root_mean_squared_error: -0.0589, Best Epoch: 2\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m Epoch 13 (Update 20449).\tTrain loss: 0.0438, Val root_mean_squared_error: -0.0598, Best Epoch: 1\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m Epoch 14 (Update 22022).\tTrain loss: 0.0438, Val root_mean_squared_error: -0.0595, Best Epoch: 2\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m Epoch 16 (Update 25168).\tTrain loss: 0.0437, Val root_mean_squared_error: -0.0605, Best Epoch: 1\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m Epoch 17 (Update 26741).\tTrain loss: 0.0437, Val root_mean_squared_error: -0.06, Best Epoch: 2\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m Epoch 19 (Update 29887).\tTrain loss: 0.0437, Val root_mean_squared_error: -0.0613, Best Epoch: 1\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m Epoch 20 (Update 31460).\tTrain loss: 0.0437, Val root_mean_squared_error: -0.0599, Best Epoch: 2\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m Best model found on Epoch 1 (Update 1573). Val root_mean_squared_error: -0.056496791541576385\n",
      "\u001b[36m(_ray_fit pid=6801)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L2/S1F3/model.pkl\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m Tabular Neural Network treats features as the following types:\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m {\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m     \"continuous\": [\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m         \"LightGBMXT_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m         \"LightGBM_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m         \"RandomForestMSE_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m         \"CatBoost_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m         \"ExtraTreesMSE_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m         \"NeuralNetFastAI_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m         \"XGBoost_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m         \"NeuralNetTorch_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m         \"LightGBMLarge_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m         \"num_lanes\",\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m         \"curvature\",\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m         \"speed_limit\",\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m         \"num_reported_accidents\"\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m     ],\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m     \"skewed\": [],\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m     \"onehot\": [\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m         \"road_type\",\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m         \"lighting\",\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m         \"weather\",\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m         \"time_of_day\"\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m     ],\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m     \"embed\": [],\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m     \"language\": [],\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m     \"bool\": [\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m         \"road_signs_present\",\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m         \"public_road\",\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m         \"holiday\",\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m         \"school_season\"\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m     ]\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m }\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m Epoch 21 (Update 33033).\tTrain loss: 0.0436, Val root_mean_squared_error: -0.0594, Best Epoch: 2\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m Training data for TabularNeuralNetTorchModel has: 402697 examples, 21 features (21 vector, 0 embedding)\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m Training on GPU (CUDA)\n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m Best model found on Epoch 2 (Update 3146). Val root_mean_squared_error: -0.05684691667556763\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m Neural network architecture:\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m EmbedNet(\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m   (main_block): Sequential(\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m     (0): Linear(in_features=29, out_features=128, bias=True)\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m     (1): ReLU()\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m     (2): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m     (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m     (4): ReLU()\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m     (5): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m     (6): Linear(in_features=128, out_features=128, bias=True)\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m     (7): ReLU()\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m     (8): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m     (9): Linear(in_features=128, out_features=128, bias=True)\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m     (10): ReLU()\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m     (11): Linear(in_features=128, out_features=1, bias=True)\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m   )\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m )\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m Training tabular neural network for up to 1000 epochs...\n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L2/S1F4/model.pkl\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m         \"LightGBMXT_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m         \"LightGBM_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m         \"RandomForestMSE_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m         \"CatBoost_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m         \"ExtraTreesMSE_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m         \"NeuralNetFastAI_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m         \"XGBoost_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m         \"NeuralNetTorch_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m         \"LightGBMLarge_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m Tabular Neural Network treats features as the following types:\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m {\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m     \"continuous\": [\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m         \"num_lanes\",\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m         \"curvature\",\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m         \"speed_limit\",\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m         \"num_reported_accidents\"\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m     ],\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m     \"skewed\": [],\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m     \"onehot\": [\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m         \"road_type\",\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m         \"lighting\",\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m         \"weather\",\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m         \"time_of_day\"\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m     \"embed\": [],\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m     \"language\": [],\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m     \"bool\": [\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m         \"road_signs_present\",\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m         \"public_road\",\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m         \"holiday\",\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m         \"school_season\"\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m     ]\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m }\n",
      "\u001b[36m(_ray_fit pid=6833)\u001b[0m Epoch 22 (Update 34606).\tTrain loss: 0.0437, Val root_mean_squared_error: -0.0599, Best Epoch: 2\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m Epoch 1 (Update 1573).\tTrain loss: 0.0478, Val root_mean_squared_error: -0.0563, Best Epoch: 1\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m Training data for TabularNeuralNetTorchModel has: 402697 examples, 21 features (21 vector, 0 embedding)\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m Training on GPU (CUDA)\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m Neural network architecture:\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m EmbedNet(\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m   (main_block): Sequential(\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m     (0): Linear(in_features=29, out_features=128, bias=True)\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m     (1): ReLU()\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m     (2): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m     (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m     (4): ReLU()\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m     (5): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m     (6): Linear(in_features=128, out_features=128, bias=True)\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m     (7): ReLU()\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m     (8): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m     (9): Linear(in_features=128, out_features=128, bias=True)\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m     (10): ReLU()\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m     (11): Linear(in_features=128, out_features=1, bias=True)\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m   )\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m )\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m Training tabular neural network for up to 1000 epochs...\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m Epoch 2 (Update 3146).\tTrain loss: 0.0447, Val root_mean_squared_error: -0.0564, Best Epoch: 1\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m Epoch 1 (Update 1573).\tTrain loss: 0.0478, Val root_mean_squared_error: -0.0565, Best Epoch: 1\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m Epoch 3 (Update 4719).\tTrain loss: 0.0445, Val root_mean_squared_error: -0.0573, Best Epoch: 1\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m Epoch 3 (Update 4719).\tTrain loss: 0.0445, Val root_mean_squared_error: -0.0565, Best Epoch: 3\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m Epoch 6 (Update 9438).\tTrain loss: 0.0442, Val root_mean_squared_error: -0.057, Best Epoch: 1\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m Epoch 6 (Update 9438).\tTrain loss: 0.0441, Val root_mean_squared_error: -0.0573, Best Epoch: 3\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m Epoch 9 (Update 14157).\tTrain loss: 0.044, Val root_mean_squared_error: -0.0591, Best Epoch: 1\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m Epoch 9 (Update 14157).\tTrain loss: 0.044, Val root_mean_squared_error: -0.0581, Best Epoch: 3\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m Epoch 12 (Update 18876).\tTrain loss: 0.0439, Val root_mean_squared_error: -0.0599, Best Epoch: 1\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m Epoch 12 (Update 18876).\tTrain loss: 0.0438, Val root_mean_squared_error: -0.0606, Best Epoch: 3\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m Epoch 15 (Update 23595).\tTrain loss: 0.0438, Val root_mean_squared_error: -0.0589, Best Epoch: 1\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m Epoch 15 (Update 23595).\tTrain loss: 0.0438, Val root_mean_squared_error: -0.059, Best Epoch: 3\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m Epoch 18 (Update 28314).\tTrain loss: 0.0438, Val root_mean_squared_error: -0.0612, Best Epoch: 1\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m Epoch 18 (Update 28314).\tTrain loss: 0.0437, Val root_mean_squared_error: -0.0594, Best Epoch: 3\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m Best model found on Epoch 1 (Update 1573). Val root_mean_squared_error: -0.05629716441035271\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m Epoch 21 (Update 33033).\tTrain loss: 0.0437, Val root_mean_squared_error: -0.0598, Best Epoch: 1\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6895)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L2/S1F5/model.pkl\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m Tabular Neural Network treats features as the following types:\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m {\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m     \"continuous\": [\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m         \"LightGBMXT_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m         \"LightGBM_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m         \"RandomForestMSE_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m         \"CatBoost_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m         \"ExtraTreesMSE_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m         \"NeuralNetFastAI_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m         \"XGBoost_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m         \"NeuralNetTorch_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m         \"LightGBMLarge_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m         \"num_lanes\",\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m         \"curvature\",\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m         \"speed_limit\",\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m         \"num_reported_accidents\"\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m     ],\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m     \"skewed\": [],\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m     \"onehot\": [\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m         \"road_type\",\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m         \"lighting\",\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m         \"weather\",\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m         \"time_of_day\"\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m     ],\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m     \"embed\": [],\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m     \"language\": [],\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m     \"bool\": [\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m         \"road_signs_present\",\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m         \"public_road\",\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m         \"holiday\",\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m         \"school_season\"\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m     ]\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m }\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m Epoch 20 (Update 31460).\tTrain loss: 0.0437, Val root_mean_squared_error: -0.06, Best Epoch: 3\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m Training data for TabularNeuralNetTorchModel has: 402697 examples, 21 features (21 vector, 0 embedding)\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m Training on GPU (CUDA)\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m Epoch 21 (Update 33033).\tTrain loss: 0.0437, Val root_mean_squared_error: -0.0591, Best Epoch: 3\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m Neural network architecture:\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m EmbedNet(\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m   (main_block): Sequential(\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m     (0): Linear(in_features=29, out_features=128, bias=True)\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m     (1): ReLU()\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m     (2): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m     (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m     (4): ReLU()\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m     (5): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m     (6): Linear(in_features=128, out_features=128, bias=True)\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m     (7): ReLU()\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m     (8): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m     (9): Linear(in_features=128, out_features=128, bias=True)\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m     (10): ReLU()\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m     (11): Linear(in_features=128, out_features=1, bias=True)\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m   )\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m )\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m Training tabular neural network for up to 1000 epochs...\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m Epoch 22 (Update 34606).\tTrain loss: 0.0437, Val root_mean_squared_error: -0.0597, Best Epoch: 3\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m Epoch 1 (Update 1573).\tTrain loss: 0.0478, Val root_mean_squared_error: -0.0569, Best Epoch: 1\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m Epoch 23 (Update 36179).\tTrain loss: 0.0436, Val root_mean_squared_error: -0.0594, Best Epoch: 3\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m Best model found on Epoch 3 (Update 4719). Val root_mean_squared_error: -0.056479841470718384\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L2/S1F6/model.pkl\n",
      "\u001b[36m(_ray_fit pid=6932)\u001b[0m Epoch 24 (Update 37752).\tTrain loss: 0.0436, Val root_mean_squared_error: -0.0601, Best Epoch: 3\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m Tabular Neural Network treats features as the following types:\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m {\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m     \"continuous\": [\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m         \"LightGBMXT_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m         \"LightGBM_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m         \"RandomForestMSE_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m         \"CatBoost_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m         \"ExtraTreesMSE_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m         \"NeuralNetFastAI_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m         \"XGBoost_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m         \"NeuralNetTorch_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m         \"LightGBMLarge_BAG_L1\",\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m         \"num_lanes\",\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m         \"curvature\",\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m         \"speed_limit\",\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m         \"num_reported_accidents\"\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m     ],\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m     \"skewed\": [],\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m     \"onehot\": [\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m         \"road_type\",\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m         \"lighting\",\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m         \"weather\",\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m         \"time_of_day\"\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m     ],\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m     \"embed\": [],\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m     \"language\": [],\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m     \"bool\": [\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m         \"road_signs_present\",\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m         \"public_road\",\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m         \"holiday\",\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m         \"school_season\"\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m     ]\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m }\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m Epoch 4 (Update 6292).\tTrain loss: 0.0443, Val root_mean_squared_error: -0.057, Best Epoch: 2\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m Training data for TabularNeuralNetTorchModel has: 402697 examples, 21 features (21 vector, 0 embedding)\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m Training on GPU (CUDA)\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m Neural network architecture:\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m EmbedNet(\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m   (main_block): Sequential(\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m     (0): Linear(in_features=29, out_features=128, bias=True)\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m     (1): ReLU()\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m     (2): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m     (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m     (4): ReLU()\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m     (5): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m     (6): Linear(in_features=128, out_features=128, bias=True)\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m     (7): ReLU()\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m     (8): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m     (9): Linear(in_features=128, out_features=128, bias=True)\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m     (10): ReLU()\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m     (11): Linear(in_features=128, out_features=1, bias=True)\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m   )\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m )\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m Training tabular neural network for up to 1000 epochs...\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m Epoch 1 (Update 1573).\tTrain loss: 0.0478, Val root_mean_squared_error: -0.0564, Best Epoch: 1\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m Epoch 2 (Update 3146).\tTrain loss: 0.0447, Val root_mean_squared_error: -0.0562, Best Epoch: 2\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m Epoch 8 (Update 12584).\tTrain loss: 0.044, Val root_mean_squared_error: -0.0584, Best Epoch: 2\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m Epoch 5 (Update 7865).\tTrain loss: 0.0442, Val root_mean_squared_error: -0.0578, Best Epoch: 2\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m Epoch 11 (Update 17303).\tTrain loss: 0.0439, Val root_mean_squared_error: -0.0596, Best Epoch: 2\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m Epoch 8 (Update 12584).\tTrain loss: 0.044, Val root_mean_squared_error: -0.0574, Best Epoch: 2\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m Epoch 14 (Update 22022).\tTrain loss: 0.0438, Val root_mean_squared_error: -0.0588, Best Epoch: 2\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m Epoch 11 (Update 17303).\tTrain loss: 0.0439, Val root_mean_squared_error: -0.0587, Best Epoch: 2\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m Epoch 17 (Update 26741).\tTrain loss: 0.0437, Val root_mean_squared_error: -0.0613, Best Epoch: 2\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m Epoch 14 (Update 22022).\tTrain loss: 0.0438, Val root_mean_squared_error: -0.0605, Best Epoch: 2\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m Epoch 20 (Update 31460).\tTrain loss: 0.0437, Val root_mean_squared_error: -0.0594, Best Epoch: 2\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m Epoch 17 (Update 26741).\tTrain loss: 0.0437, Val root_mean_squared_error: -0.06, Best Epoch: 2\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m Best model found on Epoch 2 (Update 3146). Val root_mean_squared_error: -0.05670269578695297\n",
      "\u001b[36m(_ray_fit pid=6990)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L2/S1F7/model.pkl\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m Epoch 19 (Update 29887).\tTrain loss: 0.0437, Val root_mean_squared_error: -0.0599, Best Epoch: 2\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m Epoch 21 (Update 33033).\tTrain loss: 0.0437, Val root_mean_squared_error: -0.0605, Best Epoch: 2\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m Best model found on Epoch 2 (Update 3146). Val root_mean_squared_error: -0.05622806027531624\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L2/S1F8/model.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t-0.0565\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t473.82s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t1.52s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t377.7\t = Inference  throughput (rows/s | 57529 batch size)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 2261.26s of the 2261.19s of remaining time.\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tFitting LightGBMLarge_BAG_L2 with 'num_gpus': 2, 'num_cpus': 4\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L2/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=0.94%)\n",
      "\u001b[36m(_ray_fit pid=7186)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=7186)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'device': 'gpu'}\n",
      "\u001b[36m(_ray_fit pid=7031)\u001b[0m Epoch 22 (Update 34606).\tTrain loss: 0.0437, Val root_mean_squared_error: -0.0616, Best Epoch: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=7186)\u001b[0m [50]\tvalid_set's rmse: 0.0658581\n",
      "\u001b[36m(_ray_fit pid=7186)\u001b[0m [200]\tvalid_set's rmse: 0.0560915\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=7185)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L2/S1F2/model.pkl\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=7185)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=7185)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'device': 'gpu'}\n",
      "\u001b[36m(_ray_fit pid=7268)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=7268)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'device': 'gpu'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=7268)\u001b[0m [50]\tvalid_set's rmse: 0.0658054\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=7268)\u001b[0m [200]\tvalid_set's rmse: 0.056058\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=7268)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L2/S1F3/model.pkl\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=7269)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=7269)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'device': 'gpu'}\n",
      "\u001b[36m(_ray_fit pid=7349)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=7349)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'device': 'gpu'}\n",
      "\u001b[36m(_ray_fit pid=7269)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L2/S1F4/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=7349)\u001b[0m [50]\tvalid_set's rmse: 0.0654571\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=7349)\u001b[0m [200]\tvalid_set's rmse: 0.0558766\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=7349)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L2/S1F5/model.pkl\n",
      "\u001b[36m(_ray_fit pid=7379)\u001b[0m \tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=7379)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'device': 'gpu'}\n",
      "\u001b[36m(_ray_fit pid=7430)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=7430)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'device': 'gpu'}\n",
      "\u001b[36m(_ray_fit pid=7379)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L2/S1F6/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=7430)\u001b[0m [50]\tvalid_set's rmse: 0.0655746\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=7430)\u001b[0m [200]\tvalid_set's rmse: 0.0559116\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=7430)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L2/S1F7/model.pkl\n",
      "\u001b[36m(_ray_fit pid=7460)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=7460)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'device': 'gpu'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=7460)\u001b[0m [350]\tvalid_set's rmse: 0.0558343\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=288)\u001b[0m \t-0.056\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t66.38s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t7.98s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t362.3\t = Inference  throughput (rows/s | 57529 batch size)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/RandomForestMSE_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/trainer.pkl\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/ExtraTreesMSE_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/RandomForestMSE_BAG_L2/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/ExtraTreesMSE_BAG_L2/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/NeuralNetFastAI_BAG_L2/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L2/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L2/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L2/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Model configs that will be trained (in order):\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tWeightedEnsemble_L3: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': False}}\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 500.24s of the 2190.70s of remaining time.\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tFitting WeightedEnsemble_L3 with 'num_gpus': 0, 'num_cpus': 4\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L3/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Ensemble size: 14\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Ensemble weights: \n",
      "\u001b[36m(_dystack pid=288)\u001b[0m [0.         0.         0.         0.         0.         0.\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m  0.         0.         0.         0.         0.         0.14285714\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m  0.         0.5        0.21428571 0.         0.         0.14285714]\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t1.31s\t= Estimated out-of-fold prediction time...\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tEnsemble Weights: {'ExtraTreesMSE_BAG_L2': 0.5, 'NeuralNetFastAI_BAG_L2': 0.214, 'RandomForestMSE_BAG_L2': 0.143, 'LightGBMLarge_BAG_L2': 0.143}\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t-0.0559\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t1.17s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t347.2\t = Inference  throughput (rows/s | 57529 batch size)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m AutoGluon training complete, total runtime = 5906.26s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 347.2 rows/s (57529 batch size)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/utils/data/X.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/utils/data/y.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/model.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tFitting LightGBMXT_BAG_L1_FULL with 'num_gpus': 1, 'num_cpus': 4\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1_FULL/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tFitting 2249 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True, 'device': 'gpu'}\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t26.77s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/model.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tFitting LightGBM_BAG_L1_FULL with 'num_gpus': 1, 'num_cpus': 4\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1_FULL/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1_FULL/utils/model_template.pkl\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tFitting 851 rounds... Hyperparameters: {'learning_rate': 0.05, 'device': 'gpu'}\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t9.94s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/RandomForestMSE_BAG_L1/model.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Saving /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/trainer.pkl\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Fitting model: RandomForestMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t117.5s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t13.93s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t33030.6\t = Inference  throughput (rows/s | 460225 batch size)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/model.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tFitting CatBoost_BAG_L1_FULL with 'num_gpus': 1, 'num_cpus': 4\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1_FULL/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tCatboost model hyperparameters: {'iterations': 1442, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'RMSE', 'thread_count': 4, 'loss_function': 'RMSE', 'task_type': 'GPU'}\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tWarning: Exception caused CatBoost_BAG_L1_FULL to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \t\tcatboost/cuda/cuda_lib/cuda_base.h:281: CUDA error 100: no CUDA-capable device is detected\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2171, in _train_and_save\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2055, in _train_single\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1068, in fit\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 364, in _fit\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m     self._fit_single(\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 643, in _fit_single\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m     model_base.fit(X=X_fit, y=y_fit, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1068, in fit\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 264, in _fit\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m     self.model.fit(X, **fit_final_kwargs)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/catboost/core.py\", line 5873, in fit\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m     return self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline,\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/catboost/core.py\", line 2410, in _fit\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m     self._train(\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/catboost/core.py\", line 1790, in _train\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m     self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m   File \"_catboost.pyx\", line 5023, in _catboost._CatBoost._train\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m   File \"_catboost.pyx\", line 5072, in _catboost._CatBoost._train\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m _catboost.CatBoostError: catboost/cuda/cuda_lib/cuda_base.h:281: CUDA error 100: no CUDA-capable device is detected\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1_FULL/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m WARNING: Refit training failure detected for 'CatBoost_BAG_L1'... Falling back to using first fold to avoid downstream exception.\n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tThis is likely due to an out-of-memory error or other memory related issue. \n",
      "\u001b[36m(_dystack pid=288)\u001b[0m \tPlease create a GitHub issue if this was triggered from a non-memory related problem.\n",
      "Warning: Exception encountered during DyStack sub-fit:\n",
      "\tCannot avoid training failure during refit for 'CatBoost_BAG_L1' by falling back to copying the first fold because it does not exist! (save_bag_folds=False)\n",
      "\tPlease specify `save_bag_folds=True` in the `.fit` call to avoid this exception.\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t5953s\t = DyStack   runtime |\t26447s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/learner.pkl\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/predictor.pkl\n",
      "Beginning AutoGluon training ... Time limit = 26447s\n",
      "AutoGluon will save models to \"/kaggle/working/AutogluonModels/ag-20251001_072554\"\n",
      "Train Data Rows:    517754\n",
      "Train Data Columns: 12\n",
      "Label Column:       accident_risk\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    29812.35 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.03 MB (0.5% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
      "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('bool', 'bool')     : 4 | ['road_signs_present', 'public_road', 'holiday', 'school_season']\n",
      "\t\t\t\t('float64', 'float') : 1 | ['curvature']\n",
      "\t\t\t\t('int64', 'int')     : 3 | ['num_lanes', 'speed_limit', 'num_reported_accidents']\n",
      "\t\t\t\t('object', 'object') : 4 | ['road_type', 'lighting', 'weather', 'time_of_day']\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('bool', [])   : 4 | ['road_signs_present', 'public_road', 'holiday', 'school_season']\n",
      "\t\t\t\t('float', [])  : 1 | ['curvature']\n",
      "\t\t\t\t('int', [])    : 3 | ['num_lanes', 'speed_limit', 'num_reported_accidents']\n",
      "\t\t\t\t('object', []) : 4 | ['road_type', 'lighting', 'weather', 'time_of_day']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', [])     : 1 | ['curvature']\n",
      "\t\t\t\t('int', [])       : 3 | ['num_lanes', 'speed_limit', 'num_reported_accidents']\n",
      "\t\t\t\t('int', ['bool']) : 4 | ['road_signs_present', 'public_road', 'holiday', 'school_season']\n",
      "\t\t\t\t('object', [])    : 4 | ['road_type', 'lighting', 'weather', 'time_of_day']\n",
      "\t\t\t0.2s = Fit runtime\n",
      "\t\t\t12 features in original data used to generate 12 features in processed data.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', [])     : 1 | ['curvature']\n",
      "\t\t\t\t('int', [])       : 3 | ['num_lanes', 'speed_limit', 'num_reported_accidents']\n",
      "\t\t\t\t('int', ['bool']) : 4 | ['road_signs_present', 'public_road', 'holiday', 'school_season']\n",
      "\t\t\t\t('object', [])    : 4 | ['road_type', 'lighting', 'weather', 'time_of_day']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', [])     : 1 | ['curvature']\n",
      "\t\t\t\t('int', [])       : 3 | ['num_lanes', 'speed_limit', 'num_reported_accidents']\n",
      "\t\t\t\t('int', ['bool']) : 4 | ['road_signs_present', 'public_road', 'holiday', 'school_season']\n",
      "\t\t\t\t('object', [])    : 4 | ['road_type', 'lighting', 'weather', 'time_of_day']\n",
      "\t\t\t0.2s = Fit runtime\n",
      "\t\t\t12 features in original data used to generate 12 features in processed data.\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', [])     : 1 | ['curvature']\n",
      "\t\t\t\t('int', [])       : 3 | ['num_lanes', 'speed_limit', 'num_reported_accidents']\n",
      "\t\t\t\t('int', ['bool']) : 4 | ['road_signs_present', 'public_road', 'holiday', 'school_season']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', [])     : 1 | ['curvature']\n",
      "\t\t\t\t('int', [])       : 3 | ['num_lanes', 'speed_limit', 'num_reported_accidents']\n",
      "\t\t\t\t('int', ['bool']) : 4 | ['road_signs_present', 'public_road', 'holiday', 'school_season']\n",
      "\t\t\t0.1s = Fit runtime\n",
      "\t\t\t8 features in original data used to generate 8 features in processed data.\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t\t('category', []) : 4 | ['road_type', 'lighting', 'weather', 'time_of_day']\n",
      "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t\t('category', []) : 4 | ['road_type', 'lighting', 'weather', 'time_of_day']\n",
      "\t\t\t\t0.1s = Fit runtime\n",
      "\t\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('object', []) : 4 | ['road_type', 'lighting', 'weather', 'time_of_day']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('category', []) : 4 | ['road_type', 'lighting', 'weather', 'time_of_day']\n",
      "\t\t\t0.3s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('category', [])  : 4 | ['road_type', 'lighting', 'weather', 'time_of_day']\n",
      "\t\t\t\t('float', [])     : 1 | ['curvature']\n",
      "\t\t\t\t('int', [])       : 3 | ['num_lanes', 'speed_limit', 'num_reported_accidents']\n",
      "\t\t\t\t('int', ['bool']) : 4 | ['road_signs_present', 'public_road', 'holiday', 'school_season']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('category', [])  : 4 | ['road_type', 'lighting', 'weather', 'time_of_day']\n",
      "\t\t\t\t('float', [])     : 1 | ['curvature']\n",
      "\t\t\t\t('int', [])       : 3 | ['num_lanes', 'speed_limit', 'num_reported_accidents']\n",
      "\t\t\t\t('int', ['bool']) : 4 | ['road_signs_present', 'public_road', 'holiday', 'school_season']\n",
      "\t\t\t0.1s = Fit runtime\n",
      "\t\t\t12 features in original data used to generate 12 features in processed data.\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('category', [])  : 4 | ['road_type', 'lighting', 'weather', 'time_of_day']\n",
      "\t\t\t\t('float', [])     : 1 | ['curvature']\n",
      "\t\t\t\t('int', [])       : 3 | ['num_lanes', 'speed_limit', 'num_reported_accidents']\n",
      "\t\t\t\t('int', ['bool']) : 4 | ['road_signs_present', 'public_road', 'holiday', 'school_season']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('category', [])  : 4 | ['road_type', 'lighting', 'weather', 'time_of_day']\n",
      "\t\t\t\t('float', [])     : 1 | ['curvature']\n",
      "\t\t\t\t('int', [])       : 3 | ['num_lanes', 'speed_limit', 'num_reported_accidents']\n",
      "\t\t\t\t('int', ['bool']) : 4 | ['road_signs_present', 'public_road', 'holiday', 'school_season']\n",
      "\t\t\t0.1s = Fit runtime\n",
      "\t\t\t12 features in original data used to generate 12 features in processed data.\n",
      "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
      "\t\t('bool', 'bool')     : 4 | ['road_signs_present', 'public_road', 'holiday', 'school_season']\n",
      "\t\t('float64', 'float') : 1 | ['curvature']\n",
      "\t\t('int64', 'int')     : 3 | ['num_lanes', 'speed_limit', 'num_reported_accidents']\n",
      "\t\t('object', 'object') : 4 | ['road_type', 'lighting', 'weather', 'time_of_day']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('bool', [])   : 4 | ['road_signs_present', 'public_road', 'holiday', 'school_season']\n",
      "\t\t('float', [])  : 1 | ['curvature']\n",
      "\t\t('int', [])    : 3 | ['num_lanes', 'speed_limit', 'num_reported_accidents']\n",
      "\t\t('object', []) : 4 | ['road_type', 'lighting', 'weather', 'time_of_day']\n",
      "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t('category', 'category') : 4 | ['road_type', 'lighting', 'weather', 'time_of_day']\n",
      "\t\t('float64', 'float')     : 1 | ['curvature']\n",
      "\t\t('int64', 'int')         : 3 | ['num_lanes', 'speed_limit', 'num_reported_accidents']\n",
      "\t\t('int8', 'int')          : 4 | ['road_signs_present', 'public_road', 'holiday', 'school_season']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 4 | ['road_type', 'lighting', 'weather', 'time_of_day']\n",
      "\t\t('float', [])     : 1 | ['curvature']\n",
      "\t\t('int', [])       : 3 | ['num_lanes', 'speed_limit', 'num_reported_accidents']\n",
      "\t\t('int', ['bool']) : 4 | ['road_signs_present', 'public_road', 'holiday', 'school_season']\n",
      "\t1.7s = Fit runtime\n",
      "\t12 features in original data used to generate 12 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 19.75 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.85s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/learner.pkl\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/utils/data/X.pkl\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/utils/data/y.pkl\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Model configs that will be trained (in order):\n",
      "\tLightGBMXT_BAG_L1: \t{'extra_trees': True, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}, 'ag_args_ensemble': {'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\tLightGBM_BAG_L1: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}, 'ag_args_ensemble': {'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\tRandomForestMSE_BAG_L1: \t{'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'problem_types': ['regression', 'quantile'], 'name_suffix': 'MSE', 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True, 'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\tCatBoost_BAG_L1: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}, 'ag_args_ensemble': {'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\tExtraTreesMSE_BAG_L1: \t{'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'problem_types': ['regression', 'quantile'], 'name_suffix': 'MSE', 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True, 'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\tNeuralNetFastAI_BAG_L1: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}, 'ag_args_ensemble': {'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\tXGBoost_BAG_L1: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}, 'ag_args_ensemble': {'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\tNeuralNetTorch_BAG_L1: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}, 'ag_args_ensemble': {'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\tLightGBMLarge_BAG_L1: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_ensemble': {'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "Fitting 9 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 17625.52s of the 26444.88s of remaining time.\n",
      "\tFitting LightGBMXT_BAG_L1 with 'num_gpus': 2, 'num_cpus': 4\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=0.45%)\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMXT_BAG_L1/model.pkl\n",
      "\t-0.0564\t = Validation score   (-root_mean_squared_error)\n",
      "\t280.67s\t = Training   runtime\n",
      "\t124.25s\t = Validation runtime\n",
      "\t520.9\t = Inference  throughput (rows/s | 64720 batch size)\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/trainer.pkl\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 17319.90s of the 26139.26s of remaining time.\n",
      "\tFitting LightGBM_BAG_L1 with 'num_gpus': 2, 'num_cpus': 4\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=0.45%)\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBM_BAG_L1/model.pkl\n",
      "\t-0.0561\t = Validation score   (-root_mean_squared_error)\n",
      "\t96.14s\t = Training   runtime\n",
      "\t34.92s\t = Validation runtime\n",
      "\t1853.5\t = Inference  throughput (rows/s | 64720 batch size)\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/trainer.pkl\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 17214.86s of the 26034.23s of remaining time.\n",
      "\tFitting RandomForestMSE_BAG_L1 with 'num_gpus': 1, 'num_cpus': 4\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/RandomForestMSE_BAG_L1/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/RandomForestMSE_BAG_L1/utils/model_template.pkl\n",
      "\t81.34s\t= Estimated out-of-fold prediction time...\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/RandomForestMSE_BAG_L1/utils/oof.pkl\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/RandomForestMSE_BAG_L1/model.pkl\n",
      "\t-0.0565\t = Validation score   (-root_mean_squared_error)\n",
      "\t158.62s\t = Training   runtime\n",
      "\t15.55s\t = Validation runtime\n",
      "\t33289.6\t = Inference  throughput (rows/s | 517754 batch size)\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/trainer.pkl\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 17039.33s of the 25858.69s of remaining time.\n",
      "\tFitting CatBoost_BAG_L1 with 'num_gpus': 2, 'num_cpus': 4\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=1.76%)\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/CatBoost_BAG_L1/model.pkl\n",
      "\t-0.0561\t = Validation score   (-root_mean_squared_error)\n",
      "\t241.09s\t = Training   runtime\n",
      "\t1.28s\t = Validation runtime\n",
      "\t50610.3\t = Inference  throughput (rows/s | 64720 batch size)\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/trainer.pkl\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 16795.88s of the 25615.24s of remaining time.\n",
      "\tFitting ExtraTreesMSE_BAG_L1 with 'num_gpus': 1, 'num_cpus': 4\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/ExtraTreesMSE_BAG_L1/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/ExtraTreesMSE_BAG_L1/utils/model_template.pkl\n",
      "\t82.26s\t= Estimated out-of-fold prediction time...\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/ExtraTreesMSE_BAG_L1/utils/oof.pkl\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/ExtraTreesMSE_BAG_L1/model.pkl\n",
      "\t-0.0562\t = Validation score   (-root_mean_squared_error)\n",
      "\t126.07s\t = Training   runtime\n",
      "\t14.61s\t = Validation runtime\n",
      "\t35426.4\t = Inference  throughput (rows/s | 517754 batch size)\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/trainer.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 16653.89s of the 25473.25s of remaining time.\n",
      "\tFitting NeuralNetFastAI_BAG_L1 with 'num_gpus': 2, 'num_cpus': 4\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=0.75%)\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "\t-0.0565\t = Validation score   (-root_mean_squared_error)\n",
      "\t1150.26s\t = Training   runtime\n",
      "\t3.87s\t = Validation runtime\n",
      "\t16707.9\t = Inference  throughput (rows/s | 64720 batch size)\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/trainer.pkl\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 15501.00s of the 24320.36s of remaining time.\n",
      "\tFitting XGBoost_BAG_L1 with 'num_gpus': 2, 'num_cpus': 4\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=0.61%)\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/XGBoost_BAG_L1/model.pkl\n",
      "\t-0.0561\t = Validation score   (-root_mean_squared_error)\n",
      "\t25.48s\t = Training   runtime\n",
      "\t0.85s\t = Validation runtime\n",
      "\t76281.9\t = Inference  throughput (rows/s | 64720 batch size)\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/trainer.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 15472.84s of the 24292.20s of remaining time.\n",
      "\tFitting NeuralNetTorch_BAG_L1 with 'num_gpus': 2, 'num_cpus': 4\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=0.42%)\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "\t-0.0568\t = Validation score   (-root_mean_squared_error)\n",
      "\t1353.69s\t = Training   runtime\n",
      "\t2.98s\t = Validation runtime\n",
      "\t21730.5\t = Inference  throughput (rows/s | 64720 batch size)\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/trainer.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 14116.39s of the 22935.75s of remaining time.\n",
      "\tFitting LightGBMLarge_BAG_L1 with 'num_gpus': 2, 'num_cpus': 4\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=0.52%)\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "\t-0.056\t = Validation score   (-root_mean_squared_error)\n",
      "\t82.4s\t = Training   runtime\n",
      "\t14.54s\t = Validation runtime\n",
      "\t4452.6\t = Inference  throughput (rows/s | 64720 batch size)\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/trainer.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/RandomForestMSE_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/ExtraTreesMSE_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': False}}\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 1762.55s of the 22848.98s of remaining time.\n",
      "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 4\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Ensemble size: 12\n",
      "Ensemble weights: \n",
      "[0.         0.16666667 0.08333333 0.         0.08333333 0.\n",
      " 0.08333333 0.         0.58333333]\n",
      "\t3.08s\t= Estimated out-of-fold prediction time...\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/WeightedEnsemble_L2/utils/oof.pkl\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/WeightedEnsemble_L2/model.pkl\n",
      "\tEnsemble Weights: {'LightGBMLarge_BAG_L1': 0.583, 'LightGBM_BAG_L1': 0.167, 'RandomForestMSE_BAG_L1': 0.083, 'ExtraTreesMSE_BAG_L1': 0.083, 'XGBoost_BAG_L1': 0.083}\n",
      "\t-0.056\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.8s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "\t1196.9\t = Inference  throughput (rows/s | 64720 batch size)\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/trainer.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tLightGBMXT_BAG_L2: \t{'extra_trees': True, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}, 'ag_args_ensemble': {'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\tLightGBM_BAG_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}, 'ag_args_ensemble': {'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\tRandomForestMSE_BAG_L2: \t{'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'problem_types': ['regression', 'quantile'], 'name_suffix': 'MSE', 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True, 'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\tCatBoost_BAG_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}, 'ag_args_ensemble': {'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\tExtraTreesMSE_BAG_L2: \t{'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'problem_types': ['regression', 'quantile'], 'name_suffix': 'MSE', 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True, 'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\tNeuralNetFastAI_BAG_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}, 'ag_args_ensemble': {'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\tXGBoost_BAG_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}, 'ag_args_ensemble': {'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\tNeuralNetTorch_BAG_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}, 'ag_args_ensemble': {'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\tLightGBMLarge_BAG_L2: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_ensemble': {'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "Fitting 9 L2 models, fit_strategy=\"sequential\" ...\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/RandomForestMSE_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/ExtraTreesMSE_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 22848.11s of the 22848.04s of remaining time.\n",
      "\tFitting LightGBMXT_BAG_L2 with 'num_gpus': 2, 'num_cpus': 4\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=0.83%)\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMXT_BAG_L2/model.pkl\n",
      "\t-0.0561\t = Validation score   (-root_mean_squared_error)\n",
      "\t105.33s\t = Training   runtime\n",
      "\t33.73s\t = Validation runtime\n",
      "\t293.9\t = Inference  throughput (rows/s | 64720 batch size)\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/trainer.pkl\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 22738.57s of the 22738.50s of remaining time.\n",
      "\tFitting LightGBM_BAG_L2 with 'num_gpus': 2, 'num_cpus': 4\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=0.84%)\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBM_BAG_L2/utils/oof.pkl\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBM_BAG_L2/model.pkl\n",
      "\t-0.056\t = Validation score   (-root_mean_squared_error)\n",
      "\t47.37s\t = Training   runtime\n",
      "\t6.16s\t = Validation runtime\n",
      "\t336.0\t = Inference  throughput (rows/s | 64720 batch size)\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/trainer.pkl\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 22687.89s of the 22687.82s of remaining time.\n",
      "\tFitting RandomForestMSE_BAG_L2 with 'num_gpus': 1, 'num_cpus': 4\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/RandomForestMSE_BAG_L2/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/RandomForestMSE_BAG_L2/utils/model_template.pkl\n",
      "\t83.01s\t= Estimated out-of-fold prediction time...\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/RandomForestMSE_BAG_L2/utils/oof.pkl\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/RandomForestMSE_BAG_L2/model.pkl\n",
      "\t-0.056\t = Validation score   (-root_mean_squared_error)\n",
      "\t916.51s\t = Training   runtime\n",
      "\t14.47s\t = Validation runtime\n",
      "\t343.8\t = Inference  throughput (rows/s | 64720 batch size)\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/trainer.pkl\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 21756.03s of the 21755.97s of remaining time.\n",
      "\tFitting CatBoost_BAG_L2 with 'num_gpus': 2, 'num_cpus': 4\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/CatBoost_BAG_L2/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/CatBoost_BAG_L2/utils/model_template.pkl\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=2.19%)\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/CatBoost_BAG_L2/utils/oof.pkl\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/CatBoost_BAG_L2/model.pkl\n",
      "\t-0.056\t = Validation score   (-root_mean_squared_error)\n",
      "\t106.87s\t = Training   runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "\t346.0\t = Inference  throughput (rows/s | 64720 batch size)\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/trainer.pkl\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 21646.52s of the 21646.46s of remaining time.\n",
      "\tFitting ExtraTreesMSE_BAG_L2 with 'num_gpus': 1, 'num_cpus': 4\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/ExtraTreesMSE_BAG_L2/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/ExtraTreesMSE_BAG_L2/utils/model_template.pkl\n",
      "\t79.98s\t= Estimated out-of-fold prediction time...\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/ExtraTreesMSE_BAG_L2/utils/oof.pkl\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/ExtraTreesMSE_BAG_L2/model.pkl\n",
      "\t-0.0559\t = Validation score   (-root_mean_squared_error)\n",
      "\t207.53s\t = Training   runtime\n",
      "\t15.48s\t = Validation runtime\n",
      "\t343.5\t = Inference  throughput (rows/s | 64720 batch size)\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/trainer.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 21422.27s of the 21422.20s of remaining time.\n",
      "\tFitting NeuralNetFastAI_BAG_L2 with 'num_gpus': 2, 'num_cpus': 4\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetFastAI_BAG_L2/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetFastAI_BAG_L2/utils/model_template.pkl\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=1.44%)\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetFastAI_BAG_L2/utils/oof.pkl\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetFastAI_BAG_L2/model.pkl\n",
      "\t-0.056\t = Validation score   (-root_mean_squared_error)\n",
      "\t1156.33s\t = Training   runtime\n",
      "\t3.92s\t = Validation runtime\n",
      "\t340.0\t = Inference  throughput (rows/s | 64720 batch size)\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/trainer.pkl\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 20262.91s of the 20262.85s of remaining time.\n",
      "\tFitting XGBoost_BAG_L2 with 'num_gpus': 2, 'num_cpus': 4\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/XGBoost_BAG_L2/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/XGBoost_BAG_L2/utils/model_template.pkl\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=1.15%)\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/XGBoost_BAG_L2/utils/oof.pkl\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/XGBoost_BAG_L2/model.pkl\n",
      "\t-0.056\t = Validation score   (-root_mean_squared_error)\n",
      "\t26.1s\t = Training   runtime\n",
      "\t1.24s\t = Validation runtime\n",
      "\t344.8\t = Inference  throughput (rows/s | 64720 batch size)\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/trainer.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 20233.93s of the 20233.86s of remaining time.\n",
      "\tFitting NeuralNetTorch_BAG_L2 with 'num_gpus': 2, 'num_cpus': 4\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetTorch_BAG_L2/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetTorch_BAG_L2/utils/model_template.pkl\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=0.80%)\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetTorch_BAG_L2/utils/oof.pkl\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetTorch_BAG_L2/model.pkl\n",
      "\t-0.0566\t = Validation score   (-root_mean_squared_error)\n",
      "\t610.52s\t = Training   runtime\n",
      "\t3.22s\t = Validation runtime\n",
      "\t341.2\t = Inference  throughput (rows/s | 64720 batch size)\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/trainer.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 19620.50s of the 19620.44s of remaining time.\n",
      "\tFitting LightGBMLarge_BAG_L2 with 'num_gpus': 2, 'num_cpus': 4\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMLarge_BAG_L2/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMLarge_BAG_L2/utils/model_template.pkl\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=0.94%)\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMLarge_BAG_L2/utils/oof.pkl\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMLarge_BAG_L2/model.pkl\n",
      "\t-0.056\t = Validation score   (-root_mean_squared_error)\n",
      "\t75.66s\t = Training   runtime\n",
      "\t10.53s\t = Validation runtime\n",
      "\t328.5\t = Inference  throughput (rows/s | 64720 batch size)\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/trainer.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/RandomForestMSE_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/ExtraTreesMSE_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBM_BAG_L2/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/RandomForestMSE_BAG_L2/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/CatBoost_BAG_L2/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/ExtraTreesMSE_BAG_L2/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetFastAI_BAG_L2/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/XGBoost_BAG_L2/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetTorch_BAG_L2/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMLarge_BAG_L2/utils/oof.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L3: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': False}}\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 2284.81s of the 19540.84s of remaining time.\n",
      "\tFitting WeightedEnsemble_L3 with 'num_gpus': 0, 'num_cpus': 4\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/WeightedEnsemble_L3/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/WeightedEnsemble_L3/utils/model_template.pkl\n",
      "Ensemble size: 5\n",
      "Ensemble weights: \n",
      "[0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.6 0.2 0.  0.  0. ]\n",
      "\t1.38s\t= Estimated out-of-fold prediction time...\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/WeightedEnsemble_L3/utils/oof.pkl\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/WeightedEnsemble_L3/model.pkl\n",
      "\tEnsemble Weights: {'ExtraTreesMSE_BAG_L2': 0.6, 'RandomForestMSE_BAG_L2': 0.2, 'NeuralNetFastAI_BAG_L2': 0.2}\n",
      "\t-0.0559\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.23s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "\t333.4\t = Inference  throughput (rows/s | 64720 batch size)\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/trainer.pkl\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/trainer.pkl\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/trainer.pkl\n",
      "AutoGluon training complete, total runtime = 6907.23s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 333.4 rows/s (64720 batch size)\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/trainer.pkl\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/utils/data/X.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/utils/data/y.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\tFitting LightGBMXT_BAG_L1_FULL with 'num_gpus': 1, 'num_cpus': 4\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMXT_BAG_L1_FULL/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMXT_BAG_L1_FULL/utils/model_template.pkl\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tFitting 2475 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True, 'device': 'gpu'}\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMXT_BAG_L1_FULL/model.pkl\n",
      "\t26.56s\t = Training   runtime\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/trainer.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBM_BAG_L1/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\tFitting LightGBM_BAG_L1_FULL with 'num_gpus': 1, 'num_cpus': 4\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBM_BAG_L1_FULL/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBM_BAG_L1_FULL/utils/model_template.pkl\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tFitting 888 rounds... Hyperparameters: {'learning_rate': 0.05, 'device': 'gpu'}\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBM_BAG_L1_FULL/model.pkl\n",
      "\t9.45s\t = Training   runtime\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/trainer.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/RandomForestMSE_BAG_L1/model.pkl\n",
      "Fitting model: RandomForestMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t158.62s\t = Training   runtime\n",
      "\t15.55s\t = Validation runtime\n",
      "\t33289.6\t = Inference  throughput (rows/s | 517754 batch size)\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/RandomForestMSE_BAG_L1_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/CatBoost_BAG_L1/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\tFitting CatBoost_BAG_L1_FULL with 'num_gpus': 1, 'num_cpus': 4\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/CatBoost_BAG_L1_FULL/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/CatBoost_BAG_L1_FULL/utils/model_template.pkl\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tCatboost model hyperparameters: {'iterations': 1792, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'RMSE', 'thread_count': 4, 'loss_function': 'RMSE', 'task_type': 'GPU'}\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.1597595\ttotal: 43.4ms\tremaining: 1m 17s\n",
      "20:\tlearn: 0.0805934\ttotal: 614ms\tremaining: 51.8s\n",
      "40:\tlearn: 0.0610420\ttotal: 1.1s\tremaining: 47s\n",
      "60:\tlearn: 0.0575291\ttotal: 1.58s\tremaining: 44.8s\n",
      "80:\tlearn: 0.0568815\ttotal: 2.05s\tremaining: 43.3s\n",
      "100:\tlearn: 0.0566662\ttotal: 2.51s\tremaining: 42.1s\n",
      "120:\tlearn: 0.0565563\ttotal: 2.98s\tremaining: 41.2s\n",
      "140:\tlearn: 0.0564893\ttotal: 3.44s\tremaining: 40.3s\n",
      "160:\tlearn: 0.0564422\ttotal: 3.91s\tremaining: 39.6s\n",
      "180:\tlearn: 0.0564081\ttotal: 4.37s\tremaining: 38.9s\n",
      "200:\tlearn: 0.0563805\ttotal: 4.85s\tremaining: 38.4s\n",
      "220:\tlearn: 0.0563529\ttotal: 5.32s\tremaining: 37.8s\n",
      "240:\tlearn: 0.0563254\ttotal: 5.81s\tremaining: 37.4s\n",
      "260:\tlearn: 0.0563038\ttotal: 6.28s\tremaining: 36.8s\n",
      "280:\tlearn: 0.0562820\ttotal: 6.76s\tremaining: 36.4s\n",
      "300:\tlearn: 0.0562618\ttotal: 7.24s\tremaining: 35.8s\n",
      "320:\tlearn: 0.0562441\ttotal: 7.71s\tremaining: 35.3s\n",
      "340:\tlearn: 0.0562259\ttotal: 8.16s\tremaining: 34.7s\n",
      "360:\tlearn: 0.0562086\ttotal: 8.62s\tremaining: 34.2s\n",
      "380:\tlearn: 0.0561944\ttotal: 9.09s\tremaining: 33.7s\n",
      "400:\tlearn: 0.0561822\ttotal: 9.58s\tremaining: 33.2s\n",
      "420:\tlearn: 0.0561692\ttotal: 10.1s\tremaining: 32.8s\n",
      "440:\tlearn: 0.0561536\ttotal: 10.5s\tremaining: 32.2s\n",
      "460:\tlearn: 0.0561430\ttotal: 11s\tremaining: 31.8s\n",
      "480:\tlearn: 0.0561316\ttotal: 11.5s\tremaining: 31.2s\n",
      "500:\tlearn: 0.0561203\ttotal: 11.9s\tremaining: 30.7s\n",
      "520:\tlearn: 0.0561081\ttotal: 12.4s\tremaining: 30.2s\n",
      "540:\tlearn: 0.0560995\ttotal: 12.9s\tremaining: 29.7s\n",
      "560:\tlearn: 0.0560884\ttotal: 13.3s\tremaining: 29.3s\n",
      "580:\tlearn: 0.0560750\ttotal: 13.8s\tremaining: 28.8s\n",
      "600:\tlearn: 0.0560646\ttotal: 14.3s\tremaining: 28.3s\n",
      "620:\tlearn: 0.0560543\ttotal: 14.8s\tremaining: 27.8s\n",
      "640:\tlearn: 0.0560452\ttotal: 15.2s\tremaining: 27.4s\n",
      "660:\tlearn: 0.0560395\ttotal: 15.7s\tremaining: 26.9s\n",
      "680:\tlearn: 0.0560294\ttotal: 16.2s\tremaining: 26.5s\n",
      "700:\tlearn: 0.0560218\ttotal: 16.7s\tremaining: 26s\n",
      "720:\tlearn: 0.0560134\ttotal: 17.2s\tremaining: 25.5s\n",
      "740:\tlearn: 0.0560061\ttotal: 17.7s\tremaining: 25.2s\n",
      "760:\tlearn: 0.0559963\ttotal: 18.4s\tremaining: 25s\n",
      "780:\tlearn: 0.0559886\ttotal: 18.9s\tremaining: 24.5s\n",
      "800:\tlearn: 0.0559811\ttotal: 19.4s\tremaining: 24s\n",
      "820:\tlearn: 0.0559721\ttotal: 19.9s\tremaining: 23.5s\n",
      "840:\tlearn: 0.0559645\ttotal: 20.3s\tremaining: 23s\n",
      "860:\tlearn: 0.0559581\ttotal: 20.8s\tremaining: 22.5s\n",
      "880:\tlearn: 0.0559516\ttotal: 21.3s\tremaining: 22s\n",
      "900:\tlearn: 0.0559451\ttotal: 21.7s\tremaining: 21.5s\n",
      "920:\tlearn: 0.0559392\ttotal: 22.2s\tremaining: 21s\n",
      "940:\tlearn: 0.0559313\ttotal: 22.7s\tremaining: 20.5s\n",
      "960:\tlearn: 0.0559253\ttotal: 23.2s\tremaining: 20.1s\n",
      "980:\tlearn: 0.0559201\ttotal: 23.7s\tremaining: 19.6s\n",
      "1000:\tlearn: 0.0559132\ttotal: 24.2s\tremaining: 19.1s\n",
      "1020:\tlearn: 0.0559062\ttotal: 24.7s\tremaining: 18.6s\n",
      "1040:\tlearn: 0.0558996\ttotal: 25.1s\tremaining: 18.1s\n",
      "1060:\tlearn: 0.0558940\ttotal: 25.6s\tremaining: 17.7s\n",
      "1080:\tlearn: 0.0558878\ttotal: 26.1s\tremaining: 17.2s\n",
      "1100:\tlearn: 0.0558834\ttotal: 26.6s\tremaining: 16.7s\n",
      "1120:\tlearn: 0.0558774\ttotal: 27s\tremaining: 16.2s\n",
      "1140:\tlearn: 0.0558701\ttotal: 27.5s\tremaining: 15.7s\n",
      "1160:\tlearn: 0.0558657\ttotal: 28s\tremaining: 15.2s\n",
      "1180:\tlearn: 0.0558604\ttotal: 28.4s\tremaining: 14.7s\n",
      "1200:\tlearn: 0.0558549\ttotal: 28.9s\tremaining: 14.2s\n",
      "1220:\tlearn: 0.0558501\ttotal: 29.4s\tremaining: 13.7s\n",
      "1240:\tlearn: 0.0558454\ttotal: 29.8s\tremaining: 13.2s\n",
      "1260:\tlearn: 0.0558412\ttotal: 30.3s\tremaining: 12.8s\n",
      "1280:\tlearn: 0.0558366\ttotal: 30.8s\tremaining: 12.3s\n",
      "1300:\tlearn: 0.0558306\ttotal: 31.2s\tremaining: 11.8s\n",
      "1320:\tlearn: 0.0558237\ttotal: 31.7s\tremaining: 11.3s\n",
      "1340:\tlearn: 0.0558190\ttotal: 32.2s\tremaining: 10.8s\n",
      "1360:\tlearn: 0.0558135\ttotal: 32.6s\tremaining: 10.3s\n",
      "1380:\tlearn: 0.0558071\ttotal: 33.1s\tremaining: 9.84s\n",
      "1400:\tlearn: 0.0558023\ttotal: 33.5s\tremaining: 9.36s\n",
      "1420:\tlearn: 0.0557984\ttotal: 34s\tremaining: 8.88s\n",
      "1440:\tlearn: 0.0557929\ttotal: 34.5s\tremaining: 8.39s\n",
      "1460:\tlearn: 0.0557880\ttotal: 34.9s\tremaining: 7.91s\n",
      "1480:\tlearn: 0.0557827\ttotal: 35.4s\tremaining: 7.44s\n",
      "1500:\tlearn: 0.0557777\ttotal: 35.9s\tremaining: 6.96s\n",
      "1520:\tlearn: 0.0557735\ttotal: 36.4s\tremaining: 6.48s\n",
      "1540:\tlearn: 0.0557685\ttotal: 36.9s\tremaining: 6s\n",
      "1560:\tlearn: 0.0557637\ttotal: 37.4s\tremaining: 5.53s\n",
      "1580:\tlearn: 0.0557583\ttotal: 37.8s\tremaining: 5.05s\n",
      "1600:\tlearn: 0.0557531\ttotal: 38.3s\tremaining: 4.57s\n",
      "1620:\tlearn: 0.0557491\ttotal: 38.8s\tremaining: 4.09s\n",
      "1640:\tlearn: 0.0557436\ttotal: 39.2s\tremaining: 3.61s\n",
      "1660:\tlearn: 0.0557376\ttotal: 39.7s\tremaining: 3.13s\n",
      "1680:\tlearn: 0.0557313\ttotal: 40.2s\tremaining: 2.65s\n",
      "1700:\tlearn: 0.0557275\ttotal: 40.6s\tremaining: 2.17s\n",
      "1720:\tlearn: 0.0557228\ttotal: 41.1s\tremaining: 1.7s\n",
      "1740:\tlearn: 0.0557183\ttotal: 41.6s\tremaining: 1.22s\n",
      "1760:\tlearn: 0.0557137\ttotal: 42s\tremaining: 740ms\n",
      "1780:\tlearn: 0.0557101\ttotal: 42.5s\tremaining: 262ms\n",
      "1791:\tlearn: 0.0557078\ttotal: 42.8s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/CatBoost_BAG_L1_FULL/model.pkl\n",
      "\t44.28s\t = Training   runtime\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/trainer.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/ExtraTreesMSE_BAG_L1/model.pkl\n",
      "Fitting model: ExtraTreesMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t126.07s\t = Training   runtime\n",
      "\t14.61s\t = Validation runtime\n",
      "\t35426.4\t = Inference  throughput (rows/s | 517754 batch size)\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/ExtraTreesMSE_BAG_L1_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L1_FULL ...\n",
      "\tFitting NeuralNetFastAI_BAG_L1_FULL with 'num_gpus': 1, 'num_cpus': 4\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetFastAI_BAG_L1_FULL/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetFastAI_BAG_L1_FULL/utils/model_template.pkl\n",
      "Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 'auto', 'lr': 0.01, 'epochs': 30, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0, 'best_epoch': 27}...\n",
      "Using 4/4 categorical features\n",
      "Using 8 cont features\n",
      "Automated batch size selection: 512\n",
      "TabularModel(\n",
      "  (embeds): ModuleList(\n",
      "    (0-3): 4 x Embedding(4, 3)\n",
      "  )\n",
      "  (emb_drop): Dropout(p=0.1, inplace=False)\n",
      "  (bn_cont): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layers): Sequential(\n",
      "    (0): LinBnDrop(\n",
      "      (0): Linear(in_features=20, out_features=200, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): LinBnDrop(\n",
      "      (0): Linear(in_features=200, out_features=100, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (2): LinBnDrop(\n",
      "      (0): Linear(in_features=100, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Better model found at epoch 0 with _rmse value: 0.10906466096639633.\n",
      "Better model found at epoch 10 with _rmse value: 0.07715481519699097.\n",
      "Saving model model at the best epoch learned earlier - 27.\n",
      "\tStopping at the best epoch learned earlier - 27.\n",
      "Model validation metrics: 0.09243985265493393\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetFastAI_BAG_L1_FULL/model.pkl\n",
      "\t240.67s\t = Training   runtime\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/trainer.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/XGBoost_BAG_L1/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\tFitting XGBoost_BAG_L1_FULL with 'num_gpus': 1, 'num_cpus': 4\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/XGBoost_BAG_L1_FULL/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/XGBoost_BAG_L1_FULL/utils/model_template.pkl\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/XGBoost_BAG_L1_FULL/model.pkl\n",
      "\t4.17s\t = Training   runtime\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/trainer.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_BAG_L1_FULL ...\n",
      "\tFitting NeuralNetTorch_BAG_L1_FULL with 'num_gpus': 1, 'num_cpus': 4\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetTorch_BAG_L1_FULL/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetTorch_BAG_L1_FULL/utils/model_template.pkl\n",
      "Tabular Neural Network treats features as the following types:\n",
      "{\n",
      "    \"continuous\": [\n",
      "        \"num_lanes\",\n",
      "        \"curvature\",\n",
      "        \"speed_limit\",\n",
      "        \"num_reported_accidents\"\n",
      "    ],\n",
      "    \"skewed\": [],\n",
      "    \"onehot\": [\n",
      "        \"road_type\",\n",
      "        \"lighting\",\n",
      "        \"weather\",\n",
      "        \"time_of_day\"\n",
      "    ],\n",
      "    \"embed\": [],\n",
      "    \"language\": [],\n",
      "    \"bool\": [\n",
      "        \"road_signs_present\",\n",
      "        \"public_road\",\n",
      "        \"holiday\",\n",
      "        \"school_season\"\n",
      "    ]\n",
      "}\n",
      "\n",
      "\n",
      "Training data for TabularNeuralNetTorchModel has: 517754 examples, 12 features (12 vector, 0 embedding)\n",
      "Training on GPU (CUDA)\n",
      "Neural network architecture:\n",
      "EmbedNet(\n",
      "  (main_block): Sequential(\n",
      "    (0): Linear(in_features=20, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (10): ReLU()\n",
      "    (11): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Training tabular neural network for up to 24 epochs...\n",
      "Best model found on Epoch 0 (Update 0).\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetTorch_BAG_L1_FULL/model.pkl\n",
      "\t130.86s\t = Training   runtime\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/trainer.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
      "\tFitting LightGBMLarge_BAG_L1_FULL with 'num_gpus': 1, 'num_cpus': 4\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMLarge_BAG_L1_FULL/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMLarge_BAG_L1_FULL/utils/model_template.pkl\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tFitting 278 rounds... Hyperparameters: {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'device': 'gpu'}\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMLarge_BAG_L1_FULL/model.pkl\n",
      "\t9.08s\t = Training   runtime\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/trainer.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/WeightedEnsemble_L2/model.pkl\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'LightGBMLarge_BAG_L1': 0.583, 'LightGBM_BAG_L1': 0.167, 'RandomForestMSE_BAG_L1': 0.083, 'ExtraTreesMSE_BAG_L1': 0.083, 'XGBoost_BAG_L1': 0.083}\n",
      "\t0.8s\t = Training   runtime\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/WeightedEnsemble_L2_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMXT_BAG_L2/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/RandomForestMSE_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/ExtraTreesMSE_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\tFitting LightGBMXT_BAG_L2_FULL with 'num_gpus': 1, 'num_cpus': 4\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMXT_BAG_L2_FULL/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMXT_BAG_L2_FULL/utils/model_template.pkl\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tFitting 792 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True, 'device': 'gpu'}\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMXT_BAG_L2_FULL/model.pkl\n",
      "\t9.69s\t = Training   runtime\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/trainer.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBM_BAG_L2/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/RandomForestMSE_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/ExtraTreesMSE_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\tFitting LightGBM_BAG_L2_FULL with 'num_gpus': 1, 'num_cpus': 4\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBM_BAG_L2_FULL/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBM_BAG_L2_FULL/utils/model_template.pkl\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tFitting 226 rounds... Hyperparameters: {'learning_rate': 0.05, 'device': 'gpu'}\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBM_BAG_L2_FULL/model.pkl\n",
      "\t4.02s\t = Training   runtime\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/trainer.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/RandomForestMSE_BAG_L2/model.pkl\n",
      "Fitting model: RandomForestMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t916.51s\t = Training   runtime\n",
      "\t14.47s\t = Validation runtime\n",
      "\t343.8\t = Inference  throughput (rows/s | 64720 batch size)\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/RandomForestMSE_BAG_L2_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/CatBoost_BAG_L2/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/CatBoost_BAG_L2/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/CatBoost_BAG_L2/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/CatBoost_BAG_L2/utils/model_template.pkl\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/RandomForestMSE_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/ExtraTreesMSE_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Fitting model: CatBoost_BAG_L2_FULL ...\n",
      "\tFitting CatBoost_BAG_L2_FULL with 'num_gpus': 1, 'num_cpus': 4\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/CatBoost_BAG_L2_FULL/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/CatBoost_BAG_L2_FULL/utils/model_template.pkl\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tCatboost model hyperparameters: {'iterations': 594, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'RMSE', 'thread_count': 4, 'loss_function': 'RMSE', 'task_type': 'GPU'}\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.1593987\ttotal: 31.7ms\tremaining: 18.8s\n",
      "20:\tlearn: 0.0795849\ttotal: 571ms\tremaining: 15.6s\n",
      "40:\tlearn: 0.0600756\ttotal: 1.03s\tremaining: 13.9s\n",
      "60:\tlearn: 0.0566493\ttotal: 1.48s\tremaining: 12.9s\n",
      "80:\tlearn: 0.0561185\ttotal: 1.94s\tremaining: 12.3s\n",
      "100:\tlearn: 0.0560257\ttotal: 2.39s\tremaining: 11.7s\n",
      "120:\tlearn: 0.0559966\ttotal: 2.85s\tremaining: 11.1s\n",
      "140:\tlearn: 0.0559765\ttotal: 3.31s\tremaining: 10.6s\n",
      "160:\tlearn: 0.0559581\ttotal: 3.78s\tremaining: 10.2s\n",
      "180:\tlearn: 0.0559468\ttotal: 4.26s\tremaining: 9.71s\n",
      "200:\tlearn: 0.0559343\ttotal: 4.74s\tremaining: 9.26s\n",
      "220:\tlearn: 0.0559245\ttotal: 5.2s\tremaining: 8.78s\n",
      "240:\tlearn: 0.0559151\ttotal: 5.67s\tremaining: 8.31s\n",
      "260:\tlearn: 0.0559055\ttotal: 6.13s\tremaining: 7.82s\n",
      "280:\tlearn: 0.0558943\ttotal: 6.59s\tremaining: 7.34s\n",
      "300:\tlearn: 0.0558831\ttotal: 7.05s\tremaining: 6.87s\n",
      "320:\tlearn: 0.0558734\ttotal: 7.51s\tremaining: 6.39s\n",
      "340:\tlearn: 0.0558622\ttotal: 7.98s\tremaining: 5.92s\n",
      "360:\tlearn: 0.0558530\ttotal: 8.44s\tremaining: 5.44s\n",
      "380:\tlearn: 0.0558439\ttotal: 8.94s\tremaining: 5s\n",
      "400:\tlearn: 0.0558360\ttotal: 9.41s\tremaining: 4.53s\n",
      "420:\tlearn: 0.0558263\ttotal: 9.87s\tremaining: 4.05s\n",
      "440:\tlearn: 0.0558178\ttotal: 10.3s\tremaining: 3.58s\n",
      "460:\tlearn: 0.0558099\ttotal: 10.8s\tremaining: 3.11s\n",
      "480:\tlearn: 0.0558023\ttotal: 11.2s\tremaining: 2.64s\n",
      "500:\tlearn: 0.0557943\ttotal: 11.7s\tremaining: 2.17s\n",
      "520:\tlearn: 0.0557859\ttotal: 12.2s\tremaining: 1.71s\n",
      "540:\tlearn: 0.0557793\ttotal: 12.6s\tremaining: 1.24s\n",
      "560:\tlearn: 0.0557716\ttotal: 13.1s\tremaining: 771ms\n",
      "580:\tlearn: 0.0557636\ttotal: 13.6s\tremaining: 303ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/CatBoost_BAG_L2_FULL/model.pkl\n",
      "\t15.24s\t = Training   runtime\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/trainer.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/ExtraTreesMSE_BAG_L2/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "593:\tlearn: 0.0557591\ttotal: 13.9s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: ExtraTreesMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t207.53s\t = Training   runtime\n",
      "\t15.48s\t = Validation runtime\n",
      "\t343.5\t = Inference  throughput (rows/s | 64720 batch size)\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/ExtraTreesMSE_BAG_L2_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetFastAI_BAG_L2/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetFastAI_BAG_L2/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetFastAI_BAG_L2/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetFastAI_BAG_L2/utils/model_template.pkl\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/RandomForestMSE_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/ExtraTreesMSE_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L2_FULL ...\n",
      "\tFitting NeuralNetFastAI_BAG_L2_FULL with 'num_gpus': 1, 'num_cpus': 4\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetFastAI_BAG_L2_FULL/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetFastAI_BAG_L2_FULL/utils/model_template.pkl\n",
      "Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 'auto', 'lr': 0.01, 'epochs': 30, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0, 'best_epoch': 28}...\n",
      "Using 4/4 categorical features\n",
      "Using 17 cont features\n",
      "Automated batch size selection: 512\n",
      "TabularModel(\n",
      "  (embeds): ModuleList(\n",
      "    (0-3): 4 x Embedding(4, 3)\n",
      "  )\n",
      "  (emb_drop): Dropout(p=0.1, inplace=False)\n",
      "  (bn_cont): BatchNorm1d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layers): Sequential(\n",
      "    (0): LinBnDrop(\n",
      "      (0): Linear(in_features=29, out_features=200, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): LinBnDrop(\n",
      "      (0): Linear(in_features=200, out_features=100, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (2): LinBnDrop(\n",
      "      (0): Linear(in_features=100, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Better model found at epoch 0 with _rmse value: 0.11419539153575897.\n",
      "Better model found at epoch 5 with _rmse value: 0.11391081660985947.\n",
      "Better model found at epoch 10 with _rmse value: 0.06609611213207245.\n",
      "Saving model model at the best epoch learned earlier - 28.\n",
      "\tStopping at the best epoch learned earlier - 28.\n",
      "Model validation metrics: 0.10390391945838928\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetFastAI_BAG_L2_FULL/model.pkl\n",
      "\t253.36s\t = Training   runtime\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/trainer.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/XGBoost_BAG_L2/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/XGBoost_BAG_L2/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/XGBoost_BAG_L2/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/XGBoost_BAG_L2/utils/model_template.pkl\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/RandomForestMSE_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/ExtraTreesMSE_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Fitting model: XGBoost_BAG_L2_FULL ...\n",
      "\tFitting XGBoost_BAG_L2_FULL with 'num_gpus': 1, 'num_cpus': 4\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/XGBoost_BAG_L2_FULL/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/XGBoost_BAG_L2_FULL/utils/model_template.pkl\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/XGBoost_BAG_L2_FULL/model.pkl\n",
      "\t4.39s\t = Training   runtime\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/trainer.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetTorch_BAG_L2/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetTorch_BAG_L2/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetTorch_BAG_L2/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetTorch_BAG_L2/utils/model_template.pkl\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/RandomForestMSE_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/ExtraTreesMSE_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L2_FULL ...\n",
      "\tFitting NeuralNetTorch_BAG_L2_FULL with 'num_gpus': 1, 'num_cpus': 4\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetTorch_BAG_L2_FULL/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetTorch_BAG_L2_FULL/utils/model_template.pkl\n",
      "Tabular Neural Network treats features as the following types:\n",
      "{\n",
      "    \"continuous\": [\n",
      "        \"LightGBMXT_BAG_L1\",\n",
      "        \"LightGBM_BAG_L1\",\n",
      "        \"RandomForestMSE_BAG_L1\",\n",
      "        \"CatBoost_BAG_L1\",\n",
      "        \"ExtraTreesMSE_BAG_L1\",\n",
      "        \"NeuralNetFastAI_BAG_L1\",\n",
      "        \"XGBoost_BAG_L1\",\n",
      "        \"NeuralNetTorch_BAG_L1\",\n",
      "        \"LightGBMLarge_BAG_L1\",\n",
      "        \"num_lanes\",\n",
      "        \"curvature\",\n",
      "        \"speed_limit\",\n",
      "        \"num_reported_accidents\"\n",
      "    ],\n",
      "    \"skewed\": [],\n",
      "    \"onehot\": [\n",
      "        \"road_type\",\n",
      "        \"lighting\",\n",
      "        \"weather\",\n",
      "        \"time_of_day\"\n",
      "    ],\n",
      "    \"embed\": [],\n",
      "    \"language\": [],\n",
      "    \"bool\": [\n",
      "        \"road_signs_present\",\n",
      "        \"public_road\",\n",
      "        \"holiday\",\n",
      "        \"school_season\"\n",
      "    ]\n",
      "}\n",
      "\n",
      "\n",
      "Training data for TabularNeuralNetTorchModel has: 517754 examples, 21 features (21 vector, 0 embedding)\n",
      "Training on GPU (CUDA)\n",
      "Neural network architecture:\n",
      "EmbedNet(\n",
      "  (main_block): Sequential(\n",
      "    (0): Linear(in_features=29, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (10): ReLU()\n",
      "    (11): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Training tabular neural network for up to 4 epochs...\n",
      "Best model found on Epoch 0 (Update 0).\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetTorch_BAG_L2_FULL/model.pkl\n",
      "\t25.09s\t = Training   runtime\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/trainer.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMLarge_BAG_L2/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMLarge_BAG_L2/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMLarge_BAG_L2/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMLarge_BAG_L2/utils/model_template.pkl\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/RandomForestMSE_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/ExtraTreesMSE_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L2_FULL ...\n",
      "\tFitting LightGBMLarge_BAG_L2_FULL with 'num_gpus': 1, 'num_cpus': 4\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMLarge_BAG_L2_FULL/utils/model_template.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMLarge_BAG_L2_FULL/utils/model_template.pkl\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tFitting 275 rounds... Hyperparameters: {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'device': 'gpu'}\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMLarge_BAG_L2_FULL/model.pkl\n",
      "\t8.23s\t = Training   runtime\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/trainer.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/WeightedEnsemble_L3/model.pkl\n",
      "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'ExtraTreesMSE_BAG_L2': 0.6, 'RandomForestMSE_BAG_L2': 0.2, 'NeuralNetFastAI_BAG_L2': 0.2}\n",
      "\t1.23s\t = Training   runtime\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/WeightedEnsemble_L3_FULL/model.pkl\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/trainer.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMXT_BAG_L1_FULL/model.pkl\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMXT_BAG_L1_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBM_BAG_L1_FULL/model.pkl\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBM_BAG_L1_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/RandomForestMSE_BAG_L1_FULL/model.pkl\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/RandomForestMSE_BAG_L1_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/CatBoost_BAG_L1_FULL/model.pkl\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/CatBoost_BAG_L1_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/ExtraTreesMSE_BAG_L1_FULL/model.pkl\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/ExtraTreesMSE_BAG_L1_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetFastAI_BAG_L1_FULL/model.pkl\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetFastAI_BAG_L1_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/XGBoost_BAG_L1_FULL/model.pkl\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/XGBoost_BAG_L1_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetTorch_BAG_L1_FULL/model.pkl\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetTorch_BAG_L1_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMLarge_BAG_L1_FULL/model.pkl\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMLarge_BAG_L1_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/WeightedEnsemble_L2_FULL/model.pkl\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/WeightedEnsemble_L2_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMXT_BAG_L2_FULL/model.pkl\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMXT_BAG_L2_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBM_BAG_L2_FULL/model.pkl\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBM_BAG_L2_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/RandomForestMSE_BAG_L2_FULL/model.pkl\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/RandomForestMSE_BAG_L2_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/CatBoost_BAG_L2_FULL/model.pkl\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/CatBoost_BAG_L2_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/ExtraTreesMSE_BAG_L2_FULL/model.pkl\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/ExtraTreesMSE_BAG_L2_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetFastAI_BAG_L2_FULL/model.pkl\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetFastAI_BAG_L2_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/XGBoost_BAG_L2_FULL/model.pkl\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/XGBoost_BAG_L2_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetTorch_BAG_L2_FULL/model.pkl\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetTorch_BAG_L2_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMLarge_BAG_L2_FULL/model.pkl\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMLarge_BAG_L2_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/WeightedEnsemble_L3_FULL/model.pkl\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/WeightedEnsemble_L3_FULL/model.pkl\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/trainer.pkl\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/trainer.pkl\n",
      "Updated best model to \"WeightedEnsemble_L3_FULL\" (Previously \"WeightedEnsemble_L3\"). AutoGluon will default to using \"WeightedEnsemble_L3_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 793.8s ... Best model: \"WeightedEnsemble_L3_FULL\"\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/models/trainer.pkl\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/learner.pkl\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/predictor.pkl\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/version.txt with contents \"1.4.0\"\n",
      "Saving /kaggle/working/AutogluonModels/ag-20251001_072554/metadata.json\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/kaggle/working/AutogluonModels/ag-20251001_072554\")\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBM_BAG_L1/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/RandomForestMSE_BAG_L1/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/CatBoost_BAG_L1/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/ExtraTreesMSE_BAG_L1/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/XGBoost_BAG_L1/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMXT_BAG_L2/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBM_BAG_L2/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/RandomForestMSE_BAG_L2/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/CatBoost_BAG_L2/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/ExtraTreesMSE_BAG_L2/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetFastAI_BAG_L2/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/XGBoost_BAG_L2/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetTorch_BAG_L2/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMLarge_BAG_L2/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/WeightedEnsemble_L3/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMXT_BAG_L1_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBM_BAG_L1_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/RandomForestMSE_BAG_L1_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/CatBoost_BAG_L1_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/ExtraTreesMSE_BAG_L1_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetFastAI_BAG_L1_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/XGBoost_BAG_L1_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetTorch_BAG_L1_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMLarge_BAG_L1_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/WeightedEnsemble_L2_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMXT_BAG_L2_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBM_BAG_L2_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/RandomForestMSE_BAG_L2_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/CatBoost_BAG_L2_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/ExtraTreesMSE_BAG_L2_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetFastAI_BAG_L2_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/XGBoost_BAG_L2_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetTorch_BAG_L2_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMLarge_BAG_L2_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/WeightedEnsemble_L3_FULL/model.pkl\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n",
      "  has_large_values = (abs_vals > 1e6).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                          model  score_val              eval_metric  pred_time_val     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0           WeightedEnsemble_L3  -0.055885  root_mean_squared_error     246.736080  5796.012762                0.008486           1.231911            3      False         20\n",
      "1          ExtraTreesMSE_BAG_L2  -0.055897  root_mean_squared_error     228.334733  3721.940812               15.484058         207.531907            2      False         15\n",
      "2               LightGBM_BAG_L2  -0.055962  root_mean_squared_error     219.006093  3561.782859                6.155418          47.373954            2      False         12\n",
      "3        NeuralNetFastAI_BAG_L2  -0.055963  root_mean_squared_error     216.769049  4670.736140                3.918374        1156.327235            2      False         16\n",
      "4           WeightedEnsemble_L2  -0.055978  root_mean_squared_error      80.480934   489.497161                0.011091           0.797705            2      False         10\n",
      "5          LightGBMLarge_BAG_L2  -0.055979  root_mean_squared_error     223.385217  3590.069137               10.534542          75.660232            2      False         19\n",
      "6                XGBoost_BAG_L2  -0.055985  root_mean_squared_error     214.087793  3540.509079                1.237118          26.100174            2      False         17\n",
      "7        RandomForestMSE_BAG_L2  -0.055986  root_mean_squared_error     227.325162  4430.921710               14.474487         916.512805            2      False         13\n",
      "8          LightGBMLarge_BAG_L1  -0.055997  root_mean_squared_error      14.535167    82.395726               14.535167          82.395726            1      False          9\n",
      "9               CatBoost_BAG_L2  -0.056001  root_mean_squared_error     213.442190  3621.279454                0.591515         106.870549            2      False         14\n",
      "10            LightGBMXT_BAG_L2  -0.056063  root_mean_squared_error     246.581984  3619.743406               33.731309         105.334501            2      False         11\n",
      "11               XGBoost_BAG_L1  -0.056077  root_mean_squared_error       0.848432    25.481696                0.848432          25.481696            1      False          7\n",
      "12              LightGBM_BAG_L1  -0.056085  root_mean_squared_error      34.918315    96.137546               34.918315          96.137546            1      False          2\n",
      "13              CatBoost_BAG_L1  -0.056122  root_mean_squared_error       1.278792   241.091818                1.278792         241.091818            1      False          4\n",
      "14         ExtraTreesMSE_BAG_L1  -0.056249  root_mean_squared_error      14.614923   126.067510               14.614923         126.067510            1       True          5\n",
      "15            LightGBMXT_BAG_L1  -0.056397  root_mean_squared_error     124.250128   280.665661              124.250128         280.665661            1      False          1\n",
      "16       NeuralNetFastAI_BAG_L1  -0.056535  root_mean_squared_error       3.873608  1150.258419                3.873608        1150.258419            1      False          6\n",
      "17       RandomForestMSE_BAG_L1  -0.056536  root_mean_squared_error      15.553005   158.616978               15.553005         158.616978            1       True          3\n",
      "18        NeuralNetTorch_BAG_L2  -0.056641  root_mean_squared_error     216.072028  4124.926446                3.221354         610.517541            2      False         18\n",
      "19        NeuralNetTorch_BAG_L1  -0.056804  root_mean_squared_error       2.978305  1353.693551                2.978305        1353.693551            1      False          8\n",
      "20    ExtraTreesMSE_BAG_L1_FULL        NaN  root_mean_squared_error      14.614923   126.067510               14.614923         126.067510            1       True         25\n",
      "21  RandomForestMSE_BAG_L1_FULL        NaN  root_mean_squared_error      15.553005   158.616978               15.553005         158.616978            1       True         23\n",
      "22          XGBoost_BAG_L2_FULL        NaN  root_mean_squared_error            NaN   754.150713                     NaN           4.391725            2       True         37\n",
      "23          XGBoost_BAG_L1_FULL        NaN  root_mean_squared_error            NaN     4.173601                     NaN           4.173601            1       True         27\n",
      "24     WeightedEnsemble_L3_FULL        NaN  root_mean_squared_error            NaN  2128.399413                     NaN           1.231911            3       True         40\n",
      "25     WeightedEnsemble_L2_FULL        NaN  root_mean_squared_error            NaN   308.185283                     NaN           0.797705            2       True         30\n",
      "26  RandomForestMSE_BAG_L2_FULL        NaN  root_mean_squared_error            NaN  1666.271793               14.474487         916.512805            2       True         33\n",
      "27   NeuralNetTorch_BAG_L2_FULL        NaN  root_mean_squared_error            NaN   774.852443                     NaN          25.093455            2       True         38\n",
      "28   NeuralNetTorch_BAG_L1_FULL        NaN  root_mean_squared_error            NaN   130.855880                     NaN         130.855880            1       True         28\n",
      "29  NeuralNetFastAI_BAG_L2_FULL        NaN  root_mean_squared_error            NaN  1003.122790                     NaN         253.363801            2       True         36\n",
      "30  NeuralNetFastAI_BAG_L1_FULL        NaN  root_mean_squared_error            NaN   240.673363                     NaN         240.673363            1       True         26\n",
      "31         LightGBM_BAG_L2_FULL        NaN  root_mean_squared_error            NaN   753.780255                     NaN           4.021267            2       True         32\n",
      "32         LightGBM_BAG_L1_FULL        NaN  root_mean_squared_error            NaN     9.453045                     NaN           9.453045            1       True         22\n",
      "33       LightGBMXT_BAG_L2_FULL        NaN  root_mean_squared_error            NaN   759.449591                     NaN           9.690603            2       True         31\n",
      "34       LightGBMXT_BAG_L1_FULL        NaN  root_mean_squared_error            NaN    26.559013                     NaN          26.559013            1       True         21\n",
      "35    LightGBMLarge_BAG_L2_FULL        NaN  root_mean_squared_error            NaN   757.984844                     NaN           8.225856            2       True         39\n",
      "36    LightGBMLarge_BAG_L1_FULL        NaN  root_mean_squared_error            NaN     9.076443                     NaN           9.076443            1       True         29\n",
      "37    ExtraTreesMSE_BAG_L2_FULL        NaN  root_mean_squared_error            NaN   957.290895               15.484058         207.531907            2       True         35\n",
      "38         CatBoost_BAG_L2_FULL        NaN  root_mean_squared_error            NaN   764.996662                     NaN          15.237674            2       True         34\n",
      "39         CatBoost_BAG_L1_FULL        NaN  root_mean_squared_error            NaN    44.283154                     NaN          44.283154            1       True         24\n",
      "Number of models trained: 40\n",
      "Types of models trained:\n",
      "{'StackerEnsembleModel_RF', 'StackerEnsembleModel_CatBoost', 'StackerEnsembleModel_TabularNeuralNetTorch', 'WeightedEnsembleModel', 'StackerEnsembleModel_XT', 'StackerEnsembleModel_LGB', 'StackerEnsembleModel_XGBoost', 'StackerEnsembleModel_NNFastAiTabular'}\n",
      "Bagging used: True  (with 8 folds)\n",
      "Multi-layer stack-ensembling used: True  (with 3 levels)\n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', [])  : 4 | ['road_type', 'lighting', 'weather', 'time_of_day']\n",
      "('float', [])     : 1 | ['curvature']\n",
      "('int', [])       : 3 | ['num_lanes', 'speed_limit', 'num_reported_accidents']\n",
      "('int', ['bool']) : 4 | ['road_signs_present', 'public_road', 'holiday', 'school_season']\n",
      "Plot summary of models saved to file: /kaggle/working/AutogluonModels/ag-20251001_072554/SummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label=label,eval_metric ='rmse',\n",
    "                            problem_type=\"regression\").fit(train,presets='good_quality',\n",
    "                                                                    time_limit=3600*9,verbosity=3,\n",
    "                                                       ag_args_fit={'num_gpus': 1}\n",
    "                                                      )\n",
    "results = predictor.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63a27252",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T11:13:34.123682Z",
     "iopub.status.busy": "2025-10-01T11:13:34.123133Z",
     "iopub.status.idle": "2025-10-01T11:13:34.147126Z",
     "shell.execute_reply": "2025-10-01T11:13:34.146318Z"
    },
    "papermill": {
     "duration": 0.136637,
     "end_time": "2025-10-01T11:13:34.148284",
     "exception": false,
     "start_time": "2025-10-01T11:13:34.011647",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n",
      "  has_large_values = (abs_vals > 1e6).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>-0.055885</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>246.736080</td>\n",
       "      <td>5796.012762</td>\n",
       "      <td>0.008486</td>\n",
       "      <td>1.231911</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExtraTreesMSE_BAG_L2</td>\n",
       "      <td>-0.055897</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>228.334733</td>\n",
       "      <td>3721.940812</td>\n",
       "      <td>15.484058</td>\n",
       "      <td>207.531907</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM_BAG_L2</td>\n",
       "      <td>-0.055962</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>219.006093</td>\n",
       "      <td>3561.782859</td>\n",
       "      <td>6.155418</td>\n",
       "      <td>47.373954</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NeuralNetFastAI_BAG_L2</td>\n",
       "      <td>-0.055963</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>216.769049</td>\n",
       "      <td>4670.736140</td>\n",
       "      <td>3.918374</td>\n",
       "      <td>1156.327235</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-0.055978</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>80.480934</td>\n",
       "      <td>489.497161</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.797705</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBMLarge_BAG_L2</td>\n",
       "      <td>-0.055979</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>223.385217</td>\n",
       "      <td>3590.069137</td>\n",
       "      <td>10.534542</td>\n",
       "      <td>75.660232</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost_BAG_L2</td>\n",
       "      <td>-0.055985</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>214.087793</td>\n",
       "      <td>3540.509079</td>\n",
       "      <td>1.237118</td>\n",
       "      <td>26.100174</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForestMSE_BAG_L2</td>\n",
       "      <td>-0.055986</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>227.325162</td>\n",
       "      <td>4430.921710</td>\n",
       "      <td>14.474487</td>\n",
       "      <td>916.512805</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LightGBMLarge_BAG_L1</td>\n",
       "      <td>-0.055997</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>14.535167</td>\n",
       "      <td>82.395726</td>\n",
       "      <td>14.535167</td>\n",
       "      <td>82.395726</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CatBoost_BAG_L2</td>\n",
       "      <td>-0.056001</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>213.442190</td>\n",
       "      <td>3621.279454</td>\n",
       "      <td>0.591515</td>\n",
       "      <td>106.870549</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LightGBMXT_BAG_L2</td>\n",
       "      <td>-0.056063</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>246.581984</td>\n",
       "      <td>3619.743406</td>\n",
       "      <td>33.731309</td>\n",
       "      <td>105.334501</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XGBoost_BAG_L1</td>\n",
       "      <td>-0.056077</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.848432</td>\n",
       "      <td>25.481696</td>\n",
       "      <td>0.848432</td>\n",
       "      <td>25.481696</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>-0.056085</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>34.918315</td>\n",
       "      <td>96.137546</td>\n",
       "      <td>34.918315</td>\n",
       "      <td>96.137546</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CatBoost_BAG_L1</td>\n",
       "      <td>-0.056122</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1.278792</td>\n",
       "      <td>241.091818</td>\n",
       "      <td>1.278792</td>\n",
       "      <td>241.091818</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ExtraTreesMSE_BAG_L1</td>\n",
       "      <td>-0.056249</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>14.614923</td>\n",
       "      <td>126.067510</td>\n",
       "      <td>14.614923</td>\n",
       "      <td>126.067510</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LightGBMXT_BAG_L1</td>\n",
       "      <td>-0.056397</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>124.250128</td>\n",
       "      <td>280.665661</td>\n",
       "      <td>124.250128</td>\n",
       "      <td>280.665661</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NeuralNetFastAI_BAG_L1</td>\n",
       "      <td>-0.056535</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>3.873608</td>\n",
       "      <td>1150.258419</td>\n",
       "      <td>3.873608</td>\n",
       "      <td>1150.258419</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RandomForestMSE_BAG_L1</td>\n",
       "      <td>-0.056536</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>15.553005</td>\n",
       "      <td>158.616978</td>\n",
       "      <td>15.553005</td>\n",
       "      <td>158.616978</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NeuralNetTorch_BAG_L2</td>\n",
       "      <td>-0.056641</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>216.072028</td>\n",
       "      <td>4124.926446</td>\n",
       "      <td>3.221354</td>\n",
       "      <td>610.517541</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NeuralNetTorch_BAG_L1</td>\n",
       "      <td>-0.056804</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>2.978305</td>\n",
       "      <td>1353.693551</td>\n",
       "      <td>2.978305</td>\n",
       "      <td>1353.693551</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ExtraTreesMSE_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>14.614923</td>\n",
       "      <td>126.067510</td>\n",
       "      <td>14.614923</td>\n",
       "      <td>126.067510</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RandomForestMSE_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>15.553005</td>\n",
       "      <td>158.616978</td>\n",
       "      <td>15.553005</td>\n",
       "      <td>158.616978</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>XGBoost_BAG_L2_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>754.150713</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.391725</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>XGBoost_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.173601</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.173601</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>WeightedEnsemble_L3_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2128.399413</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.231911</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>WeightedEnsemble_L2_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>308.185283</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.797705</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RandomForestMSE_BAG_L2_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1666.271793</td>\n",
       "      <td>14.474487</td>\n",
       "      <td>916.512805</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NeuralNetTorch_BAG_L2_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>774.852443</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.093455</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NeuralNetTorch_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130.855880</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130.855880</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NeuralNetFastAI_BAG_L2_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1003.122790</td>\n",
       "      <td>NaN</td>\n",
       "      <td>253.363801</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NeuralNetFastAI_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>240.673363</td>\n",
       "      <td>NaN</td>\n",
       "      <td>240.673363</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>LightGBM_BAG_L2_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>753.780255</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.021267</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>LightGBM_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.453045</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.453045</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>LightGBMXT_BAG_L2_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>759.449591</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.690603</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>LightGBMXT_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.559013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.559013</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>LightGBMLarge_BAG_L2_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>757.984844</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.225856</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>LightGBMLarge_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.076443</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.076443</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ExtraTreesMSE_BAG_L2_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>957.290895</td>\n",
       "      <td>15.484058</td>\n",
       "      <td>207.531907</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>CatBoost_BAG_L2_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>764.996662</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.237674</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>CatBoost_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.283154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.283154</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          model  score_val              eval_metric  \\\n",
       "0           WeightedEnsemble_L3  -0.055885  root_mean_squared_error   \n",
       "1          ExtraTreesMSE_BAG_L2  -0.055897  root_mean_squared_error   \n",
       "2               LightGBM_BAG_L2  -0.055962  root_mean_squared_error   \n",
       "3        NeuralNetFastAI_BAG_L2  -0.055963  root_mean_squared_error   \n",
       "4           WeightedEnsemble_L2  -0.055978  root_mean_squared_error   \n",
       "5          LightGBMLarge_BAG_L2  -0.055979  root_mean_squared_error   \n",
       "6                XGBoost_BAG_L2  -0.055985  root_mean_squared_error   \n",
       "7        RandomForestMSE_BAG_L2  -0.055986  root_mean_squared_error   \n",
       "8          LightGBMLarge_BAG_L1  -0.055997  root_mean_squared_error   \n",
       "9               CatBoost_BAG_L2  -0.056001  root_mean_squared_error   \n",
       "10            LightGBMXT_BAG_L2  -0.056063  root_mean_squared_error   \n",
       "11               XGBoost_BAG_L1  -0.056077  root_mean_squared_error   \n",
       "12              LightGBM_BAG_L1  -0.056085  root_mean_squared_error   \n",
       "13              CatBoost_BAG_L1  -0.056122  root_mean_squared_error   \n",
       "14         ExtraTreesMSE_BAG_L1  -0.056249  root_mean_squared_error   \n",
       "15            LightGBMXT_BAG_L1  -0.056397  root_mean_squared_error   \n",
       "16       NeuralNetFastAI_BAG_L1  -0.056535  root_mean_squared_error   \n",
       "17       RandomForestMSE_BAG_L1  -0.056536  root_mean_squared_error   \n",
       "18        NeuralNetTorch_BAG_L2  -0.056641  root_mean_squared_error   \n",
       "19        NeuralNetTorch_BAG_L1  -0.056804  root_mean_squared_error   \n",
       "20    ExtraTreesMSE_BAG_L1_FULL        NaN  root_mean_squared_error   \n",
       "21  RandomForestMSE_BAG_L1_FULL        NaN  root_mean_squared_error   \n",
       "22          XGBoost_BAG_L2_FULL        NaN  root_mean_squared_error   \n",
       "23          XGBoost_BAG_L1_FULL        NaN  root_mean_squared_error   \n",
       "24     WeightedEnsemble_L3_FULL        NaN  root_mean_squared_error   \n",
       "25     WeightedEnsemble_L2_FULL        NaN  root_mean_squared_error   \n",
       "26  RandomForestMSE_BAG_L2_FULL        NaN  root_mean_squared_error   \n",
       "27   NeuralNetTorch_BAG_L2_FULL        NaN  root_mean_squared_error   \n",
       "28   NeuralNetTorch_BAG_L1_FULL        NaN  root_mean_squared_error   \n",
       "29  NeuralNetFastAI_BAG_L2_FULL        NaN  root_mean_squared_error   \n",
       "30  NeuralNetFastAI_BAG_L1_FULL        NaN  root_mean_squared_error   \n",
       "31         LightGBM_BAG_L2_FULL        NaN  root_mean_squared_error   \n",
       "32         LightGBM_BAG_L1_FULL        NaN  root_mean_squared_error   \n",
       "33       LightGBMXT_BAG_L2_FULL        NaN  root_mean_squared_error   \n",
       "34       LightGBMXT_BAG_L1_FULL        NaN  root_mean_squared_error   \n",
       "35    LightGBMLarge_BAG_L2_FULL        NaN  root_mean_squared_error   \n",
       "36    LightGBMLarge_BAG_L1_FULL        NaN  root_mean_squared_error   \n",
       "37    ExtraTreesMSE_BAG_L2_FULL        NaN  root_mean_squared_error   \n",
       "38         CatBoost_BAG_L2_FULL        NaN  root_mean_squared_error   \n",
       "39         CatBoost_BAG_L1_FULL        NaN  root_mean_squared_error   \n",
       "\n",
       "    pred_time_val     fit_time  pred_time_val_marginal  fit_time_marginal  \\\n",
       "0      246.736080  5796.012762                0.008486           1.231911   \n",
       "1      228.334733  3721.940812               15.484058         207.531907   \n",
       "2      219.006093  3561.782859                6.155418          47.373954   \n",
       "3      216.769049  4670.736140                3.918374        1156.327235   \n",
       "4       80.480934   489.497161                0.011091           0.797705   \n",
       "5      223.385217  3590.069137               10.534542          75.660232   \n",
       "6      214.087793  3540.509079                1.237118          26.100174   \n",
       "7      227.325162  4430.921710               14.474487         916.512805   \n",
       "8       14.535167    82.395726               14.535167          82.395726   \n",
       "9      213.442190  3621.279454                0.591515         106.870549   \n",
       "10     246.581984  3619.743406               33.731309         105.334501   \n",
       "11       0.848432    25.481696                0.848432          25.481696   \n",
       "12      34.918315    96.137546               34.918315          96.137546   \n",
       "13       1.278792   241.091818                1.278792         241.091818   \n",
       "14      14.614923   126.067510               14.614923         126.067510   \n",
       "15     124.250128   280.665661              124.250128         280.665661   \n",
       "16       3.873608  1150.258419                3.873608        1150.258419   \n",
       "17      15.553005   158.616978               15.553005         158.616978   \n",
       "18     216.072028  4124.926446                3.221354         610.517541   \n",
       "19       2.978305  1353.693551                2.978305        1353.693551   \n",
       "20      14.614923   126.067510               14.614923         126.067510   \n",
       "21      15.553005   158.616978               15.553005         158.616978   \n",
       "22            NaN   754.150713                     NaN           4.391725   \n",
       "23            NaN     4.173601                     NaN           4.173601   \n",
       "24            NaN  2128.399413                     NaN           1.231911   \n",
       "25            NaN   308.185283                     NaN           0.797705   \n",
       "26            NaN  1666.271793               14.474487         916.512805   \n",
       "27            NaN   774.852443                     NaN          25.093455   \n",
       "28            NaN   130.855880                     NaN         130.855880   \n",
       "29            NaN  1003.122790                     NaN         253.363801   \n",
       "30            NaN   240.673363                     NaN         240.673363   \n",
       "31            NaN   753.780255                     NaN           4.021267   \n",
       "32            NaN     9.453045                     NaN           9.453045   \n",
       "33            NaN   759.449591                     NaN           9.690603   \n",
       "34            NaN    26.559013                     NaN          26.559013   \n",
       "35            NaN   757.984844                     NaN           8.225856   \n",
       "36            NaN     9.076443                     NaN           9.076443   \n",
       "37            NaN   957.290895               15.484058         207.531907   \n",
       "38            NaN   764.996662                     NaN          15.237674   \n",
       "39            NaN    44.283154                     NaN          44.283154   \n",
       "\n",
       "    stack_level  can_infer  fit_order  \n",
       "0             3      False         20  \n",
       "1             2      False         15  \n",
       "2             2      False         12  \n",
       "3             2      False         16  \n",
       "4             2      False         10  \n",
       "5             2      False         19  \n",
       "6             2      False         17  \n",
       "7             2      False         13  \n",
       "8             1      False          9  \n",
       "9             2      False         14  \n",
       "10            2      False         11  \n",
       "11            1      False          7  \n",
       "12            1      False          2  \n",
       "13            1      False          4  \n",
       "14            1       True          5  \n",
       "15            1      False          1  \n",
       "16            1      False          6  \n",
       "17            1       True          3  \n",
       "18            2      False         18  \n",
       "19            1      False          8  \n",
       "20            1       True         25  \n",
       "21            1       True         23  \n",
       "22            2       True         37  \n",
       "23            1       True         27  \n",
       "24            3       True         40  \n",
       "25            2       True         30  \n",
       "26            2       True         33  \n",
       "27            2       True         38  \n",
       "28            1       True         28  \n",
       "29            2       True         36  \n",
       "30            1       True         26  \n",
       "31            2       True         32  \n",
       "32            1       True         22  \n",
       "33            2       True         31  \n",
       "34            1       True         21  \n",
       "35            2       True         39  \n",
       "36            1       True         29  \n",
       "37            2       True         35  \n",
       "38            2       True         34  \n",
       "39            1       True         24  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "deb3a44f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T11:13:34.384649Z",
     "iopub.status.busy": "2025-10-01T11:13:34.383788Z",
     "iopub.status.idle": "2025-10-01T11:14:22.791256Z",
     "shell.execute_reply": "2025-10-01T11:14:22.790446Z"
    },
    "papermill": {
     "duration": 48.523475,
     "end_time": "2025-10-01T11:14:22.792444",
     "exception": false,
     "start_time": "2025-10-01T11:13:34.268969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/CatBoost_BAG_L1_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/ExtraTreesMSE_BAG_L1_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMLarge_BAG_L1_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBMXT_BAG_L1_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/LightGBM_BAG_L1_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetFastAI_BAG_L1_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetTorch_BAG_L1_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/RandomForestMSE_BAG_L1_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/XGBoost_BAG_L1_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/ExtraTreesMSE_BAG_L2_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/NeuralNetFastAI_BAG_L2_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/RandomForestMSE_BAG_L2_FULL/model.pkl\n",
      "Loading: /kaggle/working/AutogluonModels/ag-20251001_072554/models/WeightedEnsemble_L3_FULL/model.pkl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accident_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.299924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.122715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.184413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.317481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.404515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accident_risk\n",
       "0       0.299924\n",
       "1       0.122715\n",
       "2       0.184413\n",
       "3       0.317481\n",
       "4       0.404515"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = predictor.predict(test).to_frame(name=label)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bfa75faf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T11:14:23.028801Z",
     "iopub.status.busy": "2025-10-01T11:14:23.028489Z",
     "iopub.status.idle": "2025-10-01T11:14:23.110599Z",
     "shell.execute_reply": "2025-10-01T11:14:23.109734Z"
    },
    "papermill": {
     "duration": 0.202382,
     "end_time": "2025-10-01T11:14:23.112414",
     "exception": false,
     "start_time": "2025-10-01T11:14:22.910032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>accident_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>517754</td>\n",
       "      <td>0.352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>517755</td>\n",
       "      <td>0.352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>517756</td>\n",
       "      <td>0.352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>517757</td>\n",
       "      <td>0.352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>517758</td>\n",
       "      <td>0.352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  accident_risk\n",
       "0  517754          0.352\n",
       "1  517755          0.352\n",
       "2  517756          0.352\n",
       "3  517757          0.352\n",
       "4  517758          0.352"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol=pd.read_csv('/kaggle/input/playground-series-s5e10/sample_submission.csv')\n",
    "sol.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "956eee98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T11:14:23.369263Z",
     "iopub.status.busy": "2025-10-01T11:14:23.368681Z",
     "iopub.status.idle": "2025-10-01T11:14:23.376336Z",
     "shell.execute_reply": "2025-10-01T11:14:23.375666Z"
    },
    "papermill": {
     "duration": 0.13126,
     "end_time": "2025-10-01T11:14:23.377421",
     "exception": false,
     "start_time": "2025-10-01T11:14:23.246161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>accident_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>517754</td>\n",
       "      <td>0.299924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>517755</td>\n",
       "      <td>0.122715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>517756</td>\n",
       "      <td>0.184413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>517757</td>\n",
       "      <td>0.317481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>517758</td>\n",
       "      <td>0.404515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  accident_risk\n",
       "0  517754       0.299924\n",
       "1  517755       0.122715\n",
       "2  517756       0.184413\n",
       "3  517757       0.317481\n",
       "4  517758       0.404515"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol[label]=df[label]\n",
    "sol.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8ef02748",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T11:14:23.606271Z",
     "iopub.status.busy": "2025-10-01T11:14:23.605687Z",
     "iopub.status.idle": "2025-10-01T11:14:23.852667Z",
     "shell.execute_reply": "2025-10-01T11:14:23.851843Z"
    },
    "papermill": {
     "duration": 0.363032,
     "end_time": "2025-10-01T11:14:23.854332",
     "exception": false,
     "start_time": "2025-10-01T11:14:23.491300",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sol.to_csv('./Autogluon_good_quality_gpu.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 13760552,
     "sourceId": 91721,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 13850.239003,
   "end_time": "2025-10-01T11:14:29.296462",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-01T07:23:39.057459",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
