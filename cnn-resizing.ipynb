{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baf1294e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-08T09:40:07.222581Z",
     "iopub.status.busy": "2025-04-08T09:40:07.222275Z",
     "iopub.status.idle": "2025-04-08T09:40:21.323344Z",
     "shell.execute_reply": "2025-04-08T09:40:21.322120Z"
    },
    "papermill": {
     "duration": 14.106298,
     "end_time": "2025-04-08T09:40:21.324994",
     "exception": false,
     "start_time": "2025-04-08T09:40:07.218696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n",
      "100%|██████████| 83.3M/83.3M [00:00<00:00, 175MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet34 feature extractor initialized on device: cuda\n",
      "Training spot data loaded successfully.\n",
      "Training images loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "from skimage.registration import phase_cross_correlation\n",
    "\n",
    "def augment_patch(patch):\n",
    "    \"\"\"\n",
    "    Apply simple data augmentation to an image patch:\n",
    "    random horizontal flip, vertical flip, and random rotation.\n",
    "    Converts the patch to uint8 if needed.\n",
    "    \"\"\"\n",
    "    # If patch is not of type uint8, convert it.\n",
    "    if patch.dtype != np.uint8:\n",
    "        # If values are in [0, 1], scale them to [0, 255]\n",
    "        if patch.max() <= 1.0:\n",
    "            patch = (patch * 255).astype(np.uint8)\n",
    "        else:\n",
    "            patch = patch.astype(np.uint8)\n",
    "            \n",
    "    # Convert to PIL Image\n",
    "    pil_patch = Image.fromarray(patch)\n",
    "    \n",
    "    # Random horizontal flip\n",
    "    if np.random.rand() > 0.5:\n",
    "        pil_patch = pil_patch.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    # Random vertical flip\n",
    "    if np.random.rand() > 0.5:\n",
    "        pil_patch = pil_patch.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "    # Random rotation: choose 0, 90, 180, or 270 degrees\n",
    "    k = np.random.choice([0, 1, 2, 3])\n",
    "    if k:\n",
    "        pil_patch = pil_patch.rotate(90 * k)\n",
    "    \n",
    "    return np.array(pil_patch)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Function for Patch Extraction\n",
    "# -----------------------------\n",
    "def extract_patch(image, center, patch_size):\n",
    "    \"\"\"\n",
    "    Extract a square patch from the image centered at the given coordinate.\n",
    "    Assumes image shape is (height, width, channels) and center is (x, y).\n",
    "    \"\"\"\n",
    "    x, y = int(center[0]), int(center[1])\n",
    "    half_size = patch_size // 2\n",
    "    y_min = max(y - half_size, 0)\n",
    "    y_max = min(y + half_size, image.shape[0])\n",
    "    x_min = max(x - half_size, 0)\n",
    "    x_max = min(x + half_size, image.shape[1])\n",
    "    patch = image[y_min:y_max, x_min:x_max, :]\n",
    "    return patch\n",
    "\n",
    "class PatchFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, image, patch_size, cnn_model, augment=False, device='cpu'):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "          image (ndarray): The whole-slide HE image as a numpy array.\n",
    "          patch_size (int): Size (in pixels) of the square patch to extract.\n",
    "          cnn_model (nn.Module): Pre-trained PyTorch CNN model for feature extraction.\n",
    "          augment (bool): Whether to apply data augmentation on the patches.\n",
    "          device (str): Device to run the model ('cpu' or 'cuda').\n",
    "        \"\"\"\n",
    "        self.image = image\n",
    "        self.patch_size = patch_size\n",
    "        self.cnn_model = cnn_model\n",
    "        self.augment = augment\n",
    "        self.device = device\n",
    "\n",
    "        # Define the transformation pipeline.\n",
    "        # This converts the patch (numpy array) to a PIL image, resizes it to 128x128,\n",
    "        # then converts to tensor and normalizes with ImageNet means and stds.\n",
    "        self.transform_pipeline = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((128, 128)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        patches = []\n",
    "        for coord in X:\n",
    "            # Extract patch from the full image.\n",
    "            patch = extract_patch(self.image, coord, self.patch_size)\n",
    "            # Convert to RGB if patch is grayscale or has one channel.\n",
    "            if patch.ndim == 2 or (patch.ndim == 3 and patch.shape[2] != 3):\n",
    "                patch = cv2.cvtColor(patch, cv2.COLOR_GRAY2RGB)\n",
    "            # Optionally apply augmentation (only during training)\n",
    "            if self.augment:\n",
    "                patch = augment_patch(patch)\n",
    "            # Apply the transformation pipeline: PIL conversion, resize, tensor conversion, normalization.\n",
    "            patch_tensor = self.transform_pipeline(patch)\n",
    "            patches.append(patch_tensor)\n",
    "        # Stack patches to create a batch: shape (batch_size, C, H, W)\n",
    "        batch = torch.stack(patches).to(self.device)\n",
    "        self.cnn_model.eval()\n",
    "        with torch.no_grad():\n",
    "            features = self.cnn_model(batch)\n",
    "        # Convert features to numpy array\n",
    "        features_np = features.cpu().numpy()\n",
    "        return features_np\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Pipeline Class for the Elucidata Challenge with Caching and Visualization Options\n",
    "# -----------------------------\n",
    "class CellTypePipeline:\n",
    "    \"\"\"\n",
    "    Pipeline for loading data, extracting image patch features using a CNN,\n",
    "    training a multi-output regression model, and generating a submission file.\n",
    "    \n",
    "    Optionally, CNN features can be cached (saved/loaded) using pickle to speed up re-runs.\n",
    "    Additional visualization methods are provided to verify that the spot coordinates \n",
    "    and extracted patches align with the HE slide image.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, h5_file_path, patch_size=110, device='cpu'):\n",
    "        self.h5_file_path = h5_file_path\n",
    "        self.patch_size = patch_size\n",
    "        self.device = device\n",
    "        self.train_spot_tables = {}\n",
    "        self.train_images = {}\n",
    "        self.cell_type_columns = None\n",
    "        self.cnn_model = None  # To be initialized\n",
    "        self.feature_extractor_pipeline = None\n",
    "\n",
    "    def initialize_cnn_model(self):\n",
    "        \"\"\"\n",
    "        Initialize a pre-trained ResNet34 model for feature extraction using torchvision.\n",
    "        The final fully-connected layer is replaced with an identity mapping so that the model\n",
    "        outputs a feature vector.\n",
    "        \"\"\"\n",
    "        self.cnn_model = models.resnet34(pretrained=True)\n",
    "        # Replace the final fully-connected layer with identity\n",
    "        self.cnn_model.fc = nn.Identity()\n",
    "        self.cnn_model = self.cnn_model.to(self.device)\n",
    "        self.cnn_model.eval()\n",
    "        print(\"ResNet34 feature extractor initialized on device:\", self.device)\n",
    "\n",
    "    def load_train_data(self):\n",
    "        \"\"\"\n",
    "        Load training spot data from the H5 file and store each slide as a DataFrame.\n",
    "        \"\"\"\n",
    "        with h5py.File(self.h5_file_path, \"r\") as f:\n",
    "            train_spots = f[\"spots/Train\"]\n",
    "            for slide_name in train_spots.keys():\n",
    "                spot_array = np.array(train_spots[slide_name])\n",
    "                df = pd.DataFrame(spot_array, columns=[\"x\", \"y\"] + [f\"C{i}\" for i in range(1, 36)])\n",
    "                self.train_spot_tables[slide_name] = df\n",
    "        print(\"Training spot data loaded successfully.\")\n",
    "        \n",
    "    def load_train_images(self):\n",
    "        \"\"\"\n",
    "        Load training HE images from the H5 file.\n",
    "        \"\"\"\n",
    "        with h5py.File(self.h5_file_path, \"r\") as f:\n",
    "            train_imgs = f[\"images/Train\"]\n",
    "            for slide_name in train_imgs.keys():\n",
    "                image_array = np.array(train_imgs[slide_name])\n",
    "                self.train_images[slide_name] = image_array\n",
    "        print(\"Training images loaded successfully.\")\n",
    "\n",
    "    def load_test_data(self, slide_id):\n",
    "        \"\"\"\n",
    "        Load test spot data for a given slide.\n",
    "        \"\"\"\n",
    "        with h5py.File(self.h5_file_path, \"r\") as f:\n",
    "            test_spots = f[\"spots/Test\"]\n",
    "            if slide_id not in test_spots:\n",
    "                raise ValueError(f\"Slide {slide_id} not found in test spot data.\")\n",
    "            spot_array = np.array(test_spots[slide_id])\n",
    "            test_df = pd.DataFrame(spot_array, columns=[\"x\", \"y\"])\n",
    "        print(f\"Test spot data for slide {slide_id} loaded successfully.\")\n",
    "        return test_df\n",
    "\n",
    "    def load_test_image(self, slide_id):\n",
    "        \"\"\"\n",
    "        Load test HE image for a given slide.\n",
    "        \"\"\"\n",
    "        with h5py.File(self.h5_file_path, \"r\") as f:\n",
    "            test_imgs = f[\"images/Test\"]\n",
    "            if slide_id not in test_imgs:\n",
    "                raise ValueError(f\"Slide {slide_id} not found in test images.\")\n",
    "            image_array = np.array(test_imgs[slide_id])\n",
    "        print(f\"Test image for slide {slide_id} loaded successfully.\")\n",
    "        return image_array\n",
    "\n",
    "    def prepare_training_set(self, slide_id='S_1', cache_path=None):\n",
    "        \"\"\"\n",
    "        Prepare training features and targets for a given slide.\n",
    "        Uses the HE image to extract patches and then CNN features.\n",
    "        \"\"\"\n",
    "        if cache_path is not None and os.path.exists(cache_path):\n",
    "            print(f\"Loading cached training features from {cache_path} for slide {slide_id} ...\")\n",
    "            with open(cache_path, \"rb\") as f:\n",
    "                X_features, y = pickle.load(f)\n",
    "            return X_features, y\n",
    "        \n",
    "        if slide_id not in self.train_spot_tables:\n",
    "            raise ValueError(f\"Slide {slide_id} not found in training spot data.\")\n",
    "        if slide_id not in self.train_images:\n",
    "            raise ValueError(f\"Slide {slide_id} image not loaded.\")\n",
    "            \n",
    "        df = self.train_spot_tables[slide_id]\n",
    "        # First two columns: coordinates; remaining columns: cell type abundances.\n",
    "        feature_cols = ['x', 'y']\n",
    "        target_cols = [col for col in df.columns if col not in feature_cols]\n",
    "        self.cell_type_columns = target_cols\n",
    "        \n",
    "        X_coords = df[feature_cols].values.astype(float)\n",
    "        y = df[target_cols].values.astype(float)\n",
    "        \n",
    "        he_image = self.train_images[slide_id]\n",
    "        patch_extractor = PatchFeatureExtractor(he_image, self.patch_size, self.cnn_model,\n",
    "                                                 augment=True, device=self.device)\n",
    "        self.feature_extractor_pipeline = Pipeline([\n",
    "            ('patch_extractor', patch_extractor),\n",
    "            ('scaler', StandardScaler())\n",
    "        ])\n",
    "        print(f\"Extracting CNN features for slide {slide_id} ...\")\n",
    "        X_features = self.feature_extractor_pipeline.fit_transform(X_coords)\n",
    "        \n",
    "        if cache_path is not None:\n",
    "            print(f\"Saving training features for slide {slide_id} to {cache_path} ...\")\n",
    "            with open(cache_path, \"wb\") as f:\n",
    "                pickle.dump((X_features, y), f)\n",
    "                \n",
    "        print(f\"Extracted CNN features for slide {slide_id}.\")\n",
    "        return X_features, y\n",
    "\n",
    "    def prepare_all_training_set(self, cache_dir=None, align_spots=True):\n",
    "        \"\"\"\n",
    "        Prepare training features and targets for all slides in the training set.\n",
    "        \"\"\"\n",
    "        X_list = []\n",
    "        y_list = []\n",
    "        for slide_id in sorted(self.train_spot_tables.keys()):\n",
    "            if align_spots:\n",
    "                df = self.train_spot_tables[slide_id]\n",
    "                coords = df[['x', 'y']].values.astype(float)\n",
    "                self.train_spot_tables[slide_id] = df  # (Here you could adjust coordinates if needed)\n",
    "            slide_cache_path = os.path.join(cache_dir, f\"train_features_{slide_id}.pkl\") if cache_dir else None\n",
    "            X, y = self.prepare_training_set(slide_id=slide_id, cache_path=slide_cache_path)\n",
    "            X_list.append(X)\n",
    "            y_list.append(y)\n",
    "        X_all = np.concatenate(X_list, axis=0)\n",
    "        y_all = np.concatenate(y_list, axis=0)\n",
    "        print(\"All training features extracted and concatenated.\")\n",
    "        return X_all, y_all\n",
    "\n",
    "    def build_regression_pipeline(self):\n",
    "        \"\"\"\n",
    "        Build and return a regression pipeline that uses the pre-extracted CNN features.\n",
    "        \"\"\"\n",
    "        pipeline = Pipeline([\n",
    "            ('regressor', MultiOutputRegressor(RandomForestRegressor(n_estimators=100, random_state=42)))\n",
    "        ])\n",
    "        return pipeline\n",
    "\n",
    "    def train(self, X, y):\n",
    "        \"\"\"\n",
    "        Train the regression model on the provided features and targets.\n",
    "        \"\"\"\n",
    "        reg_pipeline = self.build_regression_pipeline()\n",
    "        reg_pipeline.fit(X, y)\n",
    "        print(\"Regression model training complete.\")\n",
    "        return reg_pipeline\n",
    "\n",
    "    def predict(self, reg_model, X_test):\n",
    "        \"\"\"\n",
    "        Predict cell type abundances on test features.\n",
    "        \"\"\"\n",
    "        predictions = reg_model.predict(X_test)\n",
    "        return predictions\n",
    "\n",
    "    def create_submission(self, test_df, predictions, submission_filename=\"submission.csv\"):\n",
    "        \"\"\"\n",
    "        Create a submission CSV file with predicted cell type abundances.\n",
    "        \"\"\"\n",
    "        pred_df = pd.DataFrame(predictions, columns=self.cell_type_columns, index=test_df.index)\n",
    "        pred_df.insert(0, 'ID', pred_df.index)\n",
    "        pred_df.to_csv(submission_filename, index=False)\n",
    "        print(f\"Submission file '{submission_filename}' created!\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Visualization Methods (unchanged)\n",
    "    # -----------------------------\n",
    "    def visualize_spot_overlay(self, slide_id, flip_y=False):\n",
    "        if slide_id not in self.train_images or slide_id not in self.train_spot_tables:\n",
    "            raise ValueError(f\"Slide {slide_id} data not found.\")\n",
    "        image = self.train_images[slide_id]\n",
    "        df = self.train_spot_tables[slide_id]\n",
    "        coords = df[['x', 'y']].values.astype(float)\n",
    "        if flip_y:\n",
    "            coords[:, 1] = image.shape[0] - coords[:, 1]\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(image)\n",
    "        plt.scatter(coords[:, 0], coords[:, 1], marker='o', color='red', s=25)\n",
    "        plt.title(f\"Overlay of Spot Coordinates for Slide {slide_id}\")\n",
    "        plt.show()\n",
    "\n",
    "    def visualize_extracted_patches(self, slide_id, num_patches=5, flip_y=False):\n",
    "        if slide_id not in self.train_images or slide_id not in self.train_spot_tables:\n",
    "            raise ValueError(f\"Slide {slide_id} data not found.\")\n",
    "        image = self.train_images[slide_id]\n",
    "        df = self.train_spot_tables[slide_id]\n",
    "        coords = df[['x', 'y']].values.astype(float)\n",
    "        if flip_y:\n",
    "            coords[:, 1] = image.shape[0] - coords[:, 1]\n",
    "        fig, axes = plt.subplots(1, num_patches, figsize=(num_patches * 3, 3))\n",
    "        for i in range(num_patches):\n",
    "            patch = extract_patch(image, coords[i], self.patch_size)\n",
    "            axes[i].imshow(patch)\n",
    "            axes[i].set_title(f\"Patch {i}\")\n",
    "            axes[i].axis(\"off\")\n",
    "        plt.suptitle(f\"Extracted Patches for Slide {slide_id}\")\n",
    "        plt.show()\n",
    "    \n",
    "    def visualize_cnn_input(self, slide_id, index=0, flip_y=False):\n",
    "        if slide_id not in self.train_images or slide_id not in self.train_spot_tables:\n",
    "            raise ValueError(f\"Slide {slide_id} data not found.\")\n",
    "            \n",
    "        image = self.train_images[slide_id]\n",
    "        df = self.train_spot_tables[slide_id]\n",
    "        coords = df[['x', 'y']].values.astype(float)\n",
    "        if flip_y:\n",
    "            coords[:, 1] = image.shape[0] - coords[:, 1]\n",
    "        coord = coords[index]\n",
    "        \n",
    "        half_size = self.patch_size // 2\n",
    "        x = int(coord[0])\n",
    "        y = int(coord[1])\n",
    "        x_min = max(x - half_size, 0)\n",
    "        y_min = max(y - half_size, 0)\n",
    "        patch = extract_patch(image, coord, self.patch_size)\n",
    "        \n",
    "        patch_resized = cv2.resize(patch, (128, 128))\n",
    "        rel_x = x - x_min\n",
    "        rel_y = y - y_min\n",
    "        scale_x = 128 / patch.shape[1]\n",
    "        scale_y = 128 / patch.shape[0]\n",
    "        spot_resized_x = rel_x * scale_x\n",
    "        spot_resized_y = rel_y * scale_y\n",
    "    \n",
    "        abundances = df.iloc[index][[col for col in df.columns if col not in ['x', 'y']]]\n",
    "        \n",
    "        print(f\"Patch top-left coordinates: (x_min: {x_min}, y_min: {y_min})\")\n",
    "        \n",
    "        fig, (ax_full, ax_img, ax_bar) = plt.subplots(1, 3, figsize=(18, 5))\n",
    "        ax_full.imshow(image)\n",
    "        rect = Rectangle((x_min, y_min), self.patch_size, self.patch_size, linewidth=2, edgecolor='red', facecolor='none')\n",
    "        ax_full.add_patch(rect)\n",
    "        ax_full.set_title(\"Full Slide with Patch Overlay\")\n",
    "        ax_full.axis(\"off\")\n",
    "        \n",
    "        ax_img.imshow(patch_resized)\n",
    "        ax_img.scatter([spot_resized_x], [spot_resized_y], marker='x', color='red', s=50)\n",
    "        ax_img.set_title(f\"Resized Patch (Index {index})\")\n",
    "        ax_img.text(5, 20, f\"({x_min}, {y_min})\", color='yellow', fontsize=12, \n",
    "                    bbox=dict(facecolor='black', alpha=0.5))\n",
    "        ax_img.axis(\"off\")\n",
    "        \n",
    "        cell_types = abundances.index.tolist()\n",
    "        ax_bar.bar(cell_types, abundances.values)\n",
    "        ax_bar.set_title(\"Cell Type Abundance Distribution\")\n",
    "        ax_bar.set_xticklabels(cell_types, rotation=90)\n",
    "        ax_bar.set_ylabel(\"Abundance\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "            \n",
    "    def compute_optimal_shift(self, slide_id, flip_y=False, upsample_factor=10, spot_radius=3, display=False):\n",
    "        if slide_id not in self.train_images or slide_id not in self.train_spot_tables:\n",
    "            raise ValueError(f\"Slide {slide_id} data not found.\")\n",
    "        \n",
    "        image = self.train_images[slide_id]\n",
    "        df = self.train_spot_tables[slide_id]\n",
    "        coords = df[['x', 'y']].values.astype(float)\n",
    "        if flip_y:\n",
    "            coords[:, 1] = image.shape[0] - coords[:, 1]\n",
    "        \n",
    "        if len(image.shape) == 3 and image.shape[2] == 3:\n",
    "            image_gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        else:\n",
    "            image_gray = image.copy()\n",
    "        \n",
    "        if image_gray.dtype != np.uint8:\n",
    "            image_gray = cv2.normalize(image_gray, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "                \n",
    "        _, tissue_mask = cv2.threshold(image_gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        spot_mask = np.zeros_like(tissue_mask, dtype=np.uint8)\n",
    "        for pt in coords:\n",
    "            x, y = int(round(pt[0])), int(round(pt[1]))\n",
    "            cv2.circle(spot_mask, (x, y), radius=spot_radius, color=255, thickness=-1)\n",
    "        \n",
    "        shift, error, diffphase = phase_cross_correlation(tissue_mask, spot_mask, upsample_factor=upsample_factor)\n",
    "        optimal_shift = np.array([shift[1], shift[0]])\n",
    "        print(\"Optimal shift (x, y):\", optimal_shift)\n",
    "        print(\"Registration error:\", error)\n",
    "        \n",
    "        if display:\n",
    "            plt.figure(figsize=(15, 5))\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.title(\"Tissue Mask\")\n",
    "            plt.imshow(tissue_mask, cmap='gray')\n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.title(\"Spot Mask\")\n",
    "            plt.imshow(spot_mask, cmap='gray')\n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.title(\"Overlay of Tissue and Spots\")\n",
    "            plt.imshow(tissue_mask, cmap='gray')\n",
    "            plt.imshow(spot_mask, cmap='jet', alpha=0.5)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            adjusted_coords = coords - optimal_shift\n",
    "            plt.figure(figsize=(10, 10))\n",
    "            plt.imshow(image)\n",
    "            plt.scatter(adjusted_coords[:, 0], adjusted_coords[:, 1], marker='o', color='lime', s=25)\n",
    "            plt.title(\"Corrected Spots Overlay on Tissue Image\")\n",
    "            plt.show()\n",
    "        \n",
    "        return optimal_shift, error, diffphase\n",
    "\n",
    "    def manual_shift_alignment(self, slide_id, x_shift, y_shift, flip_y=False, display=True):\n",
    "        if slide_id not in self.train_images or slide_id not in self.train_spot_tables:\n",
    "            raise ValueError(f\"Slide {slide_id} data not found.\")\n",
    "        \n",
    "        image = self.train_images[slide_id]\n",
    "        df = self.train_spot_tables[slide_id]\n",
    "        original_coords = df[['x', 'y']].values.astype(float)\n",
    "        if flip_y:\n",
    "            original_coords[:, 1] = image.shape[0] - original_coords[:, 1]\n",
    "        \n",
    "        shift_vector = np.array([x_shift, y_shift])\n",
    "        shifted_coords = original_coords + shift_vector\n",
    "        \n",
    "        if display:\n",
    "            plt.figure(figsize=(14, 7))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.imshow(image)\n",
    "            plt.scatter(original_coords[:, 0], original_coords[:, 1], \n",
    "                        marker='o', color='red', s=25, label='Original Spots')\n",
    "            plt.title(f\"Slide {slide_id} - Original Spots\")\n",
    "            plt.legend()\n",
    "            plt.axis(\"off\")\n",
    "            \n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.imshow(image)\n",
    "            plt.scatter(shifted_coords[:, 0], shifted_coords[:, 1], \n",
    "                        marker='o', color='lime', s=25, label='Shifted Spots')\n",
    "            plt.title(f\"Slide {slide_id} - Shifted Spots\\n(x_shift: {x_shift}, y_shift: {y_shift})\")\n",
    "            plt.legend()\n",
    "            plt.axis(\"off\")\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "        return original_coords, shifted_coords\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Example Usage with Caching and Visualization Options\n",
    "# -----------------------------\n",
    "\n",
    "# Path to the provided H5 data file\n",
    "h5_file_path = \"/kaggle/input/el-hackathon-2025/elucidata_ai_challenge_data.h5\"\n",
    "\n",
    "# Optionally specify a directory for caching training features (for slides S_1 to S_6)\n",
    "train_cache_dir = \"train_features_cache\"\n",
    "os.makedirs(train_cache_dir, exist_ok=True)\n",
    "test_cache_path = \"test_features_S_7.pkl\"  # For slide S_7 test features\n",
    "\n",
    "# Initialize the pipeline with desired patch size (110x110) and set the device (e.g., 'cuda' if available)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "pipeline_obj = CellTypePipeline(h5_file_path, patch_size=110, device=device)\n",
    "\n",
    "# Initialize the ResNet34 feature extractor\n",
    "pipeline_obj.initialize_cnn_model()\n",
    "\n",
    "# Load training spots and images\n",
    "pipeline_obj.load_train_data()\n",
    "pipeline_obj.load_train_images()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18e14638",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:40:21.331118Z",
     "iopub.status.busy": "2025-04-08T09:40:21.330708Z",
     "iopub.status.idle": "2025-04-08T18:04:24.771838Z",
     "shell.execute_reply": "2025-04-08T18:04:24.770777Z"
    },
    "papermill": {
     "duration": 30243.445552,
     "end_time": "2025-04-08T18:04:24.773390",
     "exception": false,
     "start_time": "2025-04-08T09:40:21.327838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting CNN features for slide S_1 ...\n",
      "Saving training features for slide S_1 to train_features_cache/train_features_S_1.pkl ...\n",
      "Extracted CNN features for slide S_1.\n",
      "Extracting CNN features for slide S_2 ...\n",
      "Saving training features for slide S_2 to train_features_cache/train_features_S_2.pkl ...\n",
      "Extracted CNN features for slide S_2.\n",
      "Extracting CNN features for slide S_3 ...\n",
      "Saving training features for slide S_3 to train_features_cache/train_features_S_3.pkl ...\n",
      "Extracted CNN features for slide S_3.\n",
      "Extracting CNN features for slide S_4 ...\n",
      "Saving training features for slide S_4 to train_features_cache/train_features_S_4.pkl ...\n",
      "Extracted CNN features for slide S_4.\n",
      "Extracting CNN features for slide S_5 ...\n",
      "Saving training features for slide S_5 to train_features_cache/train_features_S_5.pkl ...\n",
      "Extracted CNN features for slide S_5.\n",
      "Extracting CNN features for slide S_6 ...\n",
      "Saving training features for slide S_6 to train_features_cache/train_features_S_6.pkl ...\n",
      "Extracted CNN features for slide S_6.\n",
      "All training features extracted and concatenated.\n",
      "Regression model training complete.\n",
      "Test spot data for slide S_7 loaded successfully.\n",
      "Test image for slide S_7 loaded successfully.\n",
      "Extracting CNN features for test data ...\n",
      "Saving test features to test_features_S_7.pkl ...\n",
      "Submission file 'submission.csv' created!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "skip_training = False\n",
    "\n",
    "if not skip_training:\n",
    "    # Prepare training features and targets from all slides (e.g., S_1 to S_6)\n",
    "    X_train, y_train = pipeline_obj.prepare_all_training_set(cache_dir=train_cache_dir)\n",
    "\n",
    "if not skip_training:\n",
    "    # Train regression model on extracted CNN features\n",
    "    reg_model = pipeline_obj.train(X_train, y_train)\n",
    "    \n",
    "    # Load test data and image for slide S_7 (as per challenge description)\n",
    "    test_df = pipeline_obj.load_test_data(slide_id='S_7')\n",
    "    test_image = pipeline_obj.load_test_image(slide_id='S_7')\n",
    "    \n",
    "    # Build a feature extractor for test slide (disable augmentation during inference)\n",
    "    test_patch_extractor = PatchFeatureExtractor(test_image, pipeline_obj.patch_size,\n",
    "                                                  pipeline_obj.cnn_model, augment=False,\n",
    "                                                  device=pipeline_obj.device)\n",
    "    test_feature_pipeline = Pipeline([\n",
    "        ('patch_extractor', test_patch_extractor),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    X_test_coords = test_df[['x', 'y']].values.astype(float)\n",
    "    \n",
    "    # Check for cached test features\n",
    "    if os.path.exists(test_cache_path):\n",
    "        print(f\"Loading cached test features from {test_cache_path} ...\")\n",
    "        with open(test_cache_path, \"rb\") as f:\n",
    "            X_test_features = pickle.load(f)\n",
    "    else:\n",
    "        print(\"Extracting CNN features for test data ...\")\n",
    "        X_test_features = test_feature_pipeline.fit_transform(X_test_coords)\n",
    "        print(f\"Saving test features to {test_cache_path} ...\")\n",
    "        with open(test_cache_path, \"wb\") as f:\n",
    "            pickle.dump(X_test_features, f)\n",
    "\n",
    "if not skip_training:\n",
    "    # Predict cell type abundances for test data\n",
    "    predictions = pipeline_obj.predict(reg_model, X_test_features)\n",
    "    \n",
    "    # Create submission file\n",
    "    pipeline_obj.create_submission(test_df, predictions, submission_filename=\"submission.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11390004,
     "sourceId": 94147,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 30263.450618,
   "end_time": "2025-04-08T18:04:27.902604",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-08T09:40:04.451986",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
